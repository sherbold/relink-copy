7300	Justin Erenkrantz	1019716649000	For whatever it is worth, this appears to work fine on Unix platforms.  I also\nwould *not* expect readme.txt,readme.htm,readme.html variants to work.  But,\nthat is my personal interpretation of the docs and my preference as well.\n\nI'll leave this open in case it is determined that this is a Win32-specific thing.
7300	NickM	1019735268000	I know it works perfectly under UNIX, it IS a Win32 thing but surely that is \njust as relevant.  Either to the docs or to the programming.  Ive not tested \nthis under Apache2 yet, but Im guessing you have due to upgrading its status - \nif not I can if you wish?\n\nIMO on Win32 the case shouldnt matter and extensions should be none .txt \nand .html (not .htm).   --Nick
7300	Will Rowe	1021382313000	The bug you describe applies to Apache 1.3.  It does not apply to 2.0.\n\nHowever, if Multiviews is not on, automatic name 'prefixes' are no longer\nused on Apache 2.0.  With 2.0 you may need something as simple as\n\n<Files 'README.*'>\n    Options +Multiviews\n</Files>\n<Files 'HEADER.*'>\n    Options +Multiviews\n</Files>\n\nif you don't otherwise use Multiviews in the corresponding\ndirectory tree.
7300	Will Rowe	1040250787000	\n  The fix is committed and will be available with the release of 1.3.28.\n
7300	Ray Morris	1043837302000	It does NOT work with 1.3.27 under Linux or BSD.\nI have confirmed this bug or one weth very similar behavior \non multiple installations running on multiple operating\nsystems installed and tested by multiple people.\n
7300	Ray Morris	1043839630000	Please ignore my comments above.\nThe issue I saw on Linux and BSD was a seperate issue \nthat at first appeared to have similar symptoms.\n
7441	Joshua Slive	1017071625000	Confirmed.  And this is a regression from 1.3, which handles this correctly.\n\nHowever, I don't think it has anything to do with IPv6.  The same issue is\npresent with ordinary old IPv4 addresses.\n\nAlthough this should be fixed, I'm not sure why this is causing you a problem.\nAll the browsers that I've seen send the IP address in the Host: header when\nthey don't have a name, and this works fine.
7441	Justin Erenkrantz	1018839571000	This should be resolved in revision 1.73 of server/vhost.c.\n\nThis will be included in the next release of Apache httpd-2.0.\n\nThanks for using Apache!
7441	Justin Erenkrantz	1019582747000	*** Bug 8422 has been marked as a duplicate of this bug. ***
7441	Cliff Woolley	1020051815000	*** Bug 8604 has been marked as a duplicate of this bug. ***
7492	Joshua Slive	1017180847000	Could you please describe the exact problem you are experiencing?  Is it the \nfact that the key is not getting substituted properly in the RewriteMap?\n\nYou obviously have problems with the per-dir prefix getting added more than\nonce, but that is because you aren't using RewriteBase like you should be.\nOr alternatively, you should not place the RewriteRules inside a\n<Directory> section.
7492	Yuriy Ryabikov	1017215656000	Created an attachment (id=1431)\nhttpd.conf\n
7492	Yuriy Ryabikov	1017215693000	Created an attachment (id=1432)\nrewrite.log\n
7492	Yuriy Ryabikov	1017215735000	Created an attachment (id=1433)\nperl CGI\n
7492	Yuriy Ryabikov	1017217350000	Joshua,\n\nThank you for reply.\nPlease take a look at the line from rewrite log:\n  map lookup OK: map=AntiLeech key=$1 -> val=\n1. back-reference to pattern does is not resolved to URI as it should be,\nwhen used within rewrite-map reference\n  RewriteRule ^(.*)$ ${AntiLeech:$1|/leech2.html}\n2. rewrite map program does not receive any input, as it's evident from empty\nperl log, which I forgot to mention, and turned off buffering in attached perl\nscript.\n3. This bug is exposed only under Win32. Under UNIX RewriteMap works ok,\nall vars are subsituted, and per-dir prefix is added only once (latter may be\nbecause of slightly different directory layout, but that's another issue. BTW,\nRewriteBase does not help).\n\n
7492	Joshua Slive	1017241430000	OK.  I'm not sure if prg: rewritemaps have ever worked in win32.  I'm\nupdating the summary to better direct attention.
7492	Yuriy Ryabikov	1017241643000	May be will fixed in next version? ^)
7492	Will Rowe	1019242068000	This bug is difficult to address in Apache 1.3.x.  Not impossible, but\ndifficult.  As guessed, this has never worked in the 1.3 series.\n\nApache 2.0.x introduced new APIs for determining fully qualified path\nnames.  Mod_rewrite in Apache 2.0 was updated in v. 1.84 to accept \nany rooted path (based on the filesystem convention, e.g. c:/foo for \nwin32, or foo/bar:bleh for Netware.)\n\nhttp://cvs.apache.org/viewcvs/httpd-2.0/modules/mappers/mod_rewrite.c.diff?r1=1.83&r2=1.84&diff_format=h\n\nThere may also be thread saftey problems with the rewrite cache,\nintroduced in Apache 2.0's v. 1.83, that would need backporting.\n\nhttp://cvs.apache.org/viewcvs/httpd-2.0/modules/mappers/mod_rewrite.c.diff?r1=1.82&r2=1.83&diff_format=h\n\nFinally, it seems that ap_pstrcat is still being used to merge paths\nin 1.3 and 2.0.  This should be fixed in 2.0 to use apr_filepath_merge,\nand there was a similar API in 1.3.\n\nSo this can be fixed, but someone needs to take the time to write and\ntest the fixes.  I'd entertain applying a patch that was well thought out.\n\n
7492	Will Rowe	1019495480000	\n  Patch applied, this report will be resolved in 1.3.26.  Thread saftey of\n  the rewrite cache remains an issue, creating a new incident for tracking\n  thread saftey.
7492	Will Rowe	1019497315000	\n  Make that, fixed in the forthcoming 1.3.25.
7492	Jeff Trawick	1034248627000	*** Bug 8424 has been marked as a duplicate of this bug. ***
7492	Metin Savignano	1049034631000	I stepped into this bug, too. Then I found this bug report, downloaded Apache\n1.3.27, but I still have the same problem! \n\nMy .htaccess:\n\nRewriteEngine On\nRewriteRule ^vpserve.php - [L]\nRewriteRule ^(.*) vpserve.php \n\nThe resulting rewrite log:\n\n127.0.0.1 - - [30/Mar/2003:16:11:11 +0200]\n[vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir\nc:/themen/sss/htdocs/_tests/vistapoint/] add path-info postfix:\nc:/themen/sss/htdocs/_tests/vistapoint -> c:/themen/sss/htdocs/_tests/vistapoint/\n127.0.0.1 - - [30/Mar/2003:16:11:11 +0200]\n[vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir\nc:/themen/sss/htdocs/_tests/vistapoint/] strip per-dir prefix:\nc:/themen/sss/htdocs/_tests/vistapoint/ -> \n127.0.0.1 - - [30/Mar/2003:16:11:11 +0200]\n[vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir\nc:/themen/sss/htdocs/_tests/vistapoint/] applying pattern '^vpserve.php' to uri ''\n127.0.0.1 - - [30/Mar/2003:16:11:11 +0200]\n[vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir\nc:/themen/sss/htdocs/_tests/vistapoint/] add path-info postfix:\nc:/themen/sss/htdocs/_tests/vistapoint -> c:/themen/sss/htdocs/_tests/vistapoint/\n127.0.0.1 - - [30/Mar/2003:16:11:11 +0200]\n[vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir\nc:/themen/sss/htdocs/_tests/vistapoint/] strip per-dir prefix:\nc:/themen/sss/htdocs/_tests/vistapoint/ -> \n127.0.0.1 - - [30/Mar/2003:16:11:11 +0200]\n[vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir\nc:/themen/sss/htdocs/_tests/vistapoint/] applying pattern '^(.*)' to uri ''\n127.0.0.1 - - [30/Mar/2003:16:11:11 +0200]\n[vp.savignano.local/sid#5d82c8][rid#682450/initial] (2) [per-dir\nc:/themen/sss/htdocs/_tests/vistapoint/] rewrite  -> vpserve.php\n127.0.0.1 - - [30/Mar/2003:16:11:11 +0200]\n[vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir\nc:/themen/sss/htdocs/_tests/vistapoint/] add per-dir prefix: vpserve.php ->\nc:/themen/sss/htdocs/_tests/vistapoint/vpserve.php\n127.0.0.1 - - [30/Mar/2003:16:11:11 +0200]\n[vp.savignano.local/sid#5d82c8][rid#682450/initial] (3) [per-dir\nc:/themen/sss/htdocs/_tests/vistapoint/] add per-dir prefix:\nc:/themen/sss/htdocs/_tests/vistapoint/vpserve.php ->\nc:/themen/sss/htdocs/_tests/vistapoint/c:/themen/sss/htdocs/_tests/vistapoint/vpserve.php\n\nFor some reason, the directroy preix is still added twice.\n\nI re-opened the bug, but a work-around hint would be helpful as well.
7492	Metin Savignano	1049053041000	Sorry, I missed the fact that the modules were changed from .dll to .so in some\nversion, and did not update the httpd.conf accordingly.\n\nI discovered this a few minutes ago and corrected the mistake. Now it works\nflawlessly.\n\nMea culpa!
7572	Brian Bothwell	1017341056000	Here's the patch for 1.3.24:\n(just a change of line #'s since 1.3.9)\n---------------------------------------\n\n*** proxy_http.c        Thu Mar 28 13:42:32 2002\n--- proxy_http.c.patched        Thu Mar 28 13:42:17 2002\n***************\n*** 377,384 ****\n\n      /* send the request data, if any. */\n      if (ap_should_client_block(r)) {\n!         while ((i = ap_get_client_block(r, buffer, sizeof buffer)) > 0)\n!             ap_bwrite(f, buffer, i);\n      }\n      ap_bflush(f);\n      ap_kill_timeout(r);\n--- 377,386 ----\n\n      /* send the request data, if any. */\n      if (ap_should_client_block(r)) {\n!       while ((i = ap_get_client_block(r, buffer, sizeof buffer)) > 0) {\n!       ap_reset_timeout(r);\n!       ap_bwrite(f, buffer, i);\n!       }\n      }\n      ap_bflush(f);\n      ap_kill_timeout(r);\n
7572	Graham Leggett	1018206867000	Patch applied.\n
7628	Jim Jagielski	1033759707000	handled
7764	Joshua Slive	1018663135000	This is a bogus warning.  Apache uses tmpnam in a safe way.
7764	Joshua Slive	1018707851000	Comment from Cliff Woolley (glad we have peer review ;-):\n\nActually, depending on how htpasswd is used, it might be possible to\nconstruct some sort of a symlink attack to have arbitrary files corrupted.\nIt's not a bogus warning... it really should be fixed.  I've been meaning\nto do it for ages; htdigest was already fixed.  htpasswd is more difficult\nbecause the whole program needs to be APRized... there was a patch to do\nthis at one point written by Mladen Turk, but the patch was overkill IMO\n(and that of the other people that reviewed it as I recall), so it never\ngot committed.\n\nIf it were up to me, I'd leave this bug listed as open to remind us to get\nto this one day.\n
7764	Joshua Slive	1019052366000	*** Bug 8197 has been marked as a duplicate of this bug. ***
7764	Ryan Bloom	1024240522000	htpasswd has been re-written, and no longer uses tempnam.  Thank you for the\nbug report.\n
7791	Paul J. Reder	1022101492000	I have tester this on Redhat Linux 7.2 with cvs head of both apache-1.3 and\nhttpd-2.0. I get the same behavior from the identical cgi run on both versions\nof Apache. Parms $1, $2, and $3 all line up the same in my tests.\n\nCould you retry your tests with the latest versions of Apache 1.3 and 2.0?\nIf I don't hear from you to the contrary, I will close this in a couple of days\nsince it works for me.\n\nThank you.
7791	Colm	1022374563000	I'm seeing this bug aswell in 2.036 and CVS. suexec is getting passed args \nala:\n\n   /path/to/suexec (~)uid gid cmdname argv0 argv1 argv2 \n\nand so on. Previously in 1.3 it was : \n\n   /path/to/suexec (~)uid gid argv0 argv1 argv2 \n\nand argv0 was assumed to == cmdname. This patch reverts to the previous\nbehaviour.\n\nIndex: os/unix/unixd.c\n===================================================================\nRCS file: /home/cvspublic/httpd-2.0/os/unix/unixd.c,v\nretrieving revision 1.52\ndiff -u -u -r1.52 unixd.c\n--- os/unix/unixd.c     17 May 2002 11:33:10 -0000      1.52\n+++ os/unix/unixd.c     26 May 2002 00:47:29 -0000\n@@ -350,16 +350,16 @@\n            }\n     }\n     /* allocate space for 4 new args, the input args, and a null terminator */\n-    newargs = apr_palloc(p, sizeof(char *) * (i + 5));\n+    newargs = apr_palloc(p, sizeof(char *) * (i + 4));\n     newprogname = SUEXEC_BIN;\n     newargs[0] = SUEXEC_BIN;\n     newargs[1] = execuser;\n     newargs[2] = execgroup;\n     newargs[3] = apr_pstrdup(p, progname);\n\n-    i = 0;\n+    i = 1;\n     do {\n-        newargs[i + 4] = args[i];\n+        newargs[i + 3] = args[i];\n     } while (args[i++]);\n\n     return apr_proc_create(newproc, newprogname, newargs, env, attr, p);
7791	octave klaba	1022375604000	patch works for me (2.0.35)\n\nOctave
7791	Brian Pane	1022402209000	thanks, I've committed the patch
7795	Joshua Slive	1018119557000	*** Bug 7796 has been marked as a duplicate of this bug. ***
7795	Dave Hodder	1018712722000	Created an attachment (id=1542)\nTest XHTML file (index.xhtml)\n
7795	Joshua Slive	1018802718000	I've added the type to mime.types, but I'm not going to change the default\nDirectoryIndex.  I see no reason to do that unless we see this type becoming\nthe predominant default type.  For now, people can edit their own config\nfiles, just like they do for php, etc.\n\nThanks for using Apache!
7802	Doug MacEachern	1018234602000	this has been fixed in cvs.\nquick fix can be done by hand if you edit mod_ssl.h and change this line:\n#if SSL_LIBRARY_VERSION >= 0x00907000\nto\nif 0\n
7803	Andreas Hasenack	1018150196000	I have made a DESTDIR patch (I'm attaching it).
7803	Andreas Hasenack	1018150264000	Created an attachment (id=1495)\npatch to allow for 'make DESTDIR=%{buildroot} install' in packages\n
7803	Matthew Darwin	1018703610000	Thanks for the patch!  It works great!
7803	Juergen Strobel	1021574417000	Created an attachment (id=1880)\nThis is a hand-editied version of Andreas' patch so it applies against 2.0.36. 2 Minor changes.\n
7803	Ryan Bloom	1024099166000	*** Bug 9792 has been marked as a duplicate of this bug. ***
7803	Ryan Bloom	1024116150000	I have committed this patch, and it will either be in 2.0.38 or 2.0.39,\ndepending on if the RM wishes to include it in a tag that is likely to be made\nsometime tonight or tomorrow.\n
7810	Colm	1018872891000	Created an attachment (id=1580)\nPATCH os/unix/unixd.c for mpm=prefork\n
7810	Colm	1018872964000	The Patch I've attachted fixes the first case, with mpm=prefork.\n\nStill no fix for mpm=worker and likely other mpm's.
7810	Justin Erenkrantz	1019719205000	Thanks for your patch!  I have committed a variant of your patch to HEAD. \nPlease try out a CVS snapshot or wait for the forthcoming Apache 2.0.36.\n\nThanks for using Apache!
7810	Brian Pane	1022451708000	committed colm's patch that fixes suexec+userdir+cgid
7810	Dennis Kelly	1025027838000	I am experiencing this problem on Solaris 8 and the latest version httpd 2.0.39.\n  Skimming through the source it seems the patches included in the bug report\nwere applied before its release. It appears to be a problem with userdir,\nbecause apache will call suexec, but it does not recognize user directories\n(suexec is called with the target uid/gid of the httpd user/group and treats the\nCGI as if it were in the document root).  \n\nI have UserDir set to web in httpd.conf and am loading the following as DSOs:\n\naccess_module\nalias_module\nauth_module\nautoindex_module\ncgi_module\ndir_module\nenv_module\ninclude_module\nlog_config_module\nmime_magic_module\nmime_module\nnegotiation_module\nsetenvif_module\nsuexec_module\nunique_id_module\nuserdir_module\nvhost_alias_module\n\nand the following compiled in:\n\n# /usr/local/apache/bin/httpd -l\nCompiled in modules:\n  core.c\n  mod_ssl.c\n  prefork.c\n  http_core.c\n  mod_so.c\n\nHopefully I didn't miss something obvious!  Thanks in advance,\n\nDennis\n\n\n\n\n\n
7810	Colm	1025030108000	Do you have any SuexecUserGroup Directives in your config files ?\n\nTry removing them.
7810	Colm	1025045403000	Crossreference point: PR 9038 contains a discusion relevant to this issue.
7810	Dennis Kelly	1025103955000	Without the SuexecUserGroup directive set, suexec is never called... nothing\nlogged to cgi.log and CGIs (including ~user ones) are executed successfully as\nthe httpd user. With the directive set, suexec is at least called, but it does\nnot honor ~user... the target uid/gid are set to that of the httpd user and\nscript execution fails because it is not in the document root.\n\nI did check Bug 9038 before submitting, which states disabling cgid in the\nLoadModule should fix it.  I did this (noted in the modules I am loading)\nwithout success.  As I re-read 9038, Alex had success by disabling cgid at\ncompile time.  Is that the ultimate fix (vs. at LoadModule time) ?\n\nThanks,\nDennis\n
7810	Colm	1025104535000	mod_cgid + userdir + suexec has been functional as of 2.0.39, I'm\ncurrently using that combination on several platforms.\n\nTry reversing the order in which you load the userdir and suexec\nmodules. Also, did you specify --enable-suexec at configure time?\nIt's possible to have the suexec module built without that, so\nit may be an issue. 
7810	Dennis Kelly	1025108931000	I did include that config option... pullled from config.log (minus the\nformatting for readability):\n\n./configure --with-layout=Apache /\n--prefix=/usr/local/apache /\n--enable-mods-shared=access actions alias asis auth auth_anon auth_dbm autoindex\ncache cern_meta cgi cgid charset_lite dav deflate dir env example expires\next_filter file_cache headers imap include info isapi log_config mime mime_magic\nnegotiation proxy rewrite setenvif speling status suexec unique_id userdir\nusertrack vhost_alias /\n--enable-modules=ssl /\n--enable-so /\n--enable-ssl /\n--enable-suexec /\n--with-ssl=/opt /\n--enable-static-htpasswd /\n--disable-auth-digest /\n--with-suexec-caller=www /\n--with-suexec-docroot=/web /\n--with-suexec-userdir=web /\n--with-suexec-uidmin=10 /\n--with-suexec-gidmin=10 /\n--with-suexec-safepath=/usr/bin:/opt/bin\n\nAny other ideas?  Your continued to help is appreciated.\n\nDennis
7810	Dennis Kelly	1025286052000	Should have explicitly mentioned I did change the order in which suexec/userdir\nare loaded without success.
7810	Joshua Slive	1034788510000	It seems like this has been fixed at some point.  If not, please feel free\nto reopen the bug report.
7812	Jeff Trawick	1018209036000	Please verify that the User and Group directives are valid for your system.\nThese frequently have to be changed from the default (depending on the OS).\n\nI think the failure is that Apache is trying to use an invalid user or group\nid when setting accessibility to the SysV semaphore used for accept serialization.\n\nAlternatively, change from the default of using SysV semaphores to fcntl \nlocks by coding this in your config file:\n\nAcceptMutex fcntl\n
7812	Ralf Hildebrandt	1018209298000	Setting the User & Group to decent values (www:www) fixed it.The error message isn't really helpful, though.
7812	Jeff Trawick	1018285362000	The error message has been changed to point the admin\nto the User and Group directives.\n\nThanks for your report, and thanks for using Apache!\n
7818	Justin Erenkrantz	1018852440000	*** Bug 7970 has been marked as a duplicate of this bug. ***
7818	Matthew Boehm	1018857293000	I copied config.guess and config.sub from my /usr/libexec/ to the following \nlocations:\n  /root/httpd-2.0.35/\n  /root/httpd-2.0.35/srclib/apr-util\n  /root/httpd-2.0.35/srclib/apr-util/xml/expat\n\nRan main configure, got same error as Sander. Ran apr-util configure, \nsame error. Ran expat configure, same error.\n\nRan expat configure as so: ./configure --host=powerpc-apple-darwin5.3 \nand got following:\nloading cache ./config.cache\nchecking host system type... Invalid configuration "powerpc-apple-\ndarwin5.3': system "darwin5.3' not recognized\n\nchecking target system type... Invalid configuration "powerpc-apple-\ndarwin5.3': system "darwin5.3' not recognized\n\nchecking build system type... Invalid configuration "powerpc-apple-\ndarwin5.3': system "darwin5.3' not recognized\n\nchecking for ranlib... ranlib\nchecking for gcc... gcc\nchecking whether the C compiler (gcc  ) works... yes\nchecking whether the C compiler (gcc  ) is a cross-compiler... no\nchecking whether we are using GNU C... yes\nchecking whether gcc accepts -g... yes\nchecking for ld used by GCC... /usr/bin/ld\nchecking if the linker (/usr/bin/ld) is GNU ld... no\nchecking for BSD-compatible nm... /usr/bin/nm -p\nchecking whether ln -s works... yes\nupdating cache ./config.cache\nloading cache ./config.cache within ltconfig\nltconfig: you must specify a host type if you use "--no-verify'\nTry "ltconfig --help' for more information.\nconfigure: error: libtool configure failed\n\nRe-Ran with following: ./configure --host=powerpc-apple-bsd\nand everything configured fine.\n\nMatthew
7818	Justin Erenkrantz	1018947146000	I have merged in the latest config.guess/config.sub from GNU.\n\nI also explicitly added config.guess/config.sub for expat.  This should explain\nwhy our bundled expat is acting weird - it was using the config.guess from\nicarus rather than a recent one.\n\nFor more information, please see the commit log:\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/CHANGES?rev=1.709&content-type=text/vnd.viewcvs-markup\n\nPlease try a nightly build to see if your problem goes away.\n\nI will close this PR for now.  If the problem remains with the next release (or\na nightly), you may reopen it.\n\nThanks for using Apache!
7818	Justin Erenkrantz	1019582531000	*** Bug 8405 has been marked as a duplicate of this bug. ***
7818	Sander Temme	1021224947000	Verified with Apache 2.0.36 release. Closing... I assume as reporter it's \nmy prerogative/task to close.
7822	Andreas Hasenack	1018215372000	Created an attachment (id=1497)\nSmall pt_BR fixes\n
7822	Joshua Slive	1018804287000	I have a little problem which is, since I don't understand your language, I \nreally can't verify that this is an improvement.  If there is another person\nwho is fluent in this language who could append a comment to this bug report\nverifying this patch, then I can commit it.\n\nThanks.
7822	Andreas Hasenack	1018884653000	Well, I can assure you that calling 'documenta????o' (which is pt_BR for\ndocumentation, which wasn't even translated) with a big 'O' in front if it is\nlike referring to Sandra Bullock with a 'he' :)
7822	Ranier Vilela Fonseca	1019823978000	Created an attachment (id=1716)\nReally correct problems (small) in index.html.pr-br\n
7822	Ranier Vilela Fonseca	1019824961000	Really was minor problems in language in index.html.pt-br.\nThere is:\n1. The word 'temporaria' in line 'substituir esta p??gina temporaria', the\ncorrect is 'tempor??ria'\n2. The word 'apontar' in line 'ou apontar o servidor para o seu conte??do real',\nbetter 'ou configurar o servidor para o seu conte??do real', replace 'apontar'\nwith 'configurar'\n3. The prhase 'Esta p??gina est?? sendo carregada, pois o administrador...',\nbetter 'Esta p??gina foi carregada, pois provavelmente, o administrador...'\n4. The word 'contacte' in line 'Por favor, contacte...', correct is 'contate'\n5. The word 'a' in line 'e n??o poder?? ajudar a resolu????o...', better is 'na',\ncorrect is 'e n??o poder?? ajudar na resolu????o...'\n6. The line 'O Apache documentation foi inclu??do com esta distribui????o', correct\nis 'A documenta????o do Apache foi inclu??da com esta distribui????o'.\n\nThanks.\n\nP.S. My english is 'bad', but my portuguese is better ;)>
7822	Fabio Mengue	1022099349000	Hi, I'm a brazilian portuguese native speaker. Rainer's suggestions are OK.\n\nI have others, but since I'm translating all /htdocs and /htdocs/manual to\nportuguese, I think I'll commit them to CVS later (*when* I have commit access\nto CVS :)\n\nFabio.
7822	Fabio Mengue	1022099375000	Hi, I'm a brazilian portuguese native speaker. Rainer's suggestions are OK.\n\nI have others, but since I'm translating all /htdocs and /htdocs/manual to\nportuguese, I think I'll commit them to CVS later (*when* I have commit access\nto CVS :)\n\nFabio.
7822	Andr?? Malo	1045066969000	Finally fixed. Thank you guys.
7832	Sven Neuhaus	1018270694000	Created an attachment (id=1500)\ninserting the missing colon\n
7832	Sven Neuhaus	1018271090000	There are more missing colons and one line with the colon in the wrong spot.
7832	Sven Neuhaus	1018271123000	Created an attachment (id=1501)\nfix missing/wrong colons\n
7832	Joshua Slive	1018804156000	Thanks!  This will be fixed in the next release of the docs.
7840	Justin Erenkrantz	1018831647000	Fixed in revision 1.12 of support/apachectl.in.\n\nThis will be included in the next release of Apache httpd-2.0.\n\nThanks for using Apache!
7840	Justin Erenkrantz	1019582467000	*** Bug 8413 has been marked as a duplicate of this bug. ***
7841	Justin Erenkrantz	1018573812000	This has been committed to the Apache httpd-2.0 CVS repository and will\nbe included in the next release of Apache httpd-2.0.\n\ndocs/conf/httpd-std.conf.in revision 1.2 has this change.\n\nThanks for using Apache!
7841	Cliff Woolley	1019424491000	*** Bug 7798 has been marked as a duplicate of this bug. ***
7882	Joshua Slive	1034822127000	[This is a mass bug update.]\nThis bug reports a problem in an older version of Apache 2.\nCould you please update to the most recent version and see\nif you can reproduce this problem.  If the bug still exists,\nplease update the bug with the latest version number.  If \nthe bug no longer exists, please close the bug report.\n\nSorry for this impersonal response, but we get many more bug\nreports than our volunteers can keep up with.\nThanks for using Apache!
7882	Joshua Slive	1036268332000	[This is a mass bug update.] [Resolve-20021102]\nNo response from submitter; assuming issue is resolved.\nIf the problem still exists in the lastest version,\nplease reopen this report and update appropriately.
7882	Noah Arliss	1042213849000	This is still a bug in apache 2.0.43. I've tried the patch included here making \nthe changes by hand and they appear to solve the problem.
7882	Joe Orton	1078015011000	Fixed in HEAD; thanks for the report.\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/Makefile.in?r1=1.138&r2=1.139
7882	Kartik Subbarao	1093286375000	I see that the fix has been checked into HEAD. But when will this be rolled into\nan actual release? The buggy Makefile.in is still there as of 2.0.50.
7882	Joe Orton	1093291918000	This has now been proposed for backport to 2.0.
7930	Cliff Woolley	1018995243000	*** Bug 8147 has been marked as a duplicate of this bug. ***
7930	David Shane Holden	1019155593000	Created an attachment (id=1626)\nPatch.\n
7930	Will Rowe	1019244047000	\n  Patch applied, for the next release (.36).  Thanks David!\n\n
7930	Cliff Woolley	1020548019000	*** Bug 8809 has been marked as a duplicate of this bug. ***
7930	Joshua Slive	1020799218000	*** Bug 8888 has been marked as a duplicate of this bug. ***
7966	David Waring	1018543321000	I'm experiencing problems with proxies that is probably related to this bug. The\nproxy cache is cutting the reply short if / is requested, but I get the full\nreply if /index.shtml is used.
7966	Christian Lemke	1018571480000	The same bug is under Windows 2000.
7966	Justin Erenkrantz	1018576494000	This is seen on a bunch of different OSes, so change it to be All platforms and\nAll OSes.\n\nAn email has been sent to dev@httpd.apache.org asking for people to look at\nthis. There were lots of changes right before 2.0.35 regarding this code, so I\nthink something may have snuck in.\n\nIf the filters were ordered right, the C-L should be correct, so this isn't\nobvious as to where the problem is and I'll let the people who worked on it\npre-2.0.35 look at this since they were the last ones in the code.
7966	Bill Stoddard	1018986701000	I cannot recreate this problem on Windows (haven't tried elsewhere).  Can \nsomeone send me an httpd.conf (as simple as possible) that I can use to \nrecreate?
7966	Ian Holsman	1019014517000	 I can recreate this on 35/solaris 2.6 FWIW content-length and etags shouldn't be shown on a SSI page. mod_include ~line 3367    apr_table_unset(f->r->headers_out, 'Content-Length');      /* Always unset the ETag/Last-Modified fields - see RFC2616 - 13.3.4.      * We don't know if we are going to be including a file or executing      * a program which may change the Last-Modified header or make the      * content completely dynamic.  Therefore, we can't support these      * headers.      * Exception: XBitHack full means we *should* set the Last-Modified field.      */     apr_table_unset(f->r->headers_out, 'ETag');      /* Assure the platform supports Group protections */     if ((*conf->xbithack == xbithack_full)         && (r->finfo.valid & APR_FINFO_GPROT)         && (r->finfo.protection & APR_GEXECUTE)) {         ap_update_mtime(r, r->finfo.mtime);         ap_set_last_modified(r);     }     else {         apr_table_unset(f->r->headers_out, 'Last-Modified');     }  I'm thinking AutoIndex is the culprit 
7966	Ian Holsman	1019014858000	sorry about that Konqueror ate my line feeds.\nI just cut & pasted some some mod-include code from ~3767 showing it unsetting\nthe Etag & Content-length fields
7966	javier wilson	1019179708000	I have exactly the same problem. I am using linux redhat.\nWe use 'exec cgi' a lot and have this problem (incomplete \ncontent is returned as a result), right now we are trying \nto work-around it specifying 'index.html' at the end\nof our requests.
7966	Justin Erenkrantz	1019976451000	This problem has been resolved in modules/http/http_request.c revision 1.141.\n(Gnarly to reproduce!)\n\nThis should be included in the forthcoming 2.0.36 or you can try out the latest\nCVS snapshots.\n\nThanks for using Apache!
7966	Justin Erenkrantz	1020190880000	*** Bug 8141 has been marked as a duplicate of this bug. ***
7969	Joshua Slive	1018802780000	This type has now been added in 1.3 and 2.0.\n\nThanks for using Apache.
7990	Paul J Murphy	1018566668000	Created an attachment (id=1530)\n.htaccess from directory which exhibits this bug\n
7990	Paul J. Reder	1020280558000	This works for me on cvs-head (2.0.36-dev). Make sure that you have your\nAllowOverride config for the directory set to allow the .htaccess\n'IndexOptioons' and 'AddDescription' directives to work.
7990	Paul J Murphy	1020285634000	I'm still seeing the problem with 2.0.37-dev pulled from CVS yesterday (built \nat Apr 30 2002 08:53:58).\n\nSee http://www.murph.org:84/test/ for a better example of the behaviour under \n2.0.37-dev. Ports 81, 82, 83 have the same directory available under 1.3.22\n(patched), 2.0.35(patched), 2.0.35(unpatched) for easy comparison.\n\n'AllowOverride FileInfo AuthConfig Limit Indexes' is specified in httpd.conf \nfor the parent directory on all 4 servers.
7990	Paul J. Reder	1020287179000	I just tested it with 'AllowOverride FileInfo AuthConfig Limit Indexes' and it\nworks fine for me with 2.0.37-dev as of about noon today.\n\nWhat system are you running on? Can you post the full container config for the\ndirectory in question?\n\nThanks.
7990	Paul J Murphy	1020288649000	www.murph.org is running Solaris 8 4/01, patched with the Mar/28/2002\nrecommended patch cluster:\n\n\tSunOS salsa 5.8 Generic_108528-14 sun4m sparc SUNW,SPARCstation-5\n\nBuilt with gcc-2.95.2, as supplied on the Solaris 8 4/01 freeware companion CD.\n\nHere is the config for the parent directory (which is the DocumentRoot):\n\n<Directory '/usr/local/apache2/htdocs'>\n    Options Indexes IncludesNoExec FollowSymLinks MultiViews\n    AllowOverride FileInfo AuthConfig Limit Indexes\n    Order allow,deny\n    Allow from all\n</Directory>\n
7990	Paul J. Reder	1020289036000	Ah. Well I can confirm that it works on Linux. :)\n\nI will have to bow out at this point. Someone with an appropriate Sun box needs\nto pursue this further.
7990	Cliff Woolley	1022041408000	Can someone else with Solaris confirm this?
7990	Colm	1022423317000	AddDescription works fine for me with 2.0.36 and CVS. Solaris 8/sparc, \nsame patch cluster.\n\nSunOS prodigy 5.8 Generic_108528-13 sun4u sparc SUNW,Ultra-4\n\n
7990	David Shane Holden	1030862569000	Try adding a slash to the end of the directory names?\n\nAddDescription 'New York City, NY' 'New York/'\n                                            ^\n
7990	Jeff Trawick	1037911354000	I can hit the problem easily.\n\nComparing 1.3 behavior with 2.0.44-dev behavior on Solaris 8:\n\nWith 1.3, if I omit a trailing slash from the directory name on\nAddDescription, the description is applied to the directory, but if\nI add a trailing slash to the directory name on AddDescription,\nthe description is not applied to the directory.\n\nApache 2.0 is just the opposite.\n\n----\n\nWith Apache 2.0.44-dev on Linux I see the same results as with Apache \n2.0.44-dev on Solaris -- when the directory name specified on\nAddDescription has a trailing slash, it works; otherwise it doesn't\nwork.\n\n
7990	Jeff Trawick	1037922920000	A fix has just been committed to 2.0.44-dev.\n\nThanks for your report, and thanks for using Apache!\n
7990	Michael Fuhr	1069212420000	AddDescription is broken for directories again in 2.0.48.  I don't know if this\nis the root cause, but commenting out the one-line change made since 2.0.47 in\nmod_autoindex.c (line 1364) fixes this particular problem.\n
7990	Andr?? Malo	1069229139000	Yep, sorry. The previous fix wasn't 100 percent correct either. And the\ncombination broke it finally ;). It's fixed alrady in 2.1 and waiting for backport.
7990	Jeff Trawick	1070520651000	fix for 2.0.48 regression has been merged into stable branch for 2.0.49
7991	Paul J Murphy	1018568230000	Created an attachment (id=1531)\nPatch for this enhancement\n
7991	Andr?? Malo	1067722272000	There was change comitted into the 2.1 tree to solve your problem partially.\nIt's proposed for backport. Marking it as fixed so far.
8014	Joshua Slive	1018642700000	Please don't submit to the bug database and post to the newsgroup at the same\ntime.  You may reopen this report if you don't get a response within a few\ndays on the newsgroup.
8014	sam morris	1019125009000	Reopening, with more information:\n\nSnippet from httpd.conf:\n   Alias /C 'C:/'\n   <Directory \n'C:/'>\n      Options Indexes FollowSymLinks MultiViews\n      AllowOverride None\n      Order \nallow,deny\n      Allow from all\n   </Directory>\n\nRequesting \nhttp://localhost/C/Documents%20and%20Settings/ returns a listing\nof the directory, but \nwith the expected 'Sam/' entry (C:/Documents and\nSettings/Sam/ is actually a mount point) \nomitted. Instead, '[error] [client\n127.0.0.1] symlink doesn't point to a file or directory: \nC:/Documents and\nSettings/Sam' appears in the error log.\n\nRequesting \nhttp://localhost/C/Documents%20and%20Settings/Sam/, or anything\ninside of it, returns a \n403 error and likewise adds '[error] [client\n127.0.0.1] symlink doesn't point to a file or \ndirectory: C:/Documents and\nSettings/Sam' to the error log.\n\nRequesting \nhttp://localhost/C/Documents%20and%20Settings/All%20Users/ or any\nof the other links \nfrom the directory listing works as it should.\n\nAfter doing some reading, it appears that what \nApache calls symlinks on\nWindows are actually NTFS Junctions; most junctions have a target of \na\nregular pathname (such as 'C:/Target/'), but the mount point junctions\nWindows uses have a \ntarget in the form of\n'//?/Volume{90b9a960-b928-11d5-bbf2-806d6172696f}/' (the classid is \nthe\nvolume's unique identifier).\n\nThe error message suggests that Apache is checking the \njunction target to\nsee if it is a valid path (which the mount point junction target is not) \nand\nthrowing the error. So it seems the problem lies within the code that Apache uses to check the \nsymlink/juntion target.
8014	Will Rowe	1019622089000	\n  This is fixed in the current 2.0.36-dev tree, and will be part of the\n  next 2.0.36 release we expect to roll out within a week or so.\n\n  Thanks for your report, your detailed examples, and for adopting Apache 2.0!\n\n
8014	Skeuomorph	1048837570000	The precise behavior noted in the original bug still occurs in 2.0.44 on UNC \n(remote share) paths under Win2K Server or Win2K3RC2:\n\nAlias /nas/junction/dir1/dir2/ '//192.168.0.10/nas/junction/dir1/dir2/'\n<Directory '//192.168.0.10/nas/junction/dir1/dir2'>\n    Options Indexes FollowSymLinks\n    AllowOverride None\n    Order allow,deny\n    Allow from all\n</Directory>\n\n[Thu Mar 27 22:24:03 2003] [error] [client 67.67.67.117] \nForbidden: //192.168.0.10/nas/junction doesn't point to a file or directory\n\nIf FollowSymLinks is turned off, then:\n\n[Thu Mar 27 23:24:07 2003] [error] [client 67.67.67.117] Symbolic link not \nallowed: //192.168.0.10/nas/junction\n\nEither way, with indexing turned on and using the following mapping, Apache \nbrowses the directory fine, and generates an index, but does not see ANY of \nthe junctions:\n\nAlias /nas/ '//192.168.0.10/nas/'\n<Directory '//192.168.0.10/nas'>\n    Options Indexes FollowSymLinks\n    AllowOverride None\n    Order allow,deny\n    Allow from all\n</Directory>\n\nIt sees regular folders and files just fine.\n\nNFTS can create at least two common types of junctions.  One is the MountVol \ntarget format shown in Sam's bug report, and the other is a path reference as \ncreated with 'linkd.exe' from Win2K Resource Kit.  The above behavior is \nobserved with BOTH types.  \n\nI have rated this as MAJOR because without fixing this, Apache cannot be used \nto serve content from servers in a web farm that all work from a NAS server \nthat mounts many RAID arrays using the 'MountVol' or 'LinkD' method.  While \nthe LinkD method is uncommon, the MountVol method is offered in default \nWindows GUI Drive Management on volume creation, and is a common way to add \nnew volumes into an existing path structure.\n\n\n
8014	Kristofer Spinka	1048856546000	  I'm not 100% this fixes the issue mentioned at \nhttp://nagoya.apache.org/bugzilla/show_bug.cgi?id=8014 though I tried to \nreproduce the issue as I understood it.  If one of the bug submitters could \ntest it that would be great.  Bill, if you could verify that this change is \nreasonable I would appreciate it, the 'wanted' thing is a little vague to me.\n\n--- filestat.c.orig     Fri Mar  7 14:21:29 2003\n+++ filestat.c  Fri Mar 28 07:16:02 2003\n@@ -363,7 +363,8 @@\n         finfo->size = 0x7fffffff;\n #endif\n \n-    if (wininfo->dwFileAttributes & FILE_ATTRIBUTE_REPARSE_POINT) {\n+    if (wanted & APR_FINFO_LINK &&\n+        wininfo->dwFileAttributes & FILE_ATTRIBUTE_REPARSE_POINT) {\n         finfo->filetype = APR_LNK;\n     }\n     else if (wininfo->dwFileAttributes & FILE_ATTRIBUTE_DIRECTORY) {\n\n\n   /kristofer
8014	Andr?? Malo	1049998173000	Reopen to get this on the radar. Bill? your turn ;-)
8014	Will Rowe	1050598614000	\n  This was fixed in 2.0.45.  Please upgrade, and if the problem persists, please\n  reopen the bug with the new error log entries and observations.\n
8014	Will Rowe	1053353067000	  I stand corrected; that patch wasn't committed.\n\n  Now committed as of apr/file_io/win32/filestat.c revision 1.79,\n  and I expect you will see this in the forthcoming Apache 2.0.46.
8045	Will Rowe	1019880495000	Action httpd/unix-directory /directory-not-allowed\n\nRedirect 403 /directory-not-allowed\n\nmight be a gross, dirty hack, but it just might work for the moment.\n\nI suppose the default-handler should be taught to recognize and fail\nhttpd/unix-directory requests with a 404.  My only concern is that\nthis is -not- a 404, that level of the heirarchy -is- found, but\ncan't be processed in any meaningful way.  Implies a 401 or 403.\n\nThe processing schema's changed enough that you tickled this oversight.\nIn fact, we are erroring out far more often (even in late 1.3.x builds)\ndue to the possibility of one module being tricked into failure, and\nhaving another module pick up the request.  E.g. some folks used\nmultiview matching on index documents, but those could (in some very\nbizare and tangled circumstances) be evaded, and autoindex was picking\nup the slack when the admin didn't intend for that to happen.  We now\navoid Not Found as a 'catch all' if resources exist, otherwise such\npotentials will always exist.\n\nThanks for the report, and let us know about the gross hack!
8045	Ryan Bloom	1024120271000	This has been fixed in CVS, and will be available in a later release.  The\ndefault_handler wasn't catching cases where all of the previous modules had\ndeclined to serve the request.\n
8122	Martin Kutschker	1020704110000	Created an attachment (id=1794)\nnew config behaviour\n
8122	Martin Kutschker	1020704503000	The patch changes the SSLMutex command and offers these options:\n\ndefault | yes\nnone | no\nfcntl\nflock\nsysvsem\nposixsem\npthread\nsem = sysvsem | posixsem\nfile: = fcntl | flock\n\nThe meaning of 'yes' changes to 'default', 'sem' will use either Sys V or Posix\nsemaphores (the former are preferred) and file will use either Fcntl or Flock\n(preferring Fcntl).\n\nThe command remains (reasonably) backward compatible and is now in sync with the\nAcceptMutex command.
8122	Martin Kutschker	1020765327000	Created an attachment (id=1801)\nRemove debug output in ssl_engine_config.c else same as the previous which is btw a proposed fix.\n
8122	Joshua Slive	1034822076000	[This is a mass bug update.]\nThis bug reports a problem in an older version of Apache 2.\nCould you please update to the most recent version and see\nif you can reproduce this problem.  If the bug still exists,\nplease update the bug with the latest version number.  If \nthe bug no longer exists, please close the bug report.\n\nSorry for this impersonal response, but we get many more bug\nreports than our volunteers can keep up with.\nThanks for using Apache!
8122	Joshua Slive	1036268296000	[This is a mass bug update.] [Resolve-20021102]\nNo response from submitter; assuming issue is resolved.\nIf the problem still exists in the lastest version,\nplease reopen this report and update appropriately.
8122	Will Rowe	1036415686000	\n  This is a behavior change.  I don't see where we have considered this\n  patch yet, so reopening the report.  Thanks for keeping up with the stale\n  reports, Joshua!\n
8122	Jim Jagielski	1044399661000	S'funny. I didn't even see this (old) 'bug' and had just send email to dev@ proposing the \nsame sort of thing.\n\nI'm a very big +1 on this.
8122	Madhusudan Mathihalli	1047741190000	Can you please verify the options available now in the latest source base (HEAD \nincludes Jim's patch), and close the PR if you think the problem is resolved.\n\nThanks\n-Madhu
8122	Martin Kutschker	1047752809000	Sounds ok looking at the code.\n\nIn ssl_engine_mutex.c it would have been nice to us verbose eror reporting in\nssl_mutex_init and friends. See below for the relevant code of my original patch\n(it did help a lot while tracking bugs):\n\n+    status = apr_global_mutex_create(&mc->pMutex, mc->szMutexFile,\nmc->nMutexMech, p);\n+    if (status != APR_SUCCESS) {\n+        char buf[120];\n+\n+        apr_strerror(status, buf, sizeof(buf));\n+        if (mc->szMutexFile)\n+            ssl_log(s, SSL_LOG_ERROR,\n+                       'Failed to create global mutex lock using file "%s': %s',\n+                        mc->szMutexFile, buf);\n+        else\n+            ssl_log(s, SSL_LOG_ERROR,\n+                       'Failed to create global mutex lock: %s', buf);
8122	Will Rowe	1048538311000	\n  Ok, the patch is backported to 2.0.45 to honor the full range of SSLMutex\n  flavors, mirroring the AcceptMutex core directive.\n
8122	askme	1050970110000	Please look at bug 19182, ssl.conf needs to be updated.
8170	Joshua Slive	1020454014000	I've seen that this confuses many people, and a quick look at\nMakefile.in shows me that it hasn't been fixed yet.
8170	Justin Erenkrantz	1020460989000	A fix was submitted by Thom May and has been committed to httpd-2.0/Makefile.in\nrevision 1.108.\n\nThis will be included in a forthcoming release of Apache 2.0 (but did not make\nit in time for inclusion into 2.0.36).\n\nThanks for using Apache!
8223	Will Rowe	1019076594000	\nThis is the correct behavior.  All filename and uri parsing semantics are\ncase sensitive on Unix, except where noted in the documentation.\n
8223	Joshua Slive	1019077097000	Hmmm... Are you sure about this Will?  I haven't tried to see how this works in\n1.3, but the docs for TypesConfig seem to imply that this is supposed to be\ncase-insensitive.  (They aren't clear, but they use the term 'extension',\nwhich we almost always mean to be case-insensitive, and they say 'The extensions\nare lower-cased.'  I don't know what that is supposed to mean.
8223	Will Rowe	1019084818000	\nJoshua may be right ... if you can reproduce that .JPG worked in 1.3\nplease reopen this report and we can get the situation corrected.
8223	Anthony Best	1019085474000	Yes it works in Apache 1.3.22\n\nhttp://zerospace.org:80/zs10.JPG\nhttp://zerospace.org:80/zs10.jpg\n\nAlso adding JPG to the mime types does nothing.\n\nSame mime config.
8223	Joshua Slive	1019086726000	Yes, I've confirmed with 1.3 as well.  It makes sense to me that way.  All\nextension matching should be case-insensitive.
8223	Justin Erenkrantz	1019713251000	This has been resolved in modules/http/mod_mime.c revision 1.82.\n\nThis will be included in the forthcoming Apache 2.0.36 release.\n\nThanks for using Apache!
8223	Joshua Slive	1019848967000	*** Bug 8567 has been marked as a duplicate of this bug. ***
8227	Justin Erenkrantz	1019601766000	This should be resolved in docs/conf/httpd-std.conf.in revision 1.3.\n\nThis fix will be included in the next release of Apache httpd-2.0.\n\nThanks for using Apache!
8227	Cliff Woolley	1019604210000	*** Bug 7979 has been marked as a duplicate of this bug. ***
8234	Joshua Slive	1019254355000	I just tried this on FreeBSD (daedalus to be specific) and I get the same thing.\nHere is what I did: placed an .htaccess file in my public_html directory\ncontaining only\nAcceptPathInfo On\nthen requested the file\nhttp://www.apache.org/~slive/index.html/path_info\nwhich gives a 404 even though index.html exisists.\n\nPerhaps I missunderstand this directive entirely, but I thought it should allow\nthe request in that case.
8234	Cliff Woolley	1019462952000	This has been fixed for 2.0.36.  Thanks for using Apache!
8314	Robert La Ferla	1019250855000	Environment:\n\nApache 2.0.35 on RH 7.2 (i386)\n
8314	Jeff Trawick	1019251420000	Created an attachment (id=1640)\nfix for bug 8314\n
8314	Jeff Trawick	1019251505000	I was able to quickly reproduce it (need some regression test for this :) ).\nThe patch I just attached gets me past initialization and I'm able to serve\nthe cached file.  Your feedback would be appreciated.\n
8314	Jeff Trawick	1019251714000	I just now see that Paul Reder committed a fix for this earlier today.\nHis fix is the same as the patch I just posted.\n
8357	Joshua Slive	1019501420000	Confirmed this also happens on freebsd.\n\nBut we are having a hard time figuring out why you need this.\nNote that the repsponse returned by Apache is doing downgrade-1.0 and\nforce-no-vary correctly: it is using only HTTP/1.0 features.  The actual\nversion number in the HTTP response status line shouldn't matter for any\nreasonably sensible client.\n\nOn the other hand, it is a documented feature, that should work.
8357	Justin Erenkrantz	1019600186000	This is due to a reversed check in http_protocol.c.  A fix has been committed in\nmodules/http/http_protocol.c revision 1.415.\n\nThis will be included in the next release of Apache!\n\nThanks for using Apache!
8388	Joshua Slive	1020013732000	I wonder if this is caused by the same thing as bug 8253 (r->connection->aborted\nnot set)?
8388	Joshua Slive	1034822093000	[This is a mass bug update.]\nThis bug reports a problem in an older version of Apache 2.\nCould you please update to the most recent version and see\nif you can reproduce this problem.  If the bug still exists,\nplease update the bug with the latest version number.  If \nthe bug no longer exists, please close the bug report.\n\nSorry for this impersonal response, but we get many more bug\nreports than our volunteers can keep up with.\nThanks for using Apache!
8388	Jeff Trawick	1036065460000	With some fixes committed this morning to mod_cgi.c and server/protocol.c,\nthe CGI script is normally terminated when using mod_cgi.\n\nThere may be some paths in mod_cgi that aren't fixed, and mod_cgid is\ndefinitely still broken.\n
8388	Bengt 	1036764700000	I don't know why this bug is not being considered. I now try to post it as a\nLinux/Apache 2.0 bug, since it is to be found there too, in case that will draw\nmore interest. I would think it is a major problem that Apache can not run\ncgi-scripts with keep-alive, and I would like our technical department to be\nable to upgrade our apache installations (for security fixes etc) without me\nhaving to patch it first. I am not sufficiently aware of the purpose of the\nproblematic code to propose a final solution - in my own case, it is quite OK to\njust throw it out, but I would think it serves some purpose - perhaps to stop\nfaulty cgi-scripts from running endlessly. Perhaps it could be specified in the\nconfiguration file whether this action is wanted or not.
8388	Jeff Trawick	1036765253000	In general you can't assume that a PR is not being considered if there\nis no update in the last several days.\n\nAs already noted in the PR, it now works with mod_cgi with current code\nfrom CVS.  I am still working on getting it working with mod_cgid.  (I have\nit working in a patch posted to dev@httpd yesterday, but the patch needs \nsome further work before committing.)\n\nI'm confused about your statement\n\n  'Apache can not run cgi-scripts with keep-alive'\n\nWhat is the connection between keep-alive and this PR?\n
8388	Jeff Trawick	1036765511000	looks like bo@kase.se complained on the wrong PR by mistake...  ignore the last\ntwo updates :)
8388	Jeff Trawick	1037056228000	A fix has just been committed to mod_cgid to terminate scripts which the\nconnection drops.  Hopefully it will be in the next stable Apache 2 release\n(2.0.x).  The mod_cgi fixes will almost definitely be in the next\nstable Apache 2 release.\n\n\n
8449	Masao Takaku	1019637337000	Is 'ctime a typo of 'strftime' in the following text:\n\nhttp://httpd.apache.org/docs/howto/ssi.html.en#whenwasthisdocumentmodified\n\n  For more details on the timefmt format, go to your favorite search site and\nlook for ctime. The syntax is the same.\n
8449	Joshua Slive	1019761250000	You are indeed correct.  Thanks for the catch.
8453	Stephan W	1019655804000	After a few tries, I changed all the $prefix/build to \n/usr/local/share/apache2/build and compiled and installed php. This time the \ninstallation was ok. The script copied libphp4.so to the right place and \ninserted the LoadModuledirective in http.conf.\n\nNow there is another error when I start apache:\n\nSyntax error on line 218 of /usr/local/etc/apache2/httpd.conf:\nCannot load /usr/local/libexec/libphp4.so into server: \n/usr/local/libexec/libphp4.so: undefined symbol: ssl_onceonlyinit\nsbin/apachectl start: httpd could not be started\n\n\nI don't have time left for today but I think this is another problem \n(hopefully). I will work on this tomorrow. Maybe there is another point in \nsomewhere.\n
8453	Joshua Slive	1020194915000	*** Bug 8678 has been marked as a duplicate of this bug. ***
8453	Joshua Slive	1020458615000	I think that this was fixed in 2.0.36.  You can try a prelease version here:\nhttp://httpd.apache.org/dev/dist/\n\nIf that doesn't fix it, please reopen this report and up the version number.\n\nThanks for using Apache.
8453	Josh Smith	1020910864000	I'm still seeing this in 2.0.36. In my case, apxs contained\n\n  my $prefix         = '/software/stow/apache-2.0.36';\n\nand\n\n  get_config_vars('$prefix/build/config_vars.mk',/%config_vars);\n\nwhen that second line should have been\n\n  get_config_vars('$prefix/share/apache/build/config_vars.mk',/%config_vars);\n\nAlso, apxs later contained\n\n  my $envvars = get_vars('bindir') . '/envvars';\n\nwhich should have been\n\n  my $envvars = get_vars('sbindir') . '/envvars';\n\nThose two changes allowed me to configure and build PHP 4.2.0.\n\nI use a custom layout in config.layout, but it's very similar to the GNU layout;\nI can send along the details if they'd help.
8453	Josh Smith	1020927600000	I spoke too soon: There are other instances of $prefix/build in apxs, As the\noriginal reporter mentioned, and they should all probably be fixed.\n\nIt doesn't look like this is fixed in CVS either (looking via ViewCVS at\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/support/apxs.in, which seems to be\nat version 1.37).
8453	Dan Muller	1022915572000	I also ran into this, with an Apache build I did on a Debian system from \nlatest sources. I'm trying to build Subversion, and its configuration script \nfails due to this bug. I've fixed support/apxs.in on my system, sort of. I've \njust subscribed to the developers list so that I can discuss it there. In the \nmeantime, if someone's interested in the diffs, send me an email at \ndmuller@spookydistance.com.
8453	Jeff Trawick	1023278473000	A fix for this was just committed to CVS.  I'm pretty sure that it will be\nin 2.0.37 (or whatever version comes next).\n\nThanks for your report, and thanks for using Apache!\n
8462	Cliff Woolley	1020488050000	I agree this looks like a bug.  But which version of 1.3 is this working with?  From \nlooking at the CVS history, it seems like 2.0's mod_include is almost identical to \n1.3.25-dev's as far as parsing the expressions goes. 
8462	Brian Pane	1020493656000	The parsing code in 2.0 was misplacing the character after the '443'...\nthis was harmless if the character was whitespace, but bad if the character\nwas a parenthesis.  I just committed a change to fix this.
8464	James Tait	1020874869000	Created an attachment (id=1814)\nOutput of strace -f httpd -X\n
8464	James Tait	1022086226000	I've looked into this a bit further with 2.0.36, and also compared to 1.3.24.\n\nIn 1.3.24, mod_rewrite execl's a shell process itself in the function\nrewritemap_program_child(), passing the user-supplied config line as an argument:\n\nexecl(SHELL_PATH, SHELL_PATH, '-c', (char *)cmd, NULL);\n\n\nThis works, even if you supply arguments to the program to be run.\n\nIn 2.0.36 it leaves the exec to APR:\n\n    if (((rc = apr_procattr_create(&procattr, p)) != APR_SUCCESS) ||\n        ((rc = apr_procattr_io_set(procattr, APR_FULL_BLOCK,\n                                  APR_FULL_NONBLOCK,\n                                  APR_FULL_NONBLOCK)) != APR_SUCCESS) ||\n        ((rc = apr_procattr_dir_set(procattr,\n                                   ap_make_dirstr_parent(p, progname)))\n         != APR_SUCCESS) ||\n        ((rc = apr_procattr_cmdtype_set(procattr, APR_PROGRAM)) != APR_SUCCESS)) {\n        /* Something bad happened, give up and go away. */\n    }\n    else {\n        procnew = apr_pcalloc(p, sizeof(*procnew));\n        rc = apr_proc_create(procnew, progname, NULL, NULL, procattr, p);\n\n\nThis works when the program doesn't have arguments to be passed, but fails if\nthere are arguments.  Looking at the apr_proc_create() function:\n\n        else if (attr->cmdtype == APR_PROGRAM) {\n            if (attr->detached) {\n                apr_proc_detach(APR_PROC_DETACH_DAEMONIZE);\n            }\n\n            execve(progname, (char * const *)args, (char * const *)env);\n        }\n\n\nNERK!  The whole user-supplied string is passed as progname, with args and env\nempty.\n\nI can get around this by running a shell script that runs my program with\narguments, but that's kinda messy.  I'd prefer to see mod_rewrite handle this\ncorrectly and pass in the args.\n\nIf I get time, I'll settle down and fix this.  If anyone wants to beat me to it....
8464	Cliff Woolley	1022642978000	I committed the revised patch you posted to dev@httpd, with one change, which \nwas that I had to disable the stat of the program to avoid having to duplicate \nthe apr_tokenize_to_argv() call.  If the program doesn't exist, it will fail to \nstartup anyway, so this should still be fine.\n\nThanks!
8464	Cliff Woolley	1022647555000	Okay, so the apr_stat() thing wasn't *quite* that easy... apr_proc_create()\ndoes not necessarily return an error if the program specified doesn't exist... \non Unix, it only returns an error if the fork() call itself failed.  Bah.  So I \nadded another apr_stat() call just after the apr_tokenize_to_argv() call has\nalready happened.\n\nAnyway, consider it fixed.  :)
8472	Joshua Slive	1019661318000	No denying that the behavior you describe is a bug, but let me just note for\nthe record that UserDir with no argument is not correct.  What you want is\nUserDir disabled\n(Although I'm not sure if that will just pass through ~ requests, or if it\nwill return 'forbiden'.  In the latter case, the only solution is to remove\nmod_userdir.)
8472	Oliver Humpage	1019667380000	Yes, I know just putting 'Userdir' is a stupid thing to do: in fact, you get the \n'take pages straight from ~userdir/' effect by never having a 'Userdir' line. \nAt least, that worked for me...\n\nI just reckoned that if something eaily-spottable in the httpd.conf file could \nmake apache hang, it should be checked for before loading. Minor bug.....
8472	Will Rowe	1019669105000	Wouldn't \n  userdir . \naccomplish what you are trying to do?\n\nIn any case, Apache should provide more intellegent feedback.
8472	Oliver Humpage	1019669823000	Re: 'Userdir .'\n\nFair point. It does work. In fact, leaving out the Userdir line altogether as I \npreviously suggested seems to make apache revert to its default of \npublic_html (hadn't *quite* tested things properly). Thanks for your \nsuggestion.\n\nSorry, it's the end of a long, hot day (am in the UK). Brain gone walkies.
8472	Justin Erenkrantz	1019715423000	Leaving it blank doesn't cause a hang here - it doesn't do anything either. \nHowever, so that people don't get any ideas on what this means, I have committed\na change that makes UserDir with no arguments be invalid and rejected (with an\nappropriate message).\n\nThis fix is in modules/mappers/mod_userdir.c revision 1.44.  This will be\nincluded in the next release of Apache 2.0.\n\nThanks for using Apache!
8482	zapp	1019671965000	forget to say: that script worked on apache 1.3.19
8482	Andy Green	1020856164000	I am also experiencing this with a nph- cgi.  It seems to be after 64K-128K of \ndata the remainder is corrupted when sent through to the requesting web \nbrowser.  The data is clean FOR SURE when it is issued by the cgi.\n
8482	Jeff Trawick	1020867084000	Do you have a sample which exhibits the problem?  How is the data generated?  \nSlowly over time?  In one burst?  This nph- script works for me (all data \nreceived by browser):\n#!/bin/sh\n\necho 'HTTP/1.1 200 OK'\necho 'Date: Thu Nov 29 16:22:33 CET 2001'\necho 'Server: Apache'\necho 'Connection: close'\necho 'Content-Type: text/html'\necho\ncat /home/trawick/apacheinst/manual/mod/mod_ssl.html\ncat /home/trawick/apacheinst/manual/mod/mod_ssl.html\n
8482	zapp	1021025856000	well, i'm not using such a simple one. i'm using cgi-irc \n(http://cgiirc.sourceforge.net). it's a chat skript, so the data is generated \nslowly over time. anonther point maybe could be the multipart content-type:\n\n#!/usr/bin/perl\n   print 'HTTP/1.0 200 OK/n';\n   print 'Cache-Control: no-cache/nExpires: -1/nPragma: no-cache/n';\n   print 'Content-type: multipart/x-mixed-replace;boundary=BOUNDARY/n/n';\n
8482	zapp	1021132810000	still the same problem in version 2.0.36\n
8482	zapp	1024496316000	still not working in 2.0.39\n\nthe problem, that the browsers gets only a certain amount of data, seems to \nfixed, but now it looks like the connection isn't a keep-alive one.\n\nas mentioned, the problem apears using the cgi-irc (cgiirc.sourceforge.net).\nwhile the browser still can send data to the server (which this cgi is handling \nproperly), the data which should be sent from the cgi, never reaches the \nbrowser.\n\nit's working on apache 1.3.19 .. but not on apache 2.0.39\nif you wish to take a look:\n\nhttp://www.galgenberg.net/cgi-bin/cgiirc/irc.cgi <-- apache 2.0.39\n\nhttp://132.187.222.249/cgi-bin/cgiirc/irc.cgi <-- apache 1.3.19
8482	David Leadbeater	1024578581000	Hi, i'm the author of CGI:IRC - thanks to zapp for pointing me at this bug. \nI've now written a test-case that shows this working on apache 1.3 but not \napache 2.\n\nIt doesn't seem to be related to nph scripts, just anything sending content \nthat shouldn't be buffered.\n\nThe test makes use of javascript in the stream and for me works fine on apache \n1.3 (two installs tested).\n\nApache 2: http://cgiirc.blitzed.org/teststream.cgi\nApache 1.3: http://dgl.cx/test/teststream.cgi\n(Also nph- scripts at same locations as above to show it affects both nph and \nnon-nph scripts).\nSource code: http://cgiirc.sourceforge.net/files/teststream.cgi\n\nHope this helps.
8482	David Leadbeater	1024578701000	(Note that if the test fails but these values only differ by a second then it's \nlikely to be a laggy connection). On apache 2 they nearly all appear at the \nsame time. Also I know CGI:IRC has problems with opera and konqueror so don't \ntest on those browsers).
8482	David Leadbeater	1024578763000	And sourceforge appear broken for serving scripts so use \nhttp://cgiirc.sourceforge.net/files/teststream.pl.txt and rename it..
8482	Jeff Trawick	1024579074000	Thanks for the recent updates.  Just to avoid wasting anybody's time:\n\nthis is an acknowledged problem that multiple developers have been able\nto reproduce\n\nit is considered high-priority (tracked in STATUS file)\n\nhopefully this will be resolved before long\n
8482	David Leadbeater	1025472334000	Originally I said non-nph scripts had problems too, this doesn't seem to be the\ncase and i've now got cgiirc.blitzed.org working on apache 2.0 by not using an\nnph script.\n\nI think this problem might be related to bug number 8388? As The only thing\nremaining is the script doesn't always seem to be correctly killed by apache\nwhen the connection terminates, on apache 1.3 I'm quite sure it used to send a\nSIGINT (or similar) to the cgi script when the connection was closed, but apache\n2 doesn't appear to be doing that?\n
8482	Nic Doye	1028113619000	We have a CGI script which works fine in 1.3.20 (and on the command line: 'su -\nnobody -c '/opt/bin/perl /blah/cgi-bin/dpradm\npage=18.html/&arg1=val1/&arg2=val2'') but never returns all the data to the\nbrowser (or telnet port80 session).\n\nThis is on Solaris 2.6.\n\nAs a result, it looks like our only Apache 2 box is going to roll back to 1.3.26.
8482	Nic Doye	1029149361000	I believe that Apache 2.0.40 has fixed this bug for me. (only build difference\nbeing: --disable-threads).
8482	zapp	1029834858000	Bug still exists in 2.0.40\n
8482	Nic Doye	1029835058000	Agreed - bug still exists (but occurs less). I dont think this is limited to NPH\neither.
8482	Joshua Slive	1034822062000	[This is a mass bug update.]\nThis bug reports a problem in an older version of Apache 2.\nCould you please update to the most recent version and see\nif you can reproduce this problem.  If the bug still exists,\nplease update the bug with the latest version number.  If \nthe bug no longer exists, please close the bug report.\n\nSorry for this impersonal response, but we get many more bug\nreports than our volunteers can keep up with.\nThanks for using Apache!
8482	zapp	1034859545000	sry guys, but it's still not working in 2.0.43
8482	David Leadbeater	1035412799000	I haven't had chance to try apache 2 recently, but people are still reporting\nthis and asking about it.\nAny chance of some sort of update about when it might be fixed?\n
8482	Jeff Trawick	1035413737000	Zapp, were you using mod_cgi or mod_cgid when you tried with 2.0.43?\n\n2.0.43 has some fixes to help streaming in general (nph or not).\n\nA problem specific to mod_cgid which broke streaming with wasn't fixed \nuntil right after 2.0.43 was released.\n\n
8482	zapp	1035455028000	hi trawick\n\nLoadModule cgi_module libexec/apache2/mod_cgi.so\n\nwe're going to update to the latest CVS version this (maybe tomorrow) \nafternoon. keep u informed!\n\nany ideas, when v2.0.43++ will be released?
8482	Jeff Trawick	1035460896000	If you were using mod_cgi with 2.0.43, you have all the fixes that are\navailable.\n\nHere is teststream.pl on cvs HEAD with mod_cgid:\n\n---------\nTesting streaming of content (with scripting)\nIf most of the tests below succeed then it is likely streaming of content works\nfine. If they fail then either the webserver, a proxy between you and the\nwebserver or your browser is having problems with streams (and sometimes scripts\nembedded inside streams). If the difference in any failed tests is only a second\nthen it is more likely that your internet connection to the server is slow.\n\nTest 0: OK\nTest 1: Failed: 1035460289 != 1035460288\nTest 2: Failed: 1035460294 != 1035460293\nTest 3: Failed: 1035460299 != 1035460298\nTest 4: Failed: 1035460304 != 1035460303\nTest 5: Failed: 1035460309 != 1035460308\nLess than 4 tests were successful. You probably have a problem with streaming of\ncontent (or a slow internet connection)\nEnd of test.\n------------\n\nNote that the failures were all only 1 second too late.\n\nHere is teststream.pl on cvs HEAD with mod_cgi:\n\n------\nTesting streaming of content (with scripting)\nIf most of the tests below succeed then it is likely streaming of content works\nfine. If they fail then either the webserver, a proxy between you and the\nwebserver or your browser is having problems with streams (and sometimes scripts\nembedded inside streams). If the difference in any failed tests is only a second\nthen it is more likely that your internet connection to the server is slow.\n\nTest 0: OK\nTest 1: OK\nTest 2: OK\nTest 3: OK\nTest 4: OK\nTest 5: OK\n6 out of 6 tests were OK, looks like streaming is working\nEnd of test.\n-----\n\nShould I assume that there is a functional problem with mod_cgid based\non this test, or perhaps it is just a bit slower than mod_cgi?\n
8482	zapp	1035464286000	weird..\n\ntesting with CGI:IRC v0.5\n\n2.0.43:\nclient receives an exact number of bytes, then nothing for about 10 secs. after \nthat, CGI:IRC connects to the IRC-Server and the client completely receives the \nrest. the connection is now closed. (data can be sent to (irc-)server, but \ncannot be received)\n\n2.0.44-dev: (httpd-2.0_20021024101256.tar.gz)\nclient receives exact number of bytes, too. no waiting. CGI:IRC starts \nimmediately. BUT the client doesn't receive the all the data. the amount of \nbytes, received by the client after CGI:IRC has connected to IRC-Server, is \nchanging from time to time; after a dozen tests, the data hasn't been fully \nreceived one single time.\nthe connection stays alive till termination (by user =)\n(same as above: data sending, not receiving...)\n\nmaybe david can provide some more details, what's going on that could terminate \nthe data-flow.
8482	David Leadbeater	1035470314000	I've just installed apache 2.0.43 to test with - using mod_cgi and prefork\n(default ./configure options). \n\nteststream works fine -but- if it is called nph-teststream.cgi all but one of\nthe tests fail (and it's out by much more than a second).\n\nSo, the first problem is fixed by renaming it something not beinging with nph-\n(I don't understand that - I thought the idea was to do less processing on nph-\nscripts). For CGI:IRC renaming nph-irc.cgi to something like irc-main.cgi and\nupdating config (and removing the 'HTTP/1.0 200 OK' line on non-CVS versions)\nfixes it. \n\nThe other problem briefly mentioned above is still present, no signal is sent to\nthe process to terminate it when the user stops the request, Apache 1.3 does,\nalthough I can't find this in any CGI specification, but it's a very useful feature.
8482	Jeff Trawick	1035474197000	Thanks for the reminder about calling the script nph-...  Nothing written\nto the network in that case, so I'll start debugging that.\n
8482	Jeff Trawick	1035483026000	The nph flavor of teststream.pl works fine for me with this patch.\n\nWanna try the patch with the more complicated test (irc script)?\n\nIndex: server/core.c\n===================================================================\nRCS file: /home/cvs/httpd-2.0/server/core.c,v\nretrieving revision 1.213\ndiff -u -r1.213 core.c\n--- server/core.c       14 Oct 2002 20:08:15 -0000      1.213\n+++ server/core.c       24 Oct 2002 17:26:10 -0000\n@@ -3653,6 +3653,7 @@\n     conn_rec *c = f->c;\n     core_net_rec *net = f->ctx;\n     core_output_filter_ctx_t *ctx = net->out_ctx;\n+    apr_read_type_e eblock = APR_NONBLOCK_READ;\n\n     if (ctx == NULL) {\n         ctx = apr_pcalloc(c->pool, sizeof(*ctx));\n@@ -3728,7 +3729,16 @@\n                 const char *str;\n                 apr_size_t n;\n\n-                rv = apr_bucket_read(e, &str, &n, APR_BLOCK_READ);\n+                rv = apr_bucket_read(e, &str, &n, eblock);\n+                if (APR_STATUS_IS_EAGAIN(rv)) {\n+                    /* send what we have so far since we shouldn't expect more\n+                     * output for a while...  next time we read, block\n+                     */\n+                    more = apr_brigade_split(b, e);\n+                    eblock = APR_BLOCK_READ;\n+                    break;\n+                }\n+                eblock = APR_NONBLOCK_READ;\n                 if (n) {\n                     if (!fd) {\n                         if (nvec == MAX_IOVEC_TO_WRITE) {\n
8482	Jeff Trawick	1035560293000	The last patch posted to this PR has been tested successfully and will be\nin the next release of Apache.\n\nThere is still a concern about the issue described in PR 8388, but the\nissue of server-pushed output for nph- and non-nph- seems to be resolved.\n
8482	ValK	1055987732000	Apache/2.0.46 (Unix) mod_perl/1.99_09 Perl/v5.6.1 mod_ssl/2.0.46 OpenSSL/0.9.6c\nServer at valk.ath.cx Port 443\n\nUsing https connection it not work... with http it work some helps?
8482	Cliff Woolley	1055988152000	Valk: your question would appear to be unrelated to this bug report.  And it doesn't \nappear to be a bug report of its own, but rather a user-support question.  Please \nemail your question to modssl-users@modssl.org.  They will, no doubt, want more \ndetails on your configuration in order to help diagnose your problem. 
8491	Justin Erenkrantz	1019719864000	Babelfish and Google both say Authentication is Authentisierung in German.\n\nI don't know German, but your spelling might be correct.  Authentikation surely\nisn't correct.  =)  We will wait until a committer who speaks German can review\nthe spelling (we have a bunch, so it shouldn't be much of a delay).\n\nThanks for using Apache!
8491	Joshua Slive	1019762015000	Let's call this 'documentation', since it is under the 'docs' directory in the\nsource distribution.
8491	Erik Abele	1037499769000	Thanks. This is fixed and will be included in the next release.
8493	Jon Ribbens	1032889245000	Is there any danger of this bug report ever being addressed?
8493	Will Rowe	1036863704000	\n  Try using rewritelog and rewriteloglevel 9 \n\n  http://httpd.apache.org/docs-2.0/mod/mod_rewrite.html#rewritelog\n\n  to create a snapshot of the rewrite parsing of this request, and then\n  attach that to this bug.  Only then might we be able to determine what\n  mod_rewrite is doing (correctly or incorrectly.)
8493	Jon Ribbens	1036871559000	Created an attachment (id=3792)\nRewriteLog file showing problem\n
8493	Jon Ribbens	1036871637000	OK I have attached a log file showing this, I'm not sure how it helps since it \ndoesn't really show anything not described in my original report, but here it \nis ;-)
8493	Will Rowe	1036903647000	It showed one -very- interesting thing, an empty URI.\n\nThe only way to get an empty URI is a file redirect (as opposed to\na uri redirect.)  I'll ponder this and throw you more questions later.\n\nAny 'interesting' (non-standard) modules loaded?  Any interesting\nthings you've done in the corresponding <Location > or <Directory >\nblocks, or the core config?
8493	Jon Ribbens	1036933756000	The configuration was completely standard. I downloaded a brand new copy of \napache 2.0.43 for this test. It was configured and installed with ./configure --\nprefix=/tmp --enable-rewrite and the httpd.conf was unchanged from the \ndistribution except for changing the listen port, adding 'AllowOverride all' so \nthe .htaccess file would work, and adding the RewriteLog[Level] lines.\n\nThe htdocs directory was unchanged from the distribution except for adding a \ntrivial index.html file, creating a 'wt' directory under the htdocs directory, \ncreating an empty file 'wt/index.html.py', and creating a '.htaccess' file in \nthe htdocs directory whose contents were identical to that shown in the \noriginal bug report.
8493	Derek Chee	1038940680000	I've seen this problem, too, with 2.0.40 (RH Linux 8.0 distribution).  I checked an old copy \nof 1.3.26 for comparison.\n\nI made a simple rule for testing:\nRewriteRule ^index/.html$ rewritten.html\n\nThe internal redirects do not appear to be going through mod_rewrite.  See attachment \nfor a comparison of the rewrite_log between 2.0.40 and 1.3.26
8493	Derek Chee	1038940751000	Created an attachment (id=4024)\nrewrite_log comparison between 1.3.26 and 2.0.40\n
8493	No Spam	1044343900000	I also ran in to this problem when migrating from 1.3.27 to 2.0.40-11 (Red Hat 8\nRPM). When ever / is requested (ie: http://www/example.com/ or\nhttp://www.example.com/foobar/) mod_rewrite doesn't resolve it to a\nDirectoryIndex file. This happens with REQUEST_FILENAME as well as SCRIPT_FILENAME.\n\nRewriteEngine On\n\nRewriteCond %{REQUEST_FILENAME} -f\nRewriteRule /* /cgi-bin/script.cgi [T=application/x-httpd-cgi,L]
8493	No Spam	1044344126000	Created an attachment (id=4708)\nrewrite_log file illustrating the problem.\n
8493	Andr?? Malo	1044363863000	> RewriteEngine On\n\n> RewriteCond %{REQUEST_FILENAME} -f\n> RewriteRule /* /cgi-bin/script.cgi [T=application/x-httpd-cgi,L]\n\nThis cannot work. /* matches only slashes. You probably want something like /.*\n\nThe other problem (DirectoryIndex doesn't apply):\nIMHO, This is not a mod_rewrite bug.\nIt seems, that we have more and more issues, comin' up with the new 2.0\ninternal_fast_redirect stuff, used, for example, by mod_dir.\nThat means especially that there is no longer a real internal redirect from / to\n/index.html, so it cannot apply.\n\nJon, you may try\nRewriteCond %{LA-U:REQUEST_FILENAME} -f\n...\n\nBug 13211 suffers from the same function (fast_redirect).\n\nEither we have to document it, or we should change it back to a normal internal\nredirect (or spend some time in reworking and rethinking that fast_redirect\nfunction). Opinions?
8493	Sander Holthaus	1044372585000	What does internal_fast_redirect exactly do/mean (since it is not documented, I \nhave to ask).\n\nMy personal opinion is that the rewrite-stuff should be better documented. I \nuse Apache (2) for quite a while now, but I simply cannot get certain rewrite-\nrules to work. Not because they aren't correct, but I always have problems \ngetting mod_rewrite to work at the right time (in comparison to other \ndirectives).\nBut I'm not sure if this related?
8493	Andr?? Malo	1044441717000	the fast internal redirect doesn't do a real internal redirect (which would\nrepeat most of the request handling for the new url) instead of only merging the\ndata from a previous subrequest with the current request data at the point of\ncalling.\nmod_dir uses that for redirecting / to /index.html (or whatever).\n\nThe relation to this bug is:\nin 1.3 mod_dir causes an internal redirect, which processes all the api phases\nagain, so mod_rewrite gets a chance to match the new stuff. In 2.0 there's no\nredirect, so no chance for mod_rewrite (simple, eh? ;-)\n\nYour rewrite problems... perhaps you should look in the bug database for similar\nbugs or create a new entry?
8493	No Spam	1053124772000	I was wondering if there was any update for this bug report? I've been watching\nthe version changelog and the status of this page, but haven't seen anything.\n\nThanks much!
8493	Andr?? Malo	1053125242000	Please try the LA-U flag as already suggested.\n\nI'm changing the component to docs, since the new behaviour simply needs to be\ndocumented.
8493	No Spam	1053141595000	I wish I could Andr??, but LA-F doesn't work and LA-U returns strange results.\nI'm using Red Hat's build (httpd-2.0.40-11.3) so I don't know off hand if this\nwould be an issue with the virgin distribution or not.\n\nIs this really a 'feature' and not a bug in 2.x?
8493	No Spam	1053141660000	Created an attachment (id=6393)\nrewrite_log file for LA-F/LA-U.\n
8493	Andr?? Malo	1053211212000	Boomer, you are absolutely right. I was convinced it worked for me sometime, but\nthere was mod_negotiation involved...\n\nHowever, mod_rewrite has a bug, that LA-U in directory context doesn't work.\nJust fixed it in HEAD (and proposed for backporting to the stable trees).\n\nAfter fixing it, %{LA-U:REQUEST_URI) results in the actual delivered URI (e.g.\n/index.html) and %{LA-U:REQUEST_FILENAME} in the resulting /path/to/filename.\n\nIf you want to test it, the patch is here (the line numbers will differ for the\n2.0 branch, but that shouldn't be a problem):\n<http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/mappers/mod_rewrite.c.diff?r1=1.150&r2=1.151>.\n\n(leaving in documentation category, because it's still new behaviour)
8493	Andr?? Malo	1074040778000	In 2.1 it's fixed, since rewrite rules work also in subrequests there.\n\nUnfortunately it's not likely to be backported, because it may lead to\nunexpected results in existing configurations.
8544	Carlo Marcelo Arenas Belon	1019808471000	Created an attachment (id=1713)\nan explicative diff of the solution\n
8544	Carlo Marcelo Arenas Belon	1019977169000	Created an attachment (id=1720)\na context diff patch (finally)\n
8544	Paul J. Reder	1020288016000	A fix has been committed to correct this which will be included in a future\nrelease. Please see revision 1.100 of the file ab.c. Thank you for your submission.
8569	Joshua Slive	1020350088000	Done.
8625	Will Rowe	1020095353000	Have you checked the effect of the usecanonicalname directive on this behavior?\n
8625	Jonathan Layes	1020096773000	'UseCanonicalName off' in the VirtualHost did give the expected behaviour. \nPerhaps a note should go in the mod_proxy documentation to refer to the\nUseCanonicalName directive?  Thanks for pointing out the oversight.
8625	Andr?? Malo	1046259128000	Accept this as a documentation bug. Reopen to assign.
8625	Andr?? Malo	1046482330000	added to the docs.
8643	Jeff Trawick	1020176573000	The links are now fixed on httpd.apache.org and in the library, so\na future release of Apache will have the fixes.\n\nThanks for your report, and thanks for using Apache!\n
8696	Joshua Slive	1020349781000	Thanks.  I've brought the page up-to-date with the 1.3 version.  Of course,\nthese are all 1.3 tutorials anyway.\n\nThanks for using Apache!
8726	Will Rowe	1021434167000	\n  One final observation; you can always use NTFS 5.0 junctions (in XP)\n  [which ARE real symlinks] or NTFS hard links in place of cygwin's \n  inventive but back-asswards faux symlinks.\n\n  Jerry, I believe you know how to author a patch ... feel free to offer\n  up a patch to win_compiling.html, and submit it to docs@httpd.apache.org\n  ... but it is good to have the citation in the bug database :-)
8726	Jerry Baker	1021435468000	As far as I know, junctions are only for directories. You can make a junction so \nthat C:/directory-a is a 'junction' to C:/directory-b. I do not believe you can \ndo it with individual files.\n\nI sure would like to author a patch. No problem. Very busy with some summer \nclasses. Please ping me if you haven't heard back in a while.
8726	Will Rowe	1021436000000	\n  Thanks for the offer Jerry... reopening as a doc bug.
8726	Jerry Baker	1021492480000	Adding patch here in addition to sending to docs@httpd.apache.org
8726	Jerry Baker	1021492525000	Created an attachment (id=1875)\nPatch for win_compiling.html to add note about Cygwin's symlinked awk.exe\n
8726	Will Rowe	1021503584000	Reopening to really close
8726	Will Rowe	1021503607000	\n  Doc committed, thanks Jerry!
8740	Jiri Novak	1020348304000	But it's no rule 32 characters before . If I use real binary data, I need for \nexample 200 bytes before, 500 bytes before and so on... otherwise there is NULL \nresult...
8740	Will Rowe	1021440801000	\n  Nope, any characters are acceptable.\n\n  It seems we didn't flush for the response correctly, therefore you had some\n  very bogus results.  So could any ISAPI script.\n\n  In the next couple of days, I will make available a test build under 2.0.36\n  that should work under that version.  Am attaching you to another incident\n  so I can send that announce to all at the same time.\n\n  Presuming this solves all your problems, you will see this fix will appear\n  in release 2.0.37.\n
8789	Ryan Bloom	1033170176000	The default logfile for suexec was in /usr/local/apache, instead of\n/usr/local/apache2.  I have committed a fix for that.
8841	Joshua Slive	1020721750000	Created an attachment (id=1796)\nProposed patch: Reverse the ordering of the mod_userdir and mod_alias hooks\n
8841	Joshua Slive	1020721864000	If you can, please give the attached patch a go and see if it fixes your problem.
8841	Anthony Schorer	1020723119000	After applying the patch and recompiling...\n\n-=# ./apachectl start\nhttpd: apr_hooks.c:162: tsort: Assertion "0' failed.\n./apachectl: line 192:   719 Aborted                 (core dumped) $HTTPD\n./apachectl start: httpd could not be started\n\nIf you want the core, let me know :o
8841	Joshua Slive	1020723525000	Created an attachment (id=1797)\nSecond part of patch\n
8841	Joshua Slive	1020723578000	Sorry, my fault.  You also need to patch mod_userdir as I do in the second patch.\nGive that a shot.
8841	Anthony Schorer	1020726732000	Appears to work 'correctly' now. Thanks :-)
8841	Joshua Slive	1020730833000	OK.  Thanks very much for the report.  This will be fixed in 2.0.37.
8853	Joshua Slive	1020784975000	Created an attachment (id=1803)\nMake mod_alias run before mod_vhost_alias\n
8853	Joshua Slive	1020785081000	It looks like the ordering of the translate_name hook has not been very well\nthought-out.  Could you please try the attached patch and see if it fixes your\nproblem.
8853	Joshua Slive	1020785266000	Created an attachment (id=1804)\ncorrected patch\n
8853	Joshua Slive	1020785305000	Woops.  Sorry, but I'm not in a position to compile apache at the moment, so\nI can't test these.  The second patch should be better.
8853	Jason	1020839757000	Patching with stock 2.0.36 did not work for me.\nTried editing the changes in manually and \nresulted in an assertion error in apr_hooks.c.\nShould I try it with a CVS snapshot or?
8853	Joshua Slive	1020958155000	Yes, you should try it with the CVS snapshot.  There was another ordering change\nwith respect to mod_alias that went in a couple days ago, and without that\nchange, you will get conflicts.  Sorry I didn't think of this before.\n\nSo you will either need to work from CVS and apply this patch, or work from\n2.0.36 and apply the patches from bug 8841 before this one.\n\nLet us know the results.
8853	Joshua Slive	1021568034000	Any luck with this patch?  It looks right to me, but I'm not going to commit\nit because I don't have a mod_vhost_alias setup to test it.
8853	Joshua Slive	1026235422000	*** Bug 10503 has been marked as a duplicate of this bug. ***
8853	Joshua Slive	1027275029000	An updated version of this patch was committed.
8869	Jeff Trawick	1021310290000	Your change will be in Apache 2.0.37.\n\nThanks for your report, and thanks for using Apache!\n
8927	Joshua Slive	1020965900000	Thanks for the report!  This is now fixed.
8934	Will Rowe	1021423466000	\n  Fixed in CVS this morning... the fix will be available in .37 and an\n  interim test mod_isapi.so I will be making available this week that\n  will be build for .36.  Will let you know when that test version is\n  available [we have refactored the code significantly, and will want\n  to get it in as many hands as possible.\n\n  There were a few more instances where we needed to count the trailing\n  NULL, but I think I caught them all (and credited you with the patch\n  in CHANGES.)\n\n  Thanks for the report and analysis!\n
8934	Will Rowe	1021440900000	\n  Adding Jira for notification of test release this week.\n
8934	Will Rowe	1021759270000	\n  There is a test module of mod_isapi.c cvs version 1.73 now available from\n\n    http://www.apache.org/~wrowe/mod_isapi.so\n\n  Please feel free to test (within Apache 2.0.36) and report back with\n  any success or hassles you encounter.  The source code is available;\n\n   \nhttp://cvs.apache.org/viewcvs.cgi/*checkout*/httpd-2.0/modules/arch/win32/mod_isapi.c?rev=1.73\n   \nhttp://cvs.apache.org/viewcvs.cgi/*checkout*/httpd-2.0/modules/arch/win32/mod_isapi.h?rev=1.1\n\n  All ISAPI directives are now per-directory, except for ISAPICacheFile (which\n  remains global.)  A new  ISAPIFakeAsync on  will allow modules to believe that\n  mod_isapi is an async server, and respond to the async requests and invoke\n  the module's completion callbacks.\n\n  Unless problems are identified, this is the code expected to be released\n  with Apache 2.0.37.\n\n  TIA\n
8934	Will Rowe	1022424188000	*** Bug 9421 has been marked as a duplicate of this bug. ***
8938	Joshua Slive	1020961049000	This was actually an error in the XSLT we use to auto-generate the directive\nindex.  Thanks for pointing out the problem!
8943	Joshua Slive	1020967486000	Thanks.  Fixed.  (And I only got it once.)
8944	Joshua Slive	1020970120000	Hmmm... Me thinks your browser is a little wacky.  This looks fine to me.\n\nBy the way, if you are interested in helping out in a more efficient way,\nyou might like to visit the documentation project:\nhttp://httpd.apache.org/docs-project/
8944	Cliff Woolley	1020970452000	nope, it really did have extra whitespace.  :)  fix committed.  thanks! 
8944	Joshua Slive	1020970929000	Ahh, sorry, I was looking at an almost identical example in mod_include.\nI should read more carefully.
9003	Justin Erenkrantz	1021273074000	This has been fixed in CVS and will be included in the next release!\n\nThanks for using Apache!
9011	Cliff Woolley	1021922696000	Note: this PR is very similar though not identical to PR9169.  
9011	Joshua Slive	1034822126000	[This is a mass bug update.]\nThis bug reports a problem in an older version of Apache 2.\nCould you please update to the most recent version and see\nif you can reproduce this problem.  If the bug still exists,\nplease update the bug with the latest version number.  If \nthe bug no longer exists, please close the bug report.\n\nSorry for this impersonal response, but we get many more bug\nreports than our volunteers can keep up with.\nThanks for using Apache!
9011	Erich Prchal	1034838328000	The problem did no longer occur since 2.0.39
9011	Eider Oliveira	1047476374000	This bug still occurs to me with version 2.0.44 at this configuration:\n\nStartServers        64\nServerLimit         96\nMinSpareThreads 256\nMaxSpareThreads 512\nThreadsPerChild 24\nMaxRequestsPerChild  0\n\nI don't have to get any load into the system. Just after start apache with this \nconfiguration this message starts do fill the log file.\n
9011	Jordan Ritter	1051056233000	Also having this problem on 2xP3-1.4GHz + Linux 2.4.20 + httpd 2.0.45 + openssl 0.9.7b + PHP 4.3.1, using \nMPM worker (threadpool).   Definitely vote for dropping this from ""crit''; system still seems to \noperate fine, except for filling up my error log. \n  \nConfiguration:  \n  \nServerLimit         200  \nStartServers        1  \nMaxClients          250  \nMinSpareThreads     5  \nMaxSpareThreads     10  \nThreadsPerChild     5  \nMaxRequestsPerChild 0  \n  \n  \n  
9011	Jordan Ritter	1051056465000	Sorry if this is bothersome, but looking at the code, I'm not sure I understand this properly, maybe \nthis is a bug?  I'm probably misunderstanding this..  pthread_kill() and kill() both return 0 on \nsuccess; shouldn't this loop be in a success condition if it successfully kills the thread?  Isn't \nthat the point of the loop?  If I interpreted it correctly, then this loop will always trigger the \nerror unless pthread_kill() or kill() fails, no?   \n  \n         iter = 0;  \n        while (iter < 10 &&  \n#ifdef HAVE_PTHREAD_KILL  \n               pthread_kill(*listener_os_thread, 0)  \n#else  \n               kill(ap_my_pid, 0)  \n#endif  \n               == 0) {  \n            /* listener not dead yet */  \n            apr_sleep(apr_time_make(0, 500000));  \n            wakeup_listener();  \n            ++iter;  \n        }     \n\t if (iter >= 10) { \n            ap_log_error(APLOG_MARK, APLOG_CRIT, 0, ap_server_conf, \n                         'the listener thread didn't exit'); \n        } \n \n \n  
9011	Jeff Trawick	1051059970000	passing 0 as the signal to kill() or pthread_kill() is just a check to see if\nthe process or thread is still alive\n\nthe purpose of that loop is to keep telling the listener thread to go away\nuntil either it goes away or we give up trying
9011	Jeff Trawick	1062790856000	Severity of the message has been changed to debug in 2.1-dev, and change will\nbe proposed for merge into 2.0.48-dev.\n\nThe message is of interest to developers only, and while it does represent\na glitch (listener thread not terminating in the cleanest possible way), there \nis no known impact of the glitch.\n
9011	Jordan Ritter	1075331604000	Sounds great, thanks!
9012	Andr?? Malo	1045666710000	It's fixed in 2.1 and proposed for backport. apxs checks the last LoadModule\nline on being within section(s) and puts the new line after that section(s) then.\n(AddModule will be treated similar in 1.3).\n\nThanks for your report and thanks for using Apache!
9012	Andr?? Malo	1045784255000	*** Bug 8712 has been marked as a duplicate of this bug. ***
9012	Andr?? Malo	1045946018000	This bug will be fixed in 1.3.28 and 2.0.45.
9014	Justin Erenkrantz	1021274004000	Woo-hoo!\n\nI was tracking this down last week, but I had to leave for WWDC and didn't\nfollow up.  Your patch is right and has been committed in revision 1.4 of\nmodules/filters/mod_deflate.c.  It will be included in the next release of\nApache 2.0!\n\nThanks for using Apache (and keep the patches coming)!
9014	Bruno Wolff III	1022814769000	I am still seeing these symptoms in the httpd-2.0_20020530221254.tar.gz\nsnapshot. The difference may be that for the files having problems\nthe output is generated by a cgi script and then fed through INCLUDES\nand then DEFLATE. 50KB files work OK. 450KB files fail to be\nuncompressed using lynx 2.5-dev, Netscape 4.08 and IE 5.?.\nI am running this under linux 2.2.16 (Redhat) on a Athlon Tbird.
9014	Bruno Wolff III	1022946336000	I tested things a bit more and found that if I am just using the\nDEFLATE filter things work OK. But when I use DEFLATE after INCLUDES\nthen they don't. I also tried just INCLUDES and the only\ndifferences were the expected ones.
9014	Jeff Trawick	1023292053000	Is there any chance that you can provide a sample CGI script that \ngenerates the right include tags to causes mod_include to create \na sequence of data that mod_deflate can't handle?\n\nThanks!
9014	Bruno Wolff III	1023293883000	A CGI-BIN script isn't needed to duplicate the problem.\nA sample broken link is at:\nhttp://wolff.to/area/test.html\nSource to the actual files is available at:\nhttp://wolff.to/area/test.txt\nhttp://wolff.to/area/sig.txt\nhttp://wolff.to/area/links.txt\nThe .txt files are sym links to the .html files. INCLUDES and DEFLATE\nfilters are run on .html files, but not on .txt files.
9014	Cliff Woolley	1023295600000	Justin Erenkrantz committed a patch to mod_deflate earlier today that might \nfix this problem.  Try out the CVS version of mod_deflate.c (rev 1.16) and see \nif that fixes your problem. \n \nThanks! 
9014	Bruno Wolff III	1023297317000	I tried 1.16 in a CVS snapshot from a few days ago and the problem\nappears to be fixed. I will be removing the test files shortly.\nThanks for fixing this.
9061	Jeff Trawick	1021384363000	This is now fixed in CVS.\n\nThanks for your report, and thanks for using Apache!\n
9065	Joshua Slive	1021483473000	Could you please do us a favor and find another fluent Catalan speaker to review\nyour work and post here confirming that your new translation is accurate.\n\nWe are trying to avoid the crappy translations we have had in the past.\n\nThanks!
9065	Sergi	1021802170000	Hi,\n\nI contacted a professional translator to get my Catalan page reviewed and she \ndid some rework on it... but now it looks great and should be 100% accurate :)\n\nYou can download it from http://www.geocities.com/chavalpk/index-html-ca.zip\n\nGreetings,\n\n - Sergi -\n\n
9065	Joshua Slive	1021930343000	OK.  I'll take your word for it and commit this.  In general, though, we prefer\nto have an independent person actually post here to confirm.\n\nThanks for your contribution!
9076	Psychopath	1029605000000	Same behaviour with 1.3.26 on Windows 2000 Professional. (even with simpler test-case, i.e. \nnormal directory, only 'Satisfy')\nI wonder whether this should be split into two bugs:\n- one \ndocumentation bug to make it clearer that access restrition by client host address AND \nusername/password ist _required_ if you want to use 'Satisfy'. (It only states 'is only \nuseful')\n- one bug, because Apache should log something like this in its error log.\n
9076	Andr?? Malo	1043770068000	Well, it's a broken logic in 'satisfy any' handling. Bug is fixed in 2.1.0-dev\nand proposed for backport.\n\nThanks for using Apache!
9076	Andr?? Malo	1043980139000	It's fixed now and will be available in the next release (1.3.28).
9181	Sander van Zoest	1021582643000	Created an attachment (id=1883)\nPatch: Adds ErrorHeader Directive\n
9181	Dirk-Willem van Gulik	1033737051000	This has been added in apache 1.3.27.\n\nDw.\n-- \nDirk-Willem van Gulik
9187	Cliff Woolley	1021659867000	Fixes committed, thanks. 
9222	Ian Holsman	1021853291000	fixed in current CVS tree\nThanks Kazuhisa.
9233	Jeff Trawick	1021981908000	The runtimedir creation problem is now fixed in CVS and will be in\nthe next release of Apache.\n\nIf you wish to pursue adding the FHS layout to config.layout, either post it \nto the dev@httpd.apache.org mailing list or open a separate PR \n(enhancement request) to track that issue.\n\nThanks for your report, and thanks for using Apache!\n
9244	Robin Johnson	1021883316000	I forget to add my configure options:\n\n./configure --enable-deflate --enable-mime-magic /\n--enable-expires --enable-headers /\n--enable-unique-id --enable-http --enable-dav /\n--enable-info --enable-cgi --disable-cgid /\n--enable-speling --enable-rewrite /\n--enable-so --enable-mods-shared=most
9244	Cliff Woolley	1021922418000	What do you get for ./httpd -l and ./httpd -V ?  \n  \nWith your ./configure arguments, configure says:  \n  \nchecking which MPM to use... prefork  \nchecking whether to enable mod_http... shared (most)  \nchecking whether to enable mod_mime... shared (most)  \n  \nmod_http should never be shared!!  \n  \nWhat's happened is that by explicitly specifying --enable-http, you've tricked \nit into allowing --enable-mods-shared=most to cause mod_http to be built as a \nshared module (DSO), which you can't do.  The link failures are because the \nsymbols exported from mod_http are missing.  Get rid of the --enable-http \nfrom the ./configure line and then mod_http will go back to being statically \ncompiled like it's supposed to be and it will work.  We should try to find \nsome way to detect this misconfiguration and either fix it automatically or \nat least fail more gracefully.  \n  
9244	Robin Johnson	1021927396000	Here is a patch that seems to work for me:\nIt is patterned after a similar fragment for the mod_so DSO.\n\n--- httpd-2.0.36/modules/http/config2.m4        Wed Oct  3 10:47:51 2001\n+++ httpd-2.0.36-new/modules/http/config2.m4    Mon May 20 13:14:41 2002\n@@ -4,8 +4,15 @@\n\n http_objects='http_core.lo http_protocol.lo http_request.lo'\n\n+dnl mod_http should only be built as a static DSO\n+if test '$enable_http' = 'yes'; then\n+    enable_http='static'\n+elif test '$enable_http' = 'shared'; then\n+    AC_MSG_ERROR([mod_http can not be built as a shared DSO])\n+fi\n+\n dnl mod_http freaks out when built as a DSO\n-APACHE_MODULE(http, HTTP protocol handling, $http_objects, , static)\n+APACHE_MODULE(http, HTTP protocol handling, $http_objects, , $enable_http)\n APACHE_MODULE(mime, mapping of file-extension to MIME, , , yes)\n\n APACHE_MODPATH_FINISH\n
9244	Cliff Woolley	1021927935000	yeah, I was actually just now working on a patch almost identical, also based on the one \nfrom mod_so.  you actually don't need the: \n-APACHE_MODULE(http, HTTP protocol handling, $http_objects, , static) \n+APACHE_MODULE(http, HTTP protocol handling, $http_objects, , $enable_http) \npart, since by now you've guaranteed that $enable_http == 'static'. \n \nI'll commit this change in a few minutes. \n \nThanks! 
9299	rea	1026776331000	Yes\nI have set UserDir to public_html but in order the access the users web site \nyou must add a / at the end line\n~user/ instead of just ~user\n\nBug or my fault?
9299	Joshua Slive	1026828886000	rea: Please don't modify someone else's bug unless you are sure you are adding\nuseful information.  The problem you are reporting has nothing to do with the\noriginal bug and is answered at\nhttp://httpd.apache.org/docs/misc/FAQ.html#set-servername
9299	Ryan Bloom	1033193478000	I have committed the patch below with a slight modification, along with some\ndocumentation.  Thank you for the bug report, and thank you for using Apache 2.0.
9316	Jonathan Knispel	1022080772000	  Here are some additional path corrections for the apxs script: \n \n    my $envvars = get_vars('bindir') . '/envvars'; \n \nshould use 'sbindir' instead of 'bindir'.  Or perhaps replace the \nget_vars() call with $CFG_SBINDIR. \n \n  There are a few other references to '$prefix/build' or variants. \nThey should be replaced with references to 'installbuilddir', or a \nnew variable $CFG_INSTALLBUILDDIR, defined in the same way as \n$CFG_SBINDIR.  Don't forget this one: \n \n    include %PREFIX%/build/special.mk \n \n  If it was just a matter of changing the script I'd offer a patch, \nbut I'm an Apache novice and I don't have time to figure out how \nto get the config_vars.mk path into the apxs script.  I'm just hacking \nit in by hand. \n \nRegards, \n                                          Jonathan Knispel 
9316	Jonathan Knispel	1022081185000	  Just looking at building mod_webapp for Tomcat, it would be very \nuseful if they could 'apxs -q installbuilddir'. 
9316	Jeff Trawick	1023278639000	The installbuilddir problem is a duplicate report (see 8453).  That\nproblem is now fixed.\n\nThe sbin/envvars problem has been fixed for some time.\n\nI'll change this to an enhancment request to track your suggestion\nto support 'apxs -q installbuilddir'.\n
9316	Jeff Trawick	1023278691000	fix the severity (now 'Enhancement')
9316	Jeff Trawick	1023451443000	'apxs -q installbuilddir' now works with the current code in CVS.\n
9319	Joshua Slive	1022081856000	That is not an internal apache error message.  That is a custom multi-lingual error \nmessage that comes distributed with the server.  See the ErrorDocument directives\nin httpd.conf for instructions on how to modify these.
9319	Will Rowe	1022082368000	\n  Frankly, Josh, that's a bogus answer.  We distribute those error docs, not\n  some third party we can blame :-)\n\n  I believe we were looking at this issue, it may already be resolved in .37,\n  the question was whether we should be changing the SERVER_STRING variable or\n  adding another variable to be used by the error docs.  This may be a duplicate\n  report, as well, we need to tie out this report if that is the case.\n
9319	Joshua Slive	1022083220000	Well, ServerSignature works as documented.\n\nPersonally, I don't see a need to provide two different ways to configure\nthe sample errordocuments.  You can already simply go and edit the\ninclude file to get rid of the info that you don't want.  Or if that\nis too complicated, comment out those ErrorDocuments and use the internal\nones.\n\nThe only way I see to get what you want is to add a SERVER_SIGNATURE\nenvironment variable and then go test for that in a bunch of places in the\nerror docs.  It won't be that easy.   Just changing the SERVER_SOFTWARE\nvariable won't be sufficient because there is also SERVER_NAME and SERVER_ADMIN\nused in various places that would be need to be controlled by ServerSignature\nto make things consistent.
9319	Ryan Bloom	1024124560000	I have commented out the offending variable.  If users want to add it back, they\ncan uncomment it.  Regardless, we shouldn't be including this information by\ndefault.\n
9410	Vasiliy Gagin	1022305777000	Created an attachment (id=1939)\nBug fix\n
9410	Will Rowe	1022357282000	\n  Applied, and further protected from unterminated or single null terminated\n  REG_MULTI_SZ data.  Thanks for your report and patch!
9413	Cliff Woolley	1022337584000	Right you are... Brad Nicholes had already caught one of these after 2.0.36 was \nreleased.  Justin Erenkrantz caught a similar one in PHP4 not long ago as \nwell.  I've committed your patch for the two remaining modules that were doing \nthis.\n\nThanks for using Apache!
9413	Cliff Woolley	1022377880000	*** Bug 7992 has been marked as a duplicate of this bug. ***
9413	Cliff Woolley	1023644186000	*** Bug 7635 has been marked as a duplicate of this bug. ***
9424	Joshua Slive	1023413985000	Thanks.  This will be fixed in the next update.
9446	Joshua Slive	1023414172000	This is a patch against 1.3.9, which is very old.  I believe this issue has\nbeen fixed in more recent versions.
9446	Stanislav Brabec	1023436830000	This path is agains 1.3.9--1.3.24. There was no need to update my patch. But I\nam not updating my Apache activelly.
9446	Andr?? Malo	1046440078000	Thanks! It's really fixed now for the next release (1.3.28).\n\nAnd sorry for the long delay ;-)
9469	Cliff Woolley	1022622587000	I've fixed this by apr-izing the time functions in that file.  (It's better to use \napr_time_exp_lt() than to proliferate localtime() vs. localtime_r() everywhere... that's \nthe whole point of APR.)  Thanks for the report! 
9534	Sven Koch	1024931271000	Created an attachment (id=2167)\nWorking Fix against 2.0.39, but still needs some work (uses Non-Apache-Constant EAGAIN)\n
9534	Bruno Wolff III	1024938684000	I tried this using the current CVS after receiving the update message\nand I am still seeing the problem. I am including an extract from\nmy rewrite log. I changed the script to return the IP address it was\nasked to lookup which should match that of the request. The log makes\nit clear that it doesn't. I also included part of my httpd.conf\nfile relating to the external map. I am running a 2.2 linux kernel.\nIf you need other information, I should be able to probably help. I really would\nlike to see this issue fixed. Thanjs for working on this issue.\nRewriteLock /home/httpd/html/robot/lock\nRewritemap blocked prg:/home/httpd/html/robot/check.pl\n127.0.0.1 - - [24/Jun/2002:12:02:03 --0500] [localhost/sid#81a6cc0][rid#8241120/initial] (5) map lookup OK: map=blocked key=127.0.0.1 -> val=\n127.0.0.1 - - [24/Jun/2002:12:02:05 --0500] [localhost/sid#81a6cc0][rid#8241120/initial] (5) map lookup OK: map=blocked key=127.0.0.1 -> val=OK-127.0.0.1\n64.24.12.167 - - [24/Jun/2002:12:02:11 --0500] [wolff.to/sid#81a6cc0][rid#8247138/initial] (5) map lookup OK: map=blocked key=64.24.12.167 -> val=OK-127.0.0.1\n64.24.12.167 - - [24/Jun/2002:12:02:13 --0500] [wolff.to/sid#81a6cc0][rid#8241120/initial] (5) map lookup OK: map=blocked key=64.24.12.167 -> val=OK-64.24.12.167\n64.24.12.167 - - [24/Jun/2002:12:02:14 --0500] [wolff.to/sid#81a6cc0][rid#8241120/initial] (5) map lookup OK: map=blocked key=64.24.12.167 -> val=OK-64.24.12.167\n127.0.0.1 - - [24/Jun/2002:12:02:18 --0500] [localhost/sid#81a6cc0][rid#8241120/initial] (5) map lookup OK: map=blocked key=127.0.0.1 -> val=OK-64.24.12.167
9534	Cliff Woolley	1024938825000	This issue is not yet fixed in CVS.  The patch attached to this PR has not yet \nbeen committed.  I've reviewed it, though, and it seems quite on-target.  I'll \ncommit a variant of it (fixing it to use APR_EAGAIN) sometime tonight. \n \n--Cliff 
9534	Bruno Wolff III	1025187519000	Sorry this took a while. I managed to miss that you had included\nthe patch in the bugzilla entry so that I could use it before it\nwas committed to CVS. I just tried out the patch applied to the\ncurrent CVS (about two hours old) and it seemed to fix my problem.\nThanks.
9534	Sven Koch	1029858292000	Just adding:\nit is not fixed in apache 2.0.40, the same ugly patch from 2.0.39 is still needed.\n
9534	Cliff Woolley	1029864890000	Okay, upon further investigation, I believe the correct fix is actually this: \n \nline 3463: \n \n-        ((rc = apr_procattr_io_set(procattr, APR_FULL_BLOCK, \n-                                  APR_FULL_NONBLOCK, \n-                                  APR_FULL_NONBLOCK)) != APR_SUCCESS) || \n+        ((rc = apr_procattr_io_set(procattr, APR_FULL_BLOCK, APR_FULL_BLOCK, \n+                                   APR_NO_PIPE)) != APR_SUCCESS) || \n \n \nIt's because reads are set to nonblocking mode that we're getting hosed here.  \nYou shouldn't have to check for APR_EAGAIN from apr_file_read()... it's only \ngetting returned because we told it to (by setting nonblocking mode).  Oops! \n \nPlease let me know if this fixes it and I'll commit the change. \n \n--Cliff 
9534	Bruno Wolff III	1029949785000	I tested the suggestion to change the read to blocking and it seemed\nto work correctly. (I had also removed the previous fix for this test.)
9534	Cliff Woolley	1029952155000	Fixed for 2.0.41. \n \nThanks for your feedback! 
9534	Joshua Slive	1030653714000	*** Bug 12175 has been marked as a duplicate of this bug. ***
9587	David Shane Holden	1023409964000	Created an attachment (id=2021)\nRemoves the filename mod_dir attaches to the request_rec before find_icon receives it.\n
9587	Will Rowe	1023420502000	\n  An extra stat()?  (and in the wrong place, at that.)  ICK.\n\n  The essentials are that we already stat()ed this somewhere \n  in the way-back machine, and then ran it through to discover\n  that it is really something else [e.g. requesting /foo/ will\n  return an html document ... index.html in that directory.]\n  That means it is -more- than just another folder.\n\n  The correct fix is probably deeper in the code.  I expect we\n  will need to determine the stat() just a little bit earlier.\n  If I can prove the stat() always occurs, and that dir_walk\n  and file_walk will just borrow the pre-existing stat, then\n  noone should shoot us for requesting more detailed information\n  from apr_dir_read().\n\n  In any case, this should NOT BE OCCURING on Win32 unless some\n  patch to dir_walk, autoindex, or sub_req_lookup_dirent has it\n  borked.  Win32 apr_dir_read() already returns much more fileinfo\n  than most Unix platforms.\n\n  I will look at it, though I can't promise a fix in the 2.0.37\n  timeframe.  Certainly by 2.0.38.\n\n  \n\n  
9587	David Shane Holden	1023427593000	The problem arises when mod_autoindex calls ap_sub_req_lookup_dirent on each of\nthe sub directories.  The returned request_rec.filename has the DirectoryIndex\nfile attached to it.  So, I figured it was best to strip that file off the end\nof the rr.filename before passing it to find_icon.\n\nThe ap_is_directory call is far from necessary... all that's needed is\n    rr->filename = ap_make_dirstr_parent (rr->pool, rr->filename);\n\n
9587	Will Rowe	1023461397000	\n  'The problem arises when mod_autoindex calls ap_sub_req_lookup_dirent \n  on each of the sub directories.'\n\n  This is why the code once relied on dirent->type instead of rr->finfo->type.\n  However, some folks pointed out that Unix doesn't determine the filetype on\n  a dirread() call, and we would have to beg unix to do so.  However, if we\n  did that, we would want to prove we aren't wasting extra stats, and that\n  ap_sub_req_lookup_dirent will pass that info on to rr->finfo, which dir_walk\n  will actually consume.\n\n  If that code works correctly, it's just a matter of passing APR_FINFO_MIN\n  along with APR_FINFO_DIRENT switches to apr_dir_read.\n
9587	andy d	1058237162000	 i had to tweak the mod_autoindex.c in the\nlatest version of apache to get it\nto work right.  here are my work arounds:\n\n         //if (!(p->icon = find_icon(d, rr, 1))) {\n                // was getting wrong icons on folders\n                p->icon = find_default_icon(d, '^^DIRECTORY^^');\n            //}\n            if (!(p->alt = find_alt(d, rr, 1))) {\n                if (!(p->alt = find_default_alt(d, '^^DIRECTORY^^'))) {\n                    p->alt = 'DIR';\n                }\n            }\n        }\n        else {\n            p->icon = find_icon(d, rr, 0);\n            p->alt = find_alt(d, rr, 0);\n            p->size = rr->finfo.size;\n        }\n\n\n        p->desc = find_desc(d, rr->filename);\n\n        if ((!p->desc) && (autoindex_opts & SCAN_HTML_TITLES)) {\n                //added this check -- was getting garbage description on folder\n           if (dirent->filetype != APR_DIR)  \n                p->desc = apr_pstrdup(r->pool, find_title(rr));\n        }
9587	David Shane Holden	1058255496000	Commenting out 'if (!(p->icon = find_icon(d, rr, 1)))' breaks the ability to\nspecify an icon for a directory with an AddIcon directive .  I've walked through\nthis code a ton of times and the simplest patch i've come up with is...\n\nIndex: modules/generators/mod_autoindex.c\n===================================================================\nRCS file: /home/cvspublic/httpd-2.0/modules/generators/mod_autoindex.c,v\nretrieving revision 1.119\ndiff -u -r1.119 mod_autoindex.c\n--- modules/generators/mod_autoindex.c  2 Mar 2003 18:06:16 -0000       1.119\n+++ modules/generators/mod_autoindex.c  15 Jul 2003 07:28:50 -0000\n@@ -1361,6 +1361,7 @@\n             if (autoindex_opts & FOLDERS_FIRST) {\n                 p->isdir = 1;\n             }\n+            rr->filename = ap_make_dirstr_parent (rr->pool, rr->filename);\n             if (!(p->icon = find_icon(d, rr, 1))) {\n                 p->icon = find_default_icon(d, '^^DIRECTORY^^');\n             }\n\nwhich removes the appended filename added by mod_dir, if any, from rr->filename\nwhich results in find_icon seeing the correct filename.\n
9587	Andr?? Malo	1058275902000	this looks reasonable to me. Committed in 2.1 and proposed for backport.\n\nThanks for patch (and your patience :), Shane.
9587	Andr?? Malo	1063177700000	*** Bug 23050 has been marked as a duplicate of this bug. ***
9644	Jeff Trawick	1023735439000	This is now fixed in CVS and will be in the next release of Apache.\nYou can use this patch if you want:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/protocol.c.diff?\nr1=1.105&r2=1.106\n\nThanks for your report, and thanks for using Apache!\n
9673	Joshua Slive	1023391794000	I'm fairly sure that it is the filter itself that should be removing the\nlast-modified.  There are many filters that do not affect caching, so\napache should not be removing last-modified for every filter.\n\nSo, the punch line is, you should file this bug report with PHP.
9673	Christian Kohlsch	1023396626000	The problem is that the PHP filter is not called. Here is a dump of the \nclient-server communication: \n \n---------> from Client to Server \nGET / HTTP/1.1 \nAccept: */* \nIf-Modified-Since: Thu, 06 Jun 2002 17:47:44 GMT; length=17947 \nHost: www.newsclub.de \nConnection: Keep-Alive \n \n<-------- Reply from Server to Client \n \nHTTP/1.1 304 Not Modified \nDate: Thu, 06 Jun 2002 17:50:08 GMT \nServer: Apache/2.0.36 (Unix) DAV/2 PHP/4.2.1 \nConnection: Keep-Alive \nKeep-Alive: timeout=15, max=100 \nETag: '66ab2-4ef-63a14340' \n \n--------- End of reply, that's it - no content! \n \nSo, there is neither PHP output nor the PHP source code at all, Apache seems \nto block further processing of the request. \n 
9673	Joshua Slive	1023396969000	Still a PHP problem.\n\nContent is never returned on a 304 response.  That is the point of the response.\nWhat is happening is that Apache is running the request, seeing the \nlast-modified information, and deciding that the client already has\nup-to-date content, so it doesn't need to send it again.\n\nIt is the responsibility of the PHP filter to\nremove the last-modified information so that apache always serves\nfresh content.\n
9673	Joshua Slive	1023397445000	Oops.  I take it all back.\n\nI just tried with mod_include's INCLUDES filter, and even though it strips\nLast-Modified, Apache still serves conditional GET requests.  Ouch.\n\nHere's an example:\nab26[joshua]59% telnet httpd.apache.org 80\nTrying 63.251.56.142...\nConnected to httpd.apache.org.\nEscape character is '^]'.\nGET /docs/vhosts/index.html HTTP/1.1\nHost: httpd.apache.org\nIf-Modified-Since: Thu, 06 Jun 2002 20:58:16 GMT\n\nHTTP/1.1 304 Not Modified\nDate: Thu, 06 Jun 2002 21:01:29 GMT\nServer: Apache/2.0.37-dev (Unix)\nETag: 'ea72a-b3f-f3b22680;2434f440'\nContent-Location: index.html.en\nVary: negotiate,accept-language,accept-charset\n\n
9673	Joshua Slive	1023397962000	And what the heck is that ETag doing in the 304 response?  It is not in\nthere for a normal response:\nHEAD /docs/vhosts/index.html HTTP/1.1\nHost: httpd.apache.org\n\nHTTP/1.1 200 OK\nDate: Thu, 06 Jun 2002 21:09:12 GMT\nServer: Apache/2.0.37-dev (Unix)\nContent-Location: index.html.en\nVary: negotiate,accept-language,accept-charset\nTCN: choice\nAccept-Ranges: bytes\nContent-Length: 3158\nContent-Type: text/html\nContent-Language: en\n\nAnd what the heck is the Content-Length doing in the normal response?\n\nBoth Content-Length and ETags are explicitly unset by mod_include.\n\nI'm afraid I'm out of my league here, so I'll need to leave this to others.
9673	Cliff Woolley	1023398038000	The If-Modified-Since and If-Unmodified-Since logic uses r->mtime as the time of the entity being served, not the Last-Modified header.  I assume this is an optimization to avoid reparsing Last-Modified.  So either stripping Last-Modified is not enough (also set r->mtime to 0), or we need to change the logic on line 316 of http_protocol.c.  Note though that this is also how Apache 1.3 deals with it, so I'm not sure I see what the problem is.  Sounds like a bug (misunderstanding?) in mod_include and mod_php4.  --Cliff 
9673	Cliff Woolley	1023398290000	The Content-Length is probably being generated by the content length filter \n(that's its job).  Not sure about the etag, but I do remember some discussion \nabout that recently I think... 
9673	Christian Kohlsch	1023398715000	As I understand, the problem is the filter concept itself.    \nFilters are applied on data that is already processed by http_protocol.c    \n    \nWhat http_protocol.c checks is the modification time of a file, ie.    \n'index.php'. The script has been written in 2001, for example, but it produces    \nnew content from a database every minute.    \n    \nSo, the PHP code gets only executed, if Apache decides to pass the data to the    \nfilter. Here Apache decides not to, because it thinks that the file has not    \nchanged.    \n    \nThe ETag is probably generated because Apache looks at the program code of    \nindex.php itself, not at the content the PHP script produces.    \n   \nI suggest to add an Apache directive to disable If-Modified-Since processing   \nfor Filtered files, for example:   \n   \n<FilesMatch '/.php$'>   \n    SetInputFilter PHP   \n    SetOutputFilter PHP   \n    CheckIfModifiedSince off   \n</FilesMatch>   \n   \nPHP itself could then automatically set this directive.   \n  
9673	Joshua Slive	1023398929000	I disagree.  It should be the filter's responsibility to decide if it\nmodifies the data, not the administrator.  If the filter wants to\ndeligate that job to the administrator (like mod_include does with\nXBitHack full) then it can do so.
9673	Christian Kohlsch	1023399338000	But somehow, http_protocol.c must get that information. \n \nIs there a way to check for a certain filter in http_protocol.c? \nThat would enable me to write a quick hack for PHP. \n \nCurrently, I have disabled 'not modified' replies at all, which is \nno good idea... \n 
9673	Justin Erenkrantz	1023399921000	This is due to a bug in PHP and in the httpd-2.0 core.\n\ndefault_handler shouldn't be calling ap_meets_condition().  As I posted to\ndev@httpd, this decision should most likely be delayed until the\nap_http_header_filter() is called.\n\nHowever, PHP's use of filters is completely and totally broken in many ways.  =)\n First off, it doesn't unset Last-Modified which it needs to do.  There's a lot\nof bogosity in how it deals with buckets.  I've posted before to php-dev@ about\nthis.
9673	Christian Kohlsch	1023400705000	Can someone give me a hint how to write a quick fix for it? \nI would just need to check if PHP is in the filter chain. \n 
9673	Cliff Woolley	1023400924000	That's easier said than done.  Easier is the seemingly 'right' fix that Justin \nproposed: move the ap_meets_conditions() call from the default_handler to the \nap_http_header_filter. \n \n--Cliff  
9673	Daniel Eckl	1027178096000	I'd like to post a workaround without patching apache or PHP....\n\nJust edit your script(s) to send a 'header('Last-Modified: Mon, 26 Jul\n1997 05:00:00 GMT');' or just some other date older than the mdate of\nyour script file. This solves the problem.\n\nReason:\nThe bug causes Apache2 to look for the mdate of the .php file to\ndetermine if it has been modified.\nIf the browser first gets a header like above, it next time asks for the\npage with an 'If-Modified-Since: Mon, 26 Jul 1997 05:00:00 GMT'. Then,\nthe httpd looks at the mdate of your script, which is always newer and\nsays: Yes, it has been modified, '200 OK'. The script will be served and\nit will response again with the header line from above. Round and round\nthe story goes. :))\n\nGreets, and have fun!\n\nDaniel
9673	Christian Kohlsch	1027251260000	Daniel: Your workaround solves the problem, but creates another one. \nSearching engines that spider the pages would see 'old' Last-Modified headers \nand therefore will not index them. \n \nAt NewsClub.de, the pages are updated at least every 30 minutes, so this \nfix is at least not good for me. \n \nMaybe the bug is even fixed in the current CVS versions of apache2 and php4? \n 
9673	Daniel Eckl	1027430056000	Hmm, the actual Changelog contains:\n\n  *) Add a filter_init parameter to the filter registration functions\n     so that a filter can execute arbitrary code before the handlers\n     are invoked.  This resolves a problem where mod_include requests\n     would incorrectly return a 304.  [Justin Erenkrantz]\n\nIs this the solution to our problem?\nI'm compiling httpd-2.0_20020723101312 at the moment and will try it.
9673	Daniel Eckl	1027488026000	I'm sorry, problem not solved yet using the latest unstable cvs code of both \nphp4 and httpd-2.0.\n\n...but they are compiling and running fine :))))
9673	Justin Erenkrantz	1033317034000	This should be fixed in Apache 2.0.42 and later.\n\nUnknown when exact fix was committed (probably much earlier than 2.0.42), but\nthe behavior works as expected for filtered content now.
9673	Erlend Stromsvik	1040378574000	I'm still having this bug, even with the 'short fix' Daniel Eckl posted. :-/\n\nRunning Apache 2.0.43 for Windows with php-4.2.3-Win32.
9673	Sascha Kulawik	1040379129000	Try PHP 4.3.0 BETA, it seems to be working now.
9673	stephen fox	1040649788000	This bug has been closed but appears to still persist.  I'm running Apache \n2.0.43 with PHP 4.3 and I still have this issue.  Has it been decided wether \nthis is legitimately a bug in Apache or PHP yet?  I have heard it thrown around \nas a PHP bug by Apache and an Apache bug by PHP and was wondering if either \nside has given in and said where the bug really is.\n\nThank you,\nSteve
9673	Daniel Eckl	1040860205000	The problem can be worked around in php.\n\nSee http://bugs.php.net/bug.php?id=17098\n\nDaniel
9673	Justin Erenkrantz	1045439339000	Yes, the filter_init hook resolved this.  See how mod_include and mod_php (in their CVS tree) do it.  It should be included in the next PHP release if it isn't already, but there isn't anything more we can do with this issue.  The API is there.\n\nThanks for using Apache HTTP Server!
9729	Jeff Trawick	1023728449000	Your fix has been committed to Apache 2.0.\n\nThanks for your patch, and thanks for using Apache!\n
9770	Jeff Trawick	1023807426000	This has now been fixed.  We just missed the cutoff for 2.0.37, so expect the\nfix in 2.0.38.  For now, you can use this small patch to mod_rewrite:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/mappers/mod_rewrite.c.diff?\nr1=1.121&r2=1.122\n\nThanks for your report, and thanks for using Apache!\n
9770	Joshua Slive	1023832899000	*** Bug 9783 has been marked as a duplicate of this bug. ***
9787	Ryan Bloom	1024125579000	I have committed this to CVS, and it will be available in the next release.\n
9858	Cliff Woolley	1024131674000	This has been fixed in CVS and will be good to go in 2.0.38.  Thanks for your \nreport!
9866	Ping Xiao	1024062081000	Don't know how to correct original description, so I add my correction here:\n\nIt didn't actually perform the 'do 2' but it performed the 'if true 2' \nwhen 'true 1' was satisfied.\n
9866	Brian Pane	1024120374000	Thanks for catching this.\n\nI've just committed a fix for inclusion in 2.0.38 (which hopefully\nwill be tagged tomorrow).
9977	Andr?? Malo	1045095024000	It's fixed in 2.1 (using the patch provided in\nhttp://bugs.apache.org/index.cgi/full/5913) and proposed for backport.\n\nThanks for the report and thanks for using Apache!
9977	Andr?? Malo	1045945614000	Finally fixed in 1.3 and 2.0 branch. It will appear in the next releases (1.3.28\nand 2.0.45).
9989	Cliff Woolley	1024507661000	AWWWW MAN!!! Sorry, my fault.  The logic before said : \n \nif (*mask & (APHTP_NEWFILE & APHTP_NOFILE)) { \n \nwhich was visibly broken, so I changed it without actually testing to what it \nis now, which is also wrong.  ;( \n \nAnyway, I'm officially changing it to: \n \nif ((*mask & APHTP_NEWFILE) && (*mask & APHTP_NOFILE)) { \n \nI'll place a patch in \nhttp://www.apache.org/dist/httpd/patches/apply_to_2.0.39/ \n \nThanks for your report! 
9989	Will Rowe	1024604456000	*** Bug 10075 has been marked as a duplicate of this bug. ***
9989	Will Rowe	1024604465000	*** Bug 10014 has been marked as a duplicate of this bug. ***
9989	David Tonhofer	1024926128000	This bug is back in 2.0.39:\n\n    if (*mask & (APHTP_NEWFILE | APHTP_NOFILE)) {\n        apr_file_printf(errfile, '%s: -c and -n options conflict/n', argv[0]);\n        exit(ERR_SYNTAX);\n    }\n
9989	Cliff Woolley	1024929359000	Yes, I know the bug is in 2.0.39.  That's why I gave a URL for a patch that \nis /dist/httpd/patches/apply_to_2.0.39/.  :)  The first version released with \nthe patch incorporated will be 2.0.40.\n\n--Cliff
9989	Cliff Woolley	1025238840000	*** Bug 10309 has been marked as a duplicate of this bug. ***
9989	David Shane Holden	1027644576000	*** Bug 11173 has been marked as a duplicate of this bug. ***
10074	Jeff Trawick	1024601413000	The code is not in main.c; it is called before the normal cmd-line processing in\nmain.c runs.\n\nWhat is the symptom when you use apachectl from 2.0.39?  What is the output\nof 'apachectl -V'?
10074	James Dugal	1024631991000	Created an attachment (id=2144)\nscript demonstrating the problem, and httpd -V, -l report\n
10074	Jeff Trawick	1024654771000	Oh, the perchild MPM :)\n\nIf I can get it to build I'll make the minor change necessary to get it to\nsupport -k.\n\nThanks for the extra doc!\n\n
10074	Jeff Trawick	1024657339000	This problem with the perchild MPM as been fixed in CVS and will be in the\nnext release.  In the meantime, you can use this patch:\n\nIndex: server/mpm/experimental/perchild/mpm.h\n===================================================================\nRCS file: /home/cvs/httpd-2.0/server/mpm/experimental/perchild/mpm.h,v\nretrieving revision 1.16\ndiff -u -r1.16 mpm.h\n--- server/mpm/experimental/perchild/mpm.h      1 Apr 2002 08:27:42 -0000       1.16\n+++ server/mpm/experimental/perchild/mpm.h      21 Jun 2002 10:53:29 -0000\n@@ -76,6 +76,7 @@\n #define AP_MPM_WANT_SET_MAX_REQUESTS\n #define AP_MPM_WANT_SET_COREDUMPDIR\n #define AP_MPM_WANT_SET_ACCEPT_LOCK_MECH\n+#define AP_MPM_WANT_SIGNAL_SERVER\n #define AP_MPM_USES_POD\n\n #define MPM_CHILD_PID(i) (ap_scoreboard_image->parent[i].pid)\nIndex: server/mpm/experimental/perchild/perchild.c\n===================================================================\nRCS file: /home/cvs/httpd-2.0/server/mpm/experimental/perchild/perchild.c,v\nretrieving revision 1.126\ndiff -u -r1.126 perchild.c\n--- server/mpm/experimental/perchild/perchild.c 13 Jun 2002 16:36:19 -0000     \n1.126\n+++ server/mpm/experimental/perchild/perchild.c 21 Jun 2002 10:53:30 -0000\n@@ -1999,7 +1999,7 @@\n\n module AP_MODULE_DECLARE_DATA mpm_perchild_module = {\n     MPM20_MODULE_STUFF,\n-    NULL,                       /* hook to run before apache parses args */\n+    ap_mpm_rewrite_args,        /* hook to run before apache parses args */\n     NULL,                       /* create per-directory config structure */\n     NULL,                       /* merge per-directory config structures */\n     perchild_create_config,     /* create per-server config structure */\n\nApply the patch, then 'make clean && make && make install'.\n\nThanks for your report, and thanks for using Apache!\n
10130	Will Rowe	1024681257000	\n  Please describe\n\n   1. how you invoked the build (in the studio ide?  which target project?\n      command line?  what command?)\n   2. is awk correctly installed on your machine?\n   3. which package you obtained (-win32-src.zip?  .tar.gz?  CVS checkout?)\n   4. what Visual Studio 6.0 service pack you have installed.\n
10130	Dustin Cavanaugh	1024686024000	Built with /VS C++ 6.0/sp5.\nTarget project InstallBin - Win32Release.\nBuild command line: 'NMAKE /f makefile.win INSTDIR='/Apache2' SHORT=R \nLONG=Release _install'.\n\nawk: From command line:\nC:/>awk --version\nGNU Awk 3.0.6\nCopyright (C) 1989, 1991-2000 Free Software Foundation.\n\nSource: httpd-2.0.39-win32-src.zip downloaded from mirror.
10130	Will Rowe	1024687242000	\n  Since I can reproduce this on DevStudio 7.0 (missing the #include clue that we\n  better generate ApacheMonitorVersion.rc in order to compile ApacheMonitor.rc)\n  I'm leaving this report open.\n\n  However, I expect the problem lies in GNU 3.06 built under [???  cygwin?]\n  Can you share where you obtained that, if it is cygwin (perhaps the command\n  depends awk.exe  will reveal which clib and other .dll's it's bound to.)\n\n  cygwin does it's own thing with pathnames and so forth, and cannot handle\n  win32 backslash path delimiters and the like.  It's very possible that your\n  problem is isolated to this issue.\n\n  Please track further discussion with your GNU [cygwin?] awk on bug 10131.\n  This indicent will track DevStudio's unwillingness to grok #include in\n  .rc source files.
10130	James Cox	1024765106000	i'd like to grab this bug if no-one objects...
10130	Will Rowe	1024776164000	\n  Please do James... see the microsoft.public.vc.ide_general list for some \n  observations, just search for .rc and #include and you will see others have\n  observed this same behavior and some [not many] have worked around it on\n  Visual Studio 7.0.  I suspect the user's problems in VS6.0 were phantoms of\n  not having a working awk.\n\n  After you create an account on this bugzilla, you might want to see yourself\n  to this bug.\n
10130	Ryan Bloom	1026100608000	I have committed a fix for this.  Please test the latest CVS and let us know if\nit solves your problem.
10130	Dustin Cavanaugh	1026139669000	I don't know what you mean, 'test the latest CVS'. I pulled\nhttpd-2.0_20020708101252.tar.gz and httpd-2.0_20020708041218.tar.gz, but neither\nApache.dsw would load anything into VC++ 6.0.\n\nAre you referring to other code somewhere else?
10130	James Cox	1026177089000	OK, i fixed this and the patch was committed by Ryan yesterday into CVS. You \nmay wish to check a snapshot from today, and make sure your env is extraclean.\n\n -- james
10146	Kozin Maxim	1024743105000	Created an attachment (id=2156)\ncode for DoS 2.0.39 on FreeBSD 4.[56]\n
10146	Justin Erenkrantz	1026111835000	Fixed in CVS.  Will be included in next release (2.0.40).  Thanks for using Apache httpd!
10147	Jeff Trawick	1024757657000	I wasn't able to reproduce the lost filter definition when using this configuration:\n\n<Directory /photo>\nDirectoryIndex index.cgi\nOptions Indexes ExecCGI\nAddHandler cgi-script .cgi\n\nSetOutputFilter sed-replace\nExtFilterOptions DebugLevel=9\n</Directory>\n\nExtFilterDefine sed-replace cmd='/bin/sed 's/photos/picurs/g''\n\n(I didn't see any output at the client because sed got confused by the single\nquotes.  When I remove the single quotes it works fine.)\n\nCan you spot something about my testcase which is inconsistent with your\ndescription, or can you perhaps supply a set of minimal changes to the\ndefault httpd-std.conf which would expose the problem?\n\nThanks so much!\n\n(Certainly I need to update the doc to describe quoting issues like this!!)\n
10147	Christoph Vogel	1024762334000	I did it the other way 'round and tried to reproduce your situation :)\nIt does work if the ExtFilterDefine and the ExtFilterOptions statement are \nlocated _within the same VH_.\nIn my configuration ExtFilterDefine is located in the main config (so I can \nreuse it otherwhere) and ExtFilterOptions + SetOutputFilter in a directory \ncontext within a VH. Contrarily the ExtFilter works fine in this situation if \nExtFilterOptions is not set. So the bahaviour is inconsistent and I think one \nshould have the possibility to split Define and Options for ExtFilter just like \nI did.\nApart from that - wouldn't it be nice to have a separate logfile for ExtFilters \njust like with CGIs oder URL rewriting? I dunno if it's a enough for a formal \nfeature request.
10147	Jeff Trawick	1024937137000	Thanks for the update...  I was able to reproduce and am working on a change\nto mod_ext_filter so that filter definitions can be used across multiple\nservers/vhosts.\n\n(I'm ignoring your feature request for the moment :) )\n\nThanks again!\n
10147	Jeff Trawick	1025121675000	mod_ext_filter has been changed to find filter definitions in the main\nserver in case they weren't defined in the vhost...  the patch as committed\nis below, and will be in the next release of Apache:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-\n2.0/modules/experimental/mod_ext_filter.c.diff?r1=1.29&r2=1.30\n\nI tweaked the documentation to try to clarify how parameters to the\nexternal program are specified.  In addition, I added a new example\nwhich you might recognize.\n\nIf you really want to have stderr from the filter written to a file,\nplease write another PR for the feature request.  I don't personally\nplan on doing anything about that unless it is clear that there is\na widespread desire for it.  (Other folks may be interested however.)\nNote that the LogStderr option (on the ExtFilterOptions directive) can \nbe used to capture the external filter's stderr in the Apache error log.\n\nThanks again for your report!\n
10216	Jiri Novak	1025016626000	Primary, I need load and CACHE any cgi script (windows library) without \nunloading. I'm windows programer so I don't know other option except ISAPI... \nAny help please?
10216	Jiri Novak	1025075943000	I traced SSL is without influence...
10216	Jiri Novak	1025085929000	Hi again boys.\n\nI changed line 1532 in 'mod_isapi.c' from \n\n    /* Set the status (for logging) */\n    if (cid->ecb->dwHttpStatusCode) {\n        cid->r->status = cid->ecb->dwHttpStatusCode;\n    }\n\nto\n\n    /* Set the status (for logging) */\n    if (cid->ecb->dwHttpStatusCode && cid->ecb->dwHttpStatusCode!=200) {\n        cid->r->status = cid->ecb->dwHttpStatusCode;\n    }\n\nI don't check what you do with 'cid->r->status' variable,\nbut it resolve my problem.\n\nAve, GeniuZ\n
10216	Will Rowe	1036417930000	\n  Have just committed a bugfix for this report.\n\n  Rather than Status!=200 tests, we will simply track response_sent, and\n  once it has been sent, we will return 0 (assuring the server core module\n  that it's been handled.)  This also assures that if the ISAPI module wants\n  to return the 200, or 500, or redirect, and completely handles it internally,\n  that this bug won't appear again.
10259	marcs@znep.com	1025116689000	It is supposed to have a charset param when not using custom errordocuments beca\nuse we output a response body with HTML in it, and we are specifying what charse\nt that response body has.  This is not a 'default' charset, it is the charset th\nat we wrote the document in.\n
10259	Klaus Johannes Rusch	1027438278000	Since the generated page uses ISO-8859-1 the charset parameter is allowed but \nnot required on the redirect response. Removing the charset attribute will have \nno effect on compliant browsers, and resolve the issue for non-compliant \nbrowsers.
10259	Bill Stoddard	1029161535000	The current Apache behaviour is correct but breaks some older versions of \nNetscape. I suggest code be added to enable a BrowserMatch directive to \nselectively disable adding the charset (specifically on redirects?).
10259	Joshua Slive	1029783405000	The suppress-error-charset variable is now available for this purpose.
10324	Jeff Trawick	1028130308000	I renamed the field certtdb to certdb in util_ldap.h (part of httpd-2.0\ndistribution).  I don't see the word 'certtdb' being used anywhere else\nin the world :)\n\nThanks for your report, and thanks for using Apache!\n
10422	Ryan Bloom	1025639416000	Fixed in CVS, we weren't adding a newline at the end of each record.
10422	Cliff Woolley	1025639688000	*** Bug 10221 has been marked as a duplicate of this bug. ***
10422	Jon Noack	1026108515000	Why did no one look at bug 10221?  I had this issue fixed via an attached patch \non 6/27, while it was fixed in CVS until 7/2.  Basically, I'm just wondering \nwhat, if anything, I need to do differently to be heard.
10422	William Campbell	1026135130000	I searched the database for this problem and saw nothing similar, otherwise I \nwould not have posted it.\n
10422	Andr?? Malo	1046552575000	Just a word. People actually try to track the bug db, but it's mostly done in\ntheir spare time, which is quite limited, as you may guess.\n\nThanks for your reports and for using Apache.
10424	Jeff Trawick	1025646768000	Thanks for your report.  This has now been fixed in CVS\nand updated on httpd.apache.org.\n\n
10430	Jeff Trawick	1037796781000	The doc was fixed some time ago.  The config in highperformance-std.conf\nwas just now fixed and will be in the next release.\n\nThanks for your report, and thanks for using Apache!\n
10449	Andr?? Malo	1044847147000	hmm, shouldn't one check for a '=' sign?\n\n(or alternatively append a '=' to the variable names within the 'safe' list?)\nOptions?
10449	Joshua Slive	1044887407000	I guess it could be fixed with just a quick strlen comparison.\n\nBut note that this is probably not a security risk.  The point of cleaning\ndown the environment is to prevent unsafe env variables from being passed\n(think LD_LIBRARY_PATH, etc).  It is HIGHLY unlikely that an attacker\nwould be able to construct an unsafe env variable using a prefix of a\nsafe env variable.
10449	Andr?? Malo	1045684729000	strlen doesn't work here, because the env array consists of enties ala\n'PATH=/foo/bar'.\n\nBut you're right, it's not really a security risk. But I'm pedantic ;-))\nI found, however, <http://bugs.apache.org/index.cgi/full/2790> and I think, most\nof the stuff suggested there is worth to be patched. (the current problem is\nalso described there - with the same solution, I proposed here 5 years later ;-)
10449	Andr?? Malo	1045690988000	Well, it's fixed in 2.1 and proposed for backport.\n\nThanks for the report and thanks for using Apache!
10449	Andr?? Malo	1045945709000	The fix will appear in 1.3.28 and 2.0.45.
10460	Will Rowe	1029704290000	\n  I believe we have addressed this in Apache 2.0.40 - please upgrade\n  and check out the new behavior.  There were several bogus permission\n  assumptions that -have- been fixed.
10460	Tamer Abdelgawad	1029706496000	Done and done.  Service monitor now works correctly with 2.0.40.\n\nThanks.
10574	Phil Almquist	1026239964000	*** Bug 10514 has been marked as a duplicate of this bug. ***
10574	Joshua Slive	1029782952000	I'll take this as a documentation bug.
10574	Joshua Slive	1029944730000	Thanks.  This will be fixed in the next release.
10575	Mark Nottingham	1050951046000	To be a bit more verbose - \n\nmod_autoindex hides directories and files that require authentication, which\nleads to a catch-22; how does someone find the file to log in if they can't see\nthat it exists?\n\nIt's very nifty that it can hide authentiated resources *if* the site requires\nusers to log in earlier; however, this doesn't work in all situations.\n\nTherefore, it's necessary to have an option where this behaviour is turned off.\n\n[changing the severity, as this isn't an enhancement; it's a bug in a 2.0\nenhancement ]
10575	Joshua Slive	1050951699000	I know It's silly to argue over the serverity level, but this was a deliberate\ndesign decision, \nand hence can't be classified as a bug.  It was considered unsafe to\ngive un-authenticated users information on areas of the server to which\nthey don't have access.\n\nYes, it would be nice to be able to turn this off.  But it's not a bug.
10575	Phil Almquist	1050984716000	wow i forgot this bug report even existed since ive stopped using autoindex (due\nto this problem actually).  this might only be an enhancement but it is very\nnecessary for doing seemingly simple things like indexing userdirs and forces\nthe user to create their own custom cgi or similar autoindex which is not at all\nan ideal solution.  other than requiring auth in the root directory which is not\nan option there is currently no possible way to have a completely autoindexed\nsite that uses any sort of authentication.  with the new header / footer options\nand other enhancements mod_autoindex is becoming much more useable and more\nintegrated in websites structures; it would be very nice if it wasnt\nincompatable with authentication.
10575	andy d	1058237218000	 i had to tweak the mod_autoindex.c in the\nlatest version of apache to get it\nto work right.  here are my work-arounds:\n\n         //if (!(p->icon = find_icon(d, rr, 1))) {\n                // was getting wrong icons on folders\n                p->icon = find_default_icon(d, '^^DIRECTORY^^');\n            //}\n            if (!(p->alt = find_alt(d, rr, 1))) {\n                if (!(p->alt = find_default_alt(d, '^^DIRECTORY^^'))) {\n                    p->alt = 'DIR';\n                }\n            }\n        }\n        else {\n            p->icon = find_icon(d, rr, 0);\n            p->alt = find_alt(d, rr, 0);\n            p->size = rr->finfo.size;\n        }\n\n\n        p->desc = find_desc(d, rr->filename);\n\n        if ((!p->desc) && (autoindex_opts & SCAN_HTML_TITLES)) {\n                //added this check -- was getting garbage description on folder\n           if (dirent->filetype != APR_DIR)  \n                p->desc = apr_pstrdup(r->pool, find_title(rr));\n        }\n
10575	Martin Horak	1080648804000	This patch doesn't solve the problem of hiding directories with authenticated\naccess does it?\nIs there any patch which does this work? Or any other workaround? I need it very\nmuch...\n\nThanks,\nMartin
10575	Martin Horak	1081334173000	Created an attachment (id=11165)\nFinally I found a workaround - this dirty hack disables directory hiding feature.\n
10575	Jose de Leon	1085166987000	Can this feature be brought back?  Perhaps be default, auth protected dirs files\ncan be hidden, but allow to specify to display hidden directories and files with\nIndexOptions?\n\n
10575	Paul Querna	1087706003000	Incoming Patch adds a new IndexOptions Command 'ShowForbidden'.  This will list\ndirectories or files that normaly wouldn't be shown because the subrequest\nreturns  forbidden.  This patch is against 2.1-CVS Head.
10575	Paul Querna	1087706063000	Created an attachment (id=11890)\nAdds 'ShowForbidden' to IndexOptions\n
10575	Joe Orton	1087719237000	Oooh, nice, +1.  Watch the code style though:\n\n+    if((autoindex_opts & SHOW_FORBIDDEN) && \n+       (rr->status == HTTP_UNAUTHORIZED || rr->status == HTTP_FORBIDDEN)) {\n\nshould be:\n\n   if ((blah)\n       && (blee)) {\n\n(I also detest the (1 == foo) style rather than (foo == 1) but that's not in the\nstyle guide :)
10575	Paul Querna	1089427557000	Patch Commited to 2.1.  Thanks for the feature request!\n\n-Paul Querna
10575	Paul Querna	1093476050000	*** Bug 30854 has been marked as a duplicate of this bug. ***
10575	Joshua Slive	1119366612000	*** Bug 35443 has been marked as a duplicate of this bug. ***
10617	Arthur P. Smith	1026253676000	Note this was for a location also serviced by mod_proxy - I haven't tried it for\nCGI or other ways you could get a Location: directive returned, so it could be\nreally a problem in mod_proxy. I'd suspect mod_ext_filter though first.
10617	Jeff Trawick	1026264216000	mod_ext_filter definitely needs to watch out for NULL content_type.\nAt the very least, the if statement should be changed to:\n\n     if (ctx->filter->intype &&\n         ctx->filter->intype != INTYPE_ALL &&\n         (!f->r->content_type ||\n          strcasecmp(ctx->filter->intype, f->r->content_type))) {\n\nSo if the user specifies a certain content_type to process we'll make\ncertain that there is a content_type associated with the response.\nI do not know whether or not a NULL content_type always implies that there \nis no actual response body.  I doubt that it is true in general.  \n\nmod_ext_filter should already handle an empty response okay (or that is another \nbug :) ), so the fix above should be sufficient for your problem and\nwe don't worry about whether or not there is a response body to filter.\n
10617	Arthur P. Smith	1026265623000	Good point - your fix is definitely the right one. Thanks!
10617	Jeff Trawick	1026302387000	The fix has been committed and will be in the next release of Apache.\n\nThanks for your report/patch, and thanks for using Apache!\n
10644	Christoph Vogel	1029944070000	Applies to 2.0.40 too. Dirty hack for me was comment the following section in \nconfigure:\n\n  if test 'x$CFLAGS' = 'x'; then\n    echo '  setting CFLAGS to /'-DNO_DBM_REWRITEMAP/''\n    CFLAGS='-DNO_DBM_REWRITEMAP'\n  else\n    apr_addto_bugger='-DNO_DBM_REWRITEMAP'\n    for i in $apr_addto_bugger; do\n      apr_addto_duplicate='0'\n      for j in $CFLAGS; do\n        if test 'x$i' = 'x$j'; then\n          apr_addto_duplicate='1'\n          break\n        fi\n      done\n      if test $apr_addto_duplicate = '0'; then\n        echo '  adding /'$i/' to CFLAGS'\n        CFLAGS='$CFLAGS $i'\n      fi\n    done\n  fi\n\n/modules/mappers/config9.m4 makes configure always set NO_DBM_REWRITEMAP.
10644	Jeff Trawick	1029959298000	mod_rewrite has just been changed to use the apr-util dbm interface.\nThis change will be in the next release of Apache 2.0.x.\n\nFor now, the SDBM dbm flavor is always used.  It won't be compatible\nwith dbm rewrite maps built for Apache 1.3 until apr-util supports\nndbm and mod_rewrite is changed to prefer ndbm over the built-in\nsdbm.   Someone has expressed to work on ndbm support soon, so \nhopefully that change will be in the next Apache 2.0.x release too.\n\nThe PR should be kept open until the ndbm support is available.\n\nThanks for your report, and thanks for using Apache.\n
10644	Ian Holsman	1029992273000	ndbm support is now in.\n
10644	Joshua Slive	1034821164000	This is fixed.
10678	Christian Hammers	1026381764000	It works with Apache 1.3.26 so it's not an usage problem.
10678	Joseph M. Hinkle	1026627605000	.htaccess isn't the problem.  It seems more to be in the use of AddHandler and \nAction.\n\nIf a similar simple script exists in the directory and is executable under the \nExecCGI rules, then REMOTE_USER is passed:\n.htaccess:\n    AuthType Basic\n    AuthName Test\n    AuthUserFile /path/to/password/file\n\n    Require valid user (or Require user name)\n\nThen a script in that directory like this shows the environment variable:\n\ntest.cgi:\n#!/bin/sh\necho 'Content-Type: text/plain'\necho\necho 'Remote User: $REMOTE_USER'\n\nHowever, identifying such a script in an Action or Script directive causes the \nvariable to be lost somewhere, as in this as well as the case originally \noutlined:\n\nhttpd.conf:\nScript PUT /path/to/the/above/script\n\n.htaccess:\n   AuthType Basic\n   AuthName 'no REMOTE_USER'\n   AuthUserFile /path/to/password/file\n\n   <Limit PUT>\n      Require user name\n   </Limit>\n\nand the variable REMOTE_USER does not appear.\n\n\n\n
10678	Thomas K	1026981849000	A further interesting effect occurs when using two .htaccess files.\n\n1.)\n\nhtdocs/.htaccess:\nAuthType Basic\nAuthName Test\nAuthUserFile /home/test/htdocs/.htpasswd\nRequire user b\nAddHandler test-script .sh\nAction  test-script /cgi-bin/test.cgi\n\ncgi-bin/.htaccess:\n#empty\n\nWhen trying to access a document test.sh. The server asks for user b's \npassword, but the REMOTE_USER variable doesn't exist.\n\n\n2.)\n\nhtdocs/.htaccess:\nAddHandler test-script .sh\nAction  test-script /cgi-bin/test.cgi\n\ncgi-bin/.htaccess:\nAuthType Basic\nAuthName Test\nAuthUserFile /home/test/.htpasswd\nRequire user a\n\nThe server asks for user a's password and the REMOTE_USER variable is\nshown.\n\nTo my mind this behavious is wrong because two .htaccess files are consulted,\nbut not fully applied. 
10678	Mark Jason Dominus	1028943845000	This may be the same bug as #11602.\n
10678	laurent dami	1055922084000	I encountered the same problem when moving from 1.3.12 to 2.046. As suggested \nby Joseph M. Hinkle, this has to do with mod_action, NOT .htaccess. \n\nMy config is as follows (Apache 2.046, Windows NT 4.0)\n\nAction etat-ge-tdb /cgi-bin/tdb.cgi\nAddHandler etat-ge-tdb .tdb\n\nIn my Apache 1.3.12 config, there was no access limit on the script 'tdb.cgi'.\nSome of my *.tdb files had access limits, and in those cases the REMOTE_USER \nwas appropriately passed to tdb.cgi. Now it now longer works with Apache 2. My \nworkaround was to add a 'require valid-user' directive for /cgi-bin/tdb.cgi, \nbut this is not fully satisfactory since it is no longer possible to have \nanonymous access for some of my *.tdb files.\n\nNote : in Apache 1.3.12, I used MIME types instead of AddHandler; but this is \nnot the cause of the problem (Action with MIME types in Apache 2.046 still \ndoes not transmit the REMOTE_USER).
10678	Andr?? Malo	1058217047000	The problem is fixed in 2.1. The remote user of the original request will be\npassed via REDIRECT_REMOTE_USER to the script, which is even more logical than\nthe old behaviour. If you want to get REMOTE_USER direcly, you should protect\nthe script itself (which works already fine).\n\nI'll propose it for backport to 2.0 stable branch.\n\nThanks for using Apache!
10678	Andr?? Malo	1058217203000	*** Bug 11602 has been marked as a duplicate of this bug. ***
10678	Andr?? Malo	1059388823000	*** Bug 21927 has been marked as a duplicate of this bug. ***
10678	Andr?? Malo	1059388969000	This was fixed in 2.0.48-dev. If the target script is not protected, it will get\nthe REDIRECT_REMOTE_USER env variable, containing the original user.\nSupplying r->user to an unprotected script is wrong (even in 1.3.x) and\ntherefore not supported.
10678	Andr?? Malo	1088191705000	*** Bug 29812 has been marked as a duplicate of this bug. ***
10773	Hunter Peress	1026581624000	so whe  I changed the code to 755, the cgi executed fine.
10773	Joshua Slive	1029782406000	If you are using suexec, then the security restrictions prevent more info\nfrom being passed back to apache.  But you will find a more detailed error\nreport in the suexec log file.\n\nThanks for using Apache!
10773	Andr?? Malo	1044887604000	suexec now (in 2.1) sends a message to stderr, that something within suexec\nhappened. The actual information is still available in suexec's log.
10773	Andr?? Malo	1044887679000	And therefore I'll mark this bug as fixed.
10920	Jeff Trawick	1028058444000	The ldap code now supports a non-threaded environment such as APR-on-FreeBSD.\n\nutil_ldap.h was updated in httpd-2.0 CVS and various pieces were updated in \nhttpd-ldap CVS.\n\nYour point about checking for features at configure time and disabling\nfunction as necessary is well taken.  Various such checks are present.\nThere aren't too many people using the ldap code yet so it fell through\nthe cracks.\n\nThanks for your report, and thanks for using Apache!\n\n
10946	Stefan Steinbeck	1027008699000	I'm suffering from the same problem, but in my (a bit more) complex server \nsetup the rewrite rule would have to be split up in multiple rules. \nTo clearify the things I tried to get some output in the error log, but even \nin 'LogLevel debug' I don't get any message there. It is only noted in the \naccess log as 'GET //file'.\n
10946	David Shane Holden	1027544180000	I'm not sure if this is expected or even allowed behavior, but the following\npatch should allow you to use redundant slashes.\n
10946	David Shane Holden	1027544224000	Created an attachment (id=2475)\npatch\n
10946	Will Rowe	1028651502000	\n  This bug is fixed in CVS, and that patch will hopefully be included \n  in the forthcoming Apache 2.0.40 release.\n\n  Thanks for the detailed reports, and the suggested patch, David.\n  I had to attack it a bit differently, there were actually two code\n  paths to be dealt with, your patch fixed one of them.  Co-credit and\n  kudos anyways for hacking in a fix!\n
10961	Andr?? Malo	1046482956000	The problem is fixed in main dev branch (2.1) and proposed for backport.\n\nThanks for your report and thanks for using Apache!
10961	Andr?? Malo	1051201325000	FYI: Finally merged into the 1.3 and 2.0 stable trees (1.3.28 and 2.0.46 will\ninclude the fix).
10993	Joshua Slive	1029781689000	Hmmm... We have a policy of only adding officially-registered MIME types\nto our mime.types file.  This one may be common enough to warrent an\nexception.\n\nOther opinions?
10993	Joshua Slive	1031013796000	*** Bug 12241 has been marked as a duplicate of this bug. ***
10993	Ian Holsman	1031065396000	done.\nthis should be in 2.0.41
10993	Ian Holsman	1031065430000	done for 2.0.41
11030	Frodo Looijaard	1027328438000	Created an attachment (id=2435)\nTruss log\n
11030	David Shane Holden	1027481459000	Created an attachment (id=2461)\npatch\n
11030	Jeff Trawick	1028119625000	A fix for this was just committed and will be in the next release of Apache.\n\nThanks for the report, and thanks for using Apache!\n\nThanks especially to Mr. Holden, whose debugging and initial patch pointed\nout the problem.\n
11041	Joshua Slive	1027359132000	You are, indeed, correct.  But I find the whole paragraph irrelevant now that\nthe ServerName and Port are unified, so I'll just delete it.\n\nThanks for your help!\n
11041	Joshua Slive	1027359158000	Meant to close this...
11212	Joe Orton	1038579137000	Created an attachment (id=3989)\nRemove AddModule support from apxs\n
11212	Joe Orton	1038579229000	A fix has been submitted to the black hole known as dev@httpd.
11212	Joe Orton	1040386978000	This patch was committed to HEAD.
11213	Ian Darwin	1027704822000	Created an attachment (id=2500)\nPatch to provide better error message.\n
11213	Ian Holsman	1029789655000	Commited.. Thanks for the patch!
11310	Madhusudan Mathihalli	1047451013000	Hi Charlie,\n  Although I'd like to do this, I'm curious to know if there any specific \nreason why you want it to be done ?.\n\n-Madhu
11310	Charles Reitzel	1047485243000	Hi Mahdu,\n\nThe convention with OpenSSL and many other packages is to have a top-level \ninclude directory.  It avoids file name conflicts and just makes the code \nclearer.\n\nThus, the appropriate directory to have in the INCLUDE path is \n$OPENSSL_HOME/include and the syntax in your source code should be\n\n#include <openssl/somefile.h>\n\nNOT\n\n#include <somefile.h>\n\nThis way a) it will build on MSVC and b) I can use the same INCLUDE setting for \nmy own OpenSSL code as Apache 2.\n\nThanks\nCharlie
11310	Madhusudan Mathihalli	1047658858000	I've committed the changes to HEAD. Can you please verify (if possible) and \nclose the bug ?.\n\nThanks\n-Madhu
11310	Will Rowe	1049783484000	\n  No response from reporting - I've verified this myself and am\n  tagging the report fixed.\n
11428	Andr?? Malo	1045096305000	In the past? NCSA? couldn't find it in CVS down to apache 1.2 ;-)\n\nBut, ehm, how is it useful? If one can supply any uid with any password... why\nthe effort?
11428	Brian Gallew	1045141676000	It's extremely useful in a two-tiered authentication system.  Let's say, for\ninstance, that you have a firewall.  Further, that your business application\nlives 'inside' the firewall, while the authentication system is only operative\n'outside' the firewall.  Apache on the firewall machines can do authentication\njust fine.  Apache on the internal machine cannot.  Instead, they have to\nbelieve that anything that gets through has already been authenticated.  This is\nexactly what I use this for.
11428	Andr?? Malo	1045145293000	I hope, you're checking the anon uids in any other way. Otherwise everybody\nbehind the firewall is granted access to the system...\n\nI have, however, another security problems in my mind, because one can easily\ncompromise the log files (by using weird user ids). Hmm.
11428	Andr?? Malo	1046999744000	I'm changing this to WONTFIX for 1.3 (maintenance mode) but consider this to be\nan enhancement for 2.1.\n\nThanks for using Apache.
11428	Andr?? Malo	1068402173000	Reopen to resolve
11428	Andr?? Malo	1068402244000	FYI: Applied the enhancement to the 2.1 branch. As said before, it probably\nwon't backported.
11475	Chris Darroch	1028735962000	Looking at the spot_cookie() code a bit more, I'm also suspicious that it may\nbe confused by both RFC 2965-style cookies (which can have quoted-string\nvalues, with escaped characters).\n\nFurther, I think it will also be confused just by old-style cookies where\nthe string 'Apache' (or whatever the cookie name it's looking for is) appears\nin a cookie name or value somewhere before the actual cookie name/value pair\nin the header.  For example, I suspect 'Apache2=foo; Apache=bar' or\n'foo=Apache; Apache=bar' would both cause the apr_strstr_c() call to find\nthe first, incorrect, occurance of 'Apache'.  Or, if the client has two valid\n'Apache' cookies for the server, with different paths, it may send them both,\nwith the more-specific path first ... but since we always set the path=/, our\ncookie will be the last one, not the first one.\n\nif ((value = ap_strstr_c(cookie, dcfg->cookie_name))) {\n    char *cookiebuf, *cookieend;\n\n    value += strlen(dcfg->cookie_name) + 1;  /* Skip over the '=' */\n    cookiebuf = apr_pstrdup(r->pool, value);\n    cookieend = strchr(cookiebuf, ';');\n    if (cookieend)\n        *cookieend = '/0';      /* Ignore anything after a ; */\n\nI don't know if this helps or not, but since I don't have time right now to\nimplement a complete fix, I will attach a file that parses a Cookie: header\ninto an APR hash of cookies, where each hash value is an APR array of\n'string' structures.  The first structure in an array is the first cookie\nwe found with the given name (the name is the hash key that points to the\narray), which should be the most-specific cookie of that name, assuming the\nclient is working correctly.  The last structure in an array is the last\ncookie -- which is the one mod_usertrack would want, because it would have\nto be the path=/ cookie.\n\nThe 'string' structure contains both the string itself, null-terminated, and\nthe string length, which is useful for avoiding additional strlen() calls.\nThe cookie_get() function returns the string of the first cookie, or NULL\nif there is more than one cookie with the same name.  This obviously isn't\nuseful for the mod_usertrack situation, where we want the last cookie in\nan array.  For that, you want to do something like (assuming you know\nthere's at each one element in the array):\n\n/**** DEBUG: watch out for nelts == 0 !! ****/\nstring = ((struct string*) val_arr->elts) + val_arr->nelts - 1;\nstr = string->ptr;\nstr_len = string->str_len;\n\nWhen parsing the Cookie: header, if a $Version=1 cookie is detected\nat the start (or some legal RFC 2965 variation), then the code parses\naccording to RFCs 2965 and 2616 (mostly); otherwise, it parses according\nto the old Netscape specification.\n\nWhen parsing in RFC 2965-mode, cookie names are flattened to lowercase,\nsince the spec calls for case-insensitive cookie names.  Quoted strings\nare de-quoted and escaped characters in quoted strings are un-escaped\n(except for some dubious values that RFC 2616 allows).  Unquoted cookie\nvalues must be RFC 2616 tokens, and all cookie names must be tokens as well.\nBoth commas and semicolons are legal delimiters.\n\nWhen parsing in Netscape-mode, cookie names and values are not altered,\nexcept that we ignore internal whitespace and commas, because the spec\ndoesn't allow those at all.  Only semicolons are legal delimiters.\n\nIn general, high-bit-set octets and ASCII control characters are\nstripped out, despite what RFC 2616 allows, because -- well, because\napplications really shouldn't be using such stuff in an HTTP header,\nshould they?\n\nThe code also imposes its own #defined limits on name and value lengths.\nThis probably overkill given that the header is normally limited to\nabout 8 Kb by the DEFAULT_LIMIT_REQUEST_FIELDSIZE #define, but this\ncode came from another application where we didn't have such external\nlimits.\n\nPlus, it's worth noting that both the Netscape and RFC 2965\nspecs allow clients to send 20 cookies where each one's name/value\npair is 4 Kb ... but any application that actually relied on that many\nlarge cookies would cause Apache errors for its clients, once they\nexceeded the 8 Kb header limit.  Maybe someday Cookie: headers should\nbe allowed to exceed the DEFAULT_LIMIT_REQUEST_FIELDSIZE?  Or else,\nat least a warning about this conflict with the specs should maybe go\nin the docs.\n\nThe code tries hard to avoid excess strlen()-type calls and multiple\npasses over the data.  Although it would be more elegant to allocate\nkey[] and val[] buffers off the stack for the maximum, dump characters\ninto them as we find them, and then apr_palloc() just enough space\nfor the resultant strings, that requires at least two passes over\nall the data.\n\nInstead, this code starts by allocating a small buf_size buffer\nfrom apr_palloc(), and then, once it's filled up, allocating double\nthat amount of space for the next buffer.  The doubling continues\nuntil a reasonable maximum is reached that can always contain the\nlargest string we need to handle (ideally, several large strings).\nThis does involve memcpy() calls when we have to reallocate in the\nmiddle of a name or value, and some wasted space, but we should\navoid a full 2* pass over all the data, and not waste too much more\nspace than we need.  Like I said, it's a bit of overkill just for\nthe Cookie: header, but I had the code on hand.\n\nThe attached code should compile, but it differs slightly from\nour actual implementation usage, so I can't guarantee that it's\nbug-free.\n\nPerhaps something like this might form part of an APR-util cookie\nlibrary?  Or not ...
11475	Chris Darroch	1028736066000	Created an attachment (id=2624)\nNetscape and RFC 2695 compliant cookie parser\n
11475	Chris Darroch	1028736470000	Oops, two extra comments: the last line of the cookie_parse_header() function\nshould 'return APR_SUCCESS', not 'return OK', and this code simply skips over\nany cookies whose names start with $ when parsing in RFC 2965-mode.\nAn enhancement would be to put those $name values into a fancier 'struct cookie'\nthat contains the 'struct string', and push those structures onto the APR\narrays.
11475	Jeff Trawick	1069434401000	regarding the spotcookie problem misrecogonizing cookies: that was fixed\nrecently...  no comment from me on your rfc compliance comment
11475	Andr?? Malo	1073954071000	RFC issue Fixed in 2.1 and proposed for backport into the 2.0 and 1.3 stable\nbranches.\n\nThanks for the report and thanks for using Apache.
11521	TAKAHASHI Makoto	1028700672000	Created an attachment (id=2607)\nproposed error messages\n
11521	Joshua Slive	1028823703000	Thanks for the contribution.  We really would prefer not to go back to\nmultiviews for the error messages if we can avoid it.  I'll look into the issue\nof charset in typemaps and get back to you.\n\n
11521	Joshua Slive	1028839843000	OK.  What we'll do is, rather than using MultiViews, simply use the URL: field\nof the typemap files to point to the correct document.\n\nBut before we can commit these, we need them to be read by another fluent \nJapanese speaker.  If you can have someone do that and post here, that would\nbe great.  Otherwise, someone from the documentation project may get to it.\n
11521	Jeff Trawick	1069434442000	I'm going through the bug db to make sure patches are findable.  Please see \nhttp://httpd.apache.org/dev/patches.html\n
11521	Hiroaki KAWAI	1105131531000	Thank you for the contribution. I added them with some enhancement.\n\nhttp://cvs.apache.org/viewcvs.cgi?root=Apache-SVN&rev=124566&view=rev\n
11540	Christoph Vogel	1029790891000	Same behaviour with 2.0.40
11540	Graham Leggett	1050424018000	From investigating this, ProxyTimeout only applies after the connection is\nsuccessfully established, which won't happen if the packets are dropped. Will\ncheck further to see if this is correct behaviour or not.\n
11540	Dave Lee	1083708737000	*** Bug 23122 has been marked as a duplicate of this bug. ***
11540	Graham Leggett	1085177788000	Confirmed - the ProxyTimeout applies after a successful connection. To test\nthis, you need to convince your test connection to connect successfully, but\nthen not send any data. The proxy should wait the timeout length for a response,\nand give up if this time is reached.\n\nI'm closing this bug for now, if you have further problems, reopen it.\n
11540	Anthony Pahitas	1095254490000	\nI'm facing this problem with IHS2.042.2 (Apache/2.0.46) on AIX.\n\nSimply put, I have an upstream application server that takes about 15mins to \ngenerate a large report. The reverse proxy returns a 502 error to the client \nafter the connection timeout period elapses (which is normal). I can overcome \nthe problem by increasing the Timeout directive, but believe it would be more \nappropriate to use the ProxyTimeout directive. This does not, however, produce \nthe desired effect.\n\nPerhaps the last comment 'ProxyTimeout applies after a successful connection' \ncould be clarified in more detail?
11540	Georg v. Zezschwitz	1097850246000	My observation is ProxyTimeout (by 2.0.51) rather sets the Connect timeout, not\nthe read timeout.\nAnother bug regarding ProxyTimeout is, that neither Timeout nor ProxyTimeout\napply when an SSL proxy connection ('CONNECT') is established.\nThese connections never time out.
11540	Maxim Kozin	1101219521000	Timeout for socket in case of proxy request set in modules/proxy/mod_proxy.c    \nby function ap_proxy_connect_to_backend():\n\n        /* Set a timeout on the socket */\n        if (conf->timeout_set == 1) {\n            apr_socket_timeout_set(*newsock, conf->timeout);\n        }\n        else {\n             apr_socket_timeout_set(*newsock, s->timeout);\n        }\n\nGDB show, that conf->timeout_set is 0, and timeout get from global config\n(from 'Timeout' directive).\n\nNote, that other *_set variable never used in mod_proxy* for check\nsomething.\n\nI don't know why conf->timeout_set is zero in ap_proxy_connect_to_backend().\n\nMay be need compared 2 functions from\nmodules/proxy/mod_proxy.c:\ncreate_proxy_config and merge_proxy_config\n\nCheck this:\nps->timeout= (overrides->timeout_set == 0) ? base->timeout : overrides->timeout;\nIf overrides->timeout_set equal 0, than ps->timeout setted, but may be we\nneed set too :\n   ps->timeout_set = 1; \n  /* because timeout set always, timeout_set is always setted */\n?\n\nBut probably we don't need use *_set variable anywhere in proxy_utils to\ncheck.\n\nnext patch work in my environment:\ndiff -u  modules/proxy/proxy_util.c.save  modules/proxy/proxy_util.c\n--- modules/proxy/proxy_util.c.save     Tue Nov 23 14:47:48 2004\n+++ modules/proxy/proxy_util.c  Tue Nov 23 14:48:46 2004\n@@ -1128,7 +1128,7 @@\n #endif\n \n         /* Set a timeout on the socket */\n-        if (conf->timeout_set == 1) {\n+        if (conf->timeout != 0) {\n             apr_socket_timeout_set(*newsock, conf->timeout);\n         }\n         else {\n\n
11540	Graham Collinson	1119453416000	Created an attachment (id=15511)\nensures <opt>_set properties are set correctly in merge_proxy_config\n\nProxyTimeout directive is ignored because the timeout_set property gets cleared\nin merge_proxy_config.\tAttached patch resolves this problem
11540	Graham Collinson	1119453840000	Created an attachment (id=15512)\n2.1.3-beta: ensures <opt>_set properties are set correctly in\nmerge_proxy_config\n
11540	Stuart Children	1125607046000	This bug just bit me too. The patch in attachment 15511 looks good to me,\napplies cleanly (once it's been dos2unix'd) to 2.0.54, and I can confirm fixes\nthe bug. I'd certainly like this to be applied.\n\nI would also suggest that the documentation is updated to clarify that this\ntimeout is for *establishing* the connection only (at least that's what the code\nand my tests show); and that the core Timeout directive will affect the timeout\nfor an established connection. I'm happy to knock up a patch with suitable text\n- just say the word.
11540	Stuart Children	1131455702000	So this bug is still in both 2.0.55 and the trunk. I am confirming that the\nalready supplied attachments are still good for the respective (2.0 and 2.1)\nHEADs in SVN. Could we please get these applied?
11540	Stuart Children	1171426551000	Bumping because this bug *still* exists in 2.0.58 and 2.2.4 and trunk. Will\nattach an updated patch against trunk. This should also apply against the HEAD\nof 2.2.x branch (bar lines numbers being slightly off, but given the context it\nshould apply).
11540	Stuart Children	1171426630000	Created an attachment (id=19589)\npatch against current trunk\n
11540	Nick Kew	1171429295000	(In reply to comment #13)\n> Created an attachment (id=19589) [edit]\n> patch against current trunk\n> \n\nI've just applied that one to trunk (with your tabs/indentation fixed).\n\nStuart, from memory I think I've seen your name on quite a few bugs, and they\ntend to be of the kind that look valid but need some effort to check.  These may\ntend to pass under the radar here.  Maybe it would be more productive for you to\nparticipate in dev@httpd with such points.
11540	Stuart Children	1171507837000	(In reply to comment #14)\n> I've just applied that one to trunk (with your tabs/indentation fixed).\n\nGreat, thank you. Apologies for indentation, I based it off a patch we've been\nusing for a while on a local build and totally forgot to check for tabs<->spaces.\n\n> Stuart, from memory I think I've seen your name on quite a few bugs, and they\n> tend to be of the kind that look valid but need some effort to check.  These\n> may tend to pass under the radar here. Maybe it would be more productive for\n> you to participate in dev@httpd with such points.\n\nI'm already a subscriber. In fact, I brought this bug up there before:\nhttp://marc.theaimsgroup.com/?l=apache-httpd-dev&m=113257650709794&w=2 - but got\nno response. I actually asked yesterday on Freenode's #apache what the best\nmethod to push bugs was, but people only seemed to be dealing with user queries.\nIs there a more developer-centric channel? I was planning to make another post\nto the mailing list after resubmitting these patches.\n\nI certainly appreciate that patches aren't always obvious in their effect; and\nit's good that commiters don't just apply them without thought. :) I'm more than\nhappy to help out and give examples/explain my working. If you'd like to\ncontinue the discussion on how reporters/developers without commit access can\nget their bugs (valid ones and not) dealt with more readily, let's take if off\nthis bug. Please feel free to email me directly, or bring it up on dev@ and I'll\njoin in.
11540	Stuart Children	1171596921000	Created an attachment (id=19602)\npatch against current 2.2.x HEAD\n
11540	Stuart Children	1171606975000	Created an attachment (id=19606)\npatch against current 2.0.x HEAD\n
11540	Jordi Garcia	1176789386000	I had applied the patch in 2.0.59 and 2.2.4 versions, and doesn't work. I try in\nSolaris and Linux environment.
11540	Davi Arnaut	1181291706000	What exactly doesnt work?
11540	Ruediger Pluem	1181292349000	(In reply to comment #19)\n> What exactly doesnt work?\n\nI guess he is hit by\n\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200705.mbox/%3c464F4E80.9020202@apache.org%3e
11540	Alon Dakik	1185368075000	The ProxyTimeout setting for mod_proxy is not working as described. According to\nthe documentation, ProxyTimeout should 'fail gracefully instead of waiting\nhowever long it takes the server to return.'\n\nThis means that ProxyTimeout setting should cause mod_proxy to return an error\nback to the user instead of waiting until the Server's main Timeout value is\nreached, which it is doing now. It seems the ProxyTimeout is currently ignored\nas everyone else here describes.\n\nFor example if Apache has a Timeout of 60 seconds and ProxyTimeout is 10\nseconds, then mod_proxy should return an error message back to the user if after\n10 seconds it did not receive a response to the server it connected to. \n\nPlease fix. \n\nThanks.
11540	Ruediger Pluem	1185368498000	Fixed in trunk as r546128, r550514. Backported to 2.2.x as r556972\n(http://svn.apache.org/viewvc?view=rev&rev=556972).
11626	Joshua Slive	1029162204000	Thanks.  This will be fixed in future binary builds, and I'll see what I can do\nabout getting a redirect put in at the old address.
11637	Joshua Slive	1029180699000	Assigning to the proper component (mod_dav).
11637	Joshua Slive	1034822049000	[This is a mass bug update.]\nThis bug reports a problem in an older version of Apache 2.\nCould you please update to the most recent version and see\nif you can reproduce this problem.  If the bug still exists,\nplease update the bug with the latest version number.  If \nthe bug no longer exists, please close the bug report.\n\nSorry for this impersonal response, but we get many more bug\nreports than our volunteers can keep up with.\nThanks for using Apache!
11637	Roland Betz	1044541103000	I have reproduced this bug using the latest Apache 2.0.44 (Win32).\nBelow is the communication protocol.\nThere are three requests. The first one is a OPTION request showing server info:\n\nHTTP/1.1 200 OK\nContent-Type: text/plain; charset=ISO-8859-1\nMS-Author-Via: DAV\nDate: Thu, 06 Feb 2003 13:11:47 GMT\nAllow:\nOPTIONS,GET,HEAD,POST,DELETE,TRACE,PROPFIND,PROPPATCH,COPY,MOVE,PUT,LOCK,UNLOCK\nDAV: 1,2\nContent-Length: 0\nServer: Apache/2.0.44 (Win32) DAV/2\n\n\nThe second one sets a DAV:link property on some resource.\nRequest:\n<?xml version='1.0' encoding='utf-8' ?>\n<D:propertyupdate xmlns:D='DAV:'>\n<D:set>\n<D:prop  xmlns:ns0='TENT:'>\n<ns0:parent><D:link xmlns:D='DAV:'\nxmlns:user='TENT:'><D:src>http://thrud:8080/webdav/blubber</D:src><D:dst>http://thrud:8080</D:dst></D:link></ns0:parent>\n</D:prop>\n</D:set>\n</D:propertyupdate>\n\nResponse:\nHTTP/1.1 207 Multi-Status\nContent-Type: text/xml; charset='utf-8'\nDate: Thu, 06 Feb 2003 13:11:49 GMT\nContent-Length: 280\nServer: Apache/2.0.44 (Win32) DAV/2\n\nResponse data:\n<?xml version='1.0' encoding='utf-8'?>\n<D:multistatus xmlns:D='DAV:' xmlns:ns1='TENT:' xmlns:ns0='DAV:'>\n<D:response>\n<D:href>/webdav/blubber</D:href>\n<D:propstat>\n<D:prop>\n<ns1:parent/>\n\n</D:prop>\n<D:status>HTTP/1.1 200 OK</D:status>\n</D:propstat>\n</D:response>\n</D:multistatus>\n\n\nThe third one reads this property with a PROPFIND. The final response shows that\nthe namespaces within the property value are wrong.\nRequest:\n<?xml version='1.0' encoding='utf-8' ?>\n<D:propfind xmlns:D='DAV:'>\n<D:prop  xmlns:ns0='TENT:'>\n<ns0:parent />\n</D:prop></D:propfind>\n\nHeader Depth: 0\nResponse:\nHTTP/1.1 207 Multi-Status\nContent-Type: text/xml; charset='utf-8'\nDate: Thu, 06 Feb 2003 13:11:49 GMT\nContent-Length: 435\nServer: Apache/2.0.44 (Win32) DAV/2\n\nResponse data:\n<?xml version='1.0' encoding='utf-8'?>\n<D:multistatus xmlns:D='DAV:'>\n<D:response xmlns:ns0='DAV:' xmlns:ns1='TENT:'>\n<D:href>/webdav/blubber</D:href>\n<D:propstat>\n<D:prop>\n<ns1:parent><ns9107104:link><ns9107104:src>http://thrud:8080/webdav/blubber</ns9107104:src><ns9107104:dst>http://thrud:8080</ns9107104:dst></ns9107104:link></ns1:parent>\n</D:prop>\n<D:status>HTTP/1.1 200 OK</D:status>\n</D:propstat>\n</D:response>\n</D:multistatus>\n\n\n
11637	Joe Orton	1048021383000	*** Bug 15728 has been marked as a duplicate of this bug. ***
11637	Jeff Trawick	1051873283000	A fix for this from Amit Athavale has been committed to Apache 2.1-dev.
11637	Greg Stein	1054722469000	*** Bug 14969 has been marked as a duplicate of this bug. ***
11791	Tim Hurman	1029603942000	a fix seems to be replacing \nres->unsetenv = NULL;\nwith\nres->unsetenv = apr_table_make(p, 10);\n
11791	Paul J. Reder	1030215895000	This PR has been fixed in the latest CVS HEAD. A check was put in to avoid\naccessing the structure if the value was NULL.\n\nThank you for reporting this issue.
11793	Will Rowe	1029700908000	Did you try\n  ExtFilterDefine awk_line_numbering mode=output outtype=text/html \n     cmd='/bin/awk '{print NR///': ///' $N}''\n\nIn case the '/' escaping is eating the second double quote?\n\nIf that's not the workaround, there is a bug in the parser.\n
11793	Paul J. Reder	1029774360000	This indeed seems to be a bug. parse_cmd in mod_ext_filter.c does not process\nescaping characters. It sees the first ' and scans till it finds the next '. No\nchecks for escape chars.\n\nI'll have a fix shortly.
11793	Christoph Vogel	1029789878000	If you need a line numbering ExtFilter urgently you can use pr without getting \ninto escaping issues:\n\nExtFilterDefine pr_line_numbering cmd='/usr/bin/pr -n -t'\n
11793	Jeff Trawick	1029959842000	This was fixed earlier today (go Paul!).  I just verified that this \ncmd= parameter yields a filter that prefixes the response with line \nnumbers:\n\ncmd='/bin/awk '{print NR/': /' $N}''\n\nTo pick up the fix, you need a new modules/experimental/mod_ext_filter.c \nand a new srclib/apr/strings/apr_cpystrn.c.  This will all be in the \nnext release of Apache 2.0.x.\n\nThanks for your report, and thanks for using Apache.\n
11793	Jeff Trawick	1029961198000	*** Bug 11794 has been marked as a duplicate of this bug. ***
11854	Moran Zaltsman	1029849196000	P.S. II :\nthis is not the Downloadable Binary from httpd.apache.org - but a one that i've \ncompiled myself (using VC++ 6 w/SP5)\n\nthis is FYI only : as i've tried the Binary also - but incurred with the Same \nresult.
11854	Will Rowe	1029851614000	Created an attachment (id=2775)\nPatch to call apr_initialize prior to checking if utf-8 fixups are required\n
11854	Will Rowe	1029851655000	  This is a bug.  You mention you can compile apache yourself, please try the\n  attached patch.  Apache calls apr_app_initialize, which checks if it has\n  started on a WinNT-flavor Unicode-enabled platform.  But it hadn't called\n  apr_initialize to set up the oslevel flag before checking the platform.\n\n  If you report this clears up your bug, I'll commit, fix will be in the \n  2.0.41 release.\n\n\n  
11854	Will Rowe	1029852214000	Created an attachment (id=2776)\nSmall problem, apr_app_init can be called multiple times, this patch also resets the initialized flag to prevent double-initialization.\n
11854	Moran Zaltsman	1029856809000	That was Fast man !\n\nThanks ! :]\n\nIt've Solved my Problem - Apache2 now Starts OK.\n\nThanks for your Dedication.
11854	Will Rowe	1029868371000	\n  Yup... this will become an FAQ till .41 is in user's hands.  Fix committed.\n
12011	Juan Rivera	1034630105000	Created an attachment (id=3469)\nPatches fixes the problem with sending a user define code (restart) to the service. This is causing the service not to restart properly.\n
12011	Will Rowe	1034638358000	\n  Fix committed, this will be included in Apache 2.0.44 once released.
12011	Juan Rivera	1036986009000	*** Bug 12652 has been marked as a duplicate of this bug. ***
12091	Jeff Trawick	1030562327000	Your fix has been committed.\n\nThanks for your report and thanks for using Apache!
12132	Ian Holsman	1030566517000	I'll do this soon\nalso need to fix the same spot to set it so it will be in err_headers out
12132	Ian Holsman	1030661636000	Fixed in current CVS.\nalso.. the Cookie is now being sent out in err_headers_out so it should show up\nin stuff like 302's and 404's
12151	Jeff Trawick	1030620187000	 Your fix has been committed and is reflected on the web site now.  Thanks for your report, and thanks for using Apache!  
12172	Joshua Slive	1030653809000	Not sure why I'm cc'ed here.  Remove it and note that a fix is proposed in the\nbug.
12172	Ian Holsman	1030663008000	Thanks once again Rob.\nfor my sanity, can you mention the other bugs you have open on the same piece of\nfunctionality ;-) \nsave me 3 seperate commits
12172	Rob Cromwell	1030669915000	Works great! Sorry for the trouble :/
12172	Ian Holsman	1030676640000	just me bitching.. take no heed
12181	Ian Holsman	1030662000000	done.\nif you can check the latest version of CVS to confirm that it is working for you
12181	Rob Cromwell	1030669829000	Works great!
12202	Andrew Ho	1030773586000	I have confirmed that the bug exists in the current CVS HEAD.\nSimple one-line patch is coming...
12202	Andrew Ho	1030773691000	Created an attachment (id=2879)\nPatch against apache-1.3/src/main/http_protocol.c\n
12202	Justin Erenkrantz	1030906037000	Fixed in revision 1.327 of http_protocol.c
12207	Andrew Ho	1030779644000	Created an attachment (id=2880)\nPatch against httpd-2.0/modules/http/http_protocol.c\n
12207	Andrew Ho	1030779664000	Still a problem in HEAD. The attached patch fixes the problem.
12207	Justin Erenkrantz	1030906090000	Fixed in revision 1.455 of http_protocol.c.
12340	Semenov Innokentiy	1031437451000	\nProxy crash in mod_proxy.c, function proxy_map_location():\n   +--- mod_proxy.c --------------------------------------------\n   |static int proxy_map_location(request_rec *r)\n   |{\n   |    int access_status;\n   |\n ->|    if (!r->proxyreq || strncmp(r->filename, 'proxy:', 6) != 0)\n   |        return DECLINED;\n   +------------------------------------------------------------\nr->filename points to NULL, cause strncmp access to\nviolation exception (0xC0000005).\n\nBug also in apache 2.0.39 in same place.\n
12340	Ian Holsman	1031509146000	Can you please attach your httpd.config file,\nand the actual URL requested which gives the crash ?\n\nif this is a forward proxy, the r->filename should already by mapped to\nproxy:http://foobar/uri by the time it gets into this function (or else it would\nbe breaking for >every< request anyone does, so there is something funky about\nyour config I'm thinking
12340	Semenov Innokentiy	1031516086000	Here proposed patch for fixing this bug (maked by 'diff mod_proxy.c\nfixed/mod_proxy.c' command):\n\n255,256c255,256\n<     if (!r->proxyreq || strncmp(r->filename, 'proxy:', 6) != 0)\n<         return DECLINED;\n---\n>     if (!r->proxyreq) return DECLINED;\n>     if (strncmp(r->filename, 'proxy:', 6) != 0) return DECLINED;\n\n\n\nIt seems that in 'if' operator (in compiled code) both condition are checked\neven though first already truly.
12340	Chris Ward	1031576697000	Thanks for high-speed fix. I take it that you don't need my config file any\nmore; if you want it, let me know.\nExecuting code to evaluate 'b' in (a || b) when it is not logically needed\nsounds like a compiler bug. Whose compiler do you build Apache for Windows with\n? Would they be interested in a bug report ?\n\nThe oddity in my configuration is that I run an Apache proxy on Windows. 
12340	Chris Ward	1034185211000	I am running 2.0.42 now, and the problem is fixed. Thanks !
12340	Chris Ward	1065649892000	This is giving me the same breakage again in 2.0.47; has the broken code crept\nback in ?
12340	Chris Ward	1065650153000	*** Bug 18963 has been marked as a duplicate of this bug. ***
12340	David Ramalho	1065875244000	  I'm running Win2K Advanced Server, Apache 2.0.47 with PHP 4.3.3 and NO \nmod_proxy loaded, and I'm reporting the same problems. Some of the times the \nservice actually stops (it's automaticaly restarted by Win 60 s latter), the \nrest of the times Apache seems to handle it on his own . I have a low thread \ncount (15) because of persistent connections do the database and the server is \npretty much exclusive. \n  Before I had 2.0.39 and all was fine, I tried downgrading to 2.0.46 and the \nproblem persisted. Didn't really wanted to downgrade much further, so I'll wait \nfor the outcome of this 'bug' :).\n\n  Further log details in : \n  http://nagoya.apache.org/bugzilla/show_bug.cgi?id=23300
12340	Chris Ward	1066035622000	I'm using 'squid' as cacheing proxy now (under WindowsXP Home). Works fine, and\nthe license terms are just as good.\nApache good web server, squid good proxycache, XMail good mailrouterthing ...
12340	Christian Kuhlmann	1118762210000	I'm experiencing the same problem with Apache 2.0.54 with PHP 5.0.4 on WinXP \nSP1, mod_proxy is not loaded.\nThe error occurs sporadically, sometimes with the page partly sent to the \nclient. After Apache has automatically restarted, reloading the page does not \nreproduce the error.
12340	Nico Haase	1120757662000	I also receive this error on using phpmyadmin. Here is one of the URLs causing\nthe error:\n\nhttp://localhost/phpmy/sql.php?lang=de-utf-8&server=1&collation_connection=utf8_general_ci&db=phpbb&table=phpbb_auth_access&sql_query=SELECT+%2A+FROM+%60phpbb_auth_access%60&pos=0&goto=tbl_properties_structure.php
12340	cp_coder_2006@yahoo.com	1140680873000	(In reply to comment #0)\nI'm using XAMPP 1.5.1 on Windows XP Home with SP1 and SP2.\nNo other server running.\n\nI have the error, too. I'm not using Perl when it's running.I did not compile, I\nused the .zip version, unzipped in top-level directory.I've read all the bug\nreports here, and it seems this bug dissappeared, then reappeared again.\n\nI have the following in my httpd-mpm.conf\n\n<IfModule mpm_winnt_module>\n    ThreadsPerChild     250\n    MaxRequestsPerChild   0\n    Win32DisableAcceptEx\n</IfModule>\n\nand httpd.conf has the appropriate line uncommented to Apache will read\nhttpd-mpm.conf.\n\nThat was the suggested fix for problem when CPU usage maxes out on XP Home.\nProposed fix does not work. When I attempt to view an HTML page that processes a\nPHP script (whether hard-coded in the HTML or called via SSI virtual), very\noften the CPU usage goes to 100%, Windows gives me an error 'Apache has\nencountered a problem and needs to close', and the page never loads.\n\nThere is no port conflict, but I tried changing to port 8080 just to see if that\nhelped, and it doesn't. My firewall is not blocking anything, the first time I\nstarted Apache I chose to allow Apache to run as a server and to have the\nfirewall remember this answer.\n\nAppropriate section of log file:\n\n[Wed Feb 22 16:36:47 2006] [notice] Apache/2.2.0 (Win32) DAV/2 mod_ssl/2.2.0\nOpenSSL/0.9.8a mod_autoindex_color PHP/5.1.1 configured -- resuming normal\noperations\n[Wed Feb 22 16:36:47 2006] [notice] Server built: Dec  1 2005 18:36:53\n[Wed Feb 22 16:36:47 2006] [notice] Parent: Created child process 3416\n[Wed Feb 22 16:37:21 2006] [notice] Child 3416: Child process is running\n[Wed Feb 22 16:37:22 2006] [notice] Child 3416: Acquired the start mutex.\n[Wed Feb 22 16:37:22 2006] [notice] Child 3416: Starting 250 worker threads.\n[Wed Feb 22 16:37:22 2006] [notice] Child 3416: Starting thread to listen on\nport 8080.\n[Wed Feb 22 16:37:22 2006] [notice] Child 3416: Starting thread to listen on\nport 443.\n[Wed Feb 22 16:42:43 2006] [notice] Parent: child process exited with status\n3221225477 -- Restarting.\n[Wed Feb 22 16:42:55 2006] [crit] (22)Invalid argument: unable to replace stderr\nwith error_log\n[Wed Feb 22 16:42:55 2006] [crit] (2)No such file or directory: unable to\nreplace stderr with /dev/null\n[Wed Feb 22 16:42:59 2006] [notice] Apache/2.2.0 (Win32) DAV/2 mod_ssl/2.2.0\nOpenSSL/0.9.8a mod_autoindex_color PHP/5.1.1 configured -- resuming normal\noperations(In reply to comment #0)\n> I'm using Apache as a cacheing proxy on a WindowsXP system (the upstream\n> link is Starband satellite, the downstream link is a wireless LAN around my\n> house). Apache2 breaks with messages below in the log; the web browsers get\n> some rather disjointed sessions. Apache1 works fine. I get notices about Apache\n> wanting to notify\n> Microsoft about the problem, which I duly allow it to do.\n> I'm not sure whether the problem is related to Apache on WindowsXP, or\n> 'mod_proxy' etc.\n> I am running without any upstream proxies. Starband have a\n> strange scheme involving running half the TCP stack on my computer and the\n> other half back that their satellite base station, but it works most of the\n> time.\n> [Tue Aug 27 08:33:11 2002] [notice] Parent: child process exited with\n> status 3221225477 -- Restarting.\n> [Tue Aug 27 08:33:11 2002] [notice] Parent: Created child process 4684\n> [Tue Aug 27 08:33:11 2002] [notice] Child 4684: Child process is running\n> [Tue Aug 27 08:33:11 2002] [notice] Child 4684: Acquired the start mutex.\n> [Tue Aug 27 08:33:11 2002] [notice] Child 4684: Starting 250 worker\n> threads.\n> [Tue Aug 27 08:33:15 2002] [notice] Parent: child process exited with\n> status 3221225477 -- Restarting.\n> [Tue Aug 27 08:33:15 2002] [notice] Parent: Created child process 3768\n> [Tue Aug 27 08:33:15 2002] [notice] Child 3768: Child process is running\n> [Tue Aug 27 08:33:15 2002] [notice] Child 3768: Acquired the start mutex.\n> [Tue Aug 27 08:33:15 2002] [notice] Child 3768: Starting 250 worker\n> threads.\n> [Tue Aug 27 08:33:19 2002] [notice] Parent: child process exited with\n> status 3221225477 -- Restarting.\n> [Tue Aug 27 08:33:19 2002] [notice] Parent: Created child process 5728\n\n
12340	Davi Arnaut	1181296128000	This seems anything but a httpd bug. could you try to reproduce the issue and get a backtrace? Thanks.\nInstructions at http://httpd.apache.org/dev/debugging.html#backtrace-win
12340	Nick Kew	1191776362000	No response to davi's request for detail.  And if there is a bug, it's clearly\nNOT the one originally reported, which is long-since fixed.
12353	Jeff Trawick	1044108784000	Thanks for your report/patch, and thanks for using Apache!\n\nYour fix has just been committed to 2.1-dev and proposed for merging back\nto 2.0.45-dev.\n
12353	Jeff Trawick	1045271169000	FYI... the fix has been merged back to the stable tree for inclusion\nin 2.0.45
12355	Joshua Slive	1034822123000	[This is a mass bug update.]\nThis bug reports a problem in an older version of Apache 2.\nCould you please update to the most recent version and see\nif you can reproduce this problem.  If the bug still exists,\nplease update the bug with the latest version number.  If \nthe bug no longer exists, please close the bug report.\n\nSorry for this impersonal response, but we get many more bug\nreports than our volunteers can keep up with.\nThanks for using Apache!
12355	Wolf-Dietrich Moeller	1035380200000	This bug exists also in Apache/2.0.43 (WIN32) mod_ssl/2.8.11 OpenSSL/0.9.6g.\nThis bug appears when runnimg under both Windows NT4.0 and XP(NT5.1).
12355	Wolf-Dietrich Moeller	1035382135000	Addition to last comment:\n\nSorry, it must read Apache/2.0.43 (WIN32) mod_ssl/2.0.43 OpenSSL/0.9.6g
12355	Marcin	1037123534000	I observe the same bug with Apache 2.0.43 running on Linux 2.4.19 box, but \nwith proprietary script handler. 
12355	Pascal AUBRY	1037182772000	Also observed on a Linux RedHat 8.0 (2.4.18-17 kernel) box running apache\n2.0.43-1, mod_ssl-2.0.43-1 and php 4.2.2-8.\n\n
12355	Sushil Kambampati	1045764718000	After setting up SSL to require client authentication and importing the \ncertificates into browsers, it works with Netscape 4.79 but not MSIE6 \n(6.0.2800.1106.xpsp1.020828-1920).\n\nThe https error file says:\n[error] SSL handshake failed (server myserver.com:443, client 192.168.1.2)\n[error] SSL Library Error: 336105671 error:140890C7:lib(20):func(137):reason\n(199)\nThe first time I also get the spurious SSL handshake interrupt message.\n\nServer config:\nApache/2.0.43 (Unix) mod_ssl/2.0.43 OpenSSL/0.9.7 PHP/4.3.0\nKernel 2.4.8-26mdk
12355	Eric Kraar	1049821839000	When configured for client certificate authentication, POST method fails after\nKeepAlive timeout - if KeepAlive is disabled, POST method always fails. \nSSLOptions +OptRenegotiate does not fix the problem.\n\nServer: Apache/2.0.45 (Unix) mod_ssl/2.0.45 OpenSSL/0.9.7a\nAIX 4.3.3\n\nI have tested IE 5.5, Netscape 4.8, Netscape 7, and Mozilla 1.3 - All browsers\nseem to be affected.  Log files can be found below.\n\nIE 5.5 generates a segfault of the child and a 302 error along with the general\nsymptoms - details of this can be found in the logs below.\n\n--------------------------------------------------------------------------------------------------\nConfiguration excerpts:\n\nKeepAlive On\nKeepAliveTimeout 15\n\nSSLSessionCache dbm:/var/adm/httpd.ssl.cache\nSSLSessionCacheTimeout 300\nSSLMutex file:/var/adm/httpd.ssl.mutex\n\n<Directory /docs/clientcert>\n\tSSLOptions +StdEnvVars +ExportCertData +OptRenegotiate\n\tSSLVerifyClient require\n\tSSLVerifyDepth 2\n\tSSLRequire %{SSL_CLIENT_CERT} eq file('<certfile>') /\n\t\tor %{SSL_CLIENT_CERT} eq file('<certfile>')\n\tOrder Deny,Allow\n\tDeny from all\n\tAllow from 1.1.1.1\n</Directory>\n\n--------------------------------------------------------------------------------------------------\nHTML files used for testing:\n\n$ cat index.html\n<HTML>\n<BODY>\nHello client cert\n\n<FORM action=index2.html method=post>\n<INPUT value='Post to index2.html' type=submit>\n</FORM>\n\n</BODY>\n</HTML>\n\n$ cat index2.html\n<HTML>\n<BODY>\nHello client cert - index2\n\n<FORM action=index.html method=post>\n<INPUT value='Post to index.html' type=submit>\n</FORM>\n\n</BODY>\n</HTML>\n\n--------------------------------------------------------------------------------------------------\nVH access log:\n2.2.2.2 - - [07/Apr/2003:14:23:57 -0700] 'GET /clientcert/index.html HTTP/1.1'\n200 140 '-' 'Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.3)\nGecko/20030312' GET /clientcert/index.html - 'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:14:24:03 -0700] 'POST /clientcert/index2.html HTTP/1.1'\n200 144 'https://test.domain.com/clientcert/index.html' 'Mozilla/5.0 (Windows;\nU; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index2.html -\n'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:14:24:03 -0700] 'POST /clientcert/index.html HTTP/1.1'\n200 140 'https://test.domain.com/clientcert/index2.html' 'Mozilla/5.0 (Windows;\nU; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index.html -\n'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:14:24:04 -0700] 'POST /clientcert/index2.html HTTP/1.1'\n200 144 'https://test.domain.com/clientcert/index.html' 'Mozilla/5.0 (Windows;\nU; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index2.html -\n'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:14:24:05 -0700] 'POST /clientcert/index.html HTTP/1.1'\n200 140 'https://test.domain.com/clientcert/index2.html' 'Mozilla/5.0 (Windows;\nU; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index.html -\n'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:14:24:06 -0700] 'POST /clientcert/index2.html HTTP/1.1'\n200 144 'https://test.domain.com/clientcert/index.html' 'Mozilla/5.0 (Windows;\nU; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index2.html -\n'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:14:24:07 -0700] 'POST /clientcert/index.html HTTP/1.1'\n200 140 'https://test.domain.com/clientcert/index2.html' 'Mozilla/5.0 (Windows;\nU; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index.html -\n'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:14:25:12 -0700] 'POST /clientcert/index2.html HTTP/1.1'\n405 244 'https://test.domain.com/clientcert/index.html' 'Mozilla/5.0 (Windows;\nU; Windows NT 5.0; en-US; rv:1.3) Gecko/20030312' POST /clientcert/index2.html -\n'HTTP/1.1' (-)\n\nVH error log:\n[Mon Apr 07 14:25:12 2003] [error] SSL Re-negotiation in conjunction with POST\nmethod not supported!\nhint: try SSLOptions +OptRenegotiate\n\n--------------------------------------------------------------------------------------------------\nWith Internet Explorer 5.5:\n\nVH access log:\n2.2.2.2 - - [07/Apr/2003:15:46:15 -0700] 'GET /clientcert/ HTTP/1.1' 302 227 '-'\n'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0; T312461)' GET /clientcert/ -\n'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:15:46:16 -0700] 'GET /clientcert/ HTTP/1.1' 200 140 '-'\n'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0; T312461)' GET\n/clientcert/index.html - 'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:15:46:24 -0700] 'POST /clientcert/index2.html HTTP/1.1'\n200 144 'https://test.domain.com/clientcert/' 'Mozilla/4.0 (compatible; MSIE\n5.5; Windows NT 5.0; T312461)' POST /clientcert/index2.html - 'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:15:46:25 -0700] 'POST /clientcert/index.html HTTP/1.1'\n200 140 'https://test.domain.com/clientcert/index2.html' 'Mozilla/4.0\n(compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index.html -\n'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:15:46:26 -0700] 'POST /clientcert/index2.html HTTP/1.1'\n200 144 'https://test.domain.com/clientcert/index.html' 'Mozilla/4.0\n(compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index2.html -\n'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:15:46:27 -0700] 'POST /clientcert/index.html HTTP/1.1'\n200 140 'https://test.domain.com/clientcert/index2.html' 'Mozilla/4.0\n(compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index.html -\n'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:15:46:28 -0700] 'POST /clientcert/index2.html HTTP/1.1'\n200 144 'https://test.domain.com/clientcert/index.html' 'Mozilla/4.0\n(compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index2.html -\n'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:15:46:29 -0700] 'POST /clientcert/index.html HTTP/1.1'\n200 140 'https://test.domain.com/clientcert/index2.html' 'Mozilla/4.0\n(compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index.html -\n'HTTP/1.1' (-)\n2.2.2.2 - - [07/Apr/2003:15:46:58 -0700] 'POST /clientcert/index2.html HTTP/1.1'\n405 244 'https://test.domain.com/clientcert/index.html' 'Mozilla/4.0\n(compatible; MSIE 5.5; Windows NT 5.0; T312461)' POST /clientcert/index2.html -\n'HTTP/1.1' (-)\n\nVH error log:\n[Mon Apr 07 15:46:15 2003] [error] Re-negotiation handshake failed: Not accepted\nby client!?\n[Mon Apr 07 15:46:58 2003] [error] SSL Re-negotiation in conjunction with POST\nmethod not supported!\nhint: try SSLOptions +OptRenegotiate\n\nServer error log:\n[Mon Apr 07 15:46:16 2003] [notice] child pid 28262 exit signal Segmentation\nfault (11)
12355	Matthias Wimmer	1052779005000	The existance of this 'bug' is documented in modules/ssl/ssl_engine_kernel.c\nline 525. But it would really be nice to reimplement this feature.
12355	keilh	1071750802000	Created an attachment (id=9626)\ndiff against httpd-2.0.48\n
12355	keilh	1071751575000	Fixed the problem in the following way:\nBefore the renegotiation is starting the body of the POST request\nwill be readed via ap_get_client_block().(So content-length, chunking etc.\nis handeld correctly.) \nThe data will be stored in a brigade and an input filter\nwill be added just after the http_header_filter. That input filter has the\ndata from it's ctx. \nSo in any subsequent read call that input filter will be invoked and \ncan return the stored data.\n\n\nP.S. Im not sure if the upload of the diff is ok, so I paste it to be sure\n\n\n*** mod_ssl.h.patched\tThu Dec 18 13:11:48 2003\n--- mod_ssl.h\tThu Dec 18 13:13:19 2003\n***************\n*** 709,714 ****\n--- 709,715 ----\n  void         ssl_io_filter_init(conn_rec *, SSL *);\n  void         ssl_io_filter_register(apr_pool_t *);\n  long         ssl_io_data_cb(BIO *, int, MODSSL_BIO_CB_ARG_TYPE *, int, long,\nlong);\n+ long         ssl_io_suck(request_rec *);\n  \n  /*  PRNG  */\n  int          ssl_rand_seed(server_rec *, apr_pool_t *, ssl_rsctx_t, char *);\n*** ssl_engine_kernel.c.patched\tThu Dec 18 13:11:39 2003\n--- ssl_engine_kernel.c\tThu Dec 18 13:15:04 2003\n***************\n*** 583,596 ****\n       *\n       * !! BUT ALL THIS IS STILL NOT RE-IMPLEMENTED FOR APACHE 2.0 !!\n       */\n!     if (renegotiate && !renegotiate_quick && (r->method_number == M_POST)) {\n          ap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server,\n                       'SSL Re-negotiation in conjunction '\n                       'with POST method not supported!/n'\n                       'hint: try SSLOptions +OptRenegotiate');\n! \n          return HTTP_METHOD_NOT_ALLOWED;\n      }\n  \n      /*\n       * now do the renegotiation if anything was actually reconfigured\n--- 583,602 ----\n       *\n       * !! BUT ALL THIS IS STILL NOT RE-IMPLEMENTED FOR APACHE 2.0 !!\n       */\n! \tif (renegotiate && !renegotiate_quick && (r->method_number == M_POST)) {\n! #ifdef SSL_CONSERVATIVE \t\t\n          ap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server,\n                       'SSL Re-negotiation in conjunction '\n                       'with POST method not supported!/n'\n                       'hint: try SSLOptions +OptRenegotiate');\n! \t\t\n          return HTTP_METHOD_NOT_ALLOWED;\n+ #else\t\t\n+ \t\tif( ssl_io_suck(r) != OK) {\n+ \t\t\treturn HTTP_METHOD_NOT_ALLOWED;\n+ \t\t}\n      }\n+ #endif /* SSL_CONSERVATIVE */\n  \n      /*\n       * now do the renegotiation if anything was actually reconfigured\n*** ssl_engine_io.c.patched\tThu Dec 18 13:12:02 2003\n--- ssl_engine_io.c\tThu Dec 18 13:21:31 2003\n***************\n*** 897,902 ****\n--- 897,987 ----\n  }\n  \n  static const char ssl_io_filter[] = 'SSL/TLS Filter';\n+ static const char ssl_buff_filter[] = 'SSL/TLS Buffering Filter';\n+ /*\n+  * reads the buffered data during a POST request with renegotiation\n+  * will be registere at runtime.\n+  * NOTE: we try to buffer the complete body. Use the attribute\n'LimitRequestBody'\n+  * preventing DOS attacks.\n+  */\n+ long ssl_io_suck(request_rec *r)\n+ {\n+ \tapr_bucket *bucket;\n+ \tapr_bucket_brigade *bb =\napr_brigade_create(r->pool,r->connection->bucket_alloc);\n+ \n+ \tint readed = 0;\n+ \tint len = 0;\n+ \tint toRead= 0;\n+ \tchar *buffer = NULL;\n+ \tchar *pos = NULL;\n+ \t\n+ \tif(ap_setup_client_block(r,REQUEST_CHUNKED_DECHUNK) !=OK) {\n+ \t\treturn HTTP_METHOD_NOT_ALLOWED; \n+ \t}\n+ \n+ \tif(!ap_should_client_block(r)) {\n+ \t\treturn OK;\n+ \t}\n+ \t\n+ \tdo {\n+ \t\tbuffer = apr_pcalloc(r->pool,HUGE_STRING_LEN);\n+ \t\ttoRead = HUGE_STRING_LEN;\n+ \n+ \t\t/* check malloc */\n+ \t\tif(buffer == NULL) {\n+ \t\t\tap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server,\n+                      'SSL Re-negotiation in conjunction '\n+ \t\t\t\t     'with POST (buffering body failed)!/n');\n+ \t\t\tapr_brigade_destroy(bb);\n+ \t\t\treturn HTTP_METHOD_NOT_ALLOWED;\t\t\t\n+ \t\t}\n+ \t\t\n+ \t\t/* fill the bucket */\n+ \t\tpos = buffer;\n+ \t\tlen = 0;\n+ \t\tdo {\n+ \t\t\treaded  = ap_get_client_block(r,pos,toRead);\n+ \n+ \t\t\tif(readed <=0) {\n+ \t\t\t\tbreak;\n+ \t\t\t}\n+ \t\t\t\n+ \t\t\ttoRead  -= readed;\n+ \t\t\t\n+ \t\t\t/* sanity */\n+ \t\t\tif(toRead<0) {\n+ \t\t\t\treturn HTTP_METHOD_NOT_ALLOWED;\n+ \t\t\t}\n+ \n+ \t\t\tpos += readed;\n+ \t\t\tlen += readed;\t\n+ \t\t}\n+ \t\twhile(toRead>0);\n+ \n+ \t\t/* check last read result */\n+ \t\tif(readed<0) {\n+ \t\t\tap_log_error(APLOG_MARK, APLOG_ERR, 0, r->server,\n+                      'SSL Re-negotiation in conjunction '\n+ \t\t\t\t     'with POST (reading body failed)!/n');\n+ \t\t\tapr_brigade_destroy(bb);\n+ \t\t\treturn HTTP_METHOD_NOT_ALLOWED; \n+ \t\t}\n+ \t\t\n+ \t\t/* check if we have readed everything */\n+ \t\tif(len == 0) {\n+ \t\t\tbreak;\n+ \t\t}\n+ \t\tbucket =\napr_bucket_pool_create(buffer,len,r->pool,r->connection->bucket_alloc);\n+ \t\t\n+         APR_BRIGADE_INSERT_TAIL(bb, bucket);\n+ \t} \n+ \twhile(1);\n+ \t\n+ \t//add the ssl_buff_filter_input\n+ \tap_add_input_filter(ssl_buff_filter, bb, r, r->connection);\n+ \t\n+ \treturn OK;\t\t\t\t\t\t\t\t\t  \n+ }\n  \n  /*\n   *  Close the SSL part of the socket connection\n***************\n*** 1361,1366 ****\n--- 1446,1529 ----\n      return status;\n  }\n  \n+ static apr_status_t ssl_buff_filter_input(ap_filter_t *f,\n+                                         apr_bucket_brigade *bb,\n+                                         ap_input_mode_t mode,\n+                                         apr_read_type_e block,\n+                                         apr_off_t readbytes)\n+ {\n+ \tapr_bucket_brigade *aa = f->ctx;\n+ \tapr_status_t  rv;\n+ \t\n+ \tif(aa && !APR_BRIGADE_EMPTY(aa)) {\n+ \n+ \t\tif(mode == AP_MODE_READBYTES) {\n+ \t\t\tapr_bucket *b;\n+ \t\t\tapr_off_t missing = readbytes;\n+ \t\t\tapr_size_t len;\n+ \t\t\tconst char *tmp;\n+ \t\n+ \t\t\twhile (!APR_BRIGADE_EMPTY(aa)) {\n+ \t\t\t\tb = APR_BRIGADE_FIRST(aa);\n+ \t\t\t\n+ \t\t\t\trv = apr_bucket_read(b, &tmp, &len, APR_BLOCK_READ);\n+ \t\t\t\tif (rv != APR_SUCCESS) {\n+ \t\t\t\t\treturn rv;\n+ \t\t\t\t}\n+ \t\t\t\t\n+ \t\t\t\t/* consume whole bucket */\n+ \t\t\t\tif(missing >= len) {\n+ \t\t\t\t\tAPR_BUCKET_REMOVE(b);\n+ \t\t\t\t\tAPR_BRIGADE_INSERT_TAIL(bb,b);\n+ \t\t\t\t}\n+ \t\t\t\t/* comsume only a part */ \n+ \t\t\t\telse{\n+ \t\t\t\t\trv = apr_bucket_split(b, missing);\n+ \t\t\t\t\tif (rv != APR_SUCCESS) {\n+ \t\t\t\t\t\treturn rv;\n+ \t\t\t\t\t}\n+ \t\t\t\t\t\n+ \t\t\t\t\tAPR_BUCKET_REMOVE(b);\n+ \t\t\t\t\tAPR_BRIGADE_INSERT_TAIL(bb, b);\n+ \t\t\t\t\tbreak;\n+ \t\t\t\t}\n+ \t\t\t\t\n+ \t\t\t\tmissing -= len;\n+ \t\t\t\t\n+ \t\t\t\tif (missing = 0) {\n+ \t\t\t\t\tbreak;\n+ \t\t\t\t}\n+ \n+ \t\t\t\tif(missing<0) {\n+ \t\t\t\t\treturn AP_FILTER_ERROR;\n+ \t\t\t\t}\n+ \t\t\t}\n+ \t\t\treturn APR_SUCCESS;\n+ \t\t}\n+ \t\telse if (mode == AP_MODE_READBYTES) {\n+ \t\t\tapr_bucket_brigade *nb = apr_brigade_create(f->r->pool,f->c->bucket_alloc);\n+ \t\t\t\n+ \t\t\t/* split */\n+ \t\t\trv = apr_brigade_split_line(nb,aa,block,readbytes);\n+ \t\t\tif( rv != APR_SUCCESS) {\t\t\t\t\n+ \t\t\t\treturn rv;\n+ \t\t\t} \n+ \n+ \t\t\t/* concatinate */\n+ \t\t\tAPR_BRIGADE_CONCAT(bb,aa);\n+ \t\t\t\n+ \t\t\t/* remember the rest */\n+ \t\t\tf->ctx = nb;\n+ \t\t\t\n+ \t\t\treturn APR_SUCCESS;\t\n+ \t\t}\n+ \t\t\n+ \t}\n+ \t\n+ \t\n+ \treturn ap_pass_brigade(f->next, bb);\n+ }\n+ \n  static void ssl_io_input_add_filter(ssl_filter_ctx_t *filter_ctx, conn_rec *c,\n                                      SSL *ssl)\n  {\n***************\n*** 1417,1422 ****\n--- 1580,1586 ----\n  {\n      ap_register_input_filter  (ssl_io_filter, ssl_io_filter_input,  NULL,\nAP_FTYPE_CONNECTION + 5);\n      ap_register_output_filter (ssl_io_filter, ssl_io_filter_output, NULL,\nAP_FTYPE_CONNECTION + 5);\n+     ap_register_input_filter  (ssl_buff_filter, ssl_buff_filter_input,  NULL,\nAP_FTYPE_PROTOCOL - 1);\n      return;\n  }\n  \n\n \n
12355	Erik Abele	1071752121000	Just adding the PatchAvailable keyword. Hartmut, to keep bugs in the loop please don't resolve \nthem as fixed until they're reviewed and/or committed at least to one dev-tree. Anyway, thanks for \nthe patch.
12355	Mohamed Sadok MOUHA	1072434615000	Also, this configuration does not activate the bug :\nSSLEngine on\nSSLVerifyClient optional\nSSLOptions +OptRenegotiate\n<location /location/ >\n        SSLVerifyClient optional\n        SSLVerifyDepth 10\n</location>
12355	Rob Riggs	1076290041000	I was having a similar problem with per-directory SSL authentication with DAV.\n(Note that the patch posted earlier does not fix the problem for DAV.)\n\nI have worked around the problem by having a global 'SSLVerifyClient optional'\ndirective.  The per-directory 'SSLVerifyClient required' is then processed\nproperly.  This seems to preserve all of the behavior that I need.  Those\nwithout a certificate can still access the site via SSL, and the entire site,\nincluding the portions using SSL authentication, work for those with proper\ncertificates. This may need no more than clarification in the documentation.\n
12355	William J Dennison	1076341649000	I have attempted usage of all posts in this bug to date.  I have used the patch,\nno dice.  I have altered my configurations as noted by the posts mentioning that\nthe bug will not be enabled with a configuration change, again no dice.  I have\nalso used several configurations noted in errors by the apache software and\nnothing works.  I always get 'SSL Re-negotiation in conjunction with POST method\nnot supported!' when the SSL is renegotiated and the next method is a POST\ninstead of a GET.\n\nI find it hard to swallow ('because I am a huge fan of Apache and mod_ssl'),\nthat Apache organization would make such a glaring flaw in the 2.0 builds\nconsidering all this worked great in the 1.3 builds.  My final resolution\nbecause I am in a production environment (until Apache org. fixes the problem).\n Go back to the 1.3 build ASAP.
12355	Birger Toedtmann	1076342811000	Hello,\n\nI also applied all 'remedies' so far mentioned by others (including patching), \nto no avail, the problem is still alive and healthy.  As a consequence, we are \nconsidering going back to 1.3 as well.  I'm reluctant to go in this direction, \nbut without progress for months now, there seems to be no perspective for 2.0 \nwithin environments requiring client certs and the POST method....\n\nBTW: You should remove the 'PatchAvailable' keyword.  No offense for the creator \nof the patch, but it simply doesn't work.\n\n\nRegards,\n\nBirger
12355	Joe Orton	1085654407000	*** Bug 21167 has been marked as a duplicate of this bug. ***
12355	Joe Orton	1085663685000	Created an attachment (id=11681)\npatch for 2.0 to fix #12355\n
12355	Joe Orton	1085663908000	*Experimental* patch attached above for 2.0, this is closer to fixing the issue\nproperly, without buffering the entire request body in memory.  (it makes one\nbogus assumption about the filter interfaces but seems to work OK)  This\napproach also needs careful checking bugs may allow clients to bypass the access\ncontrol checks.
12355	Joe Orton	1086253352000	Created an attachment (id=11736)\nproposed fix\n
12355	Joe Orton	1086253803000	Second patch attached is the fix I have proposed for this issue, which has no\nissues that I'm currently aware of, and could do with some wider testing.
12355	Joe Orton	1086253916000	*** Bug 18395 has been marked as a duplicate of this bug. ***
12355	Joe Orton	1086264207000	Created an attachment (id=11745)\nproposed fix for 2.0 branch\n
12355	Joe Orton	1086264336000	Proposed patch, rediffed for 2.0, attached above.
12355	Birger Toedtmann	1086431783000	Hi,\n\nwhen patching the apache2-2.0.48 source RPM for Mandrake 10 (and \nrebuilding the binaries), the SSL service crashes immediately upon\nthe use of client certificates:\n\n[Sat Jun 05 12:30:50 2004] [notice] LDAP: Built with OpenLDAP LDAP SDK\n[Sat Jun 05 12:30:50 2004] [notice] Digest: generating secret for digest\nauthentication ...\n[Sat Jun 05 12:30:50 2004] [notice] Digest: done\n[Sat Jun 05 12:30:51 2004] [notice] Apache-AdvancedExtranetServer/2.0.48\n(Mandrake Linux/6.2.100mdk) mod_ssl/2.0.48 OpenSSL/0.9.7a DAV/2 PHP/4.3.1\nconfigured -- resuming normal operations\n\n - service is now working and delivers ordinary pages successfully,\n   including PHP and MySQL_over_PHP operations and SSL (without client\n   certs) -\n\n[Sat Jun 05 12:32:21 2004] [notice] child pid 29488 exit signal Segmentation\nfault (11)\n\n - that was the child that dealt the first time with a \n   client certificate -\n\n\nWithout the patch (but same source) and without using POST, the \nsite works 'perfectly' using client certificates.\n\n\n\n\nBirger
12355	Joe Orton	1089209366000	*** Bug 29569 has been marked as a duplicate of this bug. ***
12355	Joe Orton	1089297080000	Please don't mark bugs as fixed without adding a comment, and please don't mark\nbugs as fixed if they aren't really fixed!
12355	David A. Desrosiers	1092765818000	Have there been any updates on this issue since the last comment filed on July\n8th of this year? 
12355	Joe Orton	1093292339000	No; I'm not really convinced the solution I was working on can be made to be secure.\n\nNote that for many configurations, there is a simple workaround: add\n\n  SSLVerifyClient optional\n\nto the SSL vhost config, as well as the 'SSLVerifyClient require' in whatever\nLocation/Directory context.
12355	Joe Orton	1093357087000	I was reminded privately that the other workaround for this bug is of course to\nensure that the first access the browser makes to the SSLVerifyClient-protected\nlocation uses a GET request rather than a POST request.
12355	Joe Orton	1095848414000	*** Bug 31314 has been marked as a duplicate of this bug. ***
12355	Will Rowe	1104082305000	Some general comments;\n\nHTTP/1.0\n\n  the 'classic' HTTP/1.0 handling -must- buffer the body if the connection\n  will be renegotiated.  This should no longer be handled inside the mod_ssl\n  module itself, by itself.  With the advent of filters, either apreq2 or\n  another 'client buffer' module must be implemented.  The logic looks like;\n\n    brigade read loop\n      mem_body > max_memory_body ?\n        create tmpfile if tmpfile isnull\n        response 'failure' if total_body > max_buffer_body\n        write body -> tmpfile\n    reopen tmpfile read-only\n    insert tmpfile bucket of tmpfile prior to remaining mem_body buckets.\n\n  now we have two controls that would prevent DoS attacks present in the\n  original fix proposed (unbounded growth of the body.)  Remember, the\n  renegotiation would NOT determine the client certificate is valid until\n  after these resources had been consumed by a nefarious client.\n\n  I rather like the idea of apreq2 doing this work, and actually, integrating\n  apreq2 as a 'stock' apache module.  apreq2 does nothing until some module\n  in the server configuration wants to use its services.\n\nHTTP/1.1 + client Expect: 100-continue\n\n  http://rfc.net/rfc2616.html#s8.2.3\n\n  Clients which truly pause for 100-continue could be satisfied with no\n  buffering of the body.  Schedule the renegotation prior to sending the\n  100 CONTINUE response.\n\nFinally note that this is not specific to POST, it's generic to all HTTP\nmethods which contain a client body.  The headers may be inspected to\ndetermine if the client is attempting to push a body with the request.\n\n
12355	Marc Stern	1114442798000	Isn't there any way to suppress renegotiation ?
12355	Bruno Santiago	1116021549000	Workaround!!!\n\nFollowing configuration works fine (optional for any except with CA \ncertificate, and required to an especific location):\n\nSSLEngine on\nSSLVerifyClient optional_no_ca\nSSLVerifyDepth  2\nSSLOptions +OptRenegotiate\n<location /any_location/ >\n        SSLVerifyClient require\n</location>\n\nRegards,\n\nBruno Santiago
12355	Marc Stern	1117540675000	'SSLVerifyClient optional' seems also safe.\nIs 'SSLOptions +OptRenegotiate' really needed, or is it an optimisation ?\nIs it totally safe ? The doc states to use this carefully.
12355	Yefym	1125400666000	(In reply to comment #34)\n> 'SSLVerifyClient optional' seems also safe.\n> Is 'SSLOptions +OptRenegotiate' really needed, or is it an optimisation ?\n> Is it totally safe ? The doc states to use this carefully.\n\n\nThe workaround explained above is not safe at least for apache 2.0.52.\n'\nRE: [users@httpd] Bug or Feature : global SSLVerifyClient in <VirtualHost>\noverrides the same in  <Location>?\n\nSimple test scenario is :\n1. access document root location - 'SSLVerifyClient optional' ,  cancel\ncertificate choice window.\n2. access location <Location '/auth'> with  'SSLVerifyClient require' - no\ntriggered SSL negotiation - access without certificate granted.\n\nCorrect should be the following behaviour, but there is no re-negotiation:\n>SSLVerifyClient is documented as working in directory context, so it should\nalso work in <Location> context. The manual page for mod_ssl does \n>explicitly say that a SSL renegotiation is triggered if a request for the\nlocation is received.\n \n\nconfig sample:\n\n<VirtualHost> \nSSLVerifyClient optional \n\nAlias /auth   /htdocs/access \n<Location '/access'> \nSSLVerifyClient require \nSSLOptions +ExportCertData +StdEnvVars +OptRenegotiate\nSSLVerifyDepth 5 \nOptions None \n</Location> \n\n</VirtualHost> \n\n'\n\n\n\n\n\n
12355	Yefym	1125401636000	Proposed workaround is to add an additional <VirtualHost> and \nconfigure in its context SSLVerifyClient require.\n\n\nIn my particular case creating webapi virtualhost suppose to fix problems with axis.\n\n\n\n\n\n\n\n\n\n
12355	Joe Orton	1125506687000	The problem mentioned in comment 35 is a separate issue from the bug covered\nhere, and is fixed by: http://svn.apache.org/viewcvs?rev=264800&view=rev
12355	Marc Poulhi	1125581105000	I was told to use something like this:\n\n<VirtualHost ...>\n   ...\n   SSLVerifyClient none\n   ...\n   <Location /plop>\n      ...\n      SSLVerifyClient require\n      ...\n   </Location>\n</VirtualHost>\n\nAnd this seems to work fine. Can someone confirm this is working correctly and\nI'm not missing some 'feature' for this bug ?\nThanks
12355	Scott Cantor	1125591722000	If the bug isn't fixed, the issue is that the Location-specific renegotiation\nfails on a POST. If you're testing with GET, that's not a useful test.
12355	Joe Orton	1127421486000	Created an attachment (id=16491)\nbackport of patch from trunk\n\nThis is a backport of the patch from the trunk which was committed to fix this\nissue.\tAny results from testing are welcome.
12355	Joe Orton	1127467449000	Created an attachment (id=16495)\npatch for 2.0.54\n\nThis patch can be applied to 2.0.54.\n
12355	Joe Orton	1127912420000	Now fixed for 2.1.8-beta and later.\n\nhttp://svn.apache.org/viewcvs?rev=290965&view=rev\n\nGiven sufficient testing of the patch from comment 41, this could get a backport\nto 2.0.x.
12355	Ralph Seichter	1129664049000	(In reply to comment #41)\n\n> This patch can be applied to 2.0.54.\n\nThe patch can be applied to 2.0.55 aswell, and it allows using the\nfollowing setup:\n\n  SSLVerifyClient optional\n  <Location /subversion>\n    DAV svn\n    SVNParentPath /path/to/reps\n    AuthzSVNAccessFile /path/to/accessfile\n    SSLVerifyClient require\n    SSLUserName SSL_CLIENT_S_DN_CN\n    SSLOptions +StrictRequire\n  </Location>\n\nI used Subversion 1.2.3 clients on Linux and Windows for successful\ntesting.\n\nIt is important to note that with the above configuration, access to\nthe Subversion repository requires a client certificate, while other\nareas of the server can be accessed without certificates (i.e. webmail\nvia HTTPS). Judging from my tests, this desired behaviour can not be\nachieved based on vanilla 2.0.55 sources, so I strongly welcome Joe's\npatch and hope it will be included as a 2.0.x backport in the future.
12355	Yefym	1142845251000	(In reply to comment #43)\n> (In reply to comment #41)\n> \n> > This patch can be applied to 2.0.54.\n> \n> The patch can be applied to 2.0.55 aswell, and it allows using the\n> following setup:\n> \n>   SSLVerifyClient optional\n>   <Location /subversion>\n>     DAV svn\n>     SVNParentPath /path/to/reps\n>     AuthzSVNAccessFile /path/to/accessfile\n>     SSLVerifyClient require\n>     SSLUserName SSL_CLIENT_S_DN_CN\n>     SSLOptions +StrictRequire\n>   </Location>\n> \n> I used Subversion 1.2.3 clients on Linux and Windows for successful\n> testing.\n> \n> It is important to note that with the above configuration, access to\n> the Subversion repository requires a client certificate, while other\n> areas of the server can be accessed without certificates (i.e. webmail\n> via HTTPS). Judging from my tests, this desired behaviour can not be\n> achieved based on vanilla 2.0.55 sources, so I strongly welcome Joe's\n> patch and hope it will be included as a 2.0.x backport in the future.\n\n\n\nThe problem is still not fixed. Was tested for apache 2.0.55 :\nthere is still post method not allowed message described by you and other guys\nin this topic.\n\nAfter patching apache it still doesn"t work, only the message is different.\n\n\nWe tried with apache_2.0.55 with unofficial patch from bugzilla (No.:12355) and\ngot the following messages in logfiles.\n\naccess_log:\n\n85.115.6.202 - - [17/Mar/2006:13:13:50 +0000] 'POST\n/webservice/services/SessionManagement HTTP/1.0' 403 - '-'\n '-'\n\nerror_log with debug level in http.conf:\n\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1738): OpenSSL:\nHandshake: start\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1746): OpenSSL: Loop: SSL\nrenegotiate ciphers\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1746): OpenSSL: Loop:\nSSLv3 write hello request\nA\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1746): OpenSSL: Loop:\nSSLv3 flush data\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1746): OpenSSL: Loop:\nSSLv3 write hello request\nC\n[Fri Mar 17 13:32:54 2006] [info] Awaiting re-negotiation handshake\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1738): OpenSSL:\nHandshake: start\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1746): OpenSSL: Loop:\nbefore accept initializati\non\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_io.c(1697): OpenSSL: read 0/5\nbytes from BIO#83a24b8 [mem\n: 842d708] (BIO dump follows)\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_io.c(1644):\n+--------------------------------------------\n-----------------------------+\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_io.c(1675):\n+--------------------------------------------\n-----------------------------+\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_kernel.c(1770): OpenSSL: Exit:\nfailed in SSLv3 read clien\nt hello B\n[Fri Mar 17 13:32:54 2006] [error] Re-negotiation handshake failed: Not accepted\nby client!?\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_io.c(1488): [client 85.115.6.202]\nread from buffered SSL\nbrigade, mode 0, 8192 bytes\n[Fri Mar 17 13:32:54 2006] [debug] ssl_engine_io.c(1550): [client 85.115.6.202]\nbuffered SSL brigade no\nw exhausted; removing filter\n[Fri Mar 17 13:33:07 2006] [debug] ssl_engine_io.c(1708): OpenSSL: I/O error, 5\nbytes expected to read\non BIO#83a24b8 [mem: 842d708]\n[Fri Mar 17 13:33:07 2006] [info] (70007)The timeout specified has expired: SSL\ninput filter read faile\nd.\n[Fri Mar 17 13:33:07 2006] [debug] ssl_engine_kernel.c(1756): OpenSSL: Write:\nSSL negotiation finished\nsuccessfully\n[Fri Mar 17 13:33:07 2006] [info] Connection to child 2 closed with standard\nshutdown(server drecord.de\n.something.com:443, client 85.115.6.202)\n\n--------------------------------------------------------------------------------\n\n\nP.S.\nWe have additional virtualhost configured that is responsible for certificate\nauthentication and session management with axis, there it works perfectly. So\nthe problem occures only for <location> that doesn"t have a globaly set\n<SSLVerifyClient> to optional or required\n\nP.P.S. \n<SSLVerifyClient> optional in a global context fix the problem , but this\nsolution is not acceptable because it enforce the browser to show the popup with\ninstalled certificates.(sure it is a browser issue and probably could be\nconfigured on the client side, but this is not the way it should work in\nproductive env.)\n\nRegards, Yefym
12355	Joe Orton	1143710399000	If you have any problems using this patch, please upgrade to 2.2.0 instead, and\nfile bugs giving the error_log output from 2.2.0.
12355	Ruediger Pluem	1143753374000	*** Bug 39154 has been marked as a duplicate of this bug. ***
12355	Ruediger Pluem	1144451579000	*** Bug 39243 has been marked as a duplicate of this bug. ***
12355	Ruediger Pluem	1149288882000	*** Bug 39705 has been marked as a duplicate of this bug. ***
12355	richard chen	1149493092000	I couldn't understand why this bug is not fix by Apache team since the release \nof Apache2. I really need this features to be enabled as what we have in \nmod_ssl for version for apache1.3.x.
12355	Ruediger Pluem	1149507431000	It is fixed in 2.2.x, but has not been backported to 2.0.x yet. There is a patch\nagainst 2.0.54 attached to this report for those who need to fix this\nimmediately for 2.0.x.
12355	Will Rowe	1153630086000	\n  First this IS fixed in 2.2.0.  Backports aren't discussed on Bugzilla, this\n  issue has been raised in our 2.0.x STATUS file.  And given a more accurate name.
12355	Derrier Dominique	1176510565000	this bug is always present with Apache/2.2.4.\n\nYou can't mixed SSLVerifyClient optinal and SSLVerifyClient requierd part\nTo allow some Location for non SSL valid Client.\n\n\nNOT WORKING ========\n------------------------\nSSLVerifyClient optional\nSSLVerifyDepth  1\nSSLOptions +OptRenegotiate\n<Location /Album>\nSSLRequireSSL\nSSLVerifyClient      require\nSSLCACertificateFile conf/ssl.crt/Root_Certificat.crt\nSSLCACertificatePath conf/ssl.crt\nSSLRequire  (%{SSL_CLIENT_S_DN_OU} eq 'Portable' || %{SSL_CLIENT_S_DN_OU} eq\n'Personnal')\nSSLVerifyDepth       3\n#FIX ANOTHER BUG\nSetEnv REMOTE_USER ${SSL_CLIENT_S_DN_CN}\nSSLUserName SSL_CLIENT_S_DN_CN\n</location>\n\n\nWORKING ==\n---------
12355	Derrier Dominique	1176511352000	Sorry ... I forgot to say .. that the bug is only with php.\nCGI perl work fine ..
12355	Derrier Dominique	1176600943000	It's working fine when the certificat private key is <= 512.\n2048b not working\n1024b not working.\nBut I don't understand why\n\nIf it's can help coders.\n
12355	Davi Arnaut	1181296780000	(In reply to comment #54 and previous ones)\n> It's working fine when the certificat private key is <= 512.\n> 2048b not working\n> 1024b not working.\n> But I don't understand why\n> \n> If it's can help coders.\n> \n\nThis looks like an unrelated problem, could you open a new issue for it? Thanks.
12355	Davi Arnaut	1181303740000	(In reply to comment #52)\n> this bug is always present with Apache/2.2.4.\n> \n> You can't mixed SSLVerifyClient optinal and SSLVerifyClient requierd part\n> To allow some Location for non SSL valid Client.\n> \n\nThis was fixed in Apache 2.0.55, changelog:\n\n  *) SECURITY: CVE-2005-2700 (cve.mitre.org)\n     mod_ssl: Fix a security issue where 'SSLVerifyClient' was not\n     enforced in per-location context if 'SSLVerifyClient optional'\n     was configured in the vhost configuration.  [Joe Orton]\n
12355	Ruediger Pluem	1181444543000	*** Bug 42625 has been marked as a duplicate of this bug. ***
12355	Serge Dubrouski	1181501246000	*** Bug 42625 has been marked as a duplicate of this bug. ***
12355	Ruediger Pluem	1184674957000	Backported to 2.0.x as r536373\n(http://svn.apache.org/viewvc?view=rev&revision=536373)
12395	Dr. Georg Czedik-Eysenberg	1036313679000	Hi,\n\nis there really nobody out there, who is interested in this bug,\nwhich I reported 8 weeks ago and is still in the status NEW? :-(\n\nOr do you need any additional information from me?\n\nRegards, Georg
12395	Andr?? Malo	1041126732000	Sorry for the long delay.\nIt's fixed now in HEAD (i.e. httpd-2.1.0-dev) and will probably be backported to\n1.3 and 2.0.\n\nThanks for using Apache!\n(and thanks for your patience...)
12395	Andr?? Malo	1043807577000	*** Bug 16526 has been marked as a duplicate of this bug. ***
12395	Trevor Phillips	1043808850000	Has this been resolved in Apache 1.3 yet?\nI notice it was originally logged in this bug against 1.3.23. I use 1.3.26\n(Debian Packages) and it hasn't been resolved. Skimming the 1.3.27 CHANGES file\nI can see no mention of it being fixed there either...
12395	Andr?? Malo	1043809863000	Ah, sorry, perhaps I should mention the state ;-)\nIt's resolved for the next releases of 2.0.45 and 1.3.28.
12395	Sander Holthaus	1045580964000	If I use this\n\n    RewriteEngine on\n    RewriteCond %{HTTP_REFERER} ^(.*)$\n    RewriteRule ^(.*)     -       [CO=referrer:%1:.domain.com]\n\nin combination with -FollowSymLinks, I also get the error:\n \n'Options FollowSymLinks or SymLinksIfOwnerMatch is \noff which implies that RewriteRule directive is forbidden'\n\nI'm not rewriting any URL, I just want to write out a coookie. Is this fixed in \nthis bugfix too?
12395	Andr?? Malo	1045581353000	No.\nOptions -FollowSymlinks means that you can't have any RewriteRules active.\nYou may use mod_headers for only setting headers...
12483	Will Rowe	1031674305000	\n  If you modify your httpd.conf file in utf-8, providing a legit non-ASCII, utf-8\n  encoded AuthName string, what happens?\n\n
12483	Graham Leggett	1043231865000	A new directive AuthLDAPCharsetConfig was added which specifies a charset\nconversion file to fix this problem.\n\nPatch was applied to v2.1.0-dev in December, and to v2.0.45-dev in January.\n
12596	Andr?? Malo	1046629557000	Fixed in 2.1 and proposed for backport. Thanks, Andr??, for your report ;-)
12655	Joshua Slive	1032108447000	This is probably related to bug 12542.
12655	William Drury	1033421814000	This behaviour is still occurring in 2.0.42
12655	Andr?? Malo	1053204619000	It works for me with HEAD. Can you please test the current version with your\nsetup and confirm?\n\nThanks!
12655	Andr?? Malo	1054487815000	No further response. Assuming issue resolved.\n\nPlease reopen the bug if this is not the case and you can provide additional\ninformation.\n\nThanks for using Apache.\n
12655	Deomid Ryabkov	1117477119000	the bug still exists in 2.0.54.\n\nthe problem is that during subrequest processing, QUERY_STRING is allocated from\nsubrequest's own r->pool that gets destroyed later, invalidating the table entry\nin the global suprocess_env.\n\napr_pool_join(r->main->pool, r->pool); which, if i'm correct, is supposed to\ntake care of subrequest's pool lifetime, is effectively a nop when compiled\nwithout APR_POOL_DEBUG (--enable-pool-debug).\n\nthere might be other consequences of assuming extended lifetime of subrequest's\npool, but in regard to QUERY_STRING i have made a small patch that i attach to\nthis bug.\n\nhaving investigated this i find the issue obvious enough, but i can arrange a\ntestcase if requested.
12655	Deomid Ryabkov	1117477243000	Created an attachment (id=15216)\nthe patch for QUERY_STRING case\n
12655	Joe Orton	1117539920000	Hmmm, interesting.  Do you have a simple test case which reliably reproduces the\nissue, I can't get the examples above to fail?\n\nBut I don't disagree with your analysis, though I'm not convinced your fix is\nsufficient.  Are there other places where r->main->subprocess_env will get\npopulated from r->pool during the subrequest?  I think there are: e.g., \nhandle_set().\n\nThe apr_pool_join() call isn't supposed to actually do anything for non-debug\nbuilds; it just says 'I guarantee that this subpool won't be destroyed before\nits parent'.  But in fact that guarantee is not really given: the subrequest\nr->pool *is* destroyed, when ap_destroy_sub_req is called.\n\nSo a possibly more correct fix would be to just remove the call to\nap_destroy_sub_request.  Does that fix your case, also?
12655	Deomid Ryabkov	1117552497000	i have even shorter test case.\n\nhttp://testcase12655.rbc.ru:88/?testQS - non-patched 2.0.54, QS3 should contain\ngarbage.\n\nhttp://testcase12655.rbc.ru/?testQS - patched, should be ok.\n\nyou can browse the source here:\nhttp://testcase12655.rbc.ru/index.txt\nhttp://testcase12655.rbc.ru/q.txt\nhttp://testcase12655.rbc.ru/empty.txt\n(every .shtml has a corresponding .txt symlink)\n\ni don't normally hack apache, so i can't say if there are other places to fix\npool usage in subrequests... i'm glad that i brought your attntion to this issue\nso it can be fixed thoroughly :)
12655	Joe Orton	1118788952000	Thanks a lot, that was a great help.  I've committed a fix for this to the trunk\nand will propose it for backport to 2.0.x.\n\nhttp://svn.apache.org/viewcvs?rev=179763&view=rev
12655	Joe Orton	1125409988000	Now merged for 2.0.55.\n\nhttp://svn.apache.org/viewcvs?rev=264762&view=rev
12655	Andr?? Malo	1125559611000	*** Bug 36452 has been marked as a duplicate of this bug. ***
12660	Erik Abele	1032094864000	I just fixed this and it will be in one of the next releases of Apache (2.0.41\npresumably).\n\nThanks for your report, and thanks for using Apache.
12678	Joshua Slive	1032197017000	Thanks.  I've corrected the link.\n\nThe 2.0 faq is short on content because we still haven't decided how\nwe are going to handle it.  The 1.3 faq is still the best faq\nfor both versions at the moment.\n\nContributions welcome.
12705	Amund Elstad	1032206488000	Shouldn't the calls to dbm_close in ssl_scache_dbm_retrieve be protected by the \nmutex ? Every other call to dbm_close appears to be .\n\n
12705	Jeff Trawick	1033494933000	The fix has been committed and will be in the next release of Apache.\n\nThanks for figuring this out!\n
12706	Will Rowe	1049786545000	\n  Invoking the .exe's should be a pre-build step of ApacheCore.dsp, methinks.\n  With a target file of the actual .h and the source being the .exe itself.\n\n  If you feel like authoring a patch - you could also set up a custom cl step\n  to compile buildmark.c as a pre-link step - I did that in httpd-2.0's\n  libhttpd.dsp, but have been to busy to invest much time.  Happy to review\n  your patch if you would like to submit.
12706	Will Rowe	1054154854000	\n  buildmark.c is now a pre-build step.  Now ApacheCore.dsp builds both of the\n  test_char.h and uri_delims.h files so they should no longer conflict or\n  exhibit the odd behaviors that you observed.\n\n  This will show up in your Apache 1.3.28 source .zip package.  Thanks for the\n  report and your analysis!\n
12712	Sander van Zoest	1032215823000	Created an attachment (id=3087)\napache_1_3_include_fnmatch.patch\n
12712	Joshua Slive	1032221960000	I believe regex is not the right word.  fnmatch or 'shell-style wildcard'\nis what you mean.
12712	Sander van Zoest	1032222817000	yes. that is what I meant.
12712	Dirk-Willem van Gulik	1033736675000	This feature has been added as from apache 1.3.27\n\nDw.\n-- \nDirk-Willem van Gulik \n
12757	Michael Dean	1039520726000	This also happens on a solaris 8 platform with the error\n\n[debug] util_ldap.c(1066): (17)File exists: [4449] ldap cache init: File exists\n\n\ni tried disabling the code in the #if APR_HAS_SHARED_MEMORY statements to at\nleast get the per server cache to work although it has the error\n\n[debug] util_ldap.c(1066): [8329] ldap cache init: Error 0\n
12757	Scooter Morris	1042239501000	Actually, wouldn't it be better to just attach to the named file?  I implemented\nsomething like this:\n\ncvs diff -c util_ldap_cache.c \nIndex: util_ldap_cache.c\n===================================================================\nRCS file:\n/usr/src/cvs/cvsroot/contrib/Apache/modules/experimental/util_ldap_cache.c,v\nretrieving revision 1.1.1.1\ndiff -c -r1.1.1.1 util_ldap_cache.c\n*** util_ldap_cache.c   8 Oct 2002 20:49:28 -0000       1.1.1.1\n--- util_ldap_cache.c   10 Jan 2003 22:55:51 -0000\n***************\n*** 296,304 ****\n      apr_status_t result;\n  \n      result = apr_shm_create(&util_ldap_shm, reqsize, '/tmp/ldap_cache', pool);\n!     if (result != APR_SUCCESS) {\n          return result;\n-     }\n  \n      /* This will create a rmm 'handler' to get into the shared memory area */\n      apr_rmm_init(&util_ldap_rmm, NULL,\n--- 296,310 ----\n      apr_status_t result;\n  \n      result = apr_shm_create(&util_ldap_shm, reqsize, '/tmp/ldap_cache', pool);\n!     if (result == EEXIST) {\n!       /*\n!        * The cache could have already been created (i.e. we may be a child\nprocess).  See\n!        * if we can attach to the existing shared memory\n!        */\n!       result = apr_shm_attach(&util_ldap_shm, '/tmp/ldap_cache', pool);\n!     } \n!     if (result != APR_SUCCESS)\n          return result;\n  \n      /* This will create a rmm 'handler' to get into the shared memory area */\n      apr_rmm_init(&util_ldap_rmm, NULL,\n\nand it seems to work for me.\n
12757	Graham Leggett	1043146678000	Patch applied to v2.0.45-dev and v2.1.0-dev
12877	Dennis Lundberg	1032594351000	This was fixed in Apache 1.3 on Tue Mar  5 08:14:25 PST 2002, following a bug\nreport from me. That bug report had the internal identification "config/10040'.
12877	Dennis Lundberg	1032594494000	A fix for this bug also requires that the file 'htdocs/index.html.se' is renamed\nto 'htdocs/index.html.sv'
12877	Dennis Lundberg	1032595927000	Created an attachment (id=3157)\nFixes docs/conf/httpd-std.conf.in\n
12877	Dennis Lundberg	1032595981000	Created an attachment (id=3158)\nFix for docs/conf/httpd-win.conf\n
12877	Dennis Lundberg	1032596015000	Created an attachment (id=3159)\nFix for docs/conf/httpd-nw.conf\n
12877	Joshua Slive	1032624679000	This is not, strictly speaking, a bug.  The extension that is chosen\nfor the filename is arbitrary.  We could just as well use .sweden-is-cool.\nWhat matters is that the correct language code is getting applied to that\nextension, and that is happening.\n\nBut it would probably be better if the extension and language code is\nconsistent, unless there is some good reason to do otherwise.\n\nOn the other hand, I'm leaning very close to removing all the AddLanguage lines\nfrom httpd.conf except those necessary to do the documentation.  I don't see\nthe benefit from us maintaining those.  All they create is bug reports ;-)\n\n(And, as a final note, it shouldn't be necessary to rename the index.html.se\nfile because the welcome page now uses a typemap rather than multiviews.)
12877	Tomas 	1033408506000	But why have the arbitrary chosen extension set to something that people get annoyed about?\nThe map is for languages, se represents the country Sverige (Sweden) and sv the\nlanguage Svenska (Swedish) according to ISO639:\nhttp://www.evertype.com/standards/iso639/iso639-en.html\nISO639-2 uses three characters per language though..\n
12877	Dennis Lundberg	1046471635000	Created an attachment (id=5094)\nChanges swedish language-code for config- and docroot-files\n
12877	Dennis Lundberg	1046471734000	Created an attachment (id=5095)\nReplacement file for docs/docroot/index.html.se\n
12877	Dennis Lundberg	1046472118000	I'll try this once again then. I've created attachments 5094 and 5095 which\nprovides a complete solution for this problem.\n\n5094 is a patch\n5095 is a new file\n\nThe file docs/docroot/index.html.se should be removed, as it is replaced by\nattachment 5095.\n\nCan someone please check these in?
12877	Andr?? Malo	1046472764000	*sigh* two points:\n\n- again: file naming has nothing to do with language codes.\n  (e.g. .pl for Polish is a quite bad choice)\n- what is your 'replacement' meant for? It's exactly the same file that exists now.\n\nBut to be consistent with 1.3 and to make you guys happy ;-), I'm going to\nchange the config and the filename...
12877	Andr?? Malo	1047073074000	Fixed for the next release (2.0.45).
12880	Dennis Lundberg	1032596524000	Created an attachment (id=3161)\nPatch for docs/error/HTTP_FORBIDDEN.html.var\n
12880	Joshua Slive	1032626067000	*** Bug 12879 has been marked as a duplicate of this bug. ***
12880	Joshua Slive	1032626093000	*** Bug 12881 has been marked as a duplicate of this bug. ***
12880	Joshua Slive	1032626120000	*** Bug 12882 has been marked as a duplicate of this bug. ***
12880	Joshua Slive	1032626204000	See also the patches in all the 'duplicate' bugs.
12880	Joshua Slive	1032635381000	Thanks.  These changes have committed and will be available in a future\nversion (but probably not the next release, because that has already \nbranched).
12901	Jeff Trawick	1033820368000	This has been committed to the default conf files and will be in the next\nrelease.\n\nThanks for your report, and thanks for using Apache!\n
12902	Silvester Erdeg	1037997474000	The problem lies function hook_uri2line, beginning on line 1285:\n\n1. the module (I think) wants to make sure that the resulting filename starts\nwith a slash, but it uses the ap_os_is_path_absolute function. If the filename\ndoes indeed start with a slash this call will succeed on Unix, but it will fail\non Windows because ap_os_is_path_absolute will expect a path starting with D:/\nor //machine/share. Hence the '400 Bad Request' error.\n\n2. next the module check if the first part ('the prefix') of the path exists.\nThis is done using the prefix_stat function which works only on Unixes (it\nexpects the path to start with a slash!)\n\nI think the first part is unnecessary and that the second part should be based\non core.c (as stated in the comments).
12902	Will Rowe	1038036187000	\n  The fact is that '/foo' isn't an absolute path.on Windows.  In all fairness,\n  we should still try to work around this.  Note the earlier code was much\n  more evil, in that 'c:/foo' wasn't recognized as a rooted path.\n\n  The one case I want to avoid is accepting 'c:foo' since that path is most\n  definately not sufficiently rooted.  So that said, we should try to test\n  the APR_EINCOMPLETE result and have a static is_path_rooted function within\n  mod_rewrite to test the complete and some incomplete path results.\n\n  Don't have time to work up a patch at the moment, but thought I ought to\n  add some observations while they are fresh in my mind.\n
12902	spoon	1046145720000	I to am having this EXACT problem. I thought maybe i just wasn't getting the \ngrasp of Mod_Rewrite, but it turns out to be a bug!  :-(\n\nAny update on this bug? Been a couple of months.
12902	Rik Arpino	1046178221000	After a bit of playing around, I found that version 1.3.26 did NOT suffer from \nthe same problem - in fact I was hard pressed to find problems with mod_rewrite \nin the 1.3.26 packaged version on win32. Dunno if this helps anyone? Sorry for \nnot updating sooner.....spoon reminded me!!!
12902	Andr?? Malo	1046179163000	Some patches were made to the main dev branch (2.1) and are proposed for backport.\nI think, they will solve your problems and hopefully they will go into next 2.0\nand 1.3 releases.\n\nThanks for your reports and thanks for using Apache!
12902	spoon	1046185448000	Wonder how long till the next release :-)  Is there a workaround in 2.x that \nwas not mentioned? Possibly some way of tricking it? Or possibly access to \napache-dev?
12902	Andr?? Malo	1049496881000	Uh, sorry overlooked your questions ...\n\nHowever, it should be fixed in 2.0.45. Please reopen this report if it's not.\n\nThanks.
12910	Will Rowe	1032748621000	Please try the 2.0.42 binaries for Win32 (still an alpha release candidate \nat this time, but they are not yet released).  They are available from \n\n  http://httpd.apache.org/dev/dist/\n\nAs both htpasswd and htdigest have undergone some fixes, you may\nfind that the issue is resolved in the latest code.\n\nThanks\n
12910	Bojan	1032812503000	bad news:\n  no the problem still exists:\n\n\nd:/WEB/Apache2_new/bin>htdigest.exe -c tt realm user1\nAdding password for user1 in realm realm.\nNew password: ****\nRe-type new password: ****\n\nd:/WEB/Apache2_new/bin>htdigest.exe tt realm user2\nAdding user user2 in realm realm\nNew password: **\nRe-type new password: **\nThe process cannot access the file because it is being used by another process.\n        0 file(s) copied.\n\n...
12910	Joshua Slive	1034822074000	[This is a mass bug update.]\nThis bug reports a problem in an older version of Apache 2.\nCould you please update to the most recent version and see\nif you can reproduce this problem.  If the bug still exists,\nplease update the bug with the latest version number.  If \nthe bug no longer exists, please close the bug report.\n\nSorry for this impersonal response, but we get many more bug\nreports than our volunteers can keep up with.\nThanks for using Apache!
12910	Joshua Slive	1036268294000	[This is a mass bug update.] [Resolve-20021102]\nNo response from submitter; assuming issue is resolved.\nIf the problem still exists in the lastest version,\nplease reopen this report and update appropriately.
12910	David Saxe	1046832579000	I just downloaded 2.0.44 and installed it several days ago and this error still \nexists. \n\nI am using the same workaround shown below, but this is an extremely \ninefficient method for more than just a few users.  I have tried turning off \nthe service and monitor, rebooting, running from different directories, \nchanging file names.  It always fails when you try to update an entry or add a \nnew entry.\n\nMy experience is exactly that reported by 'Bojan', apparently on 22Sep02.\n\n-David\n\n\n\n
12910	Bojan	1046852426000	They still didn't fix this problem ?\n\nHopefully I don't have many users, i think\nif you have many users than this is realy a\nbig problem.\n\nBojan.
12910	Andr?? Malo	1046883174000	A patch has been applied to the main dev branch (2.1) and is proposed for\nbackport to 2.0.\n\nThanks for your reports and thanks for using Apache.
12910	Andr?? Malo	1047229651000	FYI: fixed for the next release (2.0.45).
12981	Joe Orton	1113585799000	Fixed on the trunk, thanks for the patch!\n\nhttp://svn.apache.org/viewcvs?view=rev&rev=161483
13025	Ryan Bloom	1033167109000	I had the same problem.  Do you have DAV configured for your server?  When I\ndisabled DAV for that directory, the problem went away.  This is on my list of\nthings to investigate.
13025	Sander Holthaus	1033167895000	Well, now that you mention it, yes, I have. I cannot back up your theory I'm \naffraid since I immediatelly downgraded to 2.0.40 (downgrade, never thought I \nwould do that). But it is likely that you are right.
13025	Ryan Bloom	1033362408000	Fixed in CVS.  Mod_Dav was setting the handler for all requests for a\nDAV-enabled location to the DAV handler.  Unfortunately, this is not a good\nidea, because it means that CGI scripts that use the POST handler will always\nfail.  I have reverted that change.
13104	Ryan Bloom	1033170594000	I have committed a fix that makes all of the default paths for suexec\n/usr/local/apache2.  Thank you for the bug report and for using Apache.  I will\nfix the --with-suexec-log option next.
13104	Ryan Bloom	1033172913000	The --with-suexec-log command is working in my tests now.  Please try the latest\ncode from CVS and report back if it still fails for you.
13119	Erik Abele	1037499799000	Thanks. This is fixed and will be included in the next release.
13141	Joshua Slive	1033422907000	I'm not exactly sure why you say that.  This page:\nhttp://httpd.apache.org/docs-2.0/mod/mod_deflate.html\nclearly documents the gzip-only-text/html env variable.
13141	Joshua Slive	1033422962000	Oops.  Sorry.  I was confused.
13141	Jeff Trawick	1033748119000	I just updated the mod_gzip doc to mention no-gzip.\n
13204	Jeff Trawick	1033749570000	Please try this change to mod_rewrite at around line 2968.\n\nIndex: modules/mappers/mod_rewrite.c\n===================================================================\nRCS file: /home/cvs/httpd-2.0/modules/mappers/mod_rewrite.c,v\nretrieving revision 1.134\ndiff -u -r1.134 mod_rewrite.c\n--- modules/mappers/mod_rewrite.c       30 Aug 2002 04:47:57 -0000      1.134\n+++ modules/mappers/mod_rewrite.c       4 Oct 2002 16:37:02 -0000\n@@ -2968,7 +2968,7 @@\n     if ((rv = apr_dbm_open_ex(&dbmfp, dbmtype, file, APR_DBM_READONLY,\n                               0 /* irrelevant when reading */, r->pool)) == \nAPR_SUCCESS) {\n         rv = apr_dbm_fetch(dbmfp, dbmkey, &dbmval);\n-        if (rv == APR_SUCCESS) {\n+        if (rv == APR_SUCCESS && dbmval.dptr != NULL) {\n             memcpy(buf, dbmval.dptr,\n                    dbmval.dsize < sizeof(buf)-1 ?\n                    dbmval.dsize : sizeof(buf)-1  );\n\nThanks!
13204	Jeff Trawick	1033750786000	A fix has been committed.  This will be in the next release (2.0.44).\n\nThanks for your report, and thanks for using Apache!
13211	Frank Faubert	1045232864000	Build and install v2.0.44 as follows:\n\n./configure --prefix=/tmp/apache --enable-usertrack\n\nAdd 'CookieTracking on' to the end of the default httpd.conf file, start up\nApache and look at the headers for '/' -- only one cookie.  Now copy\n/tmp/apache/htdocs/index.html.en to /tmp/apache/htdocs/index.html and look\nat the headers for '/'.  I get two cookies for every page that does NOT use\ncontent negotiation (which unfortunately for me is my entire site...).\n\nI also ran the same tests with v1.3.27 built as follows:\n\n./configure --prefix=/tmp/apache --enable-module=usertrack\n\nAnd -never- got two cookies.  I ran these tests on Red Hat Linux 7.3, but\nhave also seen the problem on Solaris.\n
13211	Frank Faubert	1045232961000	Comments below are from Andr?? Malo [nd@perlig.de] from the dev@httpd.apache.org \nmailing list:\n\n*hrm* I can verify that behaviour for directory requests (i.e. \nmod_dir/DirectoryIndex) without negotiation of the index file.\n\nIt seems to happen the following (GET / HTTP/1.0) without negotiation:\n\nrun_fixup:\n->mod_usertrack: spot_cookie\n->mod_dir: search and find index.html using sub_req_lookup_uri, which runs a \nfixup itself (->next spot_cookie)\n  ->internal_fast_redirect -> apr_table_overlay(r->headers_out, \n                                                rr->headers_out)\n\n                               ^^ two cookies here ^^\n\nmod_negotiation instead (in case of index.html.var) does an additional normal \ninternal_redirect to the negotiated resource, which drops the old stuff and \ncooks (not only) its own cookie.\n\nright?\n\nConclusion: are overlay'ed tables in internal_fast_redirect semantically \nintended? Could someone please explain in slow words ;-), why?
13211	Andr?? Malo	1047072921000	A workaround has been applied and will appear in the next release (2.0.45).\nIf you wanna try it before the next release, the patch is rather small and can\nbe found here:\n<http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/metadata/mod_usertrack.c.diff?r1=1.39.2.1&r2=1.39.2.2>\n\nIf there are further problems, please reopen this bug report.\n\nThanks for using Apache!
13311	Ryan Bloom	1034350875000	I have fixed the code to force FCNTL and write a warning to the log if the\nserver is configured with an incorrect accept mutex.
13311	Jeff Trawick	1037907898000	*** Bug 14674 has been marked as a duplicate of this bug. ***
13311	Jeff Trawick	1039734420000	*** Bug 15336 has been marked as a duplicate of this bug. ***
13383	Erik Abele	1034099241000	Fixed.\n\nThanks for using Apache!
13511	Joshua Slive	1034787536000	Hmmm... I'm not really an expert in this, but it seems it is the CGI script\nthat needs to guard against the out-of-space condition, not Apache.\nWhat could Apache do to prevent this?
13511	Dave Dyer	1034788732000	\nNo, the CGI is not even aware that a log file is being written; it\nis merely emitting some text on stderr.  For its pains, it gets\nterminated by apache.\n\n
13511	Joshua Slive	1034818513000	Again, I'm not an expert in this, but Apache is just attaching the stderr pipe to \nthe error log.  If this pipe can't be written, the OS is probably just sending\nSIGPIPE to your CGI.  If you CGI doesn't handle that, it will die.\n\nI don't see anything that Apache could do about this.
13511	Dave Dyer	1034832474000	Apache can't be doing anything as simpleminded as you\nsuggest, because it is running many concurrent CGI threads.\nSo the fate of this particular thread could be better.\n\nSecondarily, as I suggested, apache must know that globally\nspeaking, it's log file is not working.  There should be some\nalert procedure - it shouldn't just allow shit to happen until\nsomeone notices the mess and deduces the cause and cure.\n\n
13511	Joshua Slive	1034861442000	I don't understand your first paragraph at all.  How does multiple CGI\nprocesses have anything to do with it?  They are all handled identically.\n\nRegarding behaving better when the error log is full, that seems\nkind of absurd to me.  Apache writes errors to the the error log.\nIf it can't do that, what is it supposed to do?  Write to another\nlog file?  What if that log can't be written to?  Send a message to\nyour pager?  Walk down the hall and tap you on the shoulder? ;-)\n\nAt some point it needs to be the administrator's responsibility\nto maintain available system resources.
13511	Will Rowe	1034866337000	\n  In this case, this minimum requirement is that a 500 error (with no\n  additional 'helpful information') should be sent to the client of this\n  terminated script.\n
13511	Dave Dyer	1034878081000	Re: multiple CGI processes - it their output was tee'd directly from\nstderr to a log file, the output from multiple processes would be \nchaotically interspersed.  That in itself would be a problem. The \noutput from DTDOUT is clearly handled individually, so why not STDERR?\n\nFor the momement, lets separate the question of what happened to \nthis particular CGI from that happens in general.\n\n1) For this particular CGI, a warning message caused the process to terminate,\neffectively turning friendly glitch audit trail into a black hole.  Clearly \nnot a desirable outcome.\n\n2) From the viewpoint of apache as a whole, if log files are not being maintained\nand processes are being killed randomly, the system as a whole is in serious\njeopordy.  Perhaps Apache should shut down (which will surely get someone's\nattention) but at the very least there should be an emergency channel of some\nsort throug which apache reports serious internal problems.  The standard log\nfiles are not a good place for this, because apache's (rare we hope) internal\nproblems would be lost in mountains of routine log data.\n\nConsider the current case; Apache knows exactly what is wrong, and can/should\ntell the sysop 'error log can't be written'.    Consider the current behavior\nas a debugging problem 'my email arrived blank'.  Which would you rather deal\nwith?\n
13511	Jeff Trawick	1045258892000	This is the 2GB log file problem :(\n\n32-bit builds of Apache (1.3 or 2.0) don't currently handle 'large' files. \nApache child processes will die trying to write logs which have reached 2GB in\nsize.  The obvious place to report the proble is -- you guessed it -- the\nlog file that we can't write to.\n\nThe current message to users is that they need to use log rotation to keep the\nsize well under 2GB.\n\nYes this sucks, yes it will eventually get fixed, yes there are issues that make\nit problematic to enable on some platforms (including Linux).\n\nSorry :(\n
13511	Jeff Trawick	1053628786000	*** Bug 20160 has been marked as a duplicate of this bug. ***
13511	Joe Orton	1053633419000	Yeah, you can improve the failure mode for this problem by setting SIGXFSZ (the\nsignal which kills the process when it write()s past 2gb) to SIG_IGN.  It's a\ntrivial change - I'll submit a patch.
13511	Joe Orton	1083840787000	Fixed in HEAD by allowing >2Gb log files on platforms which have this limit;\nwill be proposed for backport for the next 2.0 release.
13511	Joe Orton	1084532777000	*** Bug 28968 has been marked as a duplicate of this bug. ***
13511	Joe Orton	1093379836000	*** Bug 30170 has been marked as a duplicate of this bug. ***
13511	Joe Orton	1110397019000	*** Bug 33937 has been marked as a duplicate of this bug. ***
13594	Erik Abele	1034615076000	This is fixed in CVS.\n\nThanks for submitting the bug and for using Apache 2!
13598	Leif W	1066753709000	See the thread on the Apache Users mailing list archive for more information and\na reproducible test-case and verifications on Linux and Windows.\n\nQuoting Robert Andersson:\nAs I see it, the 'bug' in mod_autoindex would be that it doesn't URI-escape the\nfilename before sending it to the sub_request function.
13598	Robert Andersson	1066884448000	A quick note. After a little further research, I see that the 'bug' is rather in\nserver/request.c/ap_sub_req_lookup_dirent(), which calls\nap_process_request_internal() with r->uri set to the plain unescaped filename,\nwhich can result in ap_process_request_internal() returning  'not found' or 'bad\nrequest', eg:\n\n'/xxx%0.txt' -> bad request\n'/xxx%20.txt' -> not found\n\nI have been able to fix this behaviour. I'll be back later.
13598	Andr?? Malo	1067725999000	Fixed in 2.1 and proposed for backport into the 2.0 stable branch.\n\nThanks for your report and thanks for using Apache!
13609	Jeff Trawick	1042629836000	I'm a little confused at the symptom you saw.  I can see the ulimit command\nfail on Tru64 when using /bin/sh, but after the command fails at configure time\nI end up with this in apachectl, so apachectl doesn't try to do ulimit.\n\nULIMIT_MAX_FILES=''\n\nAny ideas why we are seeing something different?
13609	Joseph Senulis	1042654048000	Created an attachment (id=4439)\nconfiguration log which resulted in bad apachectl file\n
13609	Joseph Senulis	1042654460000	I definitely got the following in apachectl:\n\nUMIMIT_MAX_FILES='ulimit -S -n "ulimit -H -n"'\n\nI did not get any errors when running configure.  I have attached the\nconfiguration log from when I created this.  I will make some time to rerun\nconfigure with better logging to see if I can get better info.
13609	Joseph Senulis	1042737008000	OK, I'm confused too.  I rebuilt Apache and I still get the problem.  When I run\n/bin/sh by hand on that computer, I definitely get an error when I try to run\n\nulimit -H -n\n\nThe configure also is running /bin/sh, but the script did not get an error when\nexecuting the line \n\nif TMP_ULIMIT="ulimit -H -n" && ulimit -S -n $TMP_ULIMIT ; then\n\nand as a result does not set APACHECTL_ULIMIT to null.  When I try running this\ncode fragment by hand I get an error.  I will attach config.log and\nconfig.status.  I also piped stdout and stderr from the configure into\nconfigure.log.  I will keep checking here to see what I can find, but any\nsuggestions would be appreciated.\n
13609	Joseph Senulis	1042737159000	Created an attachment (id=4466)\nconfig.log from rebuild\n
13609	Joseph Senulis	1042738358000	Created an attachment (id=4467)\nconfig.status from rebuild\n
13609	Joseph Senulis	1042738453000	Created an attachment (id=4468)\nstdout and stderr from configure, with set -v -x added at start\n
13609	Jeff Trawick	1042815060000	Regardless of why configure fails to realize that the standard ulimit command\nwon't work on your box yet configure does realize it won't work on my box,\nthe fix is the same: check for Tru64 and substitute the right command rather\nthan trying the default.\n\nThe fix has been committed to Apache 2.1 development tree.  If nobody complains \nabout the change, I'll ask for it to be considered for merging into Apache \n2.0.45.\n\nThanks for your report/debug assistance, and thanks for using Apache!\n
13609	Joseph Senulis	1043187987000	I have done some more poking about.  The configure script changes the shell \nfrom Bourne to Korn, in (I believe) the line:\n\nexec '$CONFIG_SHELL' '$0' ${1+'$@'}\n\nwhich restarts the script using the Korn shell.  At that point, it eventually \ngets to the line:\n\nif TMP_ULIMIT="ulimit -H -n" && ulimit -S -n $TMP_ULIMIT ; then\n\nand is still running the Korn shell.  The argument "ulimit -H -n" is perfectly \nvalid in T64 Korn shell, so the configure script would not assign null to \nAPACHECTL_ULIMIT.  What I don't understand is why you were seeing differently.  \nPresumably, when you tested this, configure did not restart itself with the \nKorn Shell?  In any event, there is a discrepancy between T64 ksh and sh, in \nthat -H is valid in ksh, but -h should be used in sh.\n
13609	Jeff Trawick	1043507249000	*** Bug 16415 has been marked as a duplicate of this bug. ***
13625	Erik Abele	1034705392000	Fixed in CVS.\nThanks for using Apache 2.0!
13914	Ville Skytt	1035436692000	Created an attachment (id=3590)\nCGI command line argument fix\n
13914	Joshua Slive	1035565970000	This seems pretty obviously correct to me, but I'm not setup to test it at the\nmoment.
13914	Will Rowe	1035566950000	\n  The patch appears correct.  As simple as it is to patch and move on, it\n  seems like the sort of exception we should be looking for in the test\n  suite.  I'll see what we can do about that, since we aught to prove \n  the old module wrong (from the perl-testsuite), apply the patch and \n  confirm it solves the bug complete.\n\n
13914	Ville Skytt	1035737084000	Ok, I tested this a bit further with 1.3.26 and 2.0.40 and made a perl CGI that\ncan be used for testing (attaching it in a jiffy).  The script contains test\nURLs, expected results and results for the two tested servers.\n\n1.3.26 passed all tests, while 2.0.40 failed 3 of them; 2) and 6) supposedly\nbecause of the bug described here, and 9) since it doesn't seem to check if the\nquery string after '?' is empty, but passes an empty string.
13914	Ville Skytt	1035737134000	Created an attachment (id=3622)\nPerl CGI for testing CGI command line arguments\n
13914	Jeff Trawick	1037976436000	Fixes were just committed for mod_cgi and mod_cgid.\n\nThanks for the mod_cgi fix and the testcase, and thanks for using\nApache!\n
13946	Paul J. Reder	1039054028000	Can you specify where you think the problem is in the log you attached?\n\nIf you are concerned about the 'no cache - add cache_in filter and DECLINE' part\nof the message, that is perfectly normal. This simply indicates that the cache\nhandler has noticed that new, cacheable content is arriving. It inserts the\ncache_in filter into the filter chain so that the caching code can store the new\ncontent as it flows through, but it returns 'declined' to indicate that the\ncache handler didn't process the response.\n\nI'm going to wait a few days for a clarification on this. If there isn't\nsomething I've missed here then I'll go ahead and close this PR at that point.
13946	Paul J. Reder	1039467786000	Having received no response to the contrary, I have to assume that this was not\nactually a problem after all. I'm closing it now. It can be re-opened if someone\ndisagrees.
13946	Fabio Wakim Trentini	1039470686000	Hi, sorry for the delay.\nWell, the error is right here:\n---\n[Fri Oct 25 18:59:00 2002] [debug] proxy_http.c(221): proxy: HTTP connecting \nhttp://10.0.0.2/proxy:http://10.0.0.2/index.html to 10.0.0.2:80\n---\n\nit tries to get the URL http://10.0.0.2/proxy:http://10.0.0.2/index.html, \ngenerating errors. it only happens when using mod_proxy with mod_rewrite. it \nlooks like mod_rewrite appends the 'http://10.0.0.2/proxy:' string, in the \nexample, but *only* when the document expires from the cache.\n
13946	Paul J. Reder	1039472033000	Does the server return an error to the client or does the server succeed in\nretrieving and returning the page from the proxy machine? In other words, is it\njust a logging issue or does it actually fail to retrieve the page after it expires?\n\nI don't see a log entry indicating that the page isn't found, and the only entry\nin the log from the cache code indicates that it is inserting the\ncache_in_filter to handle the page returned from the proxy.\n\nThanks for any additional info you can provide.
13946	Fabio Wakim Trentini	1039472551000	in all these requests, the server returns an error to the client.
13946	Paul J. Reder	1039476019000	What is the error returned to the client and what error(s) get logged into the\nserver's error_log or access_log?
13946	Graham Leggett	1043232187000	This seems to be a mod_cache bug
13946	Fabio Wakim Trentini	1043777118000	hi there,\nthe bug persists in httpd-2.0.44. Here is some piece of the error_log:\n\n[Tue Jan 28 15:48:23 2003] [error] [client 200.164.36.73] proxy: URI cannot be \nparsed: http://xxx.com.brproxy:http//xxx.com.br/imagens/pix.gif returned \nby /imagens/pix.gif\n[Tue Jan 28 15:48:23 2003] [error] [client 200.207.161.223] proxy: URI cannot \nbe parsed: http://xxx.com.brproxy:http//xxx.com.br/beach/t3.jpg returned \nby /beach/t3.jpg, referer: http://xxx.com.br/beach/left.html\n[Tue Jan 28 15:48:23 2003] [error] [client 200.191.233.186] proxy: URI cannot \nbe parsed: http://yyy.com.brproxy:http//yyy.com.br/imagens/b.gif returned \nby /imagens/b.gif, referer: http://yyy.com.br/\n
13946	Fabio Wakim Trentini	1043777428000	another error:\n\naccess_log:\n200.174.198.133 - - [28/Jan/2003:15:47:18 - 0200] 'GET /js/video.js HTTP/1.1' \n400 498 'http://xxx.com.br/' 'Mozilla/4.0 (compatible; MSIE 6.0; Windows 98)'\n\nerror_log:\n[Tue Jan 28 15:47:18 2003] [error] [client 200.174.198.133] proxy: URI cannot \nbe parsed: http://xxx.com.brproxy:http//xxx.com.br/js/video.js returned \nby /js/video.js, referer: http://xxx.com.br/\n\nIt *only* happens with mod_rewrite with reverse proxy.
13946	Eider Oliveira	1044041778000	Created an attachment (id=4670)\nPatch to solve the probem\n
13946	Eider Oliveira	1044042066000	A did attach a patch to solve this bug. It is caused when the mod_rewrite \nreprocess the request after mod_proxy return it.
13946	Eider Oliveira	1044043577000	Created an attachment (id=4671)\nPatch fix, now generated by a diff -u\n
13946	Cliff Woolley	1044047225000	Let's not mark this as resolved/fixed until a fix is actually committed... \notherwise the patch might get lost.  :)\n\nThanks,\nCliff
13946	Andr?? Malo	1054489735000	Is this fixed now or not? :-)
13946	Paul J. Reder	1057773783000	I'm currently looking into porting the old patch to the current code, verifying\nthe patch, and committing it to cvs. I am not convinced that this part of the\npatch needs to be present since we aren't seeing 'proxy:proxy:' which is what\nthis if statement would prevent...\n\n@@ -2082,6 +2098,7 @@\n             rewritelog(r, 2, '[per-dir %s] forcing proxy-throughput with %s',\n                        perdir, r->filename);\n         }\n+        if (strncasecmp('proxy:',r->filename,6))\n         r->filename = apr_pstrcat(r->pool, 'proxy:', r->filename, NULL);\n         return 1;\n     }
13946	Paul J. Reder	1057864369000	Created an attachment (id=7229)\nUpdated version of Fabio's patch from above. (current 2.1-dev branch)\n
13946	Paul J. Reder	1058201514000	I have tested the updated patch and committed it to the Apache 2.1-dev branch. I\nwill submit it for a vote to backport to the 2.0-stable branch. Thank you for\nyour efforts in identifying and fixing this bug.
13946	Andr?? Malo	1061164981000	Perhaps I'm missing something... The provided config:\n\nProxyRequests Off\nProxyVia Full\nProxyTimeout 30\nProxyReceiveBufferSize 16384\nProxyMaxForwards 10\nCacheEnable mem /\nCacheDefaultExpire 10\nCacheMaxExpire 30\nCacheLastModifiedFactor 0.1\nCacheMaxStreamingBuffer 65536 \nMCacheSize 524288\nMCacheMaxObjectCount 32768\nMCacheMinObjectSize 1 \nMCacheMaxObjectSize 100000\nMCacheRemovalAlgorithm GDSF\nRewriteEngine   on\nRewriteRule     ^(.*)$     $1 [P,L]\n\ncreates an infinite loop (proxying to itself), doesn't it? Why is this useful?
13946	Jeff Trawick	1069452815000	updating PRs to add PatchAvailable keyword\nFor updated information on submitting patches, see\nhttp://httpd.apache.org/dev/patches.html\n
13946	Paul Querna	1117766185000	Can you test this on 2.0.54? Lots of things in both proxy and cache have been\nchanged since this was last reported.
13946	Nick Kew	1155068917000	No activity after a very long time in NEEDINFO; assuming expired.
14037	Jeff Trawick	1036499140000	FYI...\n\nHere are some notes I threw together describing what I think is the proper \nsolution.  Part of that is to provide multiple Listen statements.\n\nhttp://www.apache.org/~trawick/v4mapped.html\n\nAny comments are appreciated.\n
14037	Jeff Trawick	1037283913000	Just committed was a change to add --[enable|disable]-v4-mapped configure option\nwhich defaults to --disable-v4-mapped on freebsd5*|netbsd|openbsd, which will\nresult in two listen statements in the default config file.\n\nThe default ssl config is not automatically generated, so comments were added\nto that describing the two necessary Listen directives.\n
14147	Jeff Trawick	1036098349000	That looks good.  I suspect that wrowe needs to bless it before\ncommitting it though.\n\nThe check below always succeeds, right?\n\n-->       if (r->filename[filename_len-1] == '/')\n\nI suspect that it should probably be\n\n   AP_DEBUG_ASSERT(r->filename[filename_len-1] == '/');\n   r->filename[--filename_len] = '/0';\n\nThe AP_DEBUG_ASSERT() is a good way to doc the assumption but \nit won't generate any code unless you build with \n--enable-maintainer-mode.\n\nThanks for digging into this!!!!!\n
14147	Michael Dean	1036119078000	*** Bug 10236 has been marked as a duplicate of this bug. ***
14147	Will Rowe	1036121171000	\n  In the name of Rob, Dean, and Jon, it is blessed.\n\n  Great catch, mega kudos for tracking it down!\n\n  I like Jeff's analysis, I'm leaving only an assert.\n
14147	Will Rowe	1036122023000	\n  Still makes no sense.\n\n        do {\n            int res;\n            char *seg_name;\n            char *delim;\n            int temp_slash=0;\n\n            /* We have no trailing slash, but we sure would appreciate one.\n             * However, we don't want to append a / our first time through.\n             */\n            if ((seg > startseg) && r->filename[filename_len-1] != '/') {\n                r->filename[filename_len++] = '/';\n                r->filename[filename_len] = 0;\n                temp_slash=1;\n            }\n[...]\n            /* That temporary trailing slash was useful, now drop it.\n             */\n            if (temp_slash) {\n                temp_slash = 0;\n                AP_ASSERT(r->filename[filename_len-1] == '/');\n                r->filename[--filename_len] = '/0';\n            }\n\nThere is no way around this code without resetting temp_slash to zero\nat the beginning of the loop...\n\n...UNLESS the optimizer has optimized away all but the initial assignment \nto the 0 initial value, never again to reset it on the next iteration\nthrough the do {} loop.\n\nDoes this make sense as the possible scenario?  Can you check this Dan?\n\nBill
14147	Jeff Trawick	1036150794000	Bill, you're forgetting the gotos :)\n\nI'm about to post some text to dev@httpd.\n
14147	Will Rowe	1036182152000	\n  Refixed this morning in CVS.  The revised server.c is attached complete,\n  so you don't end up with the hack-around still sitting in your sources.\n\n  directory_walk should never have the goto target above the code that\n  it was attempting to escape from.  In fact, a minimerge3: target should\n  have been used -after- the uncached-merge logic.\n\n  No matter, the new sources factor out all the goto's.  Please test this\n  new patch thoroughly.  request.c source to follow.\n\n
14147	Will Rowe	1036182226000	Created an attachment (id=3702)\nhttpd-2.0/server/request.c for 2.0.43, committed to 2.0.44-dev.\n
14147	Will Rowe	1036419098000	\n  The final patch doesn't reset the flag, as demonstrated in the attached\n  patch.  It turns out our goto loop logic was terribly flawed.  The final\n  patch to address this bug simply eliminates the odd looping that caused\n  us to chop the extra character{s}.\n\n  For each DirectoryMatch (or Directory ~ path) block, we looped back over\n  the wrong code, causing us to chop more than a single character off the\n  end of the name (when expected to simply chop off the trailing slash.)\n\n  If the fix works for you, terrific.  You might also consider the correct\n  patch, attaching in one moment.
14147	Will Rowe	1036419156000	Created an attachment (id=3711)\nPatch that eliminates the looping that caused the symptoms.\n
14147	Will Rowe	1036420737000	*** Bug 12155 has been marked as a duplicate of this bug. ***
14147	Jeff Trawick	1038026765000	*** Bug 10687 has been marked as a duplicate of this bug. ***
14147	Joshua Slive	1038334515000	*** Bug 14860 has been marked as a duplicate of this bug. ***
14147	Joshua Slive	1042131466000	*** Bug 15923 has been marked as a duplicate of this bug. ***
14235	Sergey A. Lipnevich	1036433691000	Created an attachment (id=3714)\nLDAPv3.patch\n
14235	Graham Leggett	1043147349000	Patch applied to v2.0.45-dev and v2.1.0-dev.
14253	Erik Abele	1036522986000	The links are fixed and should be up the next days. Thanks for using Apache 2.0!
14256	Jeff Trawick	1037969411000	A fix for this was just committed.\n\nThanks for your report, and thanks for using Apache!\n
14276	Erik Abele	1036534059000	Thanks for the report, but this is a configuration error.\nApache 2 doesn't have the index option 'IgnoreCase'; it is only available in\nApache 1.3.\n\nFor a list of available options, see\nhttp://httpd.apache.org/docs-2.0/mod/mod_autoindex.html#indexoptions
14276	Joshua Slive	1036598027000	But it should be available.  I'm not sure why this was never forward-ported.\nI'm going to reopen and mark this as an enhancement request, because\nI've seen other similar reports.
14276	David Shane Holden	1041836969000	Created an attachment (id=4341)\nForward port of IgnoreCase directive.\n
14276	Will Rowe	1041866844000	\n  The patch, with minor changes, is committed to the 2.0 release branch\n  and 2.1 development branch.\n\n  The changes to the patch should avoid future reformatting of the #defines\n  list and provide a deterministic ordering even for fn1.1.zzz/fn1.01.zzz which\n  might compare equally using the strnatcmp family of functions.\n\n
14303	Jeff Trawick	1036672384000	Thanks for your report, and thanks for using Apache!\n\nThis problem has now been fixed.\n
14321	Jeff Trawick	1036670884000	some comments in case somebody else has started looking at this:\n\nI was able to duplicate this on Linux easily :(\n\nThe problem does not seem to be thread-related because I duplicated it\nusing the prefork MPM.\n\nThe problem does not seem to be a misuse of zlib.  To test that theory I\nused the following patch to replace the memory allocation/deallocation\nroutines used by zlib with something that allocates from the request pool.\nI still observed the storage leak with that patch in place.  (I assume\nthat zlib always calls that hook to allocate storage.)\n\nIndex: modules/filters/mod_deflate.c\n===================================================================\nRCS file: /home/cvs/httpd-2.0/modules/filters/mod_deflate.c,v\nretrieving revision 1.24\ndiff -u -r1.24 mod_deflate.c\n--- modules/filters/mod_deflate.c\t30 Aug 2002 16:31:17 -0000\t1.24\n+++ modules/filters/mod_deflate.c\t7 Nov 2002 12:04:11 -0000\n@@ -228,6 +228,27 @@\n     return NULL;\n }\n \n+static voidpf mdalloc(voidpf opaque, uInt items, uInt size)\n+{\n+    request_rec *r = opaque;\n+    voidpf buffer = apr_pcalloc(r->pool, items * size);\n+\n+    ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r,\n+                  'alloced buffer %pp', buffer);\n+\n+    return buffer;\n+}\n+\n+static void mdfree(voidpf opaque, voidpf buffer)\n+{\n+    request_rec *r = opaque;\n+\n+    ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r,\n+                  'freed buffer %pp', buffer);\n+\n+    /* no work to do */\n+}\n+\n /* magic header */\n static char deflate_magic[2] = { '/037', '/213' };\n \n@@ -330,7 +351,9 @@\n         ctx = f->ctx = apr_pcalloc(r->pool, sizeof(*ctx));\n         ctx->bb = apr_brigade_create(r->pool, f->c->bucket_alloc);\n         ctx->buffer = apr_palloc(r->pool, c->bufferSize);\n-\n+        ctx->stream.zalloc = mdalloc;\n+        ctx->stream.zfree  = mdfree;\n+        ctx->stream.opaque = r;\n         zRC = deflateInit2(&ctx->stream, Z_BEST_SPEED, Z_DEFLATED,\n                            c->windowSize, c->memlevel,\n                            Z_DEFAULT_STRATEGY);\n@@ -341,8 +364,11 @@\n                           'unable to init Zlib: '\n                           'deflateInit2 returned %d: URL %s',\n                           zRC, r->uri);\n+            ap_remove_output_filter(f);\n             return ap_pass_brigade(f->next, bb);\n         }\n+        ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r,\n+                      'alloced stream %pp', &ctx->stream);\n \n         /* RFC 1952 Section 2.3 dictates the gzip header:\n          *\n@@ -443,7 +469,8 @@\n             }\n \n             deflateEnd(&ctx->stream);\n-\n+            ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r,\n+                          'freeing stream %pp', &ctx->stream);\n             /* Remove EOS from the old list, and insert into the new. */\n             APR_BUCKET_REMOVE(e);\n             APR_BRIGADE_INSERT_TAIL(ctx->bb, e);
14321	Jeff Trawick	1036671203000	problem isn't specific to windows... change some fields as appropriate...
14321	Ken Franken	1036707167000	The problem seems to be the apr_brigade_destroy(bb) call on the next to last\nline of deflate_out_filter(). If I remove this call, the leak stops. \n\nSomeone with more familiarity with the code might be able to confirm this, but I\nthink the apr_brigade_destroy() call unregisters the brigade from the pool\ncleanup. This would be OK (since we are cleaning it up manually), but the last\ntime the filter is called (with an EOS bucket), the function exits w/o a last\napr_brigade_destroy() call, so the last bucket brigade leaks.\n
14321	Jeff Trawick	1037282190000	I got a brigade guru to look at your PR and your debugging.  He suggested\nthis patch:\n\nIndex: modules/filters/mod_deflate.c\n===================================================================\nRCS file: /home/cvs/httpd-2.0/modules/filters/mod_deflate.c,v\nretrieving revision 1.25\ndiff -u -r1.25 mod_deflate.c\n--- modules/filters/mod_deflate.c       10 Nov 2002 06:09:20 -0000      1.25\n+++ modules/filters/mod_deflate.c       14 Nov 2002 13:52:36 -0000\n@@ -510,7 +510,7 @@\n         }\n     }\n\n-    apr_brigade_destroy(bb);\n+    apr_brigade_cleanup(bb);\n     return APR_SUCCESS;\n }\n\n\nI have tested this with your sample module and I don't see a storage leak\nor any other bad behavior.\n
14321	Cliff Woolley	1037284272000	Upon further review, I do believe that to be the correct patch.  We can't destroy the brigade because it is only created when the ctx is first initialized at the beginning of the request.  All we really want is to make sure it has no buckets in it.  That's what apr_brigade_cleanup() is for.  Ken, I'll wait for confirmation from you that the patch works as expected before committing, but it seems quite logical to me.  Note: I found a few other bucket-related buglets in that function -- I'll bring them up on dev@httpd. 
14321	Ken Franken	1037298653000	I tested the patch and it works fine for me. Thanks.
14321	Cliff Woolley	1037301781000	Committed.  Thanks!
14376	L.C.	1036712315000	The last statement should read:\n'The backend always sets the expiration date to same value as date.'\n
14376	Will Rowe	1036716002000	\n  I need to refer to the docs, but your error is setting the Expires: tag\n  in the first place after using Cache-Control: no-cache\n\n  You can't have it both ways and you will probably confuse some caches.
14376	Will Rowe	1036721963000	Ok, from RFC 2616;\n\n   The Date general-header field represents the date and time at which\n   the message was originated, having the same semantics as orig-date in\n   RFC 822. The field value is an HTTP-date, as described in section\n   3.3.1; it MUST be sent in RFC 1123 [8]-date format.\n\nand\n\n   A received message that does not have a Date header field MUST be\n   assigned one by the recipient if the message will be cached by that\n   recipient or gatewayed via a protocol which requires a Date.\n\nSo, if we have a Date:, the proxy should assign that, if we have no date,\nwe invent one.\n\nFinally, about your Expires: tag... I strongly suggest you follow the following\nsemantic;\n\n   An origin server [...] MAY assign an Expires value that is known, \n   at or before server configuration time, to be in the past (this allows \n   'pre-expiration' of responses without storing separate Expires values \n   for each resource).\n\nwhich is precisely the behavior you desired.\n
14376	L.C.	1036725141000	The conclusion that the proxy must set the Date header when it has already been\nprovided by the origin server cannot be inferred from the two paragraphs quoted\n(since the message is not originated on the proxy).\n\nUsing the rfc822 analogy mentioned in the text would imply a mail relay changing\nthe Date: header as the email passes through it, even if there is one already \nthere that respects the format. That does not happen.\n\nThe proxy's changing of the date makes the Expires header as unreliable as the\ntime on the proxy machine, because other than the Date header, the client has \nno way to know the time reference of the origin server. That essentially makes\nExpires unusable for anything other than very distant times in the future\n(depending on how much the proxy time is off).\n
14376	Co-Advisor	1042660757000	Having both Cache-Control: no-cache and Expires is\nperfectly valid/legal. 'no-cache' does not mean 'do not\ncache/store'; it means 'revalidate on every request'. Expires\nrefers to content freshness which is often a separate issue.\n\nSome applications may be able to predict expiration times and may still\nwant to see all [validation] requests. Some caches\n(think CDNs like Akamai or bookmark revalidation services) may use the combination to optimize their [caching] decisions.\n\nCache-control overrides Expires:\n\n   The presence of an Expires header field with a date value of some\n   time in the future on a response that otherwise would by default be\n   non-cacheable indicates that the response is cacheable, unless\n   indicated otherwise by a Cache-Control header field (section 14.9).\n\nSince this is not really realted to Date header changes, I will \nprobably submit a separate bug report.\n
14376	Graham Leggett	1050425297000	According to proxy_http.c this is the only code that touches the date field:\n\n  \t      if ((buf = apr_table_get(r->headers_out, 'Date')) != NULL) {\n  \t\tapr_table_set(r->headers_out, 'Date',     \n                              ap_proxy_date_canon(p, buf));\n  \t      }                                             \n\nWhat it does is try and parse the date provided using ap_proxy_date_canon().\nThis tries to parse the date, but if it fails to parse the date, the date is\ntransferred through unaltered.\n\nIf the date is being overwritten, it is likely to be happening inside the Apache\ncore, and not mod_proxy. I have updated the component to reflect this.\n
14376	Graham Leggett	1050425979000	Found the problem: inside modules/http/http_protocol.c the date is being set to\nthe current time, and the contents of the output headers array is ignored in the\ncase of the date header. The attached patch fixes this.\n
14376	Graham Leggett	1050426162000	Created an attachment (id=5840)\nPatch to fix for v2.0.46-dev\n
14376	Graham Leggett	1050428650000	Created an attachment (id=5841)\nPatch this time without compiler warnings!\n
14376	Graham Leggett	1050428689000	Patch applied to v2.1 and v2.0\n
14399	Will Rowe	1036869728000	\n  Your suggested patch is in and will be in the next release 2.0.44.  Thanks!!!\n
14451	Bruno Wolff III	1037400187000	I saw that some other fixes to mod_deflate were applied recently\nand retested on current CVS and the problem still exists.
14451	Bruno Wolff III	1037980919000	Is there some additional information that I can provide that would\nhelp you guys confirm this bug?\nI have tried looking through the bucket passing code in the past\nwhen reporting mod_deflate bugs and wasn't able to understand\nenough to be able to spot where the errors are.\nI see that you are possible going to change the status of mod_deflate\nto be a normal module instead of experimental. I have found that\npeople running IE 5.0 and IE 6.0 have been having a lot of problems\nviewing pages generate by cgi scripts and filtered by mod_deflate.\nI suspect that the problem is related to the content-length header\nissue, but I am not absolutely sure of this. If confirming this would\nhelp increase the priority on figuring this problem out, I could try\nusing mod_headers to strip the content-length headers and see if that\nsolves the problem for the IE users. However, I have to ask others\nto do the testing and it might take a few days before I get help after\nI have some modified pages for them to look at.
14451	Jeff Trawick	1037992397000	Supplying the simplest testcase you can come up with that shows the problem\nwould be very helpful.  I've tried to duplicate the problem with GET requests on\ncurrent code but I haven't been successful.  I haven't looked at the HEAD issue yet.\n
14451	Bruno Wolff III	1038021132000	I think I have figured out enough so that you should be able to\nreproduce the problem. The missing part is that I do an internal\nredirect and that is needed to make the problem show up.\nhttp://wolff.to/area/htaccess (no period) with show the .htaccess\nfile. The first line (the filter list) and the last line (the\nrelevant redirect) should be all that matters.\nhttp://wolff.to/area/test.pl , http://wolff.to/area/test.cgi and\nhttp://wolff.to/area/test.html all point to the same file. The first\nwill give you the source, the second will work correctly and the\nthird has a content-length header off by 20. However, note that in\nthe second case the file is 20 bytes longer.
14451	Bruno Wolff III	1038073806000	I looked at the difference between the compressed output returned\nby test.cgi and test.html and it appears that test.html has an\nextra 20 bytes of what appears to be a gzip header tacked on to the\nend.\nI also updated to use the latest cvs yesterday so I am now running\na 2.1.0 version of httpd.
14451	Bruno Wolff III	1038404980000	The HEAD and GET problems appear to be separate. The extra 20 bytes\nget added when there is an internal redirect (using mod_rewrite) and\nboth the new and old extension are subject to mod_deflate filtering.\nI added another rewrite rule to the htaccess file and a test.txt file\naccessible through a redirect as test1.txt to illustrate this case.\nI will see if I can do a better job of isolating the bad\ncontent-length header returns on HEAD requests.
14451	Bruno Wolff III	1038407922000	I figured out what was happenning with the odd content-length header\nvalues on HEAD requests. The short story is that it isn't a bug.\nThe script I was using only returns a content-type header on HEAD\nrequests (this is probably broken behavior) to save doing database\nlookups that won't be used. Even though the body is 0 bytes, it still\ngets gzip encoded and this encoding takes up 20 bytes. That is why\nthere is a content-length of 20.\nSo the only issue is the extra 20 bytes being tacked on to the body\nof requests that have a filtered (by mod_deflate) on both the initial\nand final filename extensions.
14451	Bruno Wolff III	1038409879000	This is sort of a related note. Normally a content-lenght header\nisn't sent when an includes filter is used or when the output\ncomes from a cgi script. However if mod_deflate is used, then a\ncontent-length header is included for either or both of these cases.
14451	Bruno Wolff III	1038782152000	I tried using addoutputfilterbytype to see if that would work around\nthe problem, but it didn't help.
14451	Bruno Wolff III	1039361068000	Is there anything else I can do to help get this bug verified?\nI think I have included enough information for someone to check\non it, but haven't heard back either way since figuring out that\ncombining internal redirects and mod_deflate exhibits the problem.
14451	Bruno Wolff III	1040063748000	I was able to find a configuration that avoided the problem in my\nsetup. I have changed things to reflect this and have removed some\nof the test pages I had up.\nThe successful way to handle *.html URLs that were redirected to\n*.cgi URLs (with internal redirects) so that the output was passed\nboth though INCLUDES and DEFLATE without getting the extra 20 bytes\nof gzip header or messing *.html files that aren't redirected is:\nAddOutputFilter INCLUDES;DEFLATE .html\nAddOutputFilter DEFLATE .txt .pl .sql .cgi\nAddOutputFilterByType INCLUDES text/html\nThis is now all being done at the top level of my document root.\nPreviously there was an addoutputfilter for .cgi files that only\nspecified DEFLATE at the top level and this was overridden in a\nsubdirectory (area) where cgi output was to get passed through both\nINCLUDES and DEFLATE. This may be related to the problem I was having\nas reduplicating the issue with the output filter directives only\nat the top level doesn't seem to work.\nBy using the addoutputfilterbytype directive I can just do INCLUDES\nprocessing for cgi output that returns text/html (as opposed to\ntext/plain) and don't need to have diferent rules in different\ndirectories.\nSo, I am not completely sure what is needed to make the problem show\nup. I was able to get the problem to occur with just plain html\nfiles (no cgi script) subject to a redirect in the subdirectory.\nI am asking one of my users to see if this fixes the problem with\naccessing the pages with IE.
14451	Bruno Wolff III	1040144925000	It turns out my new configuration didn't fix things.\nhttp://www.schroepl.net/cgi-bin/http_trace.pl started reporting a\ndata returned size that matched the content length header, but\naccording to my access_log another 20 bytes were actually sent.\nI noticed this when I got a report back from an IE user that\nthey still couldn't get compressed responses to work. So what I think\nchanged was the testing service, not the content being served.
14451	Bruno Wolff III	1040586824000	I think I have something that will point out where I am seeing the\nproblem. In mod_deflate.c there is code to not due compression for\nsubrequests. I think this check should be extended to not do it\nfor internal redirects. (I am not sure why the check that the request\ndoesn't already have a gzip encoding doesn't catch this.) I checked\nr->next to see if there will be more processing after this request\nis completed. I am not sure this is correct, because the .h that\ndefines record_rec has a comment that this link refers to external\nrequests. I suspect that that is a typo. Anyway the patch seems to\nwork for my problem. I will let you know if this fixes the IE problem\nwhen I hear back from the person who has been having problems with\ncompressed responses.\nThe diff versus mod_deflate.c follows:\n*** mod_deflate.c.orig  Sun Dec 22 13:53:19 2002\n--- mod_deflate.c       Sun Dec 22 13:36:55 2002\n***************\n*** 260,266 ****\n          const char *encoding, *accepts;\n\n          /* only work on main request/no subrequests */\n!         if (r->main) {\n              ap_remove_output_filter(f);\n              return ap_pass_brigade(f->next, bb);\n          }\n--- 260,266 ----\n          const char *encoding, *accepts;\n\n          /* only work on main request/no subrequests */\n!         if (r->main || r->next) {\n              ap_remove_output_filter(f);\n              return ap_pass_brigade(f->next, bb);\n          }
14451	Bruno Wolff III	1040656336000	I heard back from the IE user who was having problems and now that\nthere aren't an extra 20 bytes being tacked on to compressed\nresponses, things are working OK.
14451	Andr?? Malo	1045101809000	I'll try to have a closer look at the problem and the patch these days, but one\nword anyway:\n\nsending different headers for GET and HEAD is wrong. You should _not_ handle\nboth methods not differently. Just send the content regardless of the method.\nApache will do the right thing and discard the body if neccessary. But he's able\nto maintain the Content-length header (or TRansfer-Encoding).
14451	Bruno Wolff III	1045103291000	Thanks for looking at this!\nWhile working on this issue I did figure out that suppressing the\ncontent for the head method was wrong. I haven't gotten around to\nchanging the code yet, but I plan to. The original idea was to save\nresources by not doing database calls if the content was going to\nbe thrown away anyway, but it turned out that keeps the head method\nfrom being as useful as it should. I also got confused by this as\nI was expecting the content-length to be zero since there was no\nbody, not realizing that a gzip'd version of an empty content takes\nup 20 bytes.\nGet requests do seem to be broken though. And since mod_deflate checks\nto make sure it isn't run twice, I am pretty sure there is something\nwrong where I have patched the code. (Especially since it fixes things\nfor me.) I am just not sure that the fix is really correct for all\ncases.
14451	Andr?? Malo	1045450266000	strange ...\n\nSeems to happen only when redirecting to the cgi-handler. Can someone confirm or\ndisprove this?\n\nThanks anyway for your patience with us :)
14451	Andr?? Malo	1045528746000	errr, forget my last comment. I did the wrong tests ;-)\n\nHowever, your patch worked around the actual problem, it did not solve it.\nThe problem was that after finalizing the (redirected) request, the original\nrequest sent an(other) EOS bucket down the filter chain, which caused\nmod_deflate to init zlib and exit zlib with the result of 20 extra bytes.\n\nThe following patch should solve the problem entirely:\n<http://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/util_filter.c.diff?r1=1.94&r2=1.95>\n\nIt's proposed for backport and may be in the next 2.0 release.\n\nThanks again for your patience and your detailed reports!
14451	Bruno Wolff III	1045532549000	I removed my patched mod_deflate and resynced with current CVS\nand retested for the problem. It seems to be fixed now. Thanks!
14451	Andr?? Malo	1045945850000	FYI: The fix will be in 2.0.45.
14451	Steven Grimm	1055545788000	*** Bug 17629 has been marked as a duplicate of this bug. ***
14451	Joe Orton	1058796581000	*** Bug 14678 has been marked as a duplicate of this bug. ***
14451	Ruediger Pluem	1199694991000	*** Bug 14678 has been marked as a duplicate of this bug. ***
14453	Cedric Gavage	1059390532000	Created an attachment (id=7543)\nPatch we use successfully since monthes about this problem\n
14453	Andr?? Malo	1065434541000	This was fixed in 2.1 some time ago and waits for backport approval (another\nvote from a core developer).\n\nThanks for your report!
14453	Andr?? Malo	1065435535000	*** Bug 21975 has been marked as a duplicate of this bug. ***
14453	Andr?? Malo	1073935935000	It will be fixed in 1.3.30 and 2.0.49 versions.
14550	Jeff Trawick	1037328699000	A fix has just been committed.\n\nCommunication between handler and daemon was extensively reworked.\nEnvironment variables were handled as in the patch submitted with\nthis PR.\n\nThanks for your debug work, and thanks for using Apache 2.0!\n
14550	Joe Orton	1078942359000	*** Bug 9953 has been marked as a duplicate of this bug. ***
14639	Warren Volz	1037995267000	I have the same problem, only when apache is configured as a transparent proxy.
14639	Will Rowe	1038036712000	\n  You aren't reporting a bug in query strings (those strings following the\n  '?' question mark delimiter.)  You are speaking of path info, which only\n  makes sense when interpreted with the filesystem.  Because of security\n  implications, that ambiguity was disabled eaons ago.\n
14639	Rodent of Unusual Size	1055541534000	This has been addressed in Apache 2.0.46 through the new AllowEncodedSlashes\ndirective.
14648	Mike Cramer	1038410136000	This doesn't work perfectly, I've discovered. Take the follwoing setup:\n\n## relevant conf directives\nDirectoryIndex index.html index.php\nRewriteRule ^/(.*/.php)$ http://localhost:8888/$1 [P]\n##\n\n$DocRoot/blah/ contains: index.php and test.html\n\nNow...*without* patching mod_rewrite, a request for http://www.domain.org/blah/\nwill return index.php just fine, and it will be properly proxied over to\nlocalhost:8888. And, as this bug points out, if test.html just contains\n<!--#include virtual='index.php'-->, requests for it return the unparsed source\nof index.php, which is incorrect.\n\nBut if you remove the one line from mod_rewrite, allowing proxy requests in\nsubrequests, the situation reverses. The SSI part works properly, but requests\nfor /blah/ give you a directory index instead of the output of index.php.\n\nSo this patch doesn't do exactly the right thing. \n
14648	Mike Cramer	1038427738000	I've done some more digging and think I've come a little closer to the real\nsource of the problem:\n\nmod_dir makes subrequests for each of its potential index file names until it\nfinds one to return. Line 165 of mod_dir.c is this:\n\nif (rr->status == HTTP_OK && S_ISREG(rr->finfo.st_mode)) {\n\nSo, for mod_dir to return an index file the subrequest has to be HTTP_OK and it\nmust be a regular file. This works fine with the unpatched mod_rewrite, because\nit will return HTTP_OK and the file will be there -- even if the server is going\nto end up proxying it in the end.\n\nBut, if you patch mod_rewrite then you'll still get the HTTP_OK, but\nrr->filename will have been changed to start with 'proxy:', so S_ISREG() will fail. \n\nWhich leads to this solution:\n\nchange the call to ap_sub_req_lookup_uri on line 163 of mod_dir.c to\nap_sub_req_lookup_file. ap_sub_req_lookup_file doesn't do the URI translation,\nso it skips mod_rewrite in the subrequest. But then mod_dir still does an\ninternal redirect, which in turn *does* do the URI translation, so everything\nworks out in the end.\n\nWith these changes both mod_include and mod_dir do the right thing when they are\ndealing with a file proxied via mod_rewrite+mod_proxy. I'll attach a patch which\nchanges both parts.
14648	Mike Cramer	1038427866000	Created an attachment (id=3973)\nOne line fix to each: mod_dir & mod_rewrite\n
14648	Jeff Trawick	1069438107000	I'm going through the bug db to make sure patches are findable.  Please see \nhttp://httpd.apache.org/dev/patches.html\n
14648	Jeremy Brown	1069946421000	Another solution to this problem is to utilize the proxy: moniker instead of \n[P} to invoke the proxy client.\n\n[P] as you have pointed out invokes the proxy client but does not continue with \nadditional includes on the invoked page.\n\nWheras the proxy: moniker is invoked in the file mapping handler which contiues \nwith additional ssi requests.\n\nExample:\nRewriteRule ^(.*) proxy:http://host/$1\n\nThis assumes that mod_proxy is installed and configured correctly!\n\nThe other benefit is that additional SSI requests will continue to be processed \non the calling page.\n
14648	Andr?? Malo	1074040899000	Fixed in 2.1.\n\nThanks for the report and thanks for using Apache.
14892	Joshua Slive	1038413510000	Specific suggestions are always appreciated, and the suggestion for the security\ntips doc is good.\n\nGeneral statements about being more secuity conscious aren't very helpful,\nhowever.  If you have more ideas, feel free to file specific bug reports,\nor even better, join the documentation project:\nhttp://httpd.apache.org/docs-project/\n\nThanks.
14892	Joshua Slive	1038624261000	This security tip will be added to the next version.\n\nThanks.
14921	Julian Reschke	1038595141000	(likely cause: moddav duplicates code from ap_make_etag in http_protocol.c \ninstead of reusing it directly -- etag computation probably should be done in \none single place)
14921	Justin Erenkrantz	1043861374000	This is not really a bug per se.\n\nWhat happens is that we generate a weak ETag when the request is too close to the modification time of the file (as dictated by RFC 2616, ETags should have 60-second resolutions).  After that second has elasped and the file hasn't changed, that weak entity tag would be made strong.  Creating a weak tag in mod_dav_fs isn't always desirable since it isn't keyed to a request - therefore all of its entity tags should be strong rather than weak.\n\nHowever, RFC 2616 explicitly calls out strong entity comparison and weak entity comparison functions.  Currently, mod_dav only uses strong entity comparison.  So, I modified mod_dav to do weak entity comparison instead.\n\nSee modules/dav/main/util.c r1.45.\n\nThis has been proposed for the next stable release of httpd-2.0.\n\nThanks for using Apache!
14921	Justin Erenkrantz	1043861708000	*** Bug 16451 has been marked as a duplicate of this bug. ***
14921	Julian Reschke	1043864940000	I'm not sure that I agree with the analysis. First of all, RFC2616 doesn't \ndefine a specific resolution for etags.\n\n(all this probably only applies to the fs backend)\n\nThe issue here seems to be that the resource's etag starts it's life as a weak \none, and then turns into a strong etag after some delay. This works fine if you \ndiscover an already existing resource using GET/HEAD/PROPFIND, but leads to \nugly results if a client takes the entity tag returned by a PUT as validator \nfor subsequent PUT operations (because upon PUT, the entity tag returned is \nalways a weak one, because it's 'fresh').\n\nAs far as the If-* headers defined in RFC2616 are concerned (not the If: \ndefined in RFC2518), strong comparison should be applied to etags (end of para \n13.3.3).
14921	Justin Erenkrantz	1043866921000	This is why I believe the only workable solution here is to do weak entity\ncomparison for the If: header.\n\nmod_dav must be able to handle weak entity tags for its conditional headers\nbecause the entity tag might be promoted from a weak to a strong one at any time\n(given rules of 13.3.3).\n\nNote that using ap_make_etag is not an option since we don't have access to the\noriginal request, nor is that resource in the etag hook even related to the\noriginal resource that was requested.  (ap_make_etag has certain configurable\nproperties that may not be correct if we are not dealing with the original\nresource.)  And, doing so, wouldn't solve the real problem of ETag promotion.\n\nIf 2518bis clarifies this and says that If should only have strong entity\ncomparison, then we might want to rethink this.  Regardless, perhaps it should\nclarify this corner case.
15001	Andr?? Malo	1038858541000	It's actually case insensitive, but you're right, it may be confusing.\n\nThanks for using Apache!
15057	Joe Orton	1073904797000	Ah, I just found a repro case for SSL_get_session returning NULL: when serving\nthe 'you sent a plain HTTP request over an SSL connection' error message.\n\nThanks for the patch! It's committed to 2.1 and will be proposed for backport\nfor 2.0.
15113	Thomas CASTELLE	1039595334000	Hello !\n\nHave you checked this problem ? Can anyone look at it, because this is quite\nannoying for us (we are in production environment !)\n\nThanks a lot in advance,\n\nThomas.\n
15113	Paul J. Reder	1039625450000	Thomas, I am currently looking at this PR. While I am working to debug this,\ncould you attach a section of your error_log around the time this happens (with\nloglevel set to debug)? Thanks.
15113	Thomas CASTELLE	1039628730000	OK, thanks for looking !\n\nI reproduced the bug.\n\nLast CVS snapshot used, compiled with :\n\n./configure --prefix=/opt/ApacheProxy2.0 --localstatedir=/logs/ApacheProxy2.0\n--enable-cache --enable-disk-cache --enable-proxy --enable-rewrite --enable-deflate\n\nIt is configured as a proxy-cache. When the serveur behind answers a 403 or 302\nresponse, the child dies. With a telnet on a 403 page :\n\n# telnet 172.30.16.21 80\nTrying 172.30.16.21...\nConnected to 172.30.16.21.\nEscape character is '^]'.\nGET /blablabla HTTP/1.1\nHost: front.www.leda.rev.proto.generali.fr\n\nConnection closed by foreign host.\n#\n\nIn the error.log :\n\n[Wed Dec 11 18:26:57 2002] [notice] Apache configured -- resuming normal operations\n[Wed Dec 11 18:26:57 2002] [info] Server built: Dec 11 2002 18:20:58\n[Wed Dec 11 18:26:57 2002] [debug] prefork.c(1039): AcceptMutex: sysvsem\n(default: sysvsem)\n[Wed Dec 11 18:27:33 2002] [notice] child pid 1574 exit signal Segmentation\nfault (11)\n\nIn the virtual host error log :\n\n[Wed Dec 11 18:27:32 2002] [debug] mod_cache.c(118): cache: URL /blablabla is\nbeing handled by disk\n[Wed Dec 11 18:27:32 2002] [debug] mod_cache.c(202): cache: no cache - add\ncache_in filter and DECLINE\n[Wed Dec 11 18:27:32 2002] [debug] proxy_http.c(109): proxy: HTTP:\ncanonicalising URL //www.leda.rev.proto.generali.fr/blablab\nla\n[Wed Dec 11 18:27:32 2002] [debug] mod_proxy.c(440): Trying to run\nscheme_handler against proxy\n[Wed Dec 11 18:27:32 2002] [debug] proxy_http.c(1170): proxy: HTTP: serving URL\nhttp://www.leda.rev.proto.generali.fr/blablabl\na\n[Wed Dec 11 18:27:32 2002] [debug] proxy_http.c(221): proxy: HTTP connecting\nhttp://www.leda.rev.proto.generali.fr/blablabla t\no www.leda.rev.proto.generali.fr:80\n[Wed Dec 11 18:27:32 2002] [debug] proxy_util.c(1201): proxy: HTTP: fam 2 socket\ncreated to connect to proxybo1.generali.fr\n[Wed Dec 11 18:27:32 2002] [debug] proxy_http.c(370): proxy: socket is connected\n[Wed Dec 11 18:27:32 2002] [debug] proxy_http.c(404): proxy: connection complete\nto 172.30.4.4:9080 (proxybo1.generali.fr)\n[Wed Dec 11 18:27:32 2002] [debug] proxy_http.c(1012): proxy: start body send\n[Wed Dec 11 18:27:32 2002] [debug] mod_cache.c(436): cache: running CACHE_IN filter\n\nAs I said before, it seems to crash on the particular call to apr_pstrcat. If I\ncomment it, it works.\n\nin error.log :\n[Wed Dec 11 18:38:31 2002] [notice] Apache configured -- resuming normal operations\n[Wed Dec 11 18:38:31 2002] [info] Server built: Dec 11 2002 18:20:58\n[Wed Dec 11 18:38:31 2002] [debug] prefork.c(1039): AcceptMutex: sysvsem\n(default: sysvsem)\n\nin virtual host error log :\n[Wed Dec 11 18:39:03 2002] [debug] mod_cache.c(118): cache: URL /blablabla is\nbeing handled by disk\n[Wed Dec 11 18:39:03 2002] [debug] mod_cache.c(202): cache: no cache - add\ncache_in filter and DECLINE\n[Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(109): proxy: HTTP:\ncanonicalising URL //www.leda.rev.proto.generali.fr/blablab\nla\n[Wed Dec 11 18:39:03 2002] [debug] mod_proxy.c(440): Trying to run\nscheme_handler against proxy\n[Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(1170): proxy: HTTP: serving URL\nhttp://www.leda.rev.proto.generali.fr/blablabl\na\n[Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(221): proxy: HTTP connecting\nhttp://www.leda.rev.proto.generali.fr/blablabla t\no www.leda.rev.proto.generali.fr:80\n[Wed Dec 11 18:39:03 2002] [debug] proxy_util.c(1201): proxy: HTTP: fam 2 socket\ncreated to connect to proxybo1.generali.fr\n[Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(370): proxy: socket is connected\n[Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(404): proxy: connection complete\nto 172.30.4.4:9080 (proxybo1.generali.fr)\n[Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(1012): proxy: start body send\n[Wed Dec 11 18:39:03 2002] [debug] mod_cache.c(436): cache: running CACHE_IN filter\n[Wed Dec 11 18:39:03 2002] [info] disk_cache: Caching URL\nfront.www.leda.rev.proto.generali.fr/blablabla?\n[Wed Dec 11 18:39:03 2002] [debug] mod_cache.c(806): cache: Caching url: /blablabla\n[Wed Dec 11 18:39:03 2002] [info] disk_cache: Caching headers for URL\nfront.www.leda.rev.proto.generali.fr/blablabla?\n[Wed Dec 11 18:39:03 2002] [info] disk_cache: Cached body for URL\nfront.www.leda.rev.proto.generali.fr/blablabla?\n[Wed Dec 11 18:39:03 2002] [debug] proxy_http.c(1071): proxy: end body send\n\nThanks for your help ! And as a bonus-question... is mod_cache actively\ndevelopped in the moment ? Because the only problems we have with Apache 2 come\nfrom this module, and it doesn't seem to be really often updated (well, as far\nas i can see on the cvs snapshots...). Can someone tell me if it will we stable\nin the next release ?\n\nThanks a lot for your effort !\n\nThomas.\n
15113	Thomas CASTELLE	1040112935000	Hi there !\n\nIs there some news about this bug ? Have you reproduced the problem ?\nPlease keep me informed !\nThanks in advance, \n\nThomas.
15113	Paul J. Reder	1040139726000	I just applied a fix to mod_cache.c that cures the core dump. This fix will be\nincluded in a future release of Apache. Thank you for reporting this problem.
15114	Mike Cramer	1039106853000	Created an attachment (id=4060)\nFix mod_rewrite proxy bug for mod_include\n
15114	Mike Cramer	1039107251000	Oh yea...and the code that adds the args to the subrequest when checking each\nfile has to go again if it's changed to use ap_sub_req_lookup_file. Otherwise a\nrequest like http://domain.org/foo/?bar=1 will fail. Granted, the original logic\n-- that the args could be relevant to decision of which index file to use -- is\ngood, but this seems like the lesser of two evils.
15114	Jeff Trawick	1069434625000	I'm going through the bug db to make sure patches are findable.  Please see \nhttp://httpd.apache.org/dev/patches.html\n
15114	Jeremy Brown	1070394443000	Another solution to this problem is to utilize the proxy: moniker instead of \n[P} to invoke the proxy client.\n\n[P] as you have pointed out invokes the proxy client but does not continue with \nadditional includes on the invoked page.\n\nWheras the proxy: moniker is invoked in the file mapping handler which contiues \nwith additional ssi requests.\n\nExample:\nRewriteRule ^(.*) proxy:http://host/$1\n\nThis assumes that mod_proxy is installed and configured correctly!\n\nThe other benefit is that additional SSI requests will continue to be processed \non the calling page.\n\n
15114	Andr?? Malo	1074040672000	Fixed in 2.1.\n\nThanks for the report and thanks for using Apache.
15207	Zvi Har'El	1051436243000	A reverse proxy doesn't need to be transparent. It may be as well a caching\nproxy, that approached the backend server only if it doens't have a fresh copy\nof the requested object. There fore, it MAY alter the URL. However, there is a\nbug in this alteration: In the reverse proxy case, unescaping is done twice. In\nthe first   unesacping, the core does this for any non-proxy request. However,\nthis is done before reverse proxy requests are identified by matching the URL\nwith ProxyPass directives. Therefore, the second unescaping, in the function\nap_proxy_canonenc in proxy_util.c, should be done only for a standard proxy, and\nnot for a reverse proxy, and the line\n\nif (isenc && ch == '%') {\n\n(proxy_util.c:206 in httpd_2.0.45) should be replaced by\n\nif (isenc == PROXYREQ_PROXY && ch == '%') {
15207	Nick Kew	1088261426000	*** Bug 24873 has been marked as a duplicate of this bug. ***
15207	Nick Kew	1088266239000	*** Bug 18564 has been marked as a duplicate of this bug. ***
15207	Nick Kew	1088491638000	Fix now committed to HEAD (subject to review)
15207	Joshua Hirsh	1108760550000	This bug still exists as of 2.0.53. The suggested patch in proxy_util.c from Zvi\nHar'El, listed below, corrects the problem for me:\n\nif (isenc == PROXYREQ_PROXY && ch == '%') {\n\nTo reproduce the bug, I setup a Reverse Proxy and use the following urls for\ntesting:\n\nhttp://1.2.3.4/%\t\t-Returns bad request\nhttp://1.2.3.4/%25\t\t-Works\nhttp://1.2.3.4/proxy/%\t\t-Returns bad request\nhttp://1.2.3.4/proxy/%25\t-Returns bad request\n\nAfter the patch, the last example works properly.
15207	Cahya	1116959459000	I have also the same problem with apache 2.0.54, \nis there any plan to fix it in the next release?\nthanks
15207	Joe Orton	1123257749000	Fixed for 2.0.55: http://svn.apache.org/viewcvs.cgi?rev=227435&view=rev
15242	Taisuke Yamada	1039539008000	Created an attachment (id=4116)\nPatch to configure whether userland CGI could handle OPTIONS request.\n
15242	Taisuke Yamada	1039539180000	Created an attachment (id=4117)\nPatch to configure whether userland CGI could handle OPTIONS request.\n
15242	Jeff Trawick	1069438148000	I'm going through the bug db to make sure patches are findable.  Please see \nhttp://httpd.apache.org/dev/patches.html\n
15242	Thomas Jarosch	1080910864000	Created an attachment (id=11102)\nFixed for the Windows Update problem\n
15242	Mark Nottingham	1112294888000	Just a thought -- requiring extra configuration will be onerous for some users (e.g., those at certain \nhosting providers). Rather than adding a configuration directive, why not require the script that wants \nto handle OPTIONS to just emit an Apache-Specified HTTP header that gets consumed?\n\nE.g.,\n\nprint 'Status: 200 OK'\nprint 'Handling-OPTIONS: 1'\nprint 'Allow: GET, POST'\n...
15242	Mark Nottingham	1112314664000	Did you ever submit a report for 2.0? Can't seem to find anything, and 2.0.53 seems to have the same \nproblem.
15242	Mark Nottingham	1112665252000	Hmm, never mind the previous suggestion; if the script had side effects, they'd still take place, which \nwon't be good.
15242	Taisuke Yamada	1113367190000	Wow, it's been long time since I submitted this one...\n\nNo, I haven't submitted patch for 2.0.\nAt that time, 2.0 was not really for production, so I simply\nwaited for 1.3 patch to get in.\n\nIt 2005 now, so maybe I should push this patch for 2.0\n- I guess developers are more active on 2.0 than on 1.3.\n
15242	Bayle Shanks	1125606031000	I'd just like to add that it's been awhile and it would be nice if the patch was\naccepted.
15242	Roy T. Fielding	1129680320000	Also known as\n\n   http://archive.apache.org/gnats/4490\n\nThis misfeature was supposed to be deleted almost immediately following its\naddition to the server, as described in\n\n<http://mail-archives.apache.org/mod_mbox/httpd-dev/199608.mbox/%3c9608132318.aa12603@paris.ics.uci.edu%3e>\n\nYep, that's Aug 1996.  In fact, I thought that I had deleted it, and if\nthis issue had been under 'core' I would have noticed it a long long time ago.\nOh well...\n\nThe block has now been deleted from all active branches of httpd (1.3.35,\n2.0.56, 2.1+).  Thanks for sending in the more complicated patches, but I\nfeel that CGI scripts should be able to handle all methods by now (or be\nfixed to do so properly).\n\n....Roy\n
15423	Justin Erenkrantz	1045440581000	Works for me with HEAD of httpd.  Please try Apache 2.0.44.\n\nThanks for using Apache HTTP Server!
15423	Steven Grimm	1045510107000	Still broken under 2.0.44.  I've poked around a bit more and figured out some\nadditional details; it looks like this is a problem with interaction between\nchunked encoding and mod_include:\n\n---\ndozer% cat test-apache2-redir.shtml\n<!--#include virtual='/cgi-bin/redirtest' --> Got to end!\ndozer% cat foo.html\nhiya\ndozer% cat ~/apache/cgi-bin/redirtest\n#!/bin/sh\necho Location: /foo.html\necho ''\ndozer% nc dozer 8763\nGET /test-apache2-redir.shtml HTTP/1.1\nHost: dozer.ironplanet.com:8763\n\nHTTP/1.1 200 OK\nDate: Mon, 17 Feb 2003 19:09:24 GMT\nServer: Apache/2.0.44 (Unix) mod_fastcgi/mod_fastcgi-SNAP-0210222112\nAccept-Ranges: bytes\nConnection: close\nTransfer-Encoding: chunked\nContent-Type: text/html; charset=ISO-8859-1\n\n5\nhiya\n\n0\n\n0\n\nd\n Got to end!\n\n0\n\n---\n\nNotice that although the 'got to end' message *does* make it through, it comes\nthrough *after* not one but two 0-length chunks, each of which is supposed to\nindicate the end of the document (see RFC2616 section 3.6.1).  If you hit this\nURL with Mozilla or MSIE or links, you just see the 'hiya' message.\n\nNow, if I replace the include of the CGI script with a direct include of\n/foo.html, the result is much more reasonable:\n\n---\ndozer% cat test-apache2-redir2.shtml\n<!--#include virtual='/foo.html' --> Got to end!\ndozer% nc dozer 8763\nGET /test-apache2-redir2.shtml HTTP/1.1\nHost: dozer.ironplanet.com:8763\n\nHTTP/1.1 200 OK\nDate: Mon, 17 Feb 2003 19:22:29 GMT\nServer: Apache/2.0.44 (Unix) mod_fastcgi/mod_fastcgi-SNAP-0210222112\nAccept-Ranges: bytes\nConnection: close\nTransfer-Encoding: chunked\nContent-Type: text/html; charset=ISO-8859-1\n\n5\nhiya\n\nd\n Got to end!\n\n0\n\n---\nI'd expect to see exactly the same output whether or not there's an internal\nredirect in the middle of the server-side processing of the .shtml file.
15423	Jeff Trawick	1046010524000	I can easily reproduce this on current code.\n\nThe problem is that we're getting down to the chunk filter on an internal redirect.\n\nI'll attach a patch that fixes it for me in just a second.  I'm not sure\nif the patch is complete, so I'm not ready to commit it.\n
15423	Jeff Trawick	1046010605000	Created an attachment (id=4981)\npatch file for adding the subrequest filter in internal_internal_redirect()\n
15423	Steven Grimm	1046025558000	This patch appears to fix the problem for me.
15423	Jeff Trawick	1046048422000	Thanks for the quick feedback.  After reviewing my patch some more I understand\nit well enough, so I've committed it to 2.1-dev.  I'll propose that it be merged\ninto\nthe stable tree (2.0.45-dev).\n\nThanks for using Apache, and thanks for your report!\n
15423	Jeff Trawick	1046059640000	*** Bug 16673 has been marked as a duplicate of this bug. ***
15423	Jeff Trawick	1047493704000	FYI, the fix for this problem has been merged into the stable tree for 2.0.45.
15491	Jeff Trawick	1042486707000	looks like exec*() is returning EFAULT in the failure case...  mod_ext_filter\nwasn't properly building the argument array in the simple case where there are\nno quotation marks...  sometimes it worked, sometimes exec*() hit bad storage...\n\nHere is the fix:\n\nIndex: modules/filters/mod_ext_filter.c\n===================================================================\nRCS file: /home/cvs/httpd-2.0/modules/filters/mod_ext_filter.c,v\nretrieving revision 1.1\ndiff -u -r1.1 mod_ext_filter.c\n--- modules/filters/mod_ext_filter.c    14 Nov 2002 20:22:50 -0000      1.1\n+++ modules/filters/mod_ext_filter.c    13 Jan 2003 19:31:11 -0000\n@@ -222,9 +222,10 @@\n     else\n     {\n         /* simple path */\n-        /* Allocate space for one argv pointer and parse the args. */\n-        filter->args = (char **)apr_palloc(p, sizeof(char *));\n+        /* Allocate space for two argv pointers and parse the args. */\n+        filter->args = (char **)apr_palloc(p, 2 * sizeof(char *));\n         filter->args[0] = ap_getword_white(p, args);\n+        filter->args[1] = NULL; /* end of args */\n     }\n     if (!filter->args[0]) {\n         return 'Invalid cmd= parameter';\n\nIt is now in CVS for Apache 2.1.  I can't make any promises on whether or \nnot it will be in 2.0.44, but it should be in one of the next couple of\n2.0 releases.\n\nThanks for your report, and thanks for using Apache!
15571	Joshua Slive	1040685808000	It would certainly be helpful if you could try this with a more recent\nversion of apache.  2.0.41-dev is quite old.
15571	Joshua Slive	1059069779000	No response from submitter.  Assuming issue is resolved.
15571	Joe Orton	1059073007000	This is a real bug, there's a fix in the mod_dav 1.0 tree which can be ported over.
15571	Jeff Trawick	1068586506000	I suspect that the fix below is what is needed.  I haven't found the mod_dav 1.0\nchange yet, but I found this change entry:\n\n'if a lock fails due to authentication problems, return a 403 (Forbidden) rather\nthan 401 (Unauthorized). this fixes an HTTP conformance issue where we returned\n401 but no WWW-Authenticate response header. (Joe Orton)'\n\nI'm guessing this is Joe's fix...  patch to 2.0's mod_dav:\n\nIndex: util.c\n===================================================================\nRCS file: /home/cvs/httpd-2.0/modules/dav/main/util.c,v\nretrieving revision 1.48\ndiff -u -r1.48 util.c\n--- util.c      22 Apr 2003 21:52:46 -0000      1.48\n+++ util.c      11 Nov 2003 21:30:58 -0000\n@@ -1212,7 +1212,7 @@\n                                             '/' submitted a locktoken created '\n                                             'by user /'',\n                                             lock->auth_user, '/'.', NULL);\n-                        return dav_new_error(p, HTTP_UNAUTHORIZED, 0, errmsg);\n+                        return dav_new_error(p, HTTP_FORBIDDEN, 0, errmsg);\n                     }\n\n                     /*\n
15571	Joe Orton	1068586815000	The fix I used was to copy over the www-auth header from the subrequest to the\nmain request, I can dig it out...
15571	Joe Orton	1070973885000	Committed to HEAD, proposed to backport to 2.0:\n\nhttp://cvs.apache.org/viewcvs/httpd-2.0/modules/dav/main/mod_dav.c.diff?r1=1.100&r2=1.101\n\nThanks for the report.
15603	Joshua Slive	1042057701000	Thanks!  Fixed.
15603	Ralf Hauser	1042091261000	Just checked the above URL again (since I am interested in what Thawte says) and\nI still get their 'You have followed a link to a page that the server can no\nlonger find.' page.
15603	Joshua Slive	1042131241000	Docs changes don't instantantly appear on the website.  You need to have\na little patience.  But I did just do an update for you, so you can find\nit now.\n\nOf course, there are still some other dead links on that page.  Someone\nneeds to do a really throrough rewrite of the ssl docs.
15610	Andr?? Malo	1040571482000	that happens, when a German trys to type English documentation... ;-)\n\nThanks for using Apache!
15616	Erik Abele	1040662124000	Fixed in the next release.\n\nThanks reporting this and the other issues and thanks for using Apache 2.0!
15627	Joshua Slive	1042049803000	Thanks for your note.  That whole paragraph is no longer relevant since\nmod_ssl was incorporated into the Apache Software Foundation, so I deleted\nit.
15679	Seth W. Klein	1040974699000	Created an attachment (id=4274)\npatch to acinclude.m4 to fix sed program used to parse config.layout\n
15679	Jeff Trawick	1044898445000	*** Bug 15678 has been marked as a duplicate of this bug. ***
15679	Justin Erenkrantz	1045449540000	Adding the 0, causes the leading parts of the files to still be included.  I finally figured out what the  right sed invocation was and committed a fix.\n\nhttpd-2.0: acinclude.m4 r1.136, configure.in r1.244\napr: build/apr_common.m4: 1.52\n\nNote that it is really unlikely that this will be backported to 2.0 though.\n\nThanks for using Apache HTTP Server!
15713	Jeff Trawick	1043958871000	This is fixed in cvs and will be in 2.0.45.  It will use your\ncompiled-in apache log directory.\n\nThanks for your report, and thanks for using Apache!\n
15761	Jeff Trawick	1044107525000	For your prefork test, add --disable-threads to your configure invocation and\ntry again, then report back whether or not it is still a problem.\n\nmake distclean && ./configure --disable-threads --whatever-else && make && make\ninstall\n\nAnything thread-enabled with Apache or APR does not work reliably on FreeBSD.\n\nNote that www.apache.org runs on FreeBSD 4.7 24x7 with no reliability problems.\nBut it uses prefork MPM and --disable-threads.\n
15761	Thomas Linden	1044261159000	In the meanwhile I found what has been the problem, and I can reproduce it:\n\nIn my config I had the following log-config entry:\n\nCustomLog |/usr/bin/ipwebcollect accounting\n\nThe script '/usr/bin/ipwebcollect' did not exist during my tries. In the error\nlog I found several (260 to be exact) entries that httpd could not find the program.\n\nIf I install the program or if I comment out the CustomLog line then the apache\nworks as expected.\n\nThis behavior could be re-produced with proforker and worker (it seems to be the\ngeneral behavior of apache, I think).\n\n\nTHe suggested fix would be to exit the httpd process if it cannot find a log\npipe program, or ot could just de-activate the log-pipe if it does not exist or\nis not executable.\n\n\nregards, Tom
15761	Jeff Trawick	1044545179000	quick update:\nApache hangs once the pipe to the logger fills in each child process.\nApache 1.3 had the same problem, though something more helpful would be logged.\n\nSome small improvement has been committed, but some infrastructure (APR) changes\nare in the works to improve it beyond the way it worked in Apache 1.3.\n\none question for you:\nYou mentioned seeing the 260 error messages in the log.  I never saw messages in\nmy testing prior to some changes I committed a couple of days ago.  Can you\nupdate the PR with the text of those messages please?\n\nThanks!
15761	Jeff Trawick	1044894804000	Changes have been committed to Apache 2.1 (active development) to utilize new\nAPR features for finding process creation errors on Unix.  These changes keep\nApache from starting up if a piped log program doesn't exist or isn't executable.\n(There are some possible errors that are found out too late, but now they\nshould result in an error message.)\n\nI'll propose these changes for merging into Apache 2.0.x (stable tree).\n\nThanks for your report, and thanks for using Apache!\n
15761	Jeff Trawick	1045272307000	FYI...  the fix has been merged into the stable tree for\ninclusion in 2.0.45
15761	Lone Wolf	1047031115000	*** Bug 17764 has been marked as a duplicate of this bug. ***
15859	Co-Advisor	1041973326000	Created an attachment (id=4352)\ntest case trace\n
15859	Graham Leggett	1050427943000	Is the following sentence correct?\n\n'A proxy MUST remove a Content-Length header from chunked responses, in case\nthis content length header is wrong'.\n
15859	Co-Advisor	1050429045000	Not exactly, but very close, IMO.\n\nThe proxy MUST ignore wrong Content-Length header in chunked\nresponses (which is what Apache is probably doing). It would\nbe OK to forward that header, provided that the proxy does\nnot decode chunks on-the-fly. A compliant recipient would\nnot have a problem handling such a response (chunked\nencoding with wrong Content-Length header).\n\nHowever, Apache decodes chunks into 'normal' (identity)\nencoding and forwards the response with the original (wrong)\nContent-Length value. While there is no specific MUST about\nthis case, the only logical interpretation or RFC 2616\nsuggests that the wrong Content-Length header must be\nremoved. Otherwise, a compliant recipient will mis-interpret\nthe response!\n\nIf you want a one sentence summary, I would say: 'A proxy\nhas to remove the wrong Content-Length header when\nforwarding a chunked response using identity encoding (i.e.,\nwhen de-chunking on-the-fly).'\n
15859	Graham Leggett	1050429454000	The problem though is that we cannot know the Content-Length is wrong until we\nhave processed the entire request. At this point we would have already sent the\nContent-Length header onwards, so it's too late to fix it if it is wrong - it\nwould require the proxy to buffer the entire request before sending it on, which\nis not practical.\n\nOne possible thing to do though is to remove the Content-Length header should\nApache decide to send chunked encoding. This needs to be done inside the filter\nresponsible for chunking, rather than mod_proxy.\n\nThoughts?\n
15859	Co-Advisor	1050429911000	The Content-Length header is _always_ wrong when it is used together\nwith chunking because Content-Length header is defined to represent\nboth entity-length and the transfer-length. It is not possible to represent both with a single value when chunking is used.\n\nThus, only two actions would be correct, IMO:\n   - leave wrong Content-Length header and do NOT de-chunk\n   - remove wrong Content-Length header\n\nNote that there is no need to remove Content-Length header if Apache decides to send chunked encoding. It is de-chunking that causes the problem.
15859	Cymen Vig	1059257311000	Is this related to:\n<http://nagoya.apache.org/bugzilla/show_bug.cgi?id=21348>\n\nIf so, this bug breaks WindowsUpdate when used behind mod_proxy. Patch is linked\nin above bug that might be applicable.
15859	Co-Advisor	1060983426000	The WindowsUpdate patch you mentioned has no visible effect\non this bug. Note that the patch seems to be designed to\naffect HEAD responses while this bug deals with GET responses.\n
15859	Nick Kew	1096398786000	*** Bug 31454 has been marked as a duplicate of this bug. ***
15859	Nick Kew	1101468693000	*** Bug 11993 has been marked as a duplicate of this bug. ***
15859	Kristian Nielsen	1101470590000	I believe that this problem relates to proxying of _all_ requests with\nchunked request data, not just those with a bogus Content-Length.\n\nmod_proxy is de-chunking and removing Transfer-Encoding: chunked, forwarding\na request with neither Content-Length: or Transfer-Encoding: header. This\ncauses the downstream server to reply with error 411 'Length Required'.\n\nBug 11618 has a network trace showing this clearly.\n\nSince it is not possible to send a correct Content-Length header without\nbuffering all request data, it seems to me that the proper fix is to not\nde-chunk if the original request is chunked?\n\nI looked briefly in the function ap_proxy_http_request in proxy_http.c.\nHow about if the original request uses chunked transfer-encoding, then\nthe proxied request is also send as chunked? I could try to create a patch\nto add that to the code, it seems not too hard:\n\n    /* send the request data, if any. */\n    seen_eos = 0;\n    do {\n        status = ap_get_brigade(r->input_filters, bb, AP_MODE_READBYTES,\n                                APR_BLOCK_READ, HUGE_STRING_LEN);\n\n        if (status != APR_SUCCESS) {\n            return status;\n        }\n\n        /* If this brigade contain EOS, either stop or remove it. */\n        if (APR_BUCKET_IS_EOS(APR_BRIGADE_LAST(bb))) {\n            /* As a shortcut, if this brigade is simply an EOS bucket,\n             * don't send anything down the filter chain.\n             */\n            if (APR_BUCKET_IS_EOS(APR_BRIGADE_FIRST(bb))) {\n                break;\n            }\n\n            /* We can't pass this EOS to the output_filters. */\n            e = APR_BRIGADE_LAST(bb);\n            apr_bucket_delete(e);\n            seen_eos = 1;\n        }\n\n        e = apr_bucket_flush_create(c->bucket_alloc);\n        APR_BRIGADE_INSERT_TAIL(bb, e);\n\n        status = ap_pass_brigade(origin->output_filters, bb);\n        if (status != APR_SUCCESS) {\n            ap_log_error(APLOG_MARK, APLOG_ERR, status, r->server,\n                         'proxy: pass request data failed to %pI (%s)',\n                         p_conn->addr, p_conn->name);\n            return status;\n        }\n        apr_brigade_cleanup(bb);\n    } while (!seen_eos);\n
15859	Jan Kratochvil	1101472223000	You do not need to code it as httpd-2.1 has it already fixed.\nI also backported it in the patch of Bug 31454 which was apparently a DUPE, you\ncan repost the patch here if you wish.\nI am using my patch on my server for: Fedora Core 3 httpd-2.0.52-3.1\n
15859	Jeff Trawick	1105127270000	I've been working on some improvements to the current solution in Apache 2.1.  A\nbackport of my current 2.0 code is in a patch at\nhttp://www.apache.org/~trawick/20proxyreqbody.txt\nThe version of this for Apache 2.1-dev is in the proxy-reqbody branch in subversion.\n.\nAny comments or additional testing would be appreciated.\n
15859	Jan Kratochvil	1107368284000	The current version of http://www.apache.org/~trawick/20proxyreqbody.txt\nsuccessfully tested on SonyEricsson P900 (sorry for the response time as I do\nnot have the device available). <bite>Patch version-name change on its content\nchange would be preferred.</bite>\n
15859	Jeff Trawick	1107371609000	>Patch version-name change on its content change would be preferred.\n\ngood idea for the future...\n\nand thanks for the test report!  I assume that some type of upload from the\nphone would not work through mod_proxy without this patch????
15859	Jan Kratochvil	1107372720000	SonyEricsson P900 uses buzzword WAP-2.0 which no longer transfers WAP/WML over\nWSP/WTP protocols but it started using HTTP/TCP. P900 will interpret WAP-1.x WAP\ngateway settings sent over SMS as HTTP proxy for its WAP-2.0 (IMO incorrectly).\nDuring MMS send operation P900 will send chunked POST, current mod_proxy will\ndechunk it but it will not fill in the Content-Length making the final head+body\nPOST request combo invalid. See (I could no longer find the TCP snaps):\nhttp://marc.theaimsgroup.com/?l=apache-httpd-dev&m=109186315924289\n
15859	Jeff Trawick	1116687273000	fix committed to 2.0.next
15859	Co-Advisor	1117842530000	Created an attachment (id=15295)\nfresh test trace\n\nSorry, but the current http://www.apache.org/~trawick/20proxyreqbody.txt\nfix does not solve the problem. Patched Apache httpd-2.0.54 is still\nsending\n    Content-Length: 15\nwhen the [dechunked] content is actually 20 bytes. \nPlease see the attached fresh trace.\nAre we testing with the wrong fix?\n
15859	Co-Advisor	1117842645000	I am taking the liberty of reopening this bug\nbecause the test case still fails (see above).\n
15859	Jeff Trawick	1117846008000	btw, the proxy-reqbody patch did not affect the response processing...\n\nany idea what is required to have the origin server send both Content-Length\n*and*  Transfer-Encoding?\n
15859	Joe Orton	1117882534000	Sending both would violate 2616, if the proxy receives a message with both C-L\nand T-E it MUST ignore the C-L header per comment 3.
15859	Jan Kratochvil	1125072476000	Created an attachment (id=16218)\nsecurity fix for C-L vs T-E handling (Joe Orton, CVE CAN-2005-2088)\n\nJust FYI Joe Orton fixed: Fedora Core Bug:\nhttps://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=162245\n, the same as Red Hat Enterprise Bug:\nhttps://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=162244\nbut unfortunately these patches will disable the funtionality of:\nhttp://www.apache.org/~trawick/20proxyreqbody.txt\nas presented here in Comment #17 .\nReverting its first part restores 20proxyreqbody.txt back as WORKSFORME,\nNot sure if its second part resolves the issue of Comment #17 .\n
15859	Nick Kew	1185905974000	Is this still open?  It appears to be fixed in trunk at least.
15859	Nick Kew	1188648756000	OK, tested in 2.2.5; the proxy removes the Content-Length.
15993	Will Rowe	1042306388000	\n  This may be trivial.  If you  Alias /foo c:/somepath/foo  the request /foo\n  will map to c:/somepath/foo, but if you  Alias /foo/ c:/somepath/foo/  \n  (or you have unbalanced trailing slashes - that is, if the virtual path has\n  a trailing slash the target path must have one as well...) then the request\n  /foo  (or a request to map the url to that path) will fail because that\n  alias '/foo/' can't evaluate the shorter path '/foo'.\n\n
15993	Detlev Vendt	1042315343000	Thanks to Will Rowe for that hint - it works so far. A little ugly behaviour is \nstill there: mod_isapi puts a trailing backslash to the end of the path. With\n\n    ScriptAlias /foo/ 'c:/myfiles/foo/'\n\nmod_isapi returns the translation\n\n    c:/myfiles/foo//\n\nTo substitute all slashes by backslashes will be a completely correct behaviour \nwith Win32 - including to avoid a double backslash at the end. 
15993	Will Rowe	1042739472000	\n  Note that the trailing backslash is due to the fact that there wasn't a trailing\n  backslash already.  Correcting the path to backslashes first will assure that\n  doubled-trailing slashes don't occur.\n
15993	Will Rowe	1150964891000	\n  Think that we've squished this in commit 416291, but it will still not\n  backslash format the filename string.\n\n  Commit 416294 changes the order a bit, appends the slash first only if\n  it's needed, and then normalizes Win32 paths to backslash.  However,\n  it's platform neutral and will not normalize the path on Unix etc.\n\n  We also pay more attention to the fact that PATH_INFO is the rest of\n  the file path that didn't corespond to a disk file, and append it.\n
15993	Will Rowe	1150964987000	Whoops, closing.  See\n\nhttp://svn.apache.org/viewvc/httpd/httpd/trunk/modules/arch/win32/mod_isapi.c\n\nto obtain the source
15993	Matt Lewandowsky	1152105132000	Will Rowe has posted a zipfile containing compiled mod_isapi modules which\ninclude the patch correcting this bug (for use with 2.0.58 and 2.2.2), for\ntesting purposes. It is available at:\n\nhttp://people.apache.org/~wrowe/mod_isapi-416293.zip\n\nYou may read his full email to the dev@httpd.apache.org list here:\n\nhttp://marc.theaimsgroup.com/?l=apache-httpd-dev&m=115206683718140&w=2\n\nIf you test this version of mod_isapi, please post your feedback to the\ndev@httpd.apache.org list. Your feedback will help ensure that there are no\nregressions or other issues in this version of mod_isapi.
16046	Jeff Trawick	1042649671000	A memory leak was fixed after 2.0.43.  Please download the latest mod_deflate\n(from http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/filters/mod_deflate.c)\nor wait for 2.0.44, then report back.\n\nThanks!\n
16046	Dmitri Dmitrienko	1042660845000	I've checked.\nYes indeed the bug went away.\n\nBut please don't close it immediately. By learning sources I see that there \nare some conditions when some additional leaks may occur again.\nmod_deflate does not always make a paired call to inflateEnd() after \ninflateInit2() was called. It make a big concern that the leak can be \nreproduced with for example a trimmed compressed part.\nRemember that after inflateInit2() was called zlib may allocate up to \n256kb of memory and releases all in inflateEnd() only.\n
16046	Dmitri Dmitrienko	1042664102000	I checked with a 'trimmed' (e.g. wrong) compressed request.\nAs expected Apache gets HTTP/1.1 400. But as predicted a memory leak occurs \ntoo. Approx. 48kB for a request.\n\nConditions: mod_deflate mod_dav mod_dav_fs installed.\nPROPFIND request made with Content-encoding: gzip and content is too short \n(trimmed) for example just 11 bytes. Gzipped content can never be less than 18 \nbytes:\n\n#####Headers:\n\nPROPFIND / HTTP/1.1\nContent-Encoding: gzip\nContent-Type: text/xml; charset='utf-8'\nContent-Length: 11\nHost: localhost:801\nAccept: text/html, */*\nAccept-Encoding: gzip\nUser-Agent: Mozilla/3.0 (compatible; DD Library)\nDepth: 1\n\n#####Content - gzipped but trimmed, hex dump\n0x1F 0x8B 0x08 0x00 0x00 0x00 0x00 0x00 0x00 0x0B 0xB3 \n\n\nMy investigation showed that a call to inflateEnd() is missed. Occurs when \nconditions above are met.\n
16046	Justin Erenkrantz	1045457344000	Should be fixed in modules/filters/mod_deflate.c r1.30\n\nThanks for using Apache HTTP Server!
16134	Dmitri Dmitrienko	1042662956000	Once again the proposed patch agains the most recent version of mod_deflate.c:\n\n--- mod_deflate.c~\t2003-01-03 02:12:36.000000000 +0300\n+++ mod_deflate.c\t2003-01-15 23:31:04.000000000 +0300\n@@ -557,7 +557,7 @@\n     int zRC;\n     apr_status_t rv;\n     deflate_filter_config *c;\n-\n+\n     /* just get out of the way of things we don't want. */\n     if (mode != AP_MODE_READBYTES) {\n         return ap_get_brigade(f->next, bb, mode, block, readbytes);\n@@ -655,6 +655,15 @@\n             return rv;\n         }\n \n+\t\tif (APR_BUCKET_IS_EOS(APR_BRIGADE_FIRST(ctx->bb))) {\n+\t\t\tapr_bucket *eos;\n+\n+\t\t\tapr_brigade_cleanup(ctx->bb);\n+\t\t\teos = apr_bucket_eos_create(f->c->bucket_alloc);\n+\t\t\tAPR_BRIGADE_INSERT_TAIL(bb, eos); \n+\t\t\treturn APR_SUCCESS;\n+\t\t}\n+\n         APR_BRIGADE_FOREACH(bkt, ctx->bb) {\n             const char *data;\n             apr_size_t len;\n
16134	Justin Erenkrantz	1045462590000	Changed how ap_xml_parse_input works in server/util_xml.c r1.22 so that it realizes when EOS is sent.  I've proposed this to be backported to the next stable release.\n\nThanks for using Apache HTTP Server!
16261	Graham Leggett	1043219573000	Docs updated to v2.0.45-dev and v2.1.0-dev.
16313	Cliff Woolley	1043209164000	 aawwwww mannnnnnnnnn.  :(  That would be my fault.  Sheesh.  I'll look into  it.  Thanks for the report and the backtrace! 
16313	Cliff Woolley	1043214623000	Try the patch given in  \nhttp://marc.theaimsgroup.com/?l=apache-httpd-dev&m=104321419500550&w=2 and see \nif that fixes it for you.  Assuming it stops crashing, try some server restarts \nand make sure you don't get any memory or file descriptor leaks. \n \nThanks, \nCliff 
16313	John Kearns	1043277789000	Tried the patch...it works just fine.\nOut of interest though, instead of (or also with) deleting the section of code \nthat calls the APR_RING_REMOVE define, why not just add error-checking into the \nAPR_RING_UNSPLICE define with a couple of 'if' statements in apr_ring.h?\nExample:\n\n#define APR_RING_UNSPLICE(ep1, epN, link) do {                          /\n        if (APR_RING_PREV((ep1), link))                                 /\n                APR_RING_NEXT(APR_RING_PREV((ep1), link), link) =       /\n                        APR_RING_NEXT((epN), link);                     /\n        if (APR_RING_NEXT((epN), link))                                 /\n                APR_RING_PREV(APR_RING_NEXT((epN), link), link) =       /\n                        APR_RING_PREV((ep1), link);                     /\n   } while (0)\n\nI tested this modification with the original mod_file_cache.c and it seems to \nwork as well.  Although, truth be told, I'm not entirely sure how to find out \nif it has memory or fd leaks (I program mainly on win32...unix still mystifies \nme at times!)  The only reason I'd suggest this is to keep this same problem \nhappening in potential future modules that register a cleanup call for a \nsimular list.\n\nThanks-\nDrew\n
16313	Cliff Woolley	1043279511000	It's a design decision we made through all of APR: we don't test for NULL.  If it's NULL, that's a bug, and it will cause a segfault.  If it segfaults, that's good, because it lets us find the bug very easily.  Another concern is that code with no bugs will never have those pointers be NULL, so non-buggy code would be paying a performance penalty just to accommodate buggy code.  Thanks for testing the patch.  I'll look for leaks myself.  --Cliff 
16313	John Kearns	1043282410000	Heh..makes sense!  Thanks for quick fix on this.\nLooking forward to the next release!\n-Drew
16368	Will Rowe	1043344729000	\n  This is a bug, in that the Apache 2.0 hook mechanisms were designed to be\n  independent of LoadModule order.  That said, we are sure to find a few edge\n  cases like the one you've identified.\n\n  Thanks for the report!\n
16368	Andr?? Malo	1044489440000	hmm, it looks like the fixup hooks of mod_rewrite and mod_proxy create the\nproblem (both HOOK_FIRST).\n\nfirst case:\nmod_rewrite runs first: create r->filename=proxy:http://foo/bar?baz\nmod_proxy runs afterwards: enode that url and append query (again):\nhttp://foo/bar%3Fbaz?baz\n-> proxy handler runs with the result\n\nsecond case:\nmod_proxy fixup runs empty (no proxy request)\nmod_rewrite creates r->filename=proxy:http://foo/bar?baz\n-> proxy handler runs with the result.\n\nWe can solve this for now by hooking mod_proxy fixup explicitely before\nmod_rewrite. But AFAICS we need some further research to handle all the proxy\nstuff more clean.\n\nOpinions?
16368	Andr?? Malo	1045602082000	Been there, done that.\nIt's fixed in HEAD (2.1) and proposed for backport.\n\nThanks for using Apache!
16368	Andr?? Malo	1045945930000	The fix will appear in the next release (2.0.45).
16452	Justin Erenkrantz	1043817360000	Fixed in modules/dav/main/util.c r1.43 of httpd-2.0.  We will now skip all lock tokens that are denoted as invalid format.\n\nThis patch has been suggested for inclusion in the next httpd 2.0 release.\n\nThanks for using Apache HTTP Server!
16533	Cliff Woolley	1043863748000	Ouch!!!!  Yes that's a very big bug.  void* killed me on that one.  :-/  Thanks for the great catch \nand for the patch!  It's now committed to 2.1.0-dev and will be suggested for inclusion in \n2.0.45. \n \n--Cliff 
16637	Will Rowe	1046285683000	\n  Actually, there was a small logic error related to the way that some\n  calls were processed in send_response_header.  We believe the new code\n  is cleaner, but it may or may not resolve your issue altogether.\n\n  If you are building Apache yourself, please replace your mod_isapi.c module\n  with the current CVS available from;\n\nhttp://cvs.apache.org/viewcvs.cgi/*checkout*/httpd-2.0/modules/arch/win32/mod_isapi.c?rev=1.88.2.2\n\n  And let us know if the error remains.  I suspect it does.\n\n  One thing you mention is that we call from ServerSupportFunction() ... in\n  fact we have several potential calls from that code - please identify which\n  call to ServerSupportFunction is't working.\n\n  I guess that sending any body, whatsoever should toggle cid->headers_set to\n  1 so that everything else works.\n\n  Let me make certain; are you trying to send a response 200 OK with *no*\n  headers, *AND* no body?\n
16637	Will Rowe	1150958817000	\n  Closed 30033, presuming fixed in trunk.\n
16637	Matt Lewandowsky	1152105039000	Will Rowe has posted a zipfile containing compiled mod_isapi modules which\ninclude the patch correcting this bug (for use with 2.0.58 and 2.2.2), for\ntesting purposes. It is available at:\n\nhttp://people.apache.org/~wrowe/mod_isapi-416293.zip\n\nYou may read his full email to the dev@httpd.apache.org list here:\n\nhttp://marc.theaimsgroup.com/?l=apache-httpd-dev&m=115206683718140&w=2\n\nIf you test this version of mod_isapi, please post your feedback to the\ndev@httpd.apache.org list. Your feedback will help ensure that there are no\nregressions or other issues in this version of mod_isapi.
16637	Will Rowe	1153246014000	*** Bug 40067 has been marked as a duplicate of this bug. ***
16656	Erik Abele	1044200294000	Fixed, thanks for reporting the issue and using Apache 2.0!
16661	Manni Wood	1044058962000	Created an attachment (id=4674)\npatch for spot_cookie() bug in mod_usertrack\n
16661	Cliff Woolley	1064356675000	*** Bug 11998 has been marked as a duplicate of this bug. ***
16661	Cliff Woolley	1064356695000	*** Bug 16662 has been marked as a duplicate of this bug. ***
16661	Cliff Woolley	1064356740000	Fixed in 2.1.0-dev, thanks Manni.  Backports to 2.0-dev and 1.3-dev will be \nproposed. 
16739	Laurent Faillie	1044399292000	According to 'netstat', it seems Apache2 only listening IPv6 networks on my\nsystem. I will try to add option '--enable-v4-mapped'.\n\nAnyway, as the documentation said 'Listen w/o network make apache waiting for\nall network', it should implie both v4 and v6 by default.
16739	Laurent Faillie	1044486049000	Using '--enable-v4-mapped', I can now connect to the machine ... but no data is\nsent :-(\n\ntelnet ra 8085\nTrying 192.168.0.3...\nConnected to ra.chez.moi.\nEscape character is '^]'.\nGET /\nConnection closed by foreign host.\n\nAny help welcome ;-D\n\nBye\n\nLaurent\n
16739	Laurent Faillie	1044487038000	Well, I found a workaround in the database : as for bug #7492 of the 'old\ndatabase', I have added a 'Listen 0.0.0.0:8085'. Now it's working :-)\n\nI keep this bug open, because I think a problem remains : ok, using\n--enable-v4-mapped, IPv4 networks is checked, but w/o this second Listen\ndirective, the server won't return correct page but only close the connection.\n\nBye\n\nLaurent\n
16739	Jeff Trawick	1044495369000	Here is what is supposed to happen with recent Apache:\n\nFor any version of netbsd with IPv6, apache \n1) assumes v4-mapped addresses can't/shouldn't be used (i.e., assumes   \n--disable-v4-mapped)\n2) puts two listen statements in default config file:\n   Listen 0.0.0.0:port\n   Listen [::]:port\n\n   (note that if you have old config file the one with the 'right' listen   \nstatements will be httpd-std.conf)\n\nAlso, when Apache doesn't plan to use v4-mapped addresses, it will enable the\nIPV6_V6ONLY socket option if it exists.\n\nThe documentation needs to talk about --enable-v4-mapped vs. --disable-v4-mapped\nand what Listen statement(s) is(are) needed in either case.\n\nAs far as the weird error scenario (--enable-v4-mapped, 'Listen 8085', whatever\nis listening on port 8085 drops the connect):\nIs there truss or strace that you can use on Apache for this case to give an\nidea of what is happening?\n 
16739	Laurent Faillie	1044890832000	Hum, netstat -a doesn't help (apache listening on both ipv4 and v6 worlds, so \nnothing abnormal).\n\nI duno which other tests I can made to have more informations but add some \ntracing 'printf()' inside Apache code. But ... where can I start ? I'm not fully \naware of 'deep inside' stuffs in Apache code.\nAnyway, I will try.\n\nIf someone want to make some checks or tests, I can give a temporary access to \nthis machine. A slow machine but w/ a permanent connection to the web thru \ncable.\n\nBye\n\nLaurent\n\nPS: hum, what do you think about adding NetBSD as target OS in your side ? ;-D
16739	Jeff Trawick	1045231927000	I'm changing this to a doc problem.\n\nI was able to verify that on NetBSD 1.6, the --enable-v4-mapped and\n--disable-v4-mapped configure options work properly and generate\nthe proper Listen directives in the default configuration file.\nBut the documentation was woefully inadequate for this issue,\nso it could not be expected that users who ignore the default\nconfiguration file would automatically arrive at the right set\nof Listen directives.\n\nBetter doc for this has now been added to the manual in this \nsection:\n\nhttp://httpd.apache.org/docs-2.0/bind.html#ipv6
16812	Matthieu Estrade	1057326144000	Created an attachment (id=7101)\nReplace strncmp with strncasecmp\n
16812	Matthieu Estrade	1057326324000	The patch i sent should fix the problem, i just replaced the compare function\nwith a case insensitive one.\n\nMatthieu
16812	Jeff Trawick	1069452902000	enabling the PatchAvailable keyword\nupdated doc on submitting patches is at http://httpd.apache.org/dev/patches.html\n
16812	Nick Kew	1088491797000	Fix committed in HEAD (cf bug 10722)
16813	Justin Erenkrantz	1045465711000	Yup, this is a major annoyance.  I've committed a fix to the tree for this problem, but it can't be backported to 2.0 because it changes a function signature.\n\nhttpd-2.0: include/http_config.h: r1.99, server/config.c: r.1.164, server/main.c: r1.143\n\nThanks for using Apache HTTP Server!
16908	Andrew Gapon	1044736153000	Created an attachment (id=4791)\nproposed patch\n
16908	Andrew Gapon	1044736215000	How-To-Repeat\n\n1. enable mod_mime_magic in apache\n2. set DefaultType to anything but text/plain\n3. create a file that is not of any known type and does not have any known \nextension, (in my case it was export of Windows2000 security console settings -\n*.msc file)\n4. make the file accessible via apache via http\n5. get the file from http client\n6. observe that apache returns content type as text/plain\n\n\n
16908	Justin Erenkrantz	1045634454000	This has been fixed in httpd-2.0: modules/metadata/mod_mime_magic.c r1.61.\n\nI'm not entirely sure this will be backported to 1.3 or 2.0.  It could be, but this is esoteric enough that I think it can wait until 2.2.
16984	Andr?? Malo	1045056060000	It's silently assumed, that people use 'suexec-umask=022'. However, changed\nconfigure to always prepend a '0' as 2.x configure does, too.\n\nThanks for the report and thanks for using Apache!
17006	Erik Abele	1045169872000	Right, this is fixed now in all versions. Thanks for the report and thanks for\nusing Apache!\n\nErik
17073	Andr?? Malo	1045231695000	Fixed.\n\nThanks for your care and thanks for using Apache!
17093	Andr?? Malo	1045277268000	ouch. reproduced.\nIt happens only if it appears in an external file.\n\nwill look at it ...
17093	Andr?? Malo	1045314195000	Well, this was a typical NULL pointer kaboom :)\nFixed in 2.1 and proposed for backport, so it will hopefully go into 2.0.45.\n\nThanks for you report and thanks for using Apache!
17093	Andr?? Malo	1046319088000	FYI: The fix will be in the next release (2.0.45).
17093	Andr?? Malo	1063895058000	*** Bug 23247 has been marked as a duplicate of this bug. ***
17108	Jeff Trawick	1045618865000	patch applied to 2.1-dev and 2.0.45-dev\n\nthanks!\n
17135	Andr?? Malo	1052181349000	yeah, it's looking for a space. will fix.\n\nThanks for your report and thanks for using Apache.
17135	Andr?? Malo	1052867492000	FYI: The fix has been merged into the stable tree and will be in the next\nrelease (2.0.46).
17206	Christian Kratzer	1045827134000	Created an attachment (id=4966)\ndisables inheriting of access and error logs\n
17206	Christian Kratzer	1045828952000	Apache httpd fails to close access and error logs when it forks and \nexecs cgi scripts.  From our preliminary understanding of the code\nthe fix is to call apr_file_inherit_unset() in place of \napr_file_inherit_set() in both server/log.c and loggers/mod_log_config.c.\n\nThe bug first appeared going from 2.0.39 to 2.0.40 because a typo in the\ndefinition of the APR_INHERIT flag had reversed the effect of\napr_file_inherit_set().  For this please see cvs diff of\n/apr/include/arch/unix/Attic/inherit.h between 1.10 and 1.11.\n\nThe attached patch forces cleanup of logfiles on fork/exec of cgi's.\n\nAll calls of *_inherit_set() and *_inherit_unset() should be validated \nfor correct behavior in their respective contexts.\n\nCredit for digging through the sources and finding the fix goes\nBjoern Zeeb <bzeeb@zabbadoz.net>.\n\nIn case of questions we have more detailed information available.\nPlease email.\n\n\n\n
17206	Bjoern A. Zeeb	1045950631000	the fix does not help with all mpms.\nPeople who need to know more got 2nd mail.
17206	Bjoern A. Zeeb	1047021287000	further public discussions on patches are here\n(apr) http://marc.theaimsgroup.com/?t=104688218100008&r=1&w=2\nand here\n(httpd) http://marc.theaimsgroup.com/?t=104696493400002&r=1&w=2\n\nAlso pointed wrowe to his commit\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/log.c.diff?r1=1.94&r2=1.95&di\nff_format=h\n
17206	Will Rowe	1048198120000	\n  Thanks to you, Christian, Bjoern and Joe I believe we have this licked.\n  Fixes are applied to the forthcoming 2.0.45 release and the 2.1.0-dev tree.\n
17206	Bjoern A. Zeeb	1049314771000	Many thanks back to you, William Rowe, for your great work\nsolving even more problems in apr/httpd related to this. Thanks.
17217	Jeff Trawick	1045962193000	The only code that references SSL_CTX_set_tmp_rsa_callback was added before\n2.0.43.  Perhaps you have a version of openssl in your library path now that\ndoesn't implement that function?\n\nMaybe openssl isn't found at all and that is simply the first function that\ncouldn't be resolved?\n\nJust maybe you didn't specify --enable-ssl on your configure invocation for\n2.0.44 and so httpd executable didn't reference the openssl library?  In this\ncase, the mod_ssl.so you're trying to use could be from a previous build of 2.0.43.\n\n?????\n
17217	Aaron Axelsen	1046021008000	the only way i could get it to work was to recomiple it with --enable-\nssl=static.  It fails to load as a loadable module.
17217	Jeff Trawick	1046092276000	That would be consistent with your openssl library being built as a static\nlibrary instead of as a dynamic library.\n
17217	Aaron Axelsen	1046095371000	Even if it was static and noy dynamic, how come it worked with only --enable-\nssl in 2.0.43 and i had to do --enable-ssl=static in 2.0.44?
17217	askme	1051207876000	You need to post exactly how you build apache and openssl, this could mean any \nnumber of things. And how you start Apache.
17217	Joe Orton	1069795512000	To state the issue concisely:\n\nIf building mod_ssl as a DSO against static OpenSSL libraries, mod_ssl will not\nload.  This is because the only place that symbols from the SSL libraries are\nreferenced is mod_ssl, but only httpd itself is linked against -lssl -lcrypto.\n\nThe workaround is to use shared OpenSSL libraries or a statically-linked mod_ssl.
17217	Joe Orton	1069795539000	*** Bug 22057 has been marked as a duplicate of this bug. ***
17217	Joe Orton	1078942071000	Fixed on HEAD, probably worthy of backport.
17236	Andr?? Malo	1045743470000	.htaccess files are well documented here: <http://httpd.apache.org/docs-\n2.0/configuring.html>.\n\nThe use of comments within AuthUserfile/AuthGroupfile isn't really recommended, \nso I tend to say 'wontfix' here.\n
17236	Ralf Hauser	1045746582000	Thanks for the hint.\n\nHow about putting a link to\nhttp://httpd.apache.org/docs-2.0/configuring.html#syntax in the htaccess file ?\n(after all we are no longer in the paper world of sequential reading, but\nhypertext and search engines are typically used today, so a user may just see\nthe htaccess file, but not all the rest of the documentation.)\n\nAs for the other two, what do you mean with 'not really recommended'? \nI would guess it is good practice to put such files under version control and\nthus  a comment with at least the version control tag would be recommended too?\nDoes it work or will it break something? I.e. s the Group file a configuration\nfile as per \nhttp://httpd.apache.org/docs-2.0/configuring.html where \nhttp://httpd.apache.org/docs-2.0/configuring.html#syntax applies or not?
17236	Joshua Slive	1080056705000	An appropriate link has been added.\n\nThanks for the suggestion.
17274	till toenges	1045825123000	i have exactly the same problem with openldap 2.0.25, apache 2.0.44 and freebsd 4.7. the quick fix solved the problem for me. i agree that the problem seems to be that the module assumes that the session can be used for authentication attempts again, which is not be permitted by the ldap servers access control.
17274	Marte Castro	1051743023000	I have the same problem, I'm using:\nhttpd-2.0.44 against ms active directory (ms w2k)\n
17274	Jeff Trawick	1069435321000	I'm going through the bug db to make sure patches are findable.  Please see \nhttp://httpd.apache.org/dev/patches.html\n
17274	John Coonrod	1080307860000	I have this problem in my production mandrake 9.2 server, and would love to just\nget a fixed binary - is this being fixed in the actual binaries, or will this\njust continue to be a sourcecode patch?
17274	Stephen Duncan Jr	1081172526000	Seeing this on Windows 200 SP4 Active Directory, using Apache HTTP Server 2.0.49\non Windows.  \n\nWhen incorrect password is input, error log logs:\n\n[*date*] [warn] [client *ipaddress*] [832] auth_ldap authenticate: user\n*username* authentication failed; URI *uri* [ldap_simple_bind_s() to check user\ncredentials failed][Invalid Credentials]\n\nSubsequent attempt to login with correct password cause this error in the logs:\n\n[*date] [warn] [client *ipaddress*] [832] auth_ldap authenticate: user\n*username* authentication failed; URI *uri* [User not found][No Such Object]
17274	Graham Leggett	1085094101000	Please try the patch at http://nagoya.apache.org/bugzilla/show_bug.cgi?id=27748\nand tell me if it fixes this problem. This patch has been applied to v2.1.0-dev,\nand awaits backporting to v2.0.50-dev.\n
17274	Laurent Blume	1085152531000	I applied the patch to 2.0.49, built it with similar options.\nIt now authenticates correctly against the AD server, even when entering invalid\nlogin/password combinations first.\n\nSo it seems to fix the problem for me.
17274	Graham Leggett	1085157360000	Sweet, thanks :)
17274	joshua@idx.com.au	1107933308000	Does 2.0.53 fix this problem?? \nI was using 2.0.47 and it has the same problem...\n\nI couldnt change the source,\n\nfrom:\n<     util_ldap_connection_close(ldc);\n\nto\n>     util_ldap_connection_destroy(ldc);\n\n\n It would give compile errors\n\n\n\n\nthanks\n\nJoshua
17274	Graham Leggett	1118665133000	This was fixed in v2.0.51 - can you confirm whether this is still broken, and\nreopen if so?
17433	Erik Abele	1046370690000	This is fixed now and will show up in the next release (2.0.45).\nThanks for reporting the issue.
17462	Andr?? Malo	1046345228000	he, you'll need a better system that finishs this endless loop under one minute ;-)\n\nIt's a known issue. You're simply creating an endless loop of internal\nredirects. Thatswhy you already should test your rules before putting them on a\nproduction server.\n\nHowever, I'm changing this to an Enhancement request. We should be able to set a\nconfigurable limit of maximum redirects issued by mod_rewrite.\n\nThanks for using Apache!
17462	Dario Gomes	1046353445000	The problem is I run a shared hosting server, and I have no control of the \nrules my users put on their sites... I got the server locked up two times \nbefore I found the source of the problem!\n\nWhy doesn't this bug affect Apache 2.0.4x? Maybe they've worked out this issue \nalready?\n\n-Dario
17462	Andr?? Malo	1046550737000	In 2.0 the trick doesn't work with your ruleset, because of a different\nbehaviour of mod_dir. You can crash the server, for example, with the following\nin a htaccess file (in docroot):\n\nRewriteEngine On\nRewriteBase /\nRewriteRule (.*) / [L]\n\nHowever, a configurable limit was introduced in 2.1 and is proposed for backport.
17462	Andr?? Malo	1048089136000	FYI: The enhancement will appear in the next releases (1.3.28 and 2.0.45).
17564	Andr?? Malo	1047147386000	I'm not sure whether I fully understand your report.\nWhy should we parse wrong numbers with commas in it?\n\n...err, I think, I start to understand. The atof function is dependent on some\nlocale settings?
17564	Maxim Zakharov	1047149020000	In some locales (include russian), comma is used as decimal point separator.\nThus atof function under such locales is false to parse right variant weight\nwith dot as desimal point separator.
17564	Andr?? Malo	1047342505000	Well, I've fixed the problem by dropping atof() entirely (and writing our own\nmore RFC compliant version).\nThe fix currently applies to version 2.1 (main dev branch) and is proposed for\nbackport.\n\nThanks for your report and thanks for using Apache!
17564	Andr?? Malo	1052787321000	*** Bug 9427 has been marked as a duplicate of this bug. ***
17564	Joshua Slive	1053799595000	Sounds fixed to me.
17719	Ralph Giles	1053128292000	As an update, our rfc's have been released. Please see\nhttp://ietf.org/rfc/rfc3534.txt or a description of the application/ogg mimetype. \n\nhttp://ietf.org/rfc/rfc3533.txt documents the ogg file format itself.
17719	Ralph Giles	1056185648000	It's been three months with absolutely no response on this issue. What's the\nhold up? Please let me know if there's anything more that we need to do to\nsupport the inclusion.\n\nBased on the discussion around bug 20440, I don't see that there can be. After\nall, we *did* jump through the hoops and obtained an official IANA mime-type.
17719	Erik Abele	1057699932000	This is now fixed in CVS and will be in the 2.0.48 release. Sorry for the delay and thanks for using \nApache.
17720	Dylan Neild	1048575285000	Created an attachment (id=5488)\nPatched for mime.types to add application/ogg mime type.\n
17720	Ralph Giles	1053128338000	As an update, our rfc's have been released. Please see\nhttp://ietf.org/rfc/rfc3534.txt or a description of the application/ogg mimetype. \n\nhttp://ietf.org/rfc/rfc3533.txt documents the ogg file format itself.
17720	Ralph Giles	1056185695000	It's been three months with absolutely no response on this issue. What's the\nhold up? Please let me know if there's anything more that we need to do to\nsupport the inclusion.
17720	Erik Abele	1057699902000	This is now fixed in CVS and will be in the 2.0.48 release. Sorry for the massive delay and thanks \nfor using Apache.
17797	Andr?? Malo	1047081836000	In fact mod_deflate should not ignore that header...\n\n...oh well, content-encoding from CGI is put into err_headers_out, we should\ncheck for these in mod_deflate, too.\n\nThanks for your report.
17797	Andr?? Malo	1049462032000	FYI: Fixed for the next release (2.0.46).
17864	Madhusudan Mathihalli	1047450775000	Thanks for pointing it out. I've committed the changes to HEAD.\n\n-Madhu
18025	Jeff Trawick	1047725309000	insufficient information
18025	Andr?? Malo	1048365476000	Ah yeah, our type map is broken (last two entries).\nThe charset is not correct, too.
18025	Andr?? Malo	1052865016000	Fixed for the next release.
18101	Andr?? Malo	1048027941000	'will not start' isn't a helpful description for the error. What happens exactly\nand what error messages will occur?\n\nThanks.
18101	Francois Genolini	1048066225000	'Will not start' is not supposed to be helpful: it is an accurate description!\n\nHEre are the steps:\n\n1) start the apache service monitor.\n\n2) Edit the apache httpd.conf file\n\n3) Modify the ServerRoot as described\n\n4) click the 'Restart' button on the Apache Service Monitor\n\n5) a popup window is displayed, saying:\nError\nThe requested operation has failed!\n\nThe Apache error log has nothing related to this error\n\nTherefore my original description was accurate and complete\n\nQED
18101	Andr?? Malo	1048066965000	Maybe accurate, but not helpful anyway ;-)\n\nHowever, please do the following:\n- open your console and cd to the apache2-bin directory\n- type apache -k start\n\nAn error message should be written to the console. This message usually appears\nto be helpful :)\n\n(Btw: Are you sure, you want to modify ServerRoot and not DocumentRoot?)\n\nThanks.
18101	Andr?? Malo	1048067551000	ehm, instead of apache -k start, I meant to say apache -k restart.
18101	Francois Genolini	1048067591000	Thanks for your help.\n\nHere is the error message:\n\nSyntax error on line 13 of C:/Program Files/Apache Group/Apache2/conf/httpd.conf\n:\nCannot load C:/MyWeb/Web/modules/mod_access.so into server: The specified module\n could not be found.\n\nI have copied the modules directory and Apache starts.\n\nRationale for modifying ServerRoot:\nThe documentation for Apache says that ServerRoot is used to determine the base \ndirectory for log files and configuration files.\nIt never mentioned that it was also used as the base directory for binaries, \nshared libraries and modules.\n\nMaybe the docs need to be updated; but I would rather think this is a coding \nerror.\nI would assume that when Apache starts, it remembers where it starts from: the \neveidence for this is that Apache knows where to find the httpd.conf file \n(located in ../conf).\nTherefore there should be no problem in accessing the modules in ../modules, \nregardless of the setting for ServerRoot.\n\nI believe that this used to be the behaviour before (2.0.39 I seem to remember).\nThe code has benn modified wrongly, I would think (at least not in keeping with \nthe published specs as described in the docs).
18101	Francois Genolini	1048067617000	Thanks for your help.\n\nHere is the error message:\n\nSyntax error on line 13 of C:/Program Files/Apache Group/Apache2/conf/httpd.conf\n:\nCannot load C:/MyWeb/Web/modules/mod_access.so into server: The specified module\n could not be found.\n\nI have copied the modules directory and Apache starts.\n\nRationale for modifying ServerRoot:\nThe documentation for Apache says that ServerRoot is used to determine the base \ndirectory for log files and configuration files.\nIt never mentioned that it was also used as the base directory for binaries, \nshared libraries and modules.\n\nMaybe the docs need to be updated; but I would rather think this is a coding \nerror.\nI would assume that when Apache starts, it remembers where it starts from: the \neveidence for this is that Apache knows where to find the httpd.conf file \n(located in ../conf).\nTherefore there should be no problem in accessing the modules in ../modules, \nregardless of the setting for ServerRoot.\n\nI believe that this used to be the behaviour before (2.0.39 I seem to remember).\nThe code has benn modified wrongly, I would think (at least not in keeping with \nthe published specs as described in the docs).
18101	Andr?? Malo	1048069005000	Ok, thanks for your update.\n\nThe documentation for Apache says that ServerRoot is _typically_ used to\ndetermine the base directory for log files and configuration files. (we should\nmention modules/ there also, right.)\n\nActually it is used to resolve any relative path (that's what it's supposed to).\nSo if you want to keep your module files in the old path, you have to use\nabsolute paths and everything is fine.\n\nIf it didn't work that way in older versions it must be a bug there ;-).\n\nWhy can't httpd take the location where it starts from? The answer is simple. On\nmost systems (especially *x) there is no reliable way to determine this location.\n\nI'm changing this report to be a docs enhancement.\n\nThanks for using Apache!
18101	Rich Bowen	1101096863000	A minor documentation update has been made to clarify this point. Committed\nrevision 106145. Closing.
18156	Hans	1080679128000	I'm having the exact same problem. Running suexec in the document root is no\nproblem, however, Apache is not sending the '~' to Suexec when a userdir is\naccessed.
18156	Joshua Slive	1080681292000	Are you actually using mod_userdir ONLY to serve these requests, or is there\nsome kind of Alias/ScriptAlias/RewriteRule that is involved?
18156	Hans	1080682765000	I've got some Rewriterules, but they don't apply for the UserDir directive. This\nis my VirtualHost config:\n\n<VirtualHost www.domain.nl:80>\n        SuexecUserGroup username group\n        ServerAdmin emailaddress\n\n        DocumentRoot '/home/sites/site1/web/'\n                <Directory '/home/sites/site1/web'>\n                    Options Indexes FollowSymLinks MultiViews Includes +ExecCGI\n                    AllowOverride All\n                    Order allow,deny\n                    Allow from all\n                </Directory>\n\n        ServerName www.domain.nl\n        ServerAlias *.domain.nl domain.nl\n\n        RewriteEngine On\n        RewriteRule ^/personal/?$       http://www.domain.nl:81 [L,R]\n        RewriteRule ^/siteadmin/?$      http://www.domain.nl:81 [L,R]\n        RewriteRule ^/admin/?$          http://www.domain.nl:81 [L,R]\n        RewriteRule ^/login/?$          http://www.domain.nl:81 [L,R]\n        RewriteRule ^/webmail/?$        http://www.domain.nl:81/webmail/ [L,R]\n        RewriteRule ^/fileman/?$        http://www.domain.nl:81/webmail/ [L,R]\n        RewriteOptions inherit\n        <Directory '/home/sites/site1/users/*/web'>\n            Options Indexes FollowSymLinks MultiViews Includes +ExecCGI\n            AllowOverride All\n            Order allow,deny\n            Allow from all\n        </Directory>\n        ErrorLog /home/sites/site1/logs/error.log\n        CustomLog /home/sites/site1/logs/web.log combined\n</VirtualHost>\n\nIn httpd.conf the following is set:\n\nUserDir web\n\nand my suexec -V output is:\n\n -D AP_DOC_ROOT='/home/sites/'\n -D AP_GID_MIN=100\n -D AP_HTTPD_USER='www'\n -D AP_LOG_EXEC='/usr/local/apache2/logs/suexec_log'\n -D AP_SAFE_PATH='/usr/local/bin:/usr/bin:/bin'\n -D AP_SUEXEC_UMASK=022\n -D AP_UID_MIN=100\n -D AP_USERDIR_SUFFIX='web'\n\n
18156	Florian Effenberger	1081595356000	Anything new regarding this bug? I'm facing EXACTLY the same problem on 2.0.49, \nwhich renders it completely unusable for me. Apache 1 worked fine, it used User \nand Group when no UserDir request was made, and used the correct user when a \nUserDir request was made.\n\nPlease have a look at this soon, it prevents me from using 2.x :-(
18156	Florian Effenberger	1081596200000	Attached is some system information that might be helpful.\n\nMy configure command-line:\n./configure --enable-mods-shared=all --enable-ssl --enable-proxy --enable-suexec \n--with-suexec-caller=nobody --with-suexec-docroot=/home\n\n\nOutput of suexec -V:\n -D AP_DOC_ROOT='/home'\n -D AP_GID_MIN=100\n -D AP_HTTPD_USER='nobody'\n -D AP_LOG_EXEC='/usr/local/apache2/logs/suexec_log'\n -D AP_SAFE_PATH='/usr/local/bin:/usr/bin:/bin'\n -D AP_UID_MIN=100\n -D AP_USERDIR_SUFFIX='public_html'\n\n\nOutput of apachectl -V:\nServer version: Apache/2.0.49\nServer built:   Apr 10 2004 13:17:23\nServer's Module Magic Number: 20020903:7\nArchitecture:   32-bit\nServer compiled with....\n -D APACHE_MPM_DIR='server/mpm/prefork'\n -D APR_HAS_SENDFILE\n -D APR_HAS_MMAP\n -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)\n -D APR_USE_SYSVSEM_SERIALIZE\n -D APR_USE_PTHREAD_SERIALIZE\n -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT\n -D APR_HAS_OTHER_CHILD\n -D AP_HAVE_RELIABLE_PIPED_LOGS\n -D HTTPD_ROOT='/usr/local/apache2'\n -D SUEXEC_BIN='/usr/local/apache2/bin/suexec'\n -D DEFAULT_PIDLOG='logs/httpd.pid'\n -D DEFAULT_SCOREBOARD='logs/apache_runtime_status'\n -D DEFAULT_LOCKFILE='logs/accept.lock'\n -D DEFAULT_ERRORLOG='logs/error_log'\n -D AP_TYPES_CONFIG_FILE='conf/mime.types'\n -D SERVER_CONFIG_FILE='conf/httpd.conf'\n\n\nRelevant settings in httpd.conf:\nUserDir disabled\nUserDir disabled root\n[...]\n<Directory /home/*/public_html>\n     AllowOverride All\n     Options -Indexes MultiViews ExecCGI SymLinksIfOwnerMatch IncludesNoExec\n        Order allow,deny\n        Allow from all\n</Directory>\n[...]\n<Directory /home/sites/*/users/*/public_html>\n    AllowOverride All\n    Options -Indexes MultiViews ExecCGI SymLinksIfOwnerMatch IncludesNoExec\n    Order Deny,Allow\n    Allow from all\n</Directory>\n\n\nRelevant settings in my included virtualhosts.conf:\nNameVirtualHost *:80\n\n<VirtualHost *:80>\nServerName my.main.domain\nUserDir disabled\nUserDir disabled root\nRewriteEngine on\nRewriteOptions inherit\n</VirtualHost>\n[...]\n<VirtualHost *:80>\nServerName www.sub.domain.ofmine\nServerAlias sub.domain.of.mine\nServerAdmin my@root.address\nDocumentRoot /home/sites/s1234/users/u0001/public_html\nUserDir disabled\nUserDir disabled root\nUserDir enabled s1234u0003\n[...some other enabled UserDirs...]\nSuexecUserGroup s1234u0074 s1234\nRewriteEngine on\nRewriteOptions inherit\n[...some RewriteRules...]\n</VirtualHost>
18156	Florian Effenberger	1083095553000	Anything new in here? This one is a really bad one :-(
18156	Andr?? Malo	1083097105000	Perhaps someone could answer to the question regarding the scriptalias directives?\nOr better - attach the *full* config?
18156	Florian Effenberger	1083098575000	I have attached my config. Is there some important part missing? It doesn't work\nwith and without RewriteRules.
18156	Robert Heller	1083099718000	'm guessing this is a variation of the 'bug' (really documentation problem)\nwith suexec + UserDir in Apache 2.0.x.\n\nBasically, you cannot use the 'old style' scriptalias directives with user dirs\nand suexec.\n\nTry this version of your user CGI bin directory setup:\n\n        <Directory ~ '/home/sites/site1/users/*/web'>\n            Options Indexes FollowSymLinks MultiViews Includes +ExecCGI\n            AllowOverride All\n            Order allow,deny\n            Allow from all\n            SetHandler cgi-script\n        </Directory>\n\nOh, you need to include the UserDir and SuExec modulea:\n\nLoadModule userdir_module modules/mod_userdir.so\nLoadModule suexec_module modules/mod_suexec.so\n\nAnd *don't* include any sort of scriptalias for your user's dirs.\n
18156	Florian Effenberger	1083161917000	LoadModule suexec_module modules/mod_suexec.so\nand\nLoadModule userdir_module modules/mod_userdir.so\nare activated in my httpd.conf.\n\nHowever, your solution shown below does not help. :-(\nMay I e-mail you my httpd.conf and my included virtualhosts.conf, so you can\ncheck it? Because of data privacy and security issues, I don't want to attach\nthe full \nconfiguration to this bug.\n\nMay I e-mail it to you privately?\n\nThanks!
18156	Robert Heller	1083163049000	I'm not one of the Apache developers, just a fellow user of suexec.  I\nam not sure how much help I can give you.  I don't presently have an \nApache 2.0.x server installed and running anywhere at present, so I \ncannot actually test anything either.  All I know is that  \n\nIt is entirely possible that it is a real bug.\n\nMaybe what you need to post is a stripped down version of your \nhttpd.conf and virtualhosts.conf files, ones that are minimually \nsuffientent to cause the problem, but which don't leak any real \n(priviledged) data -- this way the developers can re-create your problem     \nand then come up with a working solution. 
18156	Florian Effenberger	1083168501000	Hi there, and thanks for the quick reply ;-)\nIf any of the developers could post to this bug (I haven't heard anything from\nthem yet ;-( I'd happily provide them with my httpd.conf ;)
18156	Joshua Slive	1083169359000	Here's what you should do:\nStart with a default install of apache from httpd.apache.org, and then make the\nabsolute minimum changes that are necessary to show the problem.  Then give us a\nlist of the changes.
18156	Florian Effenberger	1083247490000	Here it comes ;-)\n\n\nSystem installed on:\n\nDebian GNU/Linux Sarge x86\n\n\nNon-FQDN hostname of the system tested on: floeff3.effenberger (sometimes\nmentioned in the configuration file)\n\n\nApache source code used:\n\nhttp://www.artfiles.org/apache.org/httpd/httpd-2.0.49.tar.gz\n\n\nSteps taken for compilation:\n\n- apt-get install libssl-dev binfmt-support\n\n- ./configure --enable-mods-shared=all --enable-ssl --enable-proxy\n--enable-suexec --with-suexec-caller=nobody --with-suexec-docroot=/home\n\n- make\n\n- make install\n\n- addgroup site1\n\n- adduser --shell /bin/false --ingroup site1 user1\n\n- mkdir /home/user1/public_html\n\n- chown user1:site1 /home/user1/public_html\n\n- adduser --shell /bin/false --ingroup site1 user2\n\n- mkdir /home/user2/public_html\n\n- chown user2:site1 /home/user2/public_html\n\n- Content of /home/user1/public_html/whoami.pl and\n/home/user2/public_html/whoami.pl:\n  #!/usr/bin/perl\n  print 'Content-type: text/plain/n/n';\n  system 'whoami';\n\n- chown user1:site1 /home/user1/public_html/whoami.pl\n\n- chmod 755 /home/user1/public_html/whoami.pl\n\n- chown user2:site1 /home/user2/public_html/whoami.pl\n\n- chmod 755 /home/user2/public_html/whoami.pl\n\n\nOpen http://floeff3 => 'user1' is being printed\nOpen http://floeff3/~user2/ => Internal Server Error with\n\n[2004-04-29 16:01:36]: target uid/gid (1002/1004) mismatch with directory\n(1003/1004) or program (1003/1004)\n\n\n# id user1\nuid=1002(user1) gid=1004(site1) groups=1004(site1)\n\n# id user2\nuid=1003(user2) gid=1004(site1) groups=1004(site1)\n\n\nI have put the configuration changes I've made together in the attached patch\nfile which you should use against /usr/local/apache2/httpd.conf\n\nPlease let me know if you need anything else. Thanks for taking the time. ;-)
18156	Florian Effenberger	1083247551000	Created an attachment (id=11376)\npatch for the original httpd.conf file\n
18156	Joshua Slive	1083249678000	Thanks, that's clearer.  But there is still some stuff which I assume is\nirrelevant to your problem, like the mod_rewrite directives and the UserDir\ndisabled stuff.  Does your problem go away if you remove those?\n\nUnfortunately, I don't have a unix system available to test on at the moment. \nI've looked at the code, and it appears to me that when both SuexecUserGroup and\nmod_userdir is active, there is no defined ordering between the\nget_suexec_identity hooks.  So perhaps the userdir suexec stuff doesn't work at\nall if SuexecUserGroup is present.  In that case, simply fixing the hook\nordering could fix the problem.
18156	Florian Effenberger	1083252308000	Thanks for your fast reply! I've set the following lines (in the patch) to the\nhttpd.conf defaults:\n\n===\n-UserDir public_html\n+#UserDir public_html\n+UserDir disabled\n+UserDir disabled root\n[...]\n+RewriteEngine on\n+RewriteOptions inherit\n[...]\n+Userdir enabled user2\n===\n\nI still get an Internal Server Error, so they don't seem to have anything to do\nwith the problem. ;-)\n\nIs there anything else you need or did I sent all information necessary to fix\nthe bug?
18156	Joshua Slive	1083253281000	Here's a wild guess:\n\nIndex: mod_userdir.c\n===================================================================\nRCS file: /home/cvs/httpd-2.0/modules/mappers/mod_userdir.c,v\nretrieving revision 1.52.2.4\ndiff -u -d -b -r1.52.2.4 mod_userdir.c\n--- mod_userdir.c       9 Feb 2004 20:53:19 -0000       1.52.2.4\n+++ mod_userdir.c       29 Apr 2004 15:38:30 -0000\n@@ -350,7 +350,7 @@\n \n     ap_hook_translate_name(translate_userdir,aszPre,aszSucc,APR_HOOK_MIDDLE);\n #ifdef HAVE_UNIX_SUEXEC\n-    ap_hook_get_suexec_identity(get_suexec_id_doer,NULL,NULL,APR_HOOK_MIDDLE);\n+    ap_hook_get_suexec_identity(get_suexec_id_doer,NULL,NULL,APR_HOOK_FIRST);\n #endif\n }\n \nIf that isn't it, you'll have to wait for another developer to look at it, since\nI don't have the resources to do suexec testing.
18156	Florian Effenberger	1083255727000	Thanks Joshua, this one seems to work! I've tested it locally, and I have no\nproblems anymore! ;-)\n\nWill this bugfix be incorporated in 2.0.50?
18156	Joshua Slive	1083257847000	I won't commit this myself, since I can't test it.  But another developer will\nhopefully pick it up.\n\nThis could be considered a non-compatible change, since there is a chance\nsomeone might be relying on SuexecUserGroup taking precedence of UserDir for\nsuexec.  But this change should get us closer to the way it worked in 1.3, and\nit makes sense to me as the expected way things should work, so I think it\nshould be committed.
18156	Florian Effenberger	1083260556000	Okay :)\nMaybe you just have to make the change clear in the change log or add an option \nfor httpd.conf to choose between the 'new old' and the 2.0 default behaviour.\nThanks again for your quick reply and great help, much appreciated!
18156	Florian Effenberger	1084534883000	Where can I 'find' a developer to test and eventually contribute this to the\nCVS? :-)
18156	Joe Orton	1092739190000	A workaround is to swap the order of the LoadModule lines for suexec and userdir.\n\nI'll test Joshua's patch: it's hard to argue this is an incompatible change\nsince the current behaviour is not defined so it's OK for 2.0 as well, I'd guess.
18156	Joe Orton	1092817537000	Committed, will propose for backport.  Thanks for the report and thank you\nJoshua for the patch.
18156	Florian Effenberger	1092817746000	Thanks a lot for implementing it! :-)
18332	Andr?? Malo	1049496566000	I've added a paragraph according to this issue.\n\nThanks.
18348	Jeff Trawick	1057871411000	Allegedly this scenario is handled by\n\nhttp://www.apache.org/~trawick/mod_cgi.c\n\nwhich handles the three I/O channels with the script in a more sane way, at\nleast as unix-heads would see it.\n
18348	Joe Orton	1083786385000	Fixed on HEAD by extracting the relevant change from Jeff's mod_cgi.c (thanks\nJeff!).\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/generators/mod_cgi.c?r1=1.162&r2=1.163\n\nBackport of recent mod_cgi changes to 2.0 is here:\n\nhttp://www.apache.org/~jorton/mod_cgi-2.0.diff
18443	Joshua Slive	1049653116000	OK.  Thanks.  I've toned down that text so that it is\nno longer misleading.
18452	Erik Abele	1049224517000	This is fixed in CVS and will be soon available on the website.\n\nSee: http://cvs.apache.org/viewcvs/httpd-2.0/docs/man/rotatelogs.8\n\nThanks for your report and for using Apache 2!
18623	Andr?? Malo	1049310955000	Ah yeah, somehow it was forgotten. assigned ...
18623	Andr?? Malo	1049494346000	The directive is now documented. You can find it online at\n<http://httpd.apache.org/docs-2.0/mod/mod_proxy.html#proxybadheader>.\n\nThanks for your care and thanks for using Apache.
18628	Jeff Trawick	1069438513000	Thanks for the research!  I've removed the code.\n
18649	Jeff Trawick	1049370953000	A fix for this has been committed to 2.1-dev and will be suggested for merging\ninto 2.0.46-dev.\n\nHere is the fix:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/configure.in.diff?r1=1.246&r2=1.247\n\nThanks for your report, and I'm sorry that this was broken in 2.0.45.  The\nregression was discovered at the last minute, and due to the high severity of\nsome of the issues resolved by 2.0.45 it was felt that it was best to get 2.0.45\nout the door.
18649	Jeff Trawick	1050548414000	this has now been merged into 2.0.46-dev.\n
18959	Jeff Trawick	1050092160000	can you show your configure invocation, along with any env vars such as CFLAGS\nthat might affect the build?\n\ndid you run buildconf or use the included configure script/libtool?\n\nthanks!\n
18959	Andrew Fried	1050093379000	The compilation was attempted using both the FreeBSD 'ports' script as well as \nmanually being downloaded, extracted, etc.  I made no changes to the \nenvironment variable with the exception of specifying a prefix directory.  I \nalso attempted it without the prefix directory setting, same error message.\n\nThe contents of the systems 'make.conf' file is:\n# -- use.perl generated deltas -- #\n# Created: Tue Mar  4 15:19:35 2003\n# Setting to use base perl from ports:\nPERL_VER=5.6.1\nPERL_VERSION=5.6.1\nPERL_ARCH=mach\nNOPERL=yo\nNO_PERL=yo\nNO_PERL_WRAPPER=yo\n\n\nAnd my environment is:\n_       more make.conf\n\naddsuffix\nargv    ()\ncwd     /etc\ndirstack        /etc\necho_style      bsd\nedit\nfilec\ngid     0\ngroup   wheel\nhistory 100\nhome    /root\nkillring        30\nloginsh\nmail    /var/mail/root\nowd     /root\npath    \n(/sbin /bin /usr/sbin /usr/bin /usr/games /usr/local/sbin /usr/local/bin /usr/X1\n1R6/bin /root/bin)\nprompt  WEBSERVER# \nprompt2 %R? \nprompt3 CORRECT>%R (y|n|e|a)? \nsavehist        100\nshell   /bin/csh\nshlvl   1\nstatus  0\ntcsh    6.12.00\nterm    vt100\ntty     ttyp0\nuid     0\nuser    root\nversion tcsh 6.12.00 (Astron) 2002-07-23 (i386-intel-FreeBSD) options \n8b,nls,dl,al,kan,sm,rh,color,dspm,filec\n\nFinally, I used the builtin configure script.  I noticed a patch had been \npublished, so I also attempted patching the program, running buildconf and then \nconfig.  Same error during compilation.\n\nGood luck, and thanks for looking into this!\n\n
18959	Jeff Trawick	1050101914000	works for me on FreeBSD 5.0-RELEASE...\n\nwget tarball\ntar -xzf httpd-2.0.45.tar.gz\ncd httpd-2.0.45\n./configure --prefix=/tmp/2045\n(some autoconf complaints about permissions but everything else okay)\nmake && make install\n\nHmmm...  Any chance you have apache header files in /usr/local/include from some\nprevious install?  /usr/local/include is getting searched before /tmp/httpd-\n2.0.45/include.
18959	Andrew Fried	1050112716000	My system did have older files located under /usr/local/include.  I removed \nthose files and the compilation worked flawlessly.  I've been using Apache for \nsix or seven years and never knew that it looked outside it's temp directory \nwhen compiling.  I don't know if I feel more relieved or stupid...  \n\nThank you VERY, VERY much.  Sorry to have wasted your time with my erroneous \nbug report.\n\nAndrew\n
18959	Jeff Trawick	1050142120000	This is something that at least a few people have hit.\n\nApache or apr-util or apr may need to look for include files in\n/usr/local/include, or other places where old Apache header files could have\nbeen installed, when using external libraries (zlib, berkeley db, openssl,\nwhatever).\n\nIt would be nice if the search order for Apache was\n\napache-source-directories\napr-include-directories\napr-util-include-directories\n\n(order not important for these first three)\n\nfollowed by any directories needed for libraries used by apache or apr or apr-util.\n\nThat would get rid of this problem.\n
18959	Joe Orton	1075109081000	*** Bug 23485 has been marked as a duplicate of this bug. ***
18959	Jean-Francois Gobin	1090333550000	*** Bug 30208 has been marked as a duplicate of this bug. ***
18959	Joe Orton	1092400753000	Fixed in HEAD by ensuring that the 'apache-source-directories' come first in\nINCLUDES, which should be sufficient to fix most of these cases.
18959	Joe Orton	1178631345000	*** Bug 42357 has been marked as a duplicate of this bug. ***
19012	Joshua Slive	1050361381000	Try --enable-so or --enable-modules=so\n\n(Have I mentioned how annoying it is that you can\n--enable-whatever-you-want without getting an \nerror message; yes, I think I have.)
19012	Jeff Trawick	1050362318000	Also, drop the --enable-rule=SHARED_CORE argument.  That too is Apache-1.3-style\nconfigure argument which means nothing to Apache 2.0.\n\n(But I suspect you have mod_so anyway...  mod_so defaults to on for most systems\n(including AIX 5.1)...  Try ./httpd -l and see if mod_so.c is in the output.)\n\nAlso, there is a bug in the message generation.  As you noticed, nothing is\nprinted in the expected position to say yes or no or shared.\n
19012	Tony Fan	1050521787000	Thank you for the information.  I recomplired Aapche,  I check httpd -l to make \nsure I had mod_so,  but after I used JRun 4 connector to configure with Apache.\nhere is the error I am getting.\n# ./apachectl start\nSyntax error on line 1037 of /usr/local/apache2/conf/httpd.conf:\nCannot load /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so into server: \n\nhere is line 1037 from httpd.conf:\nLoadModule jrun_module /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so\n\nthis error most likely is mod_so doesn't work.  any ideal?
19012	Andr?? Malo	1050522825000	Ehm no, the error probably says, that mod_jrun doesn't work with that httpd version.\n\n  Syntax error on line 1037 of /usr/local/apache2/conf/httpd.conf:\n  Cannot load /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so into server: \n  <here is the interesting part>\n\nwhat is the interesting message?
19012	Jeff Trawick	1050523119000	Unfortunately, some Apache modules don't build properly\non AIX and an inability to load them is a frequent symptom.\n\nSee my fun at trying to get some Tomcat connectors to build properly \non AIX: http://www.apache.org/~trawick/tomcataix.html\n\nSend me privately the output of 'dump -Tv mod_jrun20.so' and 'dump -Hv\nmod_jrun20.so' and I'll maybe have a guess as to why they won't load.\n
19012	Tony Fan	1050523882000	Here is result for dump -Tv mod_jrun20.so:\n\n# dump -Tv /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so\n\n/home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so:\n\n                        ***Loader Section***\n\n                        ***Loader Symbol Table Information***\n[Index]      Value      Scn     IMEX Sclass   Type           IMPid Name\n\n[0]     0x00000000    undef      IMP     DS EXTref               . ap_add_cgi_va\nrs\n[1]     0x00000000    undef      IMP     DS EXTref               . ap_add_common\n_vars\n[2]     0x00000000    undef      IMP     DS EXTref               . ap_destroy_su\nb_req\n[3]     0x00000000    undef      IMP     DS EXTref               . ap_get_client\n_block\n[4]     0x00000000    undef      IMP     DS EXTref               . ap_log_error\n[5]     0x00000000    undef      IMP     DS EXTref               . ap_os_escape_\npath\n[6]     0x00000000    undef      IMP     DS EXTref               . ap_rflush\n[7]     0x00000000    undef      IMP     DS EXTref               . ap_rwrite\n[8]     0x00000000    undef      IMP     DS EXTref               . ap_set_conten\nt_length\n[9]     0x00000000    undef      IMP     DS EXTref               . ap_setup_clie\nnt_block\n[10]    0x00000000    undef      IMP     DS EXTref               . ap_should_cli\nent_block\n[11]    0x00000000    undef      IMP     DS EXTref               . ap_sub_req_lo\nokup_uri\n[12]    0x00000000    undef      IMP     UA EXTref   libc.a(shr.o) errno\n[13]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) close\n[14]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) socket\n[15]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) send\n[16]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) recv\n[17]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) setsockopt\n[18]    0x00000000    undef      IMP     UA EXTref   libc.a(shr.o) _system_confi\nguration\n[19]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) free\n[20]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) malloc\n[21]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strlen\n[22]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) fopen\n[23]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strncasecmp\n[24]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) atoi\n[25]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strchr\n[26]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strtok\n[27]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) fclose\n[28]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) memset\n[29]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) vsprintf\n[30]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) sprintf\n[31]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) fwrite\n[32]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strncmp\n[33]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) tolower\n[34]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) fread\n[35]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strdup\n[36]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) ftell\n[37]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) fseek\n[38]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) time\n[39]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) gettimeofday\n[40]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strstr\n[41]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) srand\n[42]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) rand\n[43]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strerror\n[44]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) connect\n[45]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) inet_addr\n[46]    0x00000000    undef      IMP     DS EXTref   libc.a(shr.o) strcasecmp\n[47]    0x20000580    .data      EXP     RW SECdef        [noIMid] jrun_module\n[48]    0x200005b8    .data      EXP     RW SECdef        [noIMid] jrMetrics\n[49]    0x200005c0    .data      EXP     RW SECdef        [noIMid] VARIABLE_NAME\nS\n[50]    0x2000089c    .data      EXP     DS SECdef        [noIMid] loadServersFr\nomStore\n[51]    0x200008a8    .data      EXP     DS SECdef        [noIMid] mappingsTable\nNew\n[52]    0x200008b4    .data      EXP     DS SECdef        [noIMid] mappingsTable\nDelete\n[53]    0x200008c0    .data      EXP     DS SECdef        [noIMid] init_jrun_req\nuest\n[54]    0x200008cc    .data      EXP     DS SECdef        [noIMid] retrieveServe\nrsFromServer\n[55]    0x200008d8    .data      EXP     DS SECdef        [noIMid] persistServer\ns\n[56]    0x200008e4    .data      EXP     DS SECdef        [noIMid] longerThan\n[57]    0x200008f0    .data      EXP     DS SECdef        [noIMid] removePathPar\nms\n[58]    0x200008fc    .data      EXP     DS SECdef        [noIMid] jrunProxyNew\n[59]    0x20000908    .data      EXP     DS SECdef        [noIMid] startSync\n[60]    0x20000914    .data      EXP     DS SECdef        [noIMid] gtod\n[61]    0x20000920    .data      EXP     DS SECdef        [noIMid] tvToMillis\n[62]    0x2000092c    .data      EXP     DS SECdef        [noIMid] stopSync\n[63]    0x20000938    .data      EXP     DS SECdef        [noIMid] initSync\n[64]    0x20000944    .data      EXP     DS SECdef        [noIMid] getPropertyVa\nlue\n[65]    0x20000950    .data      EXP     DS SECdef        [noIMid] freePropertie\ns\n[66]    0x2000095c    .data      EXP     DS SECdef        [noIMid] describeError\n[67]    0x20000968    .data      EXP     DS SECdef        [noIMid] parseProperti\nes\n[68]    0x20000974    .data      EXP     DS SECdef        [noIMid] getSession\n[69]    0x20000980    .data      EXP     DS SECdef        [noIMid] addProperty\n[70]    0x2000098c    .data      EXP     DS SECdef        [noIMid] removePropert\nyByIndex\n[71]    0x20000998    .data      EXP     DS SECdef        [noIMid] removePropert\ny\n[72]    0x200009a4    .data      EXP     DS SECdef        [noIMid] setProperty\n[73]    0x200009b0    .data      EXP     DS SECdef        [noIMid] getPropertyVa\nlue3\n[74]    0x200009bc    .data      EXP     DS SECdef        [noIMid] getPropertyVa\nlue2\n[75]    0x200009c8    .data      EXP     DS SECdef        [noIMid] freePropertie\ns1\n[76]    0x200009d4    .data      EXP     DS SECdef        [noIMid] parseProperti\nes1\n[77]    0x200009e0    .data      EXP     DS SECdef        [noIMid] loadPropertie\ns1\n[78]    0x200009ec    .data      EXP     DS SECdef        [noIMid] loadPropertie\ns\n[79]    0x200009f8    .data      EXP     DS SECdef        [noIMid] getServerId\n[80]    0x20000a04    .data      EXP     DS SECdef        [noIMid] getNextBuddy\n[81]    0x20000a10    .data      EXP     DS SECdef        [noIMid] freeSync\n[82]    0x20000c78     .bss      EXP     RW    BSS        [noIMid] jrun_rootdir\n[83]    0x00000000    undef      IMP     DS EXTref              .. apr_palloc\n[84]    0x00000000    undef      IMP     DS EXTref              .. apr_table_add\n[85]    0x00000000    undef      IMP     DS EXTref              .. apr_table_set\n[86]    0x00000000    undef      IMP     DS EXTref              .. apr_pstrdup\n[87]    0x00000000    undef      IMP     DS EXTref              .. apr_table_get\n[88]    0x00000000    undef      IMP     DS EXTref              .. apr_pstrcat\n[89]    0x00000000    undef      IMP     DS EXTref              .. ap_hook_post_\nconfig\n[90]    0x00000000    undef      IMP     DS EXTref              .. ap_hook_child\n_init\n[91]    0x00000000    undef      IMP     DS EXTref              .. ap_hook_type_\nchecker\n[92]    0x00000000    undef      IMP     DS EXTref              .. ap_hook_handl\ner\n[93]    0x00000000    undef      IMP     DS EXTref              .. ap_run_http_m\nethod\n[94]    0x00000000    undef      IMP     DS EXTref              .. apr_table_elt\ns\n[95]    0x00000000    undef      IMP     DS EXTref              .. apr_table_set\nn\n[96]    0x00000000    undef      IMP     DS EXTref              .. apr_pool_clea\nnup_register\n\n\n--------------------------------------------------------------------------------\nHere is a result for dump -Hv /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so:\n\n# dump -Hv /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so\n\n/home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so:\n\n                        ***Loader Section***\n                      Loader Header Information\nVERSION#         #SYMtableENT     #RELOCent        LENidSTR\n0x00000001       0x00000061       0x00000149       0x00000038\n\n#IMPfilID        OFFidSTR         LENstrTBL        OFFstrTBL\n0x00000004       0x000018a4       0x00000470       0x000018dc\n\n\n                        ***Import File Strings***\nINDEX  PATH                          BASE                MEMBER\n0      /usr/lib/threads:/usr/lib:/lib\n1                                    libc.a              shr.o\n2                                    .\n3                                    ..
19012	Jeff Trawick	1050533227000	dang it, I think it is a build problem related to the display issue you noted\nback at square one...  your DSO looks great\n\ntry this:\n\n$ cd /path/to/httpd-2.0.45\n$ grep HTTPD_LDFLAGS build/config_vars.mk\n\nI bet the output is simply\n\nHTTPD_LDFLAGS = \n\nwhen it should be something similar to \n\nHTTPD_LDFLAGS = -Wl,-uXML_Parse -Wl,-bE:/path/to/server/httpd.exp\n\nThe lack of the weird '-Wl,-bE:' option means that httpd doesn't export the\nApache API to DSOs, subsequently leading to DSOs failing to load.\n\nDepending on how mod_so gets enabled, the variable $enable_so may or may not get\nset, and if it isn't set then the right LDFLAGS for linking httpd don't get\ninitialized.\n\nIf you verify that HTTPD_LDFLAGS is an empty string, here is a work-around that\nworked for me:  Add '--enable-so' to your Apache configure invocation, as in\n\nmake distclean && ./configure --enable-so --other-opts && make && make install\n\nBy explicitly turning on mod_so (using the Apache 2 option this time :) ), we\navoid the bug.
19012	Jeff Trawick	1050547578000	This has been fixed in 2.1-dev, and if nobody complains about the fix\nin the next few days I'll propose it for merging into 2.0.46-dev.\n\nUntil then, specify --enable-so.\n
19012	Tony Fan	1050595988000	I recompiled as your suggection. \nafter that I check:\n1. config.log (I can see mod_so turned on YES)\n2. HTTPD_LDFLAGS = -Wl,-uXML_Parse -Wl,-bE:/path/to/server/httpd.exp\n3. httpd -l showed mod_so\n\nbut when I start up Aapche still got same error.\n# ./apachectl start\nSyntax error on line 1037 of /usr/local/apache2/conf/httpd.conf:\nCannot load /home/tfan/jrun4/lib/wsconfig/1/mod_jrun20.so into server: \n
19012	Jeff Trawick	1050596485000	plz send me off-line (trawick@apache.org) the output of\n\n dump -Tv /path/to/new/httpd\n\n(the one picked up by your still-failing ./apachectl start)\n
19012	Jeff Trawick	1055903567000	ISTR hearing off-line that the Apache build was corrected with the --enable-so\nwork-around, and that further work was going to be done with the 3rd-party\nmodule build to see why it wasn't loading.\n\nRe-open the PR if there is still a problem with httpd not exporting symbols.\n
19023	Sami Tikka	1050398951000	Err... my mistake... The bug happens when iterating the conf->noproxies table,\nwhich is initialized from ProxyBlock directive, not NoProxy like I claimed\nbefore. Otherwise the previous report is accurate.
19023	Graham Leggett	1050423112000	Patch applied to v2.0.46 and v2.1.0\n
19084	Will Rowe	1050601541000	\n  Never fear, these are absolute violations of our style guide.\n\n  I will go axing this weekend if nobody has beaten me to it.\n\n
19084	Jeff Trawick	1052485239000	fix committed, thanks!\n\nthe fix will be in 2.0.46
19175	Andr?? Malo	1052100508000	Changed the entries.\n\nThanks for your care and thanks for using Apache!
19207	Jeff Trawick	1051011967000	Created an attachment (id=5943)\nproposed patch for PR 19207 (build URL from IPv6 literal)\n
19207	Jeff Trawick	1051011995000	Please try the attached patch and report back.\n\nThanks for your report!\n
19207	Matthew Darwin	1051015474000	Issue is resolved with given patch on Apache/2.0.45.
19207	Jeff Trawick	1051023469000	Thanks for the quick feedback.\n\nThe fix you tested has been committed to Apache 2.1-dev.  If the fix doesn't \nprove to be problematic to others, I'll propose it for merging into the \nnext stable release (e.g., 2.0.46).
19242	Mike	1051084697000	Sorry - forgot the build info..\n\nServer version: HTTPD/1.0.0\nServer built:   Apr  8 2003 20:01:30\nServer's Module Magic Number: 20020903:0\nArchitecture:   64-bit\nServer compiled with....\n -D APACHE_MPM_DIR='server/mpm/prefork'\n -D APR_HAS_SENDFILE\n -D APR_HAS_MMAP\n -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)\n -D APR_USE_PROC_PTHREAD_SERIALIZE\n -D APR_USE_PTHREAD_SERIALIZE\n -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT\n -D APR_HAS_OTHER_CHILD\n -D AP_HAVE_RELIABLE_PIPED_LOGS\n -D HTTPD_ROOT='/opt/apache'\n -D SUEXEC_BIN='/opt/apache/bin/suexec'\n -D DEFAULT_PIDLOG='logs/httpd.pid'\n -D DEFAULT_SCOREBOARD='logs/apache_runtime_status'\n -D DEFAULT_LOCKFILE='logs/accept.lock'\n -D DEFAULT_ERRORLOG='logs/error_log'\n -D AP_TYPES_CONFIG_FILE='conf/mime.types'\n -D SERVER_CONFIG_FILE='conf/httpd.conf'
19242	David Deaves	1052499146000	Created an attachment (id=6299)\nInitialise the 'block' and 'mode' members of bio_filter_in_ctx_t\n
19242	David Deaves	1052499591000	The problem was eventually tracked down.\nI traced it back to the  'block' member of\nthe 'bio_filter_in_ctx_t' structure not being\ninitialized before being used.\nSo I added initializatoins for the 'block' member\nand the 'mode' member (also not initialized but\ndidn't contribute to our problem) to the\n'ssl_io_input_add_filter' function.\n\nOf interest, the unitialized values ended up being\nbad after a SSL connection to a MicroSoft ISA server.\nThe ISA server doesn't send a 'close_notify' at\nthe end of the session.\n\n
19242	Will Rowe	1056142277000	  David, the issue with your patch is that we properly initialize within\n  the input filter, but never properly initialized the blocking mode in\n  the output filter.  The output filter must always block for a complete\n  handshake or other activity, so you will find the appropriate patches\n  with modules/ssl/ssl_engine_io.c rev 1.106, credited to both your initial\n  efforts and my patch.\n\n  This is not yet backported.  Would you test the attached patch against your\n  Apache 2.0 build and confirm the patch resolves your problem?
19242	Joe Orton	1068212996000	The fixes for this were included in 2.0.48.
19242	Joe Orton	1069069993000	*** Bug 20785 has been marked as a duplicate of this bug. ***
19304	Jess Holle	1054639726000	Another option would be to put this under the logs sub-directory like many \nother Apache MM-like usages do.
19304	Jess Holle	1054639746000	This appears to be a duplicate of 20242.
19304	Thom May	1054640052000	*** Bug 20242 has been marked as a duplicate of this bug. ***
19304	Thom May	1054640161000	No, we're trying to deprecate the usage of the logs dir for anything but\nlogging. It should use the localstatedir, it being, after all, local state.
19304	Jess Holle	1054659728000	Where is localstatedir and is it in fact guaranteed to exist (like the logs dir \nis)?\n\n[For now I've patched my Apache 2.0.46 to put this in logs, until a better home \nwhich is guaranteed to exist 'out-of-the-box' (without additional \nconfiguration) can be found for it.]
19304	Jess Holle	1054832869000	Additionally:\n\nWhatever localstatedir is supposed to be, using a hard-coded absolute path is a \nnon-starter.  Why?  Though it is certainly not recommended, there are times \nwhere one must run 2 Apache's on one system (and even on one drive on Windows).\n\nThus the path use should be configurable or relative to the Apache installation \ndirectory.  The latter is easy and relatively foolproof.  If 'logs' is \nverboten, then how about introducing a standard 'tmp' directory in the Apache \nlayout (complete with proper permission assignment in the binary installer, \netc) and using it?\n\nUntil that's done, I'll stick with using logs...
19304	Markus Herzog	1056541409000	Created an attachment (id=6969)\nmod_ldap shared mem location patch\n
19304	Markus Herzog	1056541521000	this patch add a new directice LDAPSharedMemCache. with it you can specify the\nlocation of the shared mem cache within your httpd.conf
19304	Jeff Trawick	1069453092000	enabling the PatchAvailable keyword\nupdated doc on submitting patches is at http://httpd.apache.org/dev/patches.html\n
19304	Graham Leggett	1085105327000	Does the LDAPSharedCacheFile directive solve this problem?\n
19304	Bradley Schwoerer	1085109828000	Yes the directive fixes the problem
19317	Nick Kew	1088491563000	Patch committed to HEAD; c.f. bug 15207
19355	Andr?? Malo	1067811288000	Well, fixed in 2.1 and proposed for backport.\nI've slightly modified your patch and used\n\napr_table_setn(f->r->notes, 'no-etag', '');\n\nbecause the '1' pointer is not really portable and may cause bus errors on weird\nsystems.\n\nThanks.
19405	Co-Advisor	1051567271000	Created an attachment (id=6068)\ntest case trace -- 17-line response header\n
19405	Joe Orton	1075151518000	Thanks for the excellent report - this is now fixed in HEAD.
19405	Joe Orton	1116545995000	*** Bug 34975 has been marked as a duplicate of this bug. ***
19439	Co-Advisor	1051646670000	Created an attachment (id=6079)\ntest case trace (3 old Vias in response)\n
19439	Co-Advisor	1051646904000	Created an attachment (id=6080)\ntest case trace (3 old Vias in request)\n
19439	Robert	1106667416000	Created an attachment (id=14098)\nPatch\n\nThe problem is solved by adding this single line. \nIf a request gets to the server this function is called, and the header fields\nare pooled. This effects the via-fields as can be seen in the request-TestCase.\nIf a response returns to the proxy server, this polling wasn't done, now it\nwill be.
19439	Co-Advisor	1117838316000	Indeed, httpd-2.0.54 patched with the patch #14098 \nmerges all Via response headers into one, appends\nits own Via, and passes the test case.\n
19439	Nick Kew	1191912737000	Fixed in r583155
19512	Astrid Ke??ler	1051791122000	This is not a bug. This behavior is documented at\nhttp://httpd.apache.org/docs/mod/core.html#allowoverride:\n\n'Note: AllowOverride is only valid in <Directory> sections, not in <Location> or\n<Files> sections...'\n\nThanks for using Apache.
19512	Ben Laurie	1051805060000	That doesn't make it not a bug! If a configuration directive is used in a\ncontext in which it doesn't work, then an error should occur.
19512	Andr?? Malo	1051912543000	<Location> and <Files> are caught with a warning now. <Directory[Match| ~]> is\nfun. I have no idea how to determine these cleanly.
19611	Thom May	1052134385000	I'm just about to commit a fix for this; updating ssl-std.conf to use explicit paths.
19611	Thom May	1052142016000	Fix commited, should be available in the next version of apache2. Thanks for the bug report!
19626	Andr?? Malo	1052063677000	It *may* work if you permute the LoadModule directives of mod_rewrite and\nmod_mime. Final fix is in progress.\n\nThanks for the report and thanks for using Apache.
19626	Andr?? Malo	1052866390000	FYI: The fix has been merged into the stable tree and will be in the next\nrelease (2.0.46).
19688	Marc M. Adkins	1052190500000	Somewhat belatedly I realized I should look for examples within the Apache code \nbody.  I found a call to ap_fwrite in server/protocol.c which passes f->next.  \nSo the answer here is probably 'fix the documentation' (if not 'Marc you're an \nidiot' ;).\n
19688	Marc M. Adkins	1052270530000	I went back to Ryan Bloom's 09/2001 article on writing output filters \n(http://www.onlamp.com/pub/a/apache/2001/09/13/apache_2.html) and it states \nvery clearly that the filter argument to all of these routines is filter-\n>next.  I had read this article, but apparently not with enough attention to \ndetail.  Then I went to the documentation line I quoted above in the source and \nconfused myself.\n\nSorry for registering a bug on this.  I still believe the doc should be fixed \nand it is in fact taken from the code (as it should be).  I'm willing to do it \nmyself and submit diffs if requested.\n\nMea culpa, mea culpa, mea culpa.
19688	Paul Querna	1093864596000	Diffs would be cool.  Attach em and I will look at committing them :)
19688	Nick Kew	1093891789000	Definitely a documentation bug.  To change the code will break more-or-less\nevery existing filter.  I'll do something with it if noone else gets there first.
19688	Nick Kew	1095004368000	Committing documentation fix in CVS
19699	Thom May	1052229948000	Please can you expand your description - the current bug report makes very\nlittle sense to me.\nIn particular, explain exactly what you were trying to do, and which\ndocumentation you believe is incorrect or not full enough.
19699	Ralf Hauser	1052230607000	OK, I have a directory with \nrhauser@rhauserPCGF590K:~> ls -lart $m4d/public/tilde/\ntotal 22\ndrwxr-xr-x    8 rhauser  mkgroup         0 Feb  5 06:19 ..\ndrwxr-xr-x    3 rhauser  mkgroup         0 Mar 10 14:01 .\ndrwxr-xr-x    2 rhauser  mkgroup         0 Mar 10 14:01 CVS\n-rw-r--r--    1 rhauser  mkgroup        79 Mar 10 14:49 .htaccess\n-rw-r--r--    1 rhauser  mkgroup       452 Mar 11 10:51 README.txt\n-rw-r--r--    1 rhauser  mkgroup      7125 Mar 24 14:13 ftl.el\n-rw-r--r--    1 rhauser  mkgroup      5530 Apr  4 13:14 .tcshrc\n-rw-r--r--    1 rhauser  mkgroup      3709 Apr 25 08:27 .bashrc\n-rw-r--r--    1 rhauser  mkgroup      2512 May  5 18:25 .emacs\nrhauser@rhauserPCGF590K:~>\n\n.htaccess only contains one line:\n\n  Options +Indexes\n\nWhen looking at it through apache,  I get only\n\n<<Index of public/tilde\n\n Name                     Last modified      Size  Description Parent Directory\n                             -   \n ftl.el                   06-May-2003 08:46  7.0K  \n\nApache/2.0.40 Server at www.mydomain.com Port 443>>
19699	Joshua Slive	1052231098000	Check your httpd.conf for this line:\nIndexIgnore .??* *~ *# HEADER* README* RCS CVS *,v *,t\n\nAnd see:\nhttp://httpd.apache.org/docs-2.0/mod/mod_autoindex.html#indexignore
19699	Ralf Hauser	1052233604000	Thx - appears to work.\nWhy 'invalid' - how about adding the valuable link you provided here also to the\ndocumentation (as it is hypertext, shouldn't cross-references be easy and welcome)?
19699	Joshua Slive	1052249562000	Ok.  There should be links there to mod_autoindex (for Indexes) and mod_cgi\n(for ExecCGI) and mod_include (for Includes).
19699	Joshua Slive	1052417901000	Fixed in cvs.
19753	Andr?? Malo	1058025670000	Fixed in 2.0.47. Thanks for the report, but a word for the future anyway: please\naddress security related issues to security@apache.org.\n\nThanks.
19794	Paul J. Reder	1071250381000	This PR has been fixed in the 2.1-dev branch and has been suggested for\nbackporting to the 2.0 stable branch. Thank you for using Apache and for\nsubmitting this report.
19849	Glenn Nielsen	1054138916000	I have done some more research.\n\nWhen the cgid_daemon dies I see the following error message, the pid is for\nthe cgid_daemon:\n\n[Wed May 28 11:05:59 2003] [notice] child pid 24470 exit signal Broken pipe (13)\n\nI added some debug logging to the cgid_maint function in mod_cgid.c.\n\nWhen the cgid_daemon dies with a broken pipe cgid_maint logged the following:\n\n[Wed May 28 11:05:59 2003] [error] cgid_maint\n[Wed May 28 11:05:59 2003] [error] cgid_maint APR_OC_REASON_DEATH\n[Wed May 28 11:05:59 2003] [error] cgid_maint\n[Wed May 28 11:05:59 2003] [error] cgid_maint APR_OC_REASON_UNREGISTER\n[Wed May 28 11:05:59 2003] [error] cgid_maint DONE\n[Wed May 28 11:05:59 2003] [error] cgid_maint DONE\n\nThe code for doing a graceful restart is triggered when APR_OC_REASON_LOST is\nthe reason, but this is never received by cgid_maint.\n\nHere are all the log entries when I reproduced this:\n[Wed May 28 11:05:12 2003] [notice] Apache/2.0.45 (Unix) mod_ssl/2.0.45\nOpenSSL/0.9.7a mod_jk/1.2.3 configured -- resuming normal operations\n[Wed May 28 11:05:12 2003] [info] Server built: May 15 2003 21:22:19\n[Wed May 28 11:05:57 2003] [error] [client 207.160.133.9] Premature end of\nscript headers: counterdate.cgi\n[Wed May 28 11:05:57 2003] [error] [client 207.160.133.9] unable to include\n'/cgi/counterdate.cgi' in parsed file /export/home/moxp/www/www/index.html\n[Wed May 28 11:05:57 2003] [info] (32)Broken pipe: core_output_filter: writing\ndata to the network\n[Wed May 28 11:05:58 2003] [info] (32)Broken pipe: core_output_filter: writing\ndata to the network\n[Wed May 28 11:05:58 2003] [info] (32)Broken pipe: core_output_filter: writing\ndata to the network\n[Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] Premature end of\nscript headers: counter.cgi\n[Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] unable to include\n'/cgi/counter.cgi' in parsed file /export/home/moxp/www/www/index.html\n[Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] Premature end of\nscript headers: counterdate.cgi\n[Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] unable to include\n'/cgi/counterdate.cgi' in parsed file /export/home/moxp/www/www/index.html\n[Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] Premature end of\nscript headers: counterdate.cgi\n[Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] unable to include\n'/cgi/counterdate.cgi' in parsed file /export/home/moxp/www/www/index.html\n[Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] Premature end of\nscript headers: counterdate.cgi\n[Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] unable to include\n'/cgi/counterdate.cgi' in parsed file /export/home/moxp/www/www/index.html\n[Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] Premature end of\nscript headers: counterdate.cgi\n[Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] unable to include\n'/cgi/counterdate.cgi' in parsed file /export/home/moxp/www/www/index.html\n[Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] Premature end of\nscript headers: counter.cgi\n[Wed May 28 11:05:58 2003] [error] [client 207.160.133.9] unable to include\n'/cgi/counter.cgi' in parsed file /export/home/moxp/www/www/index.html\n[Wed May 28 11:05:59 2003] [notice] child pid 24470 exit signal Broken pipe (13)\n[Wed May 28 11:05:59 2003] [error] cgid_maint\n[Wed May 28 11:05:59 2003] [error] cgid_maint APR_OC_REASON_DEATH\n[Wed May 28 11:05:59 2003] [error] cgid_maint\n[Wed May 28 11:05:59 2003] [error] cgid_maint APR_OC_REASON_UNREGISTER\n[Wed May 28 11:05:59 2003] [error] cgid_maint DONE\n[Wed May 28 11:05:59 2003] [error] cgid_maint DONE\n[Wed May 28 11:05:59 2003] [error] [client 207.160.133.9] (3)No such process:\ncgid daemon is gone; is Apache terminating?: /export/home/moxp/www/cgi/counter.cgi\n
19849	Glenn Nielsen	1054174190000	Attached is a patch which will restart the cgid daemon if it dies.\nAt first I tried doing a server restart like the cgid_maint code had\noriginally been setup to do, ( kill(getpid(), AP_SIG_GRACEFUL); ) but after \nan apache restart from cgid_maint I saw a number of the following warning\nmessages. cgid worked fine though.\n\n[Wed May 28 10:49:42 2003] [warn] long lost child came home! (pid 21018)\n[Wed May 28 10:49:42 2003] [warn] long lost child came home! (pid 21019)\n\nSo I wrote a patch that would just restart the cgid daemon rather than\nrestart apache itself.  This patch seems to work fine.
19849	Glenn Nielsen	1054174286000	Created an attachment (id=6553)\npatch to restart cgid daemon if it dies\n
19849	Glenn Nielsen	1054174550000	A final note.  We started upgrading some of our production Sun Solaris servers\nto Apache 2 seven weeks ago  Two of those servers have had the cgid daemon\ndie at once during the seven week period.  This resulted in cgi's failing until\nour customers notified us of the problem.  We then had to restart or stop/start\napache.  The patch I sumbitted will automatically restart the cgid daemon so\nthat only a few cgi requests fail rather coninuous failure until restart or\nstop/start of apache.
19849	Jeff Trawick	1056336096000	Thanks for your patch, and hopefully it will get reviewed/committed soon.\n\nI wanted to mention that if you're running into any problems with cgid, you need\nto apply this patch:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/generators/mod_cgid.c.diff?r1=1.150&r2=1.151\n\nThat fixes a simple bug with horrendous consequences, including the murder of\nthe cgid daemon process (with the sigpipe in the library).\n
19849	Jeff Trawick	1056399652000	patch committed, thanks!!!!!\n\nI'll propose it for merging into the stable branch (2.0.47-dev).\n
19849	Jeff Trawick	1061552847000	*** Bug 22483 has been marked as a duplicate of this bug. ***
19849	Jeff Trawick	1071354486000	*** Bug 23533 has been marked as a duplicate of this bug. ***
19913	Andr?? Malo	1053126960000	Yes, you're right. I've just committed your patch and proposed it for backport\ninto the stable branch.\n\nThanks for your report and thanks for using Apache.
19954	Chris Conti	1069340321000	add patchavailable keyword.
19954	Joshua Slive	1069342124000	Your patch looks reversed.\n\nYou might also want to 'attach' it rather than pasting it in, since the\nline-wrapping makes your patch very hard to apply.
19954	Jeff Trawick	1071014934000	The preferred mechanism would be to AUTOMATICALLY send down a flush bucket if a\nnon-blocking read returns EAGAIN.  No configuration directive would be necessary.\n\nThe simplistic algorithm would be\n\n  done = 0;\n  while (!done) {\n    rv = ap_get_brigade(APR_NONBLOCK_READ);\n    if (APR_STATUS_IS_EAGAIN(rv)) {\n        pass flush bucket down output filter chain;\n        rv = ap_get_brigade(APR_BLOCK_READ);\n    }\n    if (rv != APR_SUCCESS) {\n        done = 1;\n        break;\n    }\n  }\n\nThe content-length filter does this, though with a slightly more complicated and\noptimized algorithm.\n
19954	Chris Conti	1071028952000	In what context do you intend the algorithm to be used?  In proxy_http.c in \nplace of the change I proposed?  \nI would think that ordinarily a reverse proxy would want the caching behavior.  \nOnly when tunneling dynamic content would you want to disable the caching.  In \nour case, the back end server withholds sending more data until a response is \nreceived on a different socket.  When I originally was researching this I came \nacross references to people having a similar issue tunneling streaming \nmultimedia.
19954	Jeff Trawick	1071055047000	The logic to hold on to output until we get 8K is not intended to be caching\nbehavior, but instead to send out full packets so that we don't abuse the\nnetwork.  But if we don't pass flush buckets down at the right time, it breaks\nsome applications that need to send output to the client a piece at a time.\n\nA flush bucket should be passed down when we've read some output but we find out\nthat another read would block.  At this point it is safe to assume that the\nCGI/origin-server/whatever is not going to generate more output for a while and\nthe output generated so far should be flushed to the client.\n
19954	Joe Orton	1100202679000	This is fixed on HEAD using the method Jeff suggested:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/proxy/proxy_http.c?r1=1.201&r2=1.202\n
19954	Joe Orton	1105531685000	*** Bug 33029 has been marked as a duplicate of this bug. ***
19954	jfclere	1161306209000	Created an attachment (id=19034)\npatch for httpd-2.0.59\n
19954	Ruediger Pluem	1161334089000	(In reply to comment #8)\n> Created an attachment (id=19034) [edit]\n> patch for httpd-2.0.59\n> \n\nGuess you provided the reverse patch :-). Furthermore I do not think that this\nworks. The same code does not work in 2.2.x as all non blocking reads are\nconverted to blocking reads somewhere down in the call chain (currently cannot\nremember where) and thus the conditions in the if clause causing a flush bucket\nto be added never become true. This is no fault of the proxy code. Either the\nproblem somewhere down the call chain needs to be fixed what seems to be a\nlarger task or we need to use a poll approach here similar to the one currently\nused in mod_proxy_ajp on the trunk (aka autoflush property of a proxy worker).\n
19954	jfclere	1162353017000	After more testing... The patch does not work if Transfer-Encoding is chunked.\n(See modules/http/http_protocol.c around line 870).
19954	jfclere	1162454560000	Created an attachment (id=19075)\npatch for httpd-2.0.59 (works also with TE chunked).\n\nAlso patch http-protocol to allow the correct to work with TE chunked.
19954	Ruediger Pluem	1162474486000	From first glance this looks good. Mind to produce a patch against trunk, such\nthat it can be committed and follow the usual backporting process?
19954	jfclere	1162793610000	Created an attachment (id=19091)\npatch for htttpd-trunk\n\npatch for htttpd-trunk (06/11/2006).
19954	Jim Jagielski	1164609633000	+1 on the patch
19954	Joe Orton	1164610175000	The issue with the chunk filter is a separate issue to the bug in the proxy\nwhich was tracked here so please open a new PR if you want that bug tracked.
19954	Ruediger Pluem	1197183355000	Backported to 2.2.x as r602679 (http://svn.apache.org/viewvc?rev=602679&view=rev).
20111	Sander Holthaus	1053522242000	It seems that stop - start doesn't help either, you need to change the error-\nlogfile (forgot that I did that, sorry).
20111	Sander Holthaus	1053531380000	OK, figured it out. The errorlog does not seem to break (eg. other cgi-scripts \nand stuff can write to it, no restart neccesary), the bug is caused something I \ndidn't look at (since is worked in previous versions).\n\nThe error-log does not seem to be outputted when writing out a Location header.\nMy script ends with:\n\nprint 'Location http://www.mysite.com/succes.html/n/n';\n\nexit;\n\nThis code worked up to 2.0.43, but as of 2.0.45 it doesn't. If I quote out this \nline I get an error 500 (since nothing is outputted to the browser), but \neverything gets written to the error-log.\n
20111	Joe Orton	1083786271000	Was that using an nph- script?  Bug 18348 concerns loss of stderr output from\nnph- scripts.
20111	Joe Orton	1101143297000	Ah, no, you had tracked it down correctly.  This is harder to hit with 2.0.50\nand later which have the 'CGI bucket' changes, but the remaining case is fixed\non the trunk:\n\nhttp://svn.apache.org/viewcvs.cgi/httpd/httpd/trunk/modules/generators/mod_cgi.c?rev=106195&r1=106103&r2=106195\n\nThanks for the report.
20183	Joe Orton	1079025841000	Thanks for tracking that down; I've committed a complete fix here:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/proxy/proxy_http.c?r1=1.183&r2=1.184
20183	Byron Guernsey	1082056693000	I'm reopening this because I'm running into a similar related issue.\n\nI'm using rewrite rules and proxying along with an ErrorDocument to do a load \nbalancing configuration with failover when the proxy request fails.  If the \nproxy can't hit the server and returns a 502, I use an ErrorDocument to force a \nredirect to the same URL after changing a cookie that tells it to try another \nserver out of a rewrite map. \n\nThe problem is that the 302 redirect is being treated as an error and \nsubsequent requests never reach my ErrorDocument handler.  When I read this \nreport it sounds as if the patch was to treat anything other than 2xx as an \nerror.  Is a redirect truly an error?  If so, then the only way I can achieve \nwhat I'm attempting is to send a 200 response with a META-REFRESH tag. \n\nI believe the code in http_request.c in ap_die() has the same issue where it \nchecks if r->status != HTTP_OK.
20183	Byron Guernsey	1082061841000	I'm recanting my comments below.  The error I encountered was due to a bad \nrewrite rule that generated an additional 502 in the ErrorDocument script.  The \n302's are being treated correctly.  Thanks and sorry for reopening this one.\n
20195	Andr?? Malo	1058292068000	Fixed in 2.1 and proposed for inclusion into the 2.0 stable branch.\n\nThanks for your report and thanks for using Apache!
20372	Nick Kew	1088491863000	Fixed in HEAD; c.f. bug 15207
20558	Erik Abele	1060642075000	Both suggested media types were already added to the 1.3, 2.0 and 2.1-dev tree some time ago.
20558	Dave Hodder	1061118369000	The entry for the XUL media type is missing it's file extension.\n\nCan it please be changed from:\n\n    application/vnd.mozilla.xul+xml\n\n... to:\n\n    application/vnd.mozilla.xul+xml\txul\n\nMany thanks.
20558	Erik Abele	1061131390000	I've added the extension (.xul) to all three trees now. Thanks for the hint.
20617	Jesse Pelton	1055180789000	Forgot to mention the file: this is in mod_isapi.c.
20617	Jesse Pelton	1055273250000	Created an attachment (id=6740)\nTrivial patch\n
20617	Jesse Pelton	1055273458000	Note that the patch is not needed if the patch for bug 20656 is applied.
20617	Jeff Trawick	1069453128000	enabling the PatchAvailable keyword\nupdated doc on submitting patches is at http://httpd.apache.org/dev/patches.html\n
20617	Jeff Trawick	1076953229000	patch committed to Apache 2.1-dev, will propose for backport to stable branch soon\n\nthanks!\n
20617	Will Rowe	1077048005000	  +1 here to backport, thanks Jesse.
20619	Jesse Pelton	1055273310000	Created an attachment (id=6741)\nTrivial patch\n
20619	Ludek Reinstein	1057304705000	*** Bug 21302 has been marked as a duplicate of this bug. ***
20619	Jeff Trawick	1069453240000	enabling the PatchAvailable keyword\nupdated doc on submitting patches is at http://httpd.apache.org/dev/patches.html\n
20619	Jeff Trawick	1076953898000	thanks for the patch!\n\ncommitted to 2.1-dev, will suggest shortly that it be merged into the stable branch\n
20619	Will Rowe	1077048517000	\n  +1 on purusing the patch.  I believe(d) that we handled this header using\n  the statlen bytecount, so as a counted string the trailing null was not\n  important.  But trusting your patch :)  Thank you.
20656	Jesse Pelton	1055273357000	Created an attachment (id=6742)\nTrivial patch\n
20656	Jeff Trawick	1069453300000	enabling the PatchAvailable keyword\nupdated doc on submitting patches is at http://httpd.apache.org/dev/patches.html\n
20656	Jesse Pelton	1076940336000	I'd like to see this patch (and those for 20617 and 20619) applied.  All three\npatches are simple, and I think they're correct and fix errors in the mod_isapi\nimplementation.  Is there anything I can do to facilitate this?  Should I:\n\n- further explain why I believe mod_isapi is currently broken?\n- bring the patches to someone else's attention?\n- add votes or keywords?\n- change priority or severity?\n- prepare the patch differently?  (I think I got it right.)\n- provide test code that demonstrates each problem (assuming it's feasible)?\n\nThese bugs haven't actually been assigned to anyone; do you need a mod_isapi\nmaintainer?  (Hmm...\nhttp://marc.theaimsgroup.com/?l=apache-httpd-dev&m=106854151316221&w=2 may\nexplain a good deal.  Sounds like Bill is just plain busy.)
20656	Jeff Trawick	1076942451000	I've looked at the patches previously and ISTR that they looked reasonable to\nme.  But with zero experience in ISAPI-land I thought it would be best if wrowe\nhave a look ;)  But it is time to move forward, so I'll go through them again\nand commit what I'm reasonable sure of to Apache 2.1-dev and suggest for a backport.\n\nThanks for the ping ;)\n
20656	Jesse Pelton	1076943272000	Sounds good.  Please let me know if you find anything that gets in the way of\nchecking them in; I'm happy to do what I can do address any problems.\n\nThe backport should be trivial, since the trunk and 2.0 branch have been kept in\nsync to the extent possible.  I imagine the real question is whether the\nmaintainers are comfortable with the changes.
20656	Jeff Trawick	1076954340000	patch committed to 2.1-dev, thanks!!\n\nwill propose shortly that it be merged to the stable branch\n
20656	Will Rowe	1077048521000	\n  +1 on backport here ... if you validated against IIS.  Since ISAPI is an\n  abandoned API, pretty much defined by 'whatever it is IIS does', I can go\n  along with this patch.\n\n  It might confuse someone on a non-Win32 mod_isapi - but since crlf is\n  consistent in HTTP headers, I'll agree with Jesse here.  Thanks again :)
20656	Jesse Pelton	1077051267000	You're welcome!  I'm glad to see this getting in.\n\nI bumped up against this when header parsing code that worked under IIS didn't\nwork under mod_isapi.  I generated the patch from the change I made to mod_isapi\nto send headers that I could parse - that is, headers similar to the ones I got\nfrom IIS.  I think that's about as much validation as is possible under the\ncircumstances.  (Barring risking your legal neck by looking for IIS source in\nthe recently leaked Windows code, that is.)\n\nOut of curiosity, do you know if anyone is successfully using mod_isapi on a\nnon-Win32 platform?
20656	Jesse Pelton	1082039987000	Any progress on backporting this patch and the ones for 20617 and 20619?  It has\nbeen a couple of months since 2.0.49 came out; it would be nice if these could\nmake it into 2.0.50, whenever that happens.
20656	Jeff Trawick	1082041904000	All three patches have two votes for backport, awaiting one more :(\n\nFor any developers who see this, please consider these merge requests in the\nSTATUS file.  No special mod_isapi knowledge necessary.\n\n    * mod_isapi: GetServerVariable('ALL_RAW') returned the wrong buffer\n      size.  PR 20617  [Jesse Pelton <jsp pkc.com>]\n       \nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/arch/win32/mod_isapi.c?r1=1.96&r2=1.97\n      +1: trawick, stoddard\n                                                                               \n                     \n    * mod_isapi: send_response_header() failed to copy status string's\n      last character.  PR 20619.  [Jesse Pelton <jsp pkc.com>]\n     \nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/arch/win32/mod_isapi.c?r1=1.97&r2=1.98\n      +1: trawick, stoddard\n                                                                               \n                     \n    * mod_isapi: GetServerVariable returned improperly terminated header\n      fields given 'ALL_HTTP' or 'ALL_RAW'.  PR 20656.\n      [Jesse Pelton <jsp pkc.com>]\n     \nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/arch/win32/mod_isapi.c?r1=1.98&r2=1.99\n      +1: trawick, stoddard\n
20874	Joe Orton	1118788667000	Thanks for the report; now fixed on the trunk.\n\nhttp://svn.apache.org/viewcvs?rev=190392&view=rev\n
20944	Jeff Trawick	1057921969000	Note that mod_include sets additional variables in case the SSI file itself\ncauses a script to be executed, hence the difference in available variables\nbased on whether or not your external filter was processing the result of\nmod_include.\n
20944	Jeff Trawick	1057963815000	plz try the patch that is forthcoming\n
20944	Jeff Trawick	1057963868000	Created an attachment (id=7262)\nadd call to ap_add_common_vars()\n
20944	Neil Fraser	1058046096000	> plz try the patch that is forthcoming\n\nPerfect!\n\nThis bug was completely blocking my project with no workaround possible.  Thank\nyou very much for fixing this.  The project in question is here:\n  http://neil.fraser.name/software/highlighter/
20944	Jeff Trawick	1058195619000	fix committed to 2.1-dev, proposed for merging into 2.0.48-dev\n\nThanks for your report, and thanks for using Apache!\n\n(cute tool, and its nice to see mod_ext_filter put to such use!)\n
20944	Jeff Trawick	1061550369000	*** Bug 22556 has been marked as a duplicate of this bug. ***
21085	Glenn Nielsen	1056554487000	Created an attachment (id=6973)\nab - patch null pointer when parsing a partial response\n
21085	Andr?? Malo	1056909274000	Fixed in 2.1 and proposed for backport.\n\nI've added another sanity check before committing. The piece of code now looks:\n\n[...]\n\t    /* check response code */\n\t    part = strstr(c->cbuff, 'HTTP');\t/* really HTTP/1.x_ */\n            if (part && strlen(part) > strlen('HTTP/1.x_')) {\n                strncpy(respcode, (part + strlen('HTTP/1.x_')), 3);\n                respcode[3] = '/0';\n            }\n            else {\n                strcpy(respcode, '500');\n            }\n\n\t    if (respcode[0] != '2') {\n[...]\n\nThanks for your patch!
21100	Andr?? Malo	1056593428000	That is certainly not a blocker. It would be helpful, if you could provide a\npatch for the layout file.\n\nThanks.
21100	Sander Holthaus	1056625581000	<Layout FreeBSD>\n  prefix:        /usr/local\n  exec_prefix:   ${prefix}\n  bindir:        ${exec_prefix}/bin\n  sbindir:       ${exec_prefix}/sbin\n  libexecdir:    ${exec_prefix}/libexec/apache2\n  mandir:        ${prefix}/man\n  sysconfdir:    ${prefix}/etc/apache2\n  datadir:       ${prefix}/www\n  installbuilddir: ${prefix}/share/apache2/build\n  errordir:      ${datadir}/error\n  iconsdir:      ${datadir}/icons\n  htdocsdir:     ${datadir}/data\n  manualdir:     ${prefix}/share/doc/apache2\n  cgidir:        ${datadir}/cgi-bin\n  includedir:    ${prefix}/include/apache2\n  localstatedir: /var\n  runtimedir:    ${localstatedir}/run\n  logfiledir:    ${localstatedir}/log\n  proxycachedir: ${datadir}/proxy\n  infodir:       ${exec_prefix}/share/info\n</Layout>\n\nNot 100% sure if this also works for FreeBSD 5 though.\n\nKind regards,\nSander Holthaus
21100	Andr?? Malo	1056905345000	Fixed in 2.1 and proposed for backport to 2.0.\n\n(added libdir as exec_prefix/lib)
21160	David Tonhofer	1057011472000	As promised, more information (I am actually keeping my word for once, wow!):\n\nI finally got it to work, though why it *does* work is a mystery.\n\nFirst, some info on what does not work:\n\nI tried the three SSL virtual servers pairwise. On each occasion, Apache startup\nfailed. I got the ide of setting the verbosity level to debug ('LogLevel Debug'),\nthus we find the following in the logfile, in case all three SSL virtual servers\nare configured:\n\n[Mon Jun 30 23:03:31 2003] [info] Init: Initializing OpenSSL library\n[Mon Jun 30 23:03:31 2003] [info] Init: Seeding PRNG with 648 bytes of entropy\n[Mon Jun 30 23:03:31 2003] [info] Loading certificate & private key of SSL-aware\nserver\n[Mon Jun 30 23:03:31 2003] [info] Init: Requesting pass phrase via builtin\nterminal dialog\n[Mon Jun 30 23:03:38 2003] [debug] ssl_engine_pphrase.c(499): encrypted RSA\nprivate key - pass phrase requested\n[Mon Jun 30 23:03:38 2003] [info] Loading certificate & private key of SSL-aware\nserver\n[Mon Jun 30 23:03:38 2003] [info] Init: Requesting pass phrase via builtin\nterminal dialog\n[Mon Jun 30 23:03:47 2003] [debug] ssl_engine_pphrase.c(499): encrypted RSA\nprivate key - pass phrase requested\n[Mon Jun 30 23:03:47 2003] [info] Loading certificate & private key of SSL-aware\nserver\n[Mon Jun 30 23:03:47 2003] [info] Init: Requesting pass phrase via builtin\nterminal dialog\n[Mon Jun 30 23:03:54 2003] [debug] ssl_engine_pphrase.c(499): encrypted RSA\nprivate key - pass phrase requested\n[Mon Jun 30 23:03:54 2003] [info] Init: Wiped out the queried pass phrases from\nmemory\n[Mon Jun 30 23:03:54 2003] [info] Init: Generating temporary RSA private keys\n(512/1024 bits)\n[Mon Jun 30 23:03:54 2003] [info] Init: Generating temporary DH parameters\n(512/1024 bits)\n[Mon Jun 30 23:03:54 2003] [debug] ssl_scache_dbm.c(422): Inter-Process Session\nCache (DBM) Expiry: old: 0, new: 0, removed: 0\n[Mon Jun 30 23:03:54 2003] [info] Init: Initializing (virtual) servers for SSL\n[Mon Jun 30 23:03:54 2003] [info] Configuring server for SSL protocol\n[Mon Jun 30 23:03:54 2003] [debug] ssl_engine_init.c(436): Creating new SSL\ncontext (protocols: SSLv2, SSLv3, TLSv1)\n[Mon Jun 30 23:03:54 2003] [debug] ssl_engine_init.c(611): Configuring permitted\nSSL ciphers [ALL:!IDEA:!ADH:EXPORT56:EXPORT40:!NULL:+HIGH:+MEDIUM:+LOW]\n[Mon Jun 30 23:03:54 2003] [error] Failed to configure CA certificate chain!\n\nI will spare you the pairs, it's the same...\n\nI then tried each of the SSL virtual servers alone. In each case, \nstartup was a success:\n\n[Mon Jun 30 23:03:31 2003] [info] Init: Initializing OpenSSL library\n[Mon Jun 30 23:03:31 2003] [info] Init: Seeding PRNG with 648 bytes of entropy\n[Mon Jun 30 23:03:31 2003] [info] Loading certificate & private key of SSL-aware\nserver\n[Mon Jun 30 23:03:31 2003] [info] Init: Requesting pass phrase via builtin\nterminal dialog\n[Mon Jun 30 23:03:38 2003] [debug] ssl_engine_pphrase.c(499): encrypted RSA\nprivate key - pass phrase requested\n[Mon Jun 30 23:03:38 2003] [info] Loading certificate & private key of SSL-aware\nserver\n[Mon Jun 30 23:03:38 2003] [info] Init: Requesting pass phrase via builtin\nterminal dialog\n[Mon Jun 30 23:03:47 2003] [debug] ssl_engine_pphrase.c(499): encrypted RSA\nprivate key - pass phrase requested\n[Mon Jun 30 23:03:47 2003] [info] Loading certificate & private key of SSL-aware\nserver\n[Mon Jun 30 23:03:47 2003] [info] Init: Requesting pass phrase via builtin\nterminal dialog\n[Mon Jun 30 23:03:54 2003] [debug] ssl_engine_pphrase.c(499): encrypted RSA\nprivate key - pass phrase requested\n[Mon Jun 30 23:03:54 2003] [info] Init: Wiped out the queried pass phrases from\nmemory\n[Mon Jun 30 23:03:54 2003] [info] Init: Generating temporary RSA private keys\n(512/1024 bits)\n[Mon Jun 30 23:03:54 2003] [info] Init: Generating temporary DH parameters\n(512/1024 bits)\n[Mon Jun 30 23:03:54 2003] [debug] ssl_scache_dbm.c(422): Inter-Process Session\nCache (DBM) Expiry: old: 0, new: 0, removed: 0\n[Mon Jun 30 23:03:54 2003] [info] Init: Initializing (virtual) servers for SSL\n[Mon Jun 30 23:03:54 2003] [info] Configuring server for SSL protocol\n[Mon Jun 30 23:03:54 2003] [debug] ssl_engine_init.c(436): Creating new SSL\ncontext (protocols: SSLv2, SSLv3, TLSv1)\n[Mon Jun 30 23:03:54 2003] [debug] ssl_engine_init.c(611): Configuring permitted\nSSL ciphers [ALL:!IDEA:!ADH:EXPORT56:EXPORT40:!NULL:+HIGH:+MEDIUM:+LOW]\n[Mon Jun 30 23:03:54 2003] [error] Failed to configure CA certificate chain!\n\nI figured I would continue with a pair of servers and whittle down the\nSSL config file until things began to work. This actually paid off!\n\nIt turns that the presence of this block seems to be confusing:\n\n  <Files ~ '/.(cgi|shtml|phtml|php3?)$'>\n      SSLOptions +StdEnvVars\n  </Files>\n  <Directory '/usr/local/apache2/cgi-bin'>\n      SSLOptions +StdEnvVars\n  </Directory>\n\nI had this block in each of the three SSL virtual servers, taken from the\noriginal file coming with Apache. I commented it out in one (1) of the three.\n\nLo and behold! It works! Now the passphrase dialog spits out an error after\nhaving asked for the 2nd passphrase. This however, does not prevent it from\nreading the third passpharse. It is also a Good Sign, because whenever this\nerror shows up, the webserver will be able to configure itself:\n\n\nServer www.m-plify.com:443 (RSA)\nEnter pass phrase:\n\nServer rei1.m-plify.net:443 (RSA)\nEnter pass phrase:1024:error:0D094068:asn1 encoding routines:d2i_ASN1_SET:bad\ntag:a_set.c:179:\n1024:error:0D0680A8:asn1 encoding routines:ASN1_CHECK_TLEN:wrong tag:tasn_dec.c:939:\n1024:error:0D07803A:asn1 encoding routines:ASN1_ITEM_EX_D2I:nested asn1\nerror:tasn_dec.c:304:Type=RSA\n1024:error:0D09A00D:asn1 encoding routines:d2i_PrivateKey:ASN1 lib:d2i_pr.c:96:\n\n\nI'm completely at a loss to explain a relationship between the configuration\ninstructions above and SSL certificate chain configuration, sorry....but that's\nwhat happened.
21160	David Tonhofer	1057014669000	Naah, forget what I said about the workaround. The exact same file that\nearlier worked now fails to work (yeah, its the fscking SAME file). This must\nhave to do with the moon phases! OMG...\n
21160	David Tonhofer	1057020091000	I have tried with Apache 2.0.46. There were 3 successfull starts and 1 \nunsuccessful one. Not too bad. I swear I will give up all this Computer\nCrap and I'm gonna raise sheep in New Zealand!\n\nAnyway, that's it for now. -OO-
21160	kris.verbeeck@advalvas.be	1057042437000	Same problem here.  A configuration with a certificate chain and two virtual\nhosts worked on one system (always) but failed on another (always).  On the\nsystem where it failed, removing one of the virtual hosts fixed the problem.\n\nSetup: Apache 2.0.46 + OpenSSL 0.9.6i\nSuccess system: Gentoo Linux\nFailure system: RedHat Advanced Server\n\nI'm not sure whether it is related to the OS vendor.  Will do some more checks\nwhen I get the time.
21160	David Tonhofer	1076348707000	I have tried with Apache 2.0.47 and openssl-0.9.7b. Same problem.\n\nAnd the workaround is (tadaa!):\n\nDO NOT ENCRYPT THE SERVER PRIVATE KEYS.\n\nArf!
21160	Joe Orton	1076365574000	There is a bug which means the OpenSSL error stack is not cleared: I thought\nthis was a purely cosmetic issue (it causes the error dumps you see during\npphrase entry), but in fact it may well be the cause of this bug:\n\nCan anyone who can reproduce this try the following patch:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_pphrase.c?r1=1.44&r2=1.45\n
21160	kris.verbeeck@advalvas.be	1076410791000	I was able to reproduce the 'Failed to configure CA certificate chain' error\nmessage.  I started Apache and entered a wrong passphrase for the private key\nand got 'Error: Pass phrase incorrect (5 more retries permitted).'.  After that\nI entered the correct passphrase and got 'Ok: Pass Phrase Dialog successful.'. \nThen Apache failed to start (the other virtual hosts probably) and the error log\ncontained the certificate chain error.  When I enter the correct passphrase from\nthe beginning everything works allright.\n\nThen I patched the server with the patch given below and retested like above. \nApache now started succesfully.  So it seems that this error stack clearing\nreally is more than only cosmetic :)).
21160	Joe Orton	1076412197000	Wonderful, thanks Kris.  I've proposed the fix for inclusion in the next 2.0\nrelease.  Thanks for the reports.
21160	Joe Orton	1078942583000	*** Bug 13585 has been marked as a duplicate of this bug. ***
21160	Joe Orton	1086880141000	*** Bug 29496 has been marked as a duplicate of this bug. ***
21285	Massimo Torquati	1057169852000	The problem shows up on only with dynamic object generation. We have\ntested it using PHP and a small number of simple http clients.\n\nHow to reproduce the problem:\n\nSend object requests from some (2-3) clients (I wrote a simple client that at\nmax rate possible connect to server, post a GET request, read reply and close\nthe connection) to a simple php script (code follows) with the cache object\ncount very very small (Es. : MCacheMaxObjectCount 50).\n \nThe script produces different small objects (a few bytes in size)\nbased on an input variable (pippo.php?variabile=1234).\nIf you look at the cache size after some\ntime you see it decrease to zero and become negative. Eventually, some\nof the threads die because of a segfault.\n\n-------- Apache (2.0.46) configure command -------------\n\n./configure --with-mpm=worker --prefix=/apache-test/ --enable-mods-shared=all\n--enable-so --enable-cache=shared --enable-mem_cache=shared\n\n\n----- Cache configuration ------------- \n#\n# Sample Cache Configuration\n#\n<IfModule mod_cache.c>\n<IfModule mod_mem_cache.c>\nCacheEnable mem /\nCacheDefaultExpire 1000\nCacheMaxExpire 3000\nCacheIgnoreCacheControl Off\nCacheIgnoreNoLastMod    On\nMCacheSize 2000\nMCacheMaxObjectCount 50\nMCacheMinObjectSize 1\nMCacheMaxObjectSize 1048576\n</IfModule>\n</IfModule>\n\n---- php script code (pippo.php) ----\n<?php \nheader('Expires: Mon, 26 Jul 2005 05:00:00 GMT');\necho '<head>  </head>';\necho '<html> <br> html part <br> </html>';\nif (isset($_GET['variabile'])) { \necho 'mi hai passato '.$_GET['variabile'];\n}\nelse {\necho 'non mi hai passato niente';\n}\n?>
21285	Massimo Torquati	1057170076000	Created an attachment (id=7067)\nproposed patch for bug 21285 and bug 21287\n
21285	Massimo Torquati	1057170286000	The patch corrects the bugs 21285 and the bug 21287. \n\nI think there are cleaner ways to remove bug 21285; perhaps the simplest\none is to mark temporary objects in the cache as not removable. This\nclearly has consequences on the removing algorithm as well, though.\n\nIn the meanwhile, the patch I propose works well to eliminate the\nproblem, and has been extensively tested in the same settings with\nversion 2.0.44 and 2.0.46 . We have not tested if there are\ninteractions with other cache modules (e.g. mod_disk_cache).
21285	Jeff Trawick	1069453411000	enabling the PatchAvailable keyword\nupdated doc on submitting patches is at http://httpd.apache.org/dev/patches.html\n
21285	Jean-Jacques Clar	1071187123000	Created an attachment (id=9525)\nfix the defect w/o touching the pq functions\n
21285	Bill Stoddard	1071782877000	Fixed with this patch to Apache 2.1. Will port to an upcoming release of 2.0\n(2.0.49?)\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/experimental/mod_mem_cache.c?r1=1.99&r2=1.100
21287	Jean-Jacques Clar	1071259537000	Created an attachment (id=9549)\nextracted from patch in bug 21285, also mutex lock protection in remove_url\n
21287	Erik Abele	1071262119000	just adding the PatchAvailable keyword...
21287	Bill Stoddard	1071782898000	Fixed with this patch to Apache 2.1. Will port to an upcoming release of 2.0\n(2.0.49?)\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/experimental/mod_mem_cache.c?r1=1.99&r2=1.100
21370	keilh	1057584574000	Created an attachment (id=7121)\nmemory access checker output\n
21370	Joe Orton	1058789503000	Thanks very much for the report and patch; a variant of the patch has been\ncommitted to CVS.
21370	Joe Orton	1077711217000	*** Bug 22832 has been marked as a duplicate of this bug. ***
21371	Jeff Trawick	1057869561000	This is all Greek to me (i.e., it would take me a long time to figure out how to\ntest), but it looks like there is an off-by-one error in ssl_engine_vars.c that\nmesses up\nthe lookup of the cert chain info.  I'll attach a patch to test in just a sec.\n\nThe latest mod_ssl for Apache 1.3 has this change too.  I'd wager that\nbacktracking that line of code in prior releases of the original mod_ssl\nwould show that it got fixed after we imported it into Apache 2.0.\n
21371	Jeff Trawick	1057869635000	Created an attachment (id=7231)\nproposed fix for cert chain variable problem\n
21371	Jeff Trawick	1058204064000	The patch posted previously has been committed to Apache 2.1-dev and proposed\nfor merge to 2.0.48-dev.\n
21371	Mark Webb	1058301154000	I tried the patch and got the same results.  I do not think that the patch fixed\nthe problem.
21371	Jeff Trawick	1058353894000	Then I suppose more changes are required :(  The change in the patch corrected a\nblatant error which has also been fixed in the mod_ssl project for 1.3.\n\nDo you have any setup hints for testing this scenario?  Perhaps you can point to\nsome documentation?\n
21371	Mark Webb	1058358196000	This is what I do...\n\nto compile apache(2.0.47).  I am using openSSL 0.9.7b, compiled from source, and\ninstalled in /usr/local/ssl.\n./configure --enable-so --enable-ssl --with-ssl=/usr/local/ssl\ngmake \ngmake install\n\nto configure apache\ncreate a test cert for apache, set up ssl.conf properly.\nopen browser, point to test-cgi.\nobserve that certificate chain is not listed in the output.\n\nThis proves to me that the certificate chain is not being passed to the CGI, and\ntherefore would not be passed to a servlet either.  I am most interested in\ngetting apache to pass the entire certificate chain to a servlet, but am using\ncgi's to test with right now.  This is because it is easier to test, and takes\nthe tomcat connector stuff out of the equation.\n\nPlease let me know what more help I may be.
21371	Jeff Trawick	1058377848000	I'm stuck at the point of getting a certificate chain passed from the client. \n(No idea how to do that yet :) ).  I see SSL_CLIENT_CERT being set but with the\nfollowing patch to one of the mod_ssl files I see that OpenSSL is telling\nmod_ssl that there are zero certificates in the chain.\n\nTry testing with this patch to see if OpenSSL has provided mod_ssl with a chain.\nIf it hasn't, you'll see something like I did:\n\n[debug] ssl_engine_kernel.c(1064): [client 9.65.78.133] got peer certificate\nchain (0/8245458/8252f50)\n\nwhere the 0 after 'chain (' is the number of certificates in the chain returned\nby OpenSSL...\n\nIndex: modules/ssl/ssl_engine_kernel.c\n===================================================================\nRCS file: /home/cvs/httpd-2.0/modules/ssl/ssl_engine_kernel.c,v\nretrieving revision 1.82.2.6\ndiff -u -r1.82.2.6 ssl_engine_kernel.c\n--- modules/ssl/ssl_engine_kernel.c     16 May 2003 18:12:18 -0000      1.82.2.6\n+++ modules/ssl/ssl_engine_kernel.c     16 Jul 2003 17:28:03 -0000\n@@ -1059,6 +1061,9 @@\n         apr_table_setn(env, 'SSL_CLIENT_CERT', val);\n\n         if ((peer_certs = (STACK_OF(X509) *)SSL_get_peer_cert_chain(ssl))) {\n+            ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r,\n+                          'got peer certificate chain (%d/%pp/%pp)',\n+                          sk_X509_num(peer_certs), peer_certs, ssl);\n             for (i = 0; i < sk_X509_num(peer_certs); i++) {\n                 var = apr_psprintf(r->pool, 'SSL_CLIENT_CERT_CHAIN_%d', i);\n                 val = ssl_var_lookup(r->pool, r->server, r->connection,\n@@ -1067,6 +1072,10 @@\n                     apr_table_setn(env, var, val);\n                 }\n             }\n+        }\n+        else {\n+            ap_log_rerror(APLOG_MARK, APLOG_DEBUG, 0, r,\n+                          'SSL library returned no peer certificate chain');\n         }\n     }\n\n
21371	Joe Orton	1063716229000	Confirmed fixed in 2.0.46 + Jeff's off-by-one patch.\n\nMark, you did have 'SSLOptions +ExportCertData' set in the right context?\n\n(Mozilla doesn't seem to send the CA certs included in an imported PKCS#12 ccert\nfor me, neither will 'openssl s_client'; maybe MSIE does it, I had to hack my\nown code to reproduce this)
21443	Tim Jackson	1066403066000	Confirmed also on Linux.\nDoesn't appear to inhibit building with DB 4.0.14, at least as supplied by\ndefault with Red Hat 9, but does cause problems with the version supplied with\nFedora Core (Severn; 0.95) Test 3, which is DB 4.1.25.
21443	Ari Gordon-Schlosberg	1070564248000	Confirmed on Red Hat Enterprise Linux Advanced Server 3, using db4-4.1.25-8 from\nthe system RPMs.  The patch listed previously works.\n\nThis while attempting to compile apache-1.3.29.
21443	Joe Orton	1073991446000	Thanks for the report: that change would break with DB 4.0; committed this for\nthe next 1.3 release which works with both 4.0 and >=4.1:\n\nhttp://cvs.apache.org/viewcvs.cgi/apache-1.3/src/modules/standard/mod_auth_db.c?r1=1.50&r2=1.51
21443	Erik Abele	1074633766000	*** Bug 26294 has been marked as a duplicate of this bug. ***
21492	sebastien gautrias	1057914155000	Created an attachment (id=7239)\n.header and .data files\n
21492	R??diger Pl??m	1093337628000	I guess my problem is the same. I use mod_disk_cache to cache static files\ndelivered by Tomcat via\nmod_jk. Unfortunately you did not write if you are caching local files or remote\nfiles (delivered\nby mod_jk, mod_proxy or something similar).\n\nI noticed that when you abort the download of a file which should be cached and\nwhos origin is\non a remote server, the partly downloaded file gets cached.\nThe second request for this file only delivers the partly cached file and thus\nleads to the problems\ndescribed by you. In my case the problem showed up by incomplete jpg pictures.\n\nThe reason for this behaviour can be found in mod_disk_cache. mod_disk_cache\ndoes not notice\nthat a request has been aborted. I wrote a small patch (against 2.0.50) that\ndrops the partly cached file\nif the connection has been aborted. \nUnfortunately the CacheForceCompletion of mod_cache is not implemented right now\nsuch that nearly\ncompletely downloaded files get lost for the cache. But this is better than\ndelivering only\nparts of the files in the following requests.
21492	R??diger Pl??m	1093337688000	Created an attachment (id=12516)\nProposed Patch\n
21492	Paul Querna	1095624231000	Can you please test this in 2.0.51?\n\nLots of fixes for mod_disk_cache were made.
21492	R??diger Pl??m	1095938280000	I checked this with 2.0.51 and it is only partially fixed. It should work with\nlocal files, but it does not work if\nthe length of the content to be cached is unknown and the file is large as it is\nthe case if you cache large dynamic\ncontent originally created by Tomcat. And this is what I am doing. I try to\nlower the load on the Tomcats by caching\nlarge files generated by Tomcat that are valid for some time via mod_cache on\nthe webserver.\n\n\nThe problem is that in this case we get to line 663 of mod_disk_cache.c as the\ncondition in line 661 is true in\nany case (content written completely to file or only partially because the\nconnection has been aborted).\nSo this operation is handled as successful caching of the request in any case\neven if the content was only\nsaved partially.\n\n\nNevertheless the changes to mod_disk_cache provide an better environment now for\nthe needed changes so I provide\nan updated version of my patch for 2.0.51.
21492	R??diger Pl??m	1095938316000	Created an attachment (id=12847)\nPatch for 2.0.51\n
21492	Justin Erenkrantz	1096393309000	A variant of the 'patch for 2.0.51' has been committed to HEAD as\nmodules/experimental/mod_disk_cache.c rev 1.64.\n\nThanks!
21492	Graham Leggett	1097685795000	Backported to v2.0.53.\n
21495	Jeff Trawick	1057923638000	I can verify this problem with ab from Apache 2.1-dev on RedHat 8. \nInterestingly, apr_poll() hasn't changed in some time.  And yet ab hasn't\nchanged its use of socket I/O in some time either.  Go figure :)\n\nApparently the use of poll in ab is broken, as polling only for POLLIN is only\ngoing to catch failures to connect.\n\nGive this a spin (it works for me).\n\nIndex: ab.c\n===================================================================\nRCS file: /home/cvs/httpd-2.0/support/ab.c,v\nretrieving revision 1.126\ndiff -u -r1.126 ab.c\n--- ab.c        10 Jul 2003 19:16:35 -0000      1.126\n+++ ab.c        11 Jul 2003 11:32:52 -0000\n@@ -1268,7 +1268,7 @@\n            c->state = STATE_CONNECTING;\n            c->rwrite = 0;\n             new_pollfd.desc_type = APR_POLL_SOCKET;\n-            new_pollfd.reqevents = APR_POLLIN;\n+            new_pollfd.reqevents = APR_POLLIN | APR_POLLOUT;\n             new_pollfd.desc.s = c->aprsock;\n             new_pollfd.client_data = c;\n            apr_pollset_add(readbits, &new_pollfd);\n\nI rarely use ab myself, and the only testing of it that I did personally over\nthe last few releases has been over loopback, where I assume the connect\ncompleted synchronously and we didn't need to poll() until it completed.\n
21495	Kai Seidler	1057927518000	Yes, it works for me as well. Thanks a lot, Jeff!
21495	Jeff Trawick	1057970148000	For the record:\n\nWhile the patch I posted apparently makes it work, it is something of a kludge.\n\nab in 2.0.46 worked because of the way that apr_connect() was broken for purely\nnon-blocking sockets.\n\nOne would think that the poll condition between the initial connect call and\nwhen we know we've successfully found a partner would be simply POLLOUT, but it\ndoesn't work unless you have POLLOUT|POLLIN because the connect state is used\nfor more than just getting connected to the desired remote part.  Another issue\nis that we don't reissue the connect to find out whether or not it worked.  But\nthat isn't so easy because connect state is overloaded with some SSL setup.\n\nMaybe the kludge isn't so bad, since it may be some time before somebody feels\nlike cleaning house in ab and potentially breaking something else :)\n
21495	Jeff Trawick	1061837240000	*** Bug 22686 has been marked as a duplicate of this bug. ***
21495	Jeff Trawick	1064913952000	A fix for this will be in 2.0.48.\n
21523	Andr?? Malo	1057949058000	First: please try 2.0.47, which contains some further fixes.\nSecond: I can't believe, that mod_deflate compresses gzip if Accept-Encoding:\ncontains no gzip. I'd guess the compression takes place somewhere else.
21523	John Huong	1057978891000	Hi, sorry for the cross post. Anyway I'm sure it is a mod_deflate problem as \neverything works fine for the last 5 hours after I try the work around as \ndescribe in bug 9222. My problem would normally appear every now and then \nwithin an hour or two. I will try Apache 2.0.47 later on and see if I get the \nsame problem.
21523	John Huong	1058007041000	Ok I've upgraded to 2.0.47 this morning. I've done the tests with 5 SOAP::Lite \nclients sending 500 various types of requests(both valid and errorneous) each \nand without any special setenvif settings, and none of the server responses are \ngzipped. Looks great. Just curious, how come the 2.0.47 release didn't mention \nanything about fixing mod_deflate.. or was this problem attributed to other \nApache components? Thanks.
21523	Andr?? Malo	1058011218000	Oops... In fact,the changes were made in 2.0.46. Strange. This points to other\nsources of error as well, IMHO.\nI'll close the report for now. Don't hesitate to reopen it, if there are further\nissues.\n\nThanks for using Apache!
21523	John Huong	1059060807000	Created an attachment (id=7491)\nLoop test log file\n
21523	John Huong	1059060865000	Looks like I spoke too soon.\nI'm attaching the complete log file of my most recent loop test.\n
21523	Andr?? Malo	1059062506000	Hmm. The point is, mod_deflate only gets active, if the filter (DEFLATE) is\nadded *and* Accept-Encoding contains the gzip token.\nDid you add the filter somehow? What's the particular configuration?
21523	John Huong	1059087405000	Here are my settings for the filters.\n\n<Directory />\n    Options FollowSymLinks\n    AllowOverride None\nOrder Deny,Allow \nDeny from all \nAddOutputFilterByType DEFLATE text/html text/plain text/xml\nAddOutputFilterByType DEFLATE application/ms* application/vnd* \napplication/postscript\n</Directory>\n\n#\nDeflateFilterNote Input instream\nDeflateFilterNote Output outstream\nDeflateFilterNote Ratio ratio\n\n\nLogFormat '%h %l %u %t /'%r/' %>s %b /'%{Referer}i/' /'%{User-Agent}i/' In:%\n{instream}n Out:%{outstream}n:%{ratio}npct' comdef\n
21523	John Huong	1059087518000	Oh by the way.. the workaround in bug 9222 doesn't work either... the problem \nstill happens intermittently.
21523	Andr?? Malo	1059088187000	Well, and it does actually log instream/outstream/ratio for these requests?
21523	John Huong	1059094437000	I'll attach the access logs once I return from work.
21523	John Huong	1059129067000	Here is the line in the access log that matches the last entry in the attached \nlog file.\n\n127.0.0.1 - - [23/Jul/2003:08:07:50 +0800] 'POST /testsoap.php HTTP/1.1' 200 \n268 '-' 'SOAP::Lite/Perl/0.55' In:245 Out:250:102pct
21523	Joe Orton	1059136611000	Just to separate the two separate issues here:\n\n1) if you think that mod_deflate is gzip-encoding a response where the request\ndid not have 'gzip' in an Accept-Encoding header, can you attach a network trace\nagainst 2.0.47, or a log which includes the input and output headers (e.g a\nCustomLog with '%{accept-encoding}i {content-encoding}o'\n\n2) mod_deflate will indeed gzip-encode a response which already has\nContent-Encoding: deflate (given Accept-Encoding: gzip in the request, etc);\nthis is a different issue.
21523	John Huong	1059147587000	Ok I just tried what was recommended.. and I hit it again. Here is the output \nof the log.\n\n127.0.0.1 - - [25/Jul/2003:23:35:52 +0800] 'POST /testsoap.php HTTP/1.1' 200 \n268 '-' 'SOAP::Lite/Perl/0.55' In:245 Out:250:102pct 'deflate' 'deflate, gzip'\n\nHere's the logformat from my httpd.conf\n\nLogFormat '%h %l %u %t /'%r/' %>s %b /'%{Referer}i/' /'%{User-Agent}i/' In:%\n{instream}n Out:%{outstream}n:%{ratio}npct /'%{Accept-Encoding}i/' /'%{Content-\nEncoding}o/'' comdef
21523	Joe Orton	1059151439000	Created an attachment (id=7518)\naccept-encoding parsing fix\n
21523	Joe Orton	1059151467000	I may be on a wild goose chase, but can you try that patch?
21523	John Huong	1059152039000	Sorry, unfortunately I don't have any compilers with me right now on my Windows \nsystem and at home. Is there something like a nightly build I could run my \ntests against?
21523	John Huong	1061260228000	Any chances of this being fixed in 2.0.48?
21523	Andr?? Malo	1061296446000	Ha, Joe, you've found the problem! We skip the /0 delimiter and search somewhere\nin the memory... Therefore it occurs *sometimes*.\nI've finally committed a fix to 2.1 and proposed it for backport.\n\nThanks!
21523	Jeff Trawick	1069453548000	already fixed in 2.0.48 :)
21539	Erik Abele	1058049437000	This is fixed in CVS now and will be on the website soon. Thanks.
21648	Glenn Nielsen	1058357630000	Created an attachment (id=7328)\nRemove piped log program '(null)' failed unexpectedly error on apache restart\n
21648	Jeff Trawick	1069453741000	FYI... this can happen at apachectl stop too*... another PR, another patch which\nshould close this hole as well :)\n\nincidentally, part of this other patch is some infrastructure to get your\nmarvelous cgid restart patch working with prefork, which in turn will let us\nmerge it to stable\n\n*whether any of this happens seems to be timing related...  number of piped\nloggers, OS, MPM, each are inputs to a function I cannot understand that\ndetermines if this bogosity occurs\n
21648	Jeff Trawick	1071354089000	Fix committed to 2.1-dev.  Hopefully it can be committed to stable branch before\ntoo terribly long.\n
21668	Jesse Tie-Ten-Quee	1058396392000	Created an attachment (id=7338)\nPatch to fix bug.\n
21668	Andr?? Malo	1067727873000	Fixed in 2.1 and proposed for backport into the 2.0 stable branch.\n\nThanks for your report and thanks for using Apache!
21726	Andr?? Malo	1058630043000	Hmm, did you try using the MultiViewsMatch directive? I bet this will solve that\nproblem.
21726	S??nke Tesch	1058641090000	MultiViewsMatch works, thanks. Maybe Apache 2's defaults should follow more\nclosely to the paths Apache 1 set?
21726	Andr?? Malo	1058792514000	hmm. IIRC that was a design decision, because of *better* defaults...\n\nThere is also ia note at <http://httpd.apache.org/docs-2.0/upgrading.html>.\nShould we place it additionally somewhere else?
21726	S??nke Tesch	1058795688000	About the 'better defaults':\nI do agree that selecting forgotten .old or .bak files by negotiation is surely\nnot what the site maintainer wants, but if there is something (read: handler or\nfilter) mapped to an extension, why not choose it? Looks to me like the\ndevelopers did a step too far, instead of selecting too much, negotiation now\nselects too few. And that 'too much' wasn't a big problem anyway (IMHO of course:).\n\nBut apart from that, a short note about the changed behaviour on the\nmod_negotiation page would be helpful.
21726	S??nke Tesch	1058798919000	Maybe I should add that any description of the new behaviour _at all_ would be\nnice. There's not a single word in the mod_negotiation docs about excluding\nhandlers/filters and un-MIME-fied files by default; nutpickers could even argue\nthat the current Multiviews description is wrong as it just lists the 'client's\nrequirements', which 'to handle or not to handle' is surely not part of :)\n\nA 'See also: MultiViewsMatch' should be there, too.\n\nMmh, reopening as documentation bug.
21726	Joshua Slive	1058999804000	In a large part I agree with you.  But the idea behind the change is\nthat mod_negotiation is meant for content-negotiation.  Using\nMultiViews to omit the extension really has very little to do with\nnegotiation.\n\nBut I'll go add a couple notes to the docs to improve this.\n\nThanks for using Apache!
21737	J. Nick Koston	1058724438000	Created an attachment (id=7406)\nreverse what happened in 1.3.28\n
21737	J. Nick Koston	1058724485000	I've been having the same problem.  Please try that patch I attached.  
21737	J. Nick Koston	1058725195000	The problem is that when running under suexec you cannot send the process\nsigterm since apache and the script are running with diffrent uids.  Apache\n1.3.28 beleives the process is dead because the kill failed and sets\np_kill_how=kill_never.  It really should look for -ESRCH.
21737	J. Nick Koston	1058726101000	Created an attachment (id=7407)\ninstead of reverse ... fix\n
21737	J. Nick Koston	1058726216000	The second patch implements a fix instead of reverting things back to the way\n1.3.27 handled things.
21737	J. Nick Koston	1058726890000	This probably should be critical as it causes servers to crash.
21737	J. Nick Koston	1058727001000	*** Bug 21739 has been marked as a duplicate of this bug. ***
21737	rcs	1058727134000	I don't think the patch works (either of them). Still got new defuncts.\nHowever I tested on one server only.
21737	rcs	1058727480000	sorry about severity change, new to bugzilla.\n\n(altho I haven't experience any crushs on 7 servers some with multiple instances\nof apache).
21737	J. Nick Koston	1058731267000	Can you get it to reliably create a defunct process by doing the following?\n\n> a) Put a this script in your cgi-bin\n> --cut here--\n> #!/usr/bin/php\n> <?php phpinfo(); ?>\n> --cut here--\n> \n> b) Go to it your web browser.  Click reload over and over again (this\n> will eventually cause a sigpipe). \n> \n> c) watch the zombies build up
21737	rcs	1058734314000	The problem is fixed, I forgot I had another apache on that server. sorry for\nextra work I caused.
21737	J. Nick Koston	1058735614000	Just to confirm, the patched apache is working correctly?
21737	J. Nick Koston	1058735681000	*** Bug 21746 has been marked as a duplicate of this bug. ***
21737	rcs	1058736247000	I'm not sure now. I manualy patched (with the second patch) few servers and they\nlook fine, one cpanel server (with the first patch) still defuncts. not sure\nyet if it's me of the patch.
21737	rcs	1058736465000	second cpanel defuncts.
21737	rcs	1058736622000	second patch also defuncts. so to sum it, the patches don't work.
21737	rcs	1058737220000	I can create a defunct process with the script above and get it about 80% of the\ntime. The defunct process is gone very quickly now.
21737	J. Nick Koston	1058738814000	You should probably still get defunct processes (the same thing happens in\n1.3.27 and below), but they shouldn't exist for more then 5 or so seconds cause\nthere is still a wait time between the time sigpip is recieved and the timeout.\n This should be ok though.
21737	John	1058739469000	> You should probably still get defunct processes (the same thing happens in\n> 1.3.27 and below), but they shouldn't exist for more then 5 or so seconds \ncause\n> there is still a wait time between the time sigpip is recieved and the \ntimeout.\n\nOh no!\nThe defunct-processes won't clean automaticly!
21737	J. Nick Koston	1058747268000	John:  do you still see them lingering after using the patch?
21737	Cliff Woolley	1058754316000	Just so you know, we (the dev team) have seen this bug report and are looking into it.  Thanks \nfor the detailed investigation! 
21737	147099.vserver.de	1058785011000	The patch does not help!
21737	Tim Greer	1058855571000	This appears to be the modified PHP-suexec patch you have that is broken.  Note \nthis is likely only a problem for users that use Cpanel and the Apache version \nwith the newly updated alloc.c patch--looking at it, it is a source of more \nproblems.  You are looking in the wrong place.  The php-suexec patch that I've \nmodified myself and use with Apache 1.3.28 does not suffer from these problems \nat all.  I believe that is the cause of your problems and your alloc.c patch \ncauses more (look at the modifications to see why!)  Maybe I'm wrong, but this \nis how it appears looking at the patch and the alloc.c patch as well seems to \ncause yet more issues.
21737	Tim Greer	1058855735000	I.e., it's ignoring -USR1 hup's and so on, which is also conflicting with your \ncontrol panel on new account set ups and so on, which is causing more users to \nsubmit reports about this version of Apache having this bug, which beyond the \nPHP-SuEXEC patch and the messed up alloc.c patch, doesn't exist (*from what I've \nseen*--I may be wrong, but it _is_ a source of additional problems).
21737	Tim Greer	1058857124000	While I have actually been able to confirm this on .28 with the PHP-suexec patch \nunder specific circumstances--I am not able to reproduce the problem for .28 nor \n.27 without that patch being implemented.\n\nHas anyone experienced this issue that is not using the PHP suexec patch from \nhttp://www.localhost.nl/patches/ (or a similar source), be it a modified version \nof this patch or not?  I.e., the problem exists on installs without this?  I've \nnot been able to reproduce it without this patch being implemented.\n\nEither way, the alloc.c patch is not the solution, at least not a complete \nsolution and opens up other problems, with some tests.  More information about \nthat later, if it's needed.
21737	cheewai	1058925402000	Not sure why the comments I added is not in.\n\nI can confirm the problem as well. My setup is stock apache1.3.28 (no php-suexec\npath) with modssl 2.8.15-1.3.28 and php 4.3.2. A simple test script that only\ndisplay 'hello world' will stay as a defunct process owned by the suExec user.\nThe defunct process only went away after a restart of the apache processes.
21737	Tim Greer	1058925962000	Odd, I've not been able to recreate this on non 'PHP for CGI w/ SuEXEC' patched \nsystems, but I sincey you experience it as well, I personally assume it relates \nto CGI and SuEXEC.  Has anyone confirmed this on non-SuEXEC enabled installs?
21737	J. Nick Koston	1058938623000	I'm not sure why the first patch would cause USR1 not to work.  The patch just\nreverts parts of alloc.c to 1.3.27.   
21737	Tim Greer	1058940552000	I was mistaken.  This was not related.  The patch did cause other problems \nthough.  I will attempt to recreate the problem in various ways and report it in \nthe very near future.  However, since this doesn't seem to be the overall \nsolution and more of a quick fix, I suppose there's no need.
21737	J. Nick Koston	1058941422000	Which patch are you using?  The first one or the second one.  \n\nI've reviewed the second one:\n\nhttp://nagoya.apache.org/bugzilla/showattachment.cgi?attach_id=7407\n\nand I can't see how it could cause a problem.   I'm not so sure about the first\none though.
21737	Christian Noack	1058944878000	I confirm the bug for Apache 1.3.28/mod_ssl-2.8.15-1.3.28/php-4.3.1 running on\nOpenBSD 3.2. The fix (7407) seems to be working here.
21737	cheewai	1058955261000	I applied the patch 7407 and it seems to fix the problem. Now the suEXEC process\nno longer stayed in zombie state.
21737	Mads Toftum	1059388408000	*** Bug 21926 has been marked as a duplicate of this bug. ***
21737	tchesmeli	1059389675000	with the second patch: \nhttp://nagoya.apache.org/bugzilla/showattachment.cgi?attach_id=7407 \nseems to be ok. \nI got some defunct process butthey are killed in few seconds. Looks good, thanks. 
21737	EvE	1059397602000	We had severe zombie problems as well after upgrading to 1.3.28 (on Solaris \n2.8). Compiling with the second (7407) patch solved the zombie problem for us \nas well.
21737	Tim Greer	1059405947000	This second 'patch' is just reverting back to the alloc.c file for .27 instead \nof .28.  Has anyone noted any impact due to this?  This does seem to help, but \nnot completely remove the issue.  Also, bypassing the function(s) in .28--does \nthis matter?  It seems to be a logic error.
21737	J. Nick Koston	1059454907000	The first patch is the one that revents, the second one is the one that should\nfix the problem with keeping the current logic.
21737	J. Nick Koston	1059454958000	s/revents/reverts (gee 1am)
21737	Tim Greer	1059457508000	I meant first, not second. :-)
21737	EvE	1059644556000	What will happen with this patch in the future? Will this be part of 1.3.29 or \nwill it become an official patch? We like to know that before we start \nupgrading all our other apache 1.3.27 instances.
21737	Tim Greer	1059666613000	Though I am not the person that would authorize anything as official or have \nany control over what Apache does, and I don't personally assume this would be \nimplemented in .29 or be official (what do I know), I still recommend you \nupgrade to .28 and implement this patch if you find you have to (or create some \nsolution yourself that maybe you feel more comfortable with otherwise).  You \ndon't want to stick with .27 at this point anyway.
21737	Jordan Russell	1059768855000	For me, patch 7407 works like a dream. I have yet to see any zombie processes \nwith my PHP script or with the 'phpinfo()' script mentioned above. Before, I \ncould reproduce the zombies quite easily - about 50% of the time with my script \nand 100% of the time with the 'phpinfo()' script.\n\nBTW, I'm not using any 'PHP-suexec' patch.
21737	Tim Greer	1059778113000	Hi Jordan,\n\nI'm curious, do you have suexec enabled?  If so, do you have this problem \nwithout it enabled?
21737	Tim Greer	1059778294000	Sorry if that sounded obvious to ask, given the history of the reports. :-)
21737	Jordan Russell	1059779665000	Yes, I use suexec.\n\nI just tested the phpinfo() script on a virtual site that does NOT use suexec, \nand I get no zombies while holding down the browser's Refresh key (F5 in \nInternet Explorer).\n\nWhen the same script is run on a suexec site, I get about 10 zombies per second \n(great potential for DoS?). Patch 7407 fixes this for me.
21737	Tim Greer	1059780040000	How about on a build without suexec compiled in as an option, rather than a \nsite without it enabled on a build that has it?  I'm just testing out a few \nthoeries that likely have little to do with your problem, but I'd like to see if \nanyone sees this on a non-suexec build... and if so, how long they take to die \noff.  If you don't mind anyway.  Thanks.
21737	Jordan Russell	1059780633000	I tested the phpinfo() script on a 1.3.28 server that doesn't have suexec \ncompiled in, and got no zombies.
21737	Ruud van Melick	1059845940000	Ralf S. Engelschall posted a different patch on apache-http-dev:\nhttp://marc.theaimsgroup.com/?l=apache-httpd-dev&m=105952652425849&w=2\n\nIs that patch better than 4707?\n
21737	J. Nick Koston	1059846937000	Either one should work just as well
21737	Tim Greer	1059855425000	Yes, it would be a better overall patch, though, as he stated himself, the \noriginal one works, but could be improved--which it seems it was.  I'd recommend \nusing this other patch by Ralf overall.
21737	Erin Fortenberry	1060891048000	The FreeBSD port apache13-modssl (Apache 1.3.28 + ModSSL 2.8.15) has been \nupdated to include the 4707 patch. My server with heavy CGI (Perl and PHP) was \ncreating zombies left and right, about 5000/hour.\n\nI like the 4707 patch. It made me happy again.
21737	Ari Pollak	1062537457000	This patch does not work for me. I'm using suEXEC, mod_ssl compiled as a DSO,\nmod_frontpage_mirfak, mod_gzip, mod_pointer, and mod_throttle, all compiled as\nDSO modules.
21737	Ari Pollak	1062537617000	I should note that the patch given on the mailing list works fine.
21737	Jeff Trawick	1062597045000	This is the patch that actually got committed (yesterday):\n\nhttp://cvs.apache.org/viewcvs.cgi/apache-1.3/src/main/alloc.c.diff?r1=1.145&r2=1.146\n\nIt is slightly different than the patches that were posted to the mailing\nlist, but it addresses all known concerns.\n\n
21737	Eric Seidel	1062627173000	I applied the patch for alloc.c as is in the CVS tree to a APACHE_1_3_27 source.  I failed to correct \nthe problem for me under Mac OS X 10.3... investigating further...
21737	Eric Seidel	1062636674000	I have confirmed, this condition still exists on Mac OS X 10.3 with this patch.  I patched the 1.3.28 \nsources (I erred in my comment above).  And was still able to reproduce this.\n\nI did extensive further testing and found that both Mac OS X, and FreeBSD violate the POSIX \nspecification for kill() and return ESRCH, when sending a signal to a zombie process.\n\nThis violation introduces a race condition with this patched code, as a process could finish (become \nzombie) after the NEED_WAITPID 'waitpid' cleanup, but before the ap_os_kill() call and thus return \nESRCH, be marked as kill_never, and then never be cleaned up.\n\nAlthough it is my hope that Mac OS X 10.3 final will have fixed this error.  Apache is still left with \nan interoperability problem on Mac OS X 10.2 and likely FreeBSD (as they share this same \nvioloation).\n\nI have attached my program 'main.c' which tests for this phenomenon.
21737	Eric Seidel	1062636741000	Created an attachment (id=8055)\nA program to test errno after signal to zombie process.\n
21737	Eric Seidel	1062690702000	Thinking about this a little more... I think there are two options here:\n\n1.  Come up with a solution, not dependant on this behaviour of kill...  (moving the waitpid to after \nthe kill call should be sufficient?)\n\n2.  Add a configure.in rule to check for the POSIX compliance to kill and conditionally deal with it's \ncompliance or non-compliance accordingly.  There may be other systems (besides OS X and \nFreeBSD) which have this ESRCH behaviour when sending to zombies...
21737	Eric Seidel	1062702884000	Here is a 'hack' which fixes the problem on Mac OS X (likely FreeBSD as well).\n\n-           if (ap_os_kill(p->pid, SIGTERM) == -1) {\n+           if ( (ap_os_kill(p->pid, SIGTERM) == -1) && (errno == ESRCH) ) {\n+               // in case ESRCH means 'zombie'.\n+                waitpid(p->pid, (int *) 0, 0);
21737	Eric Seidel	1062730775000	Unless I'm mistaken, can't kill return EPERM for setuid processes?  Wouldn't that also leak?
21737	Jeff Trawick	1062760728000	Another data point: I received an e-mail from a Tru64 user indicating that the\npatch as committed failed there too, and that Ralf's patch worked fine.
21737	Jim Jagielski	1062765865000	Because of the bogusness of how some OSs handle errors from KILL, I've changed us to simply kill \nand wait. 
21743	Andr?? Malo	1058792220000	Fixed in CVS.\n\nThanks for your care and thanks for using Apache!
21779	Joe Orton	1058819269000	Thanks for the report - it is simple enough to reject these requests.
21779	Joshua Slive	1059664591000	*** Bug 22023 has been marked as a duplicate of this bug. ***
21779	Amit Athavale	1072773721000	I have a simple patch for this, where it checks non-null condition for\n'r->parsed_uri.fragment'. If its not NULL, it rejects the request with 403\nresponse and log a message. (Currently its for DELETE and MOVE which are most\nharmful in such cases)\n\nShould I post it for review, if anybody haven't put up a fix yet :)
21779	Amit Athavale	1073565862000	Created an attachment (id=9857)\nPatch to fix this bug (rejects requests with uri fragments)\n
21779	Amit Athavale	1073565900000	PatchAvailable
21779	Erik Abele	1073566197000	Ahmit, thanks for adding PatchAvailable but this belongs into the Keywords field :-)
21779	Amit Athavale	1073724170000	I know PatchAvailable is from keyword list. And I thought one suppose to put\nthat keyword after submitting patch. Isnt this right ?\n\nSorry this is my only second patch, so please excuse me if I have done something\nterribly wrong. :)
21779	Joe Orton	1073769763000	Thanks for the patch and report, a version of your patch was committed to the\n2.1 tree and proposed for backport to the next 2.0 release.
21830	Andr?? Malo	1058976371000	*** Bug 21829 has been marked as a duplicate of this bug. ***
21830	Robert Siemer	1058979685000	I was asked for more explanation...\n\nThe issue is a documentation bug. The documentation is wrong because a\n'correctly implemented HTTP/1.1 request' could still get a response which is\ndifferent for different 'LanguagePriority' settings.\n\nGET / HTTP/1.1\nHost: httpd.apache.org\n\nis a correct HTTP/1.1 request and does not differ from HTTP/1.0 in Content\nNegotiation aspects...\n\nRobert
21830	Joshua Slive	1058999567000	I think you're nit-picking a little.  But yes, in 2.0 sometimes LanguagePriority\ndoes have an effect, even with a properly configured HTTP/1.1 client.\n\nI'll fix it.\n\nThanks for using Apache!
21873	Erik Abele	1059158164000	This is 'fixed' in both, the 2.0 and 2.1 versions of the documentation and should be on the website \nsoon. Thanks for using Apache.
21874	Erik Abele	1059158151000	This is 'fixed' in both, the 2.0 and 2.1 versions of the documentation and should be on the website \nsoon. Thanks for using Apache.
21944	softspt@gchq.gsi.gov.uk	1060699945000	Created an attachment (id=7772)\nMinimal example of problem with SSL & nph\n
21944	softspt@gchq.gsi.gov.uk	1060700008000	I think I'm seeing the same problem under Solaris 2.6. I've attached a \nminimalist Perl script that demonstrates the problem; run under a non-SSL \nserver, it redirects immediately to the home page, whereas running it under an \nSSL server causes it to wait for the sleep to terminate before doing the \nredirect. Could be a buffering issue somewhere?\n
21944	softspt@gchq.gsi.gov.uk	1068051225000	The SSL streaming problem still exists in 2.0.48 under Solaris 2.6.\n
21944	Joe Orton	1068052222000	Confirmed on Linux too, thanks for the reports.
21944	Joe Orton	1074877291000	The fix is checked in to HEAD:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_io.c?r1=1.113&r2=1.114\n\nand will be proposed for backport for the next 2.0 release.  Thanks a lot for\nthe report.
21944	Markus Wennrich	1074890657000	Yes, confirmed, the patch works.\nThanks a lot! :-)
21964	Erik Abele	1059490322000	Thanks, it's fixed now in CVS for the 2.0 and 2.1 versions of this document (and also for the \nGerman translation) and should be on the website soon.
22030	Joshua Slive	1060791203000	*** Bug 22318 has been marked as a duplicate of this bug. ***
22030	Jeff Trawick	1062596798000	*** Bug 22900 has been marked as a duplicate of this bug. ***
22030	Rob Brown	1063222524000	This DoS vulnerability has been tickin me off for two months now. \nThe CGI is blocked on a write() to stderr trying so hard to shove the packet \ndown Apache's throat and httpd is blocked waiting for something from the CGI's \nstdout, which will never happen until that stderr is consumed, which also \nnever happens. \nMy system gets hundreds of processes with httpd and the CGI script deadlocked \nwith each other because if this issue.  I have to restart apache regularly to \navoid grinding the server to a pulp from wasted processes or 'Out of memory' \nerrors. But mostly it just reaches MaxClients all the time which prevents new \nhits from being allowed (thus creating a DoS on my machine). \nI'm surprised mod_cgi was already known to be borked in this way and not \nrepaired yet in the cvs source tree. \nAnyone with cvs write access to the httpd repository, I'm begging you to try \nto fix this. \n \nI bricked over modules/generators/mod_cgi.c with Jeff Trawic's version: \n \nhttp://www.apache.org/~trawick/mod_cgi.c \n \nAnd suddenly all the problems vanished on my linux box.  Thank you Jeff! \n \nIs there any reason why this is not incorporated into the httpd trunk source \ntree?  Does it break non *NIX platforms?  If so, would it be appropriate to at \nleast do something like the following: \n \n#ifdef LINUX \n(new version) \n#endif \n#ifndef LINUX \n(old version) \n#endif \n \nRolling back to Apache 1.3.28 also eliminates all these problems, but I cannot \nkeep running 1.3.x because I need to use the new version of mod_php which is \nnot supported as well on the old apache. \n 
22030	Nojan Moshiri	1063222857000	Diff the old mod_cgi and new mod_cgi leads to a number of changes.  It would be\ngreat if we could \nget an idea from the developers any pitfalls they may see with going up with the\nnew mod_cgi.  Is \nit safe to run on production??
22030	Rob Brown	1063225722000	Yes, the files seem quite different.  So many changes in fact that I got too \nbored (or lazy) to review everything.  I just used blind faith and replaced \nthe whole file.  I'm not sure if anyone is using it on production, but it \ncertainly works fine on my development system.  I am going to roll it out on \nmy production system now.  It can't be any worse than the old one! 
22030	Rob Brown	1063225909000	FYI: I just figured out how to buttwag around this bug until it can be \nrepaired.  Just force everyone to put this line at the top of all the perl \nscripts: \n \nuse IO::Handle; STDERR->blocking(0); \n \nEverything after the first 4096 bytes to stderr will be dropped, but at least \nthe server never falls into deadlock between the httpd and the CGI script.  \n 
22030	Nojan Moshiri	1063226143000	That's a great idea, maybe I can put that in CGI.pm or something.  But I have over 2000 perl \nscripts!! :-)\n\n
22030	Jeff Trawick	1063228626000	problems with ~/trawick/mod_cgi.c:\n\n1) buffers up the response, which is really uncool and breaks with cgis that\nneed to flush or which write huge responses\n\nthe code to parse http headers written by the cgi needs to be changed to get rid\nof the buffering\n\nhandle_script_stdout() needs to know when we've seen all the headers, then\nprocess them, then set ctx->headers_processed\n\n2) doesn't work on the ever-lame win32\n\ngroan\n\n3) needs the last few fixes to mod_cgi integraded\n\n4) doesn't help mod_cgid, which is needed by threaded MPMs\n\n5) isn't tested a whole lot\n\nbut of course you folks are helping with that\n\n--/--\n\nThe main problem to attack is #1...  with that solved, everything else is not so\nhard, other than Win32, which doesn't have to be solved.  I'll try to attack #1\nnow that I see some interest in it.  Alternately, somebody else play with it in\na debugger and see what I mean about needing to recognize when we've read the\nentire response header from the CGI and can get into the simple mode where we\npass all output down the filter chain as soon as we read it.
22030	Jeff Trawick	1064229717000	*** Bug 10515 has been marked as a duplicate of this bug. ***
22030	Jeff Trawick	1064847946000	*** Bug 23473 has been marked as a duplicate of this bug. ***
22030	Nojan Moshiri	1064936966000	This bug was issued as an Apache DOS vulnerability in a Symantec Security release yesterday. They \ncite going with the latest CVS release as a workaround.  \n\nJeff can you provide some guidance on whether  http://www.apache.org/~trawick/mod_cgi.c or \nthe latest CVS rev will be the most stable release.  I notice several diffs between the CVS version \nand the one in your home dir.\n\nThanks!
22030	Jeff Trawick	1064939848000	There is no fix in CVS for this problem.  There is no stable mod_cgi[d] that\nhandles 4097+ bytes from stderr mixed in with stdout processing.  I don't\nrecommend using any of the code in http://www.apache.org/~trawick/ in a\nproduction environment.\n\nI just uploaded jcgi.tar to www.apache.org/~trawick/.  Module was renamed to\nmod_jcgi so that hopefully it doesn't get confused with real code from CVS.\nThis has fewer big picture problems than the mod_cgi.c hacks I had before, and\nof course anyone is free to play with it and comment.  See included STATUS file\nfor some notes.\n\nFor production users: if your CGI spews gobs of stuff to stderr, change the CGI\nfor now.  For folks debugging CGIs and want to have them temporarily spew gobs\nof stuff to stderr, play with the hacked up version mentioned here and send me\ntestcases for stuff that doesn't work.\n\nAs always, anybody should feel free to make alternate changes to the real\nmod_cgi[d] and submit patches to dev@httpd.apache.org.\n
22030	Greg Stein	1065683563000	I raised this bug a long while back (Sep 25, 2002, actually:\nhttp://marc.theaimsgroup.com/?l=apache-httpd-dev&m=103291952019514&w=2) and\nsuggested a new 'CGI bucket' type that kept both stdout and stderr descriptors\nfrom the CGI process. When the bucket read() function is called, it would\nselect() across both descriptors. Content from stdout would spawn a new bucket,\nand content from stderr would be logged.\n\nThen wrowe went off with a crazy super-solution which caused a total loss of\nfocus on the practical problems.\n\nMy suggestion still stands: have mod_cgi(d) inject a new CGI_BUCKET into the\nfilter stack which can drain both streams. No more hangs. Ever. No buffering.\nWorks for both cgi implementations. Works on Windows (presumably, since we're\nusing standard apr functions to poll across the two descriptors).
22030	Jeff Trawick	1065695502000	mod_cgid does not have this particular hang problem because the script's\nstderr refers directly to the error log.\n\nNote that mod_cgid has some other issues with error log, but they are of lesser\nsignificance.  The two I can think of are:\n\n+ writing to syslog doesn't work\n+ the main error log is always used, instead of the vhost-specific error log\n\n(there are entries in this bug database already for these issues)\n
22030	Jeff Trawick	1065696755000	Regarding Greg's comments about a special CGI bucket type being produced by mod_cgi:\n\nThere is another issue to solve with mod_cgi[d] that exists in 1.3 as well:\nhangs will occur if all body data isn't read first, before the script starts\nproducing output.  Clearly this isn't something that many scripts have\nencountered, but solving this enables some interesting CGI behavior.\n\nMy own work on this problem has been to handle all three channels (script's\nstdin -- request body, stdout, and stderr) right in mod_cgi.  Sending a special\nCGI bucket down the filter chain to solve the stdout/stderr problem doesn't deal\nwith writing request body to the script as the script can handle it.  With the\nI/O handled directly in mod_cgi, an extra channel doesn't need a different model.\n\nAn unfortunate problem to solve regardless of where stderr is read is that APR\ndoesn't support polling on pipes on Win32.  In the long term hopefully some\nWin32 gurus will provide a workable solution, but in the short term special\nhandling is required.  (See APR_FILES_AS_SOCKETS.)\n
22030	Carl Brewer	1073269781000	For what it's worth, this is proving to be a real problem for us attempting to\nmigrate to apache 2.0 from 1.3 on UNIX (linux).  Is anyone actively looking at\nthis or has it fallen off the radar?
22030	Jeff Trawick	1073338945000	Carl, you can try http://www.apache.org/~trawick/jcgi.tar\n
22030	Carl Brewer	1073340922000	Thanks Jeff, is this likely to make it into 2.0.49?  I'm pretty keen on sticking\nto production releases on our production servers :)
22030	Jeff Trawick	1073479197000	definitely not going to make it to 2.0.49
22030	Carl Brewer	1073516998000	*nod*.  This ticket's been open for some time now (some 4 months), do you know\nif/when it may be fixed in the release?  2.0.50? :)
22030	Alec Edworthy	1080137069000	Is there any news at all on when this bug might get fixed please? Thanks.
22030	Jeff Trawick	1080137721000	Scroll up from the bottom of the PR to find an alternate mod_cgi which has a\nredesigned interaction with the script.  Little or no feedback on that so far.\n
22030	Alec Edworthy	1080209972000	Thanks Jeff. I gave jcgi a very quick spin a couple of months ago but didn't\nmanage to make it work (although I didn't try that hard at the time). I will try\nagain sometime soon and see if I have any more luck.\n\nHow urgent is fixing this bug viewed as by those who are actively working on\nApache? Obviously to me it seems pretty important because it breaks all my\nscripts (although I'm sure that it could be argued that my scripts are at fault\nfor sending so much to stderr) but I don't really have that much knowledge of\nthe internals of Apache and what other issues are outstanding against it at the\nmoment. Are we likely to see a proper fix for this included in a production\nrelease in the foreseeable future or will work arounds within scripts and fixes\nlike Jeff's be the norm for now?
22030	Wayne Scott	1080219942000	I have to agree with Jeff.   Having the server to hang with no explanation\nwhen your error output reaches some magic threshold is hopeless broken.\nIt is the type of problem that won't show up in testing, but will break after\ndeployment.   This is a 'I can't trust Apache 2.0' problem.
22030	Jeff Trawick	1080221172000	>How urgent is fixing this bug viewed as by those who are actively working on\nApache?\n\nEmperical evidence would suggest that it is not very important.\n\n>Are we likely to see a proper fix for this included in a production\n>release in the foreseeable future or will work arounds within scripts\n>and fixes like Jeff's be the norm for now?\n\nI have no idea about the first question.\n\nThe answer to the second question is, in general, no.  This particular situation\nis one which requires a complete redesign of how mod_cgi interacts with scripts.\n I have made a set of code available which for Unix has a design that should\nsolve this problem, it works for my testcases, etc.\n\nAnother unusual example: 2.0.49 provided an overhaul of mod_include with\ncompletely new parsing engine and a number of existing problems resolved.  For\nquite a while, people with 2.0.x  mod_include problems were asked to try this\nalternate implementation.  After a relatively long time it was merged into 2.0.x\nfor the 2.0.49 release.\n\nIf somebody has time/energy to move the ball forward they can offer their own\nsolution or try out what I have and offer feedback.\n\nIf somebody does not have time/energy to help move the ball forward they can\nalways buy commercial support for Apache or an Apache-based server and complain\nto the vendor that it does not meet their requirements.\n\nOr modify scripts to redirect stderr or not output so much stuff to stderr.
22030	Dave Evans	1082012005000	My lame workaround has been to start all my CGIs by re-opening STDERR to a plain\nfile: open(STDERR, '>>/tmp/error.log').  Yuck.\n\nWithout that hack, this is bug a show-stopper for me too - there's no way I\ncould deploy httpd2 on a system with CGIs I don't 100% trust (e.g. the shared\nwebserver we virtualhost all our customer's webs on).
22030	Joe Orton	1082018455000	How about taking the simpler 'CGI bucket' approach for a lower risk change to\nincorporate into 2.0 than the fundamental rewrite:\n\n- fix just the regression since 1.3 (not the issue of handling stdin too)\n- simple #if APR_FILES_AS_SOCKETS to avoid breaking Win32\n\nI have a patch to implement this based largely on mod_jcgi and the existing\napr_buckets_pipe.c.
22030	Joe Orton	1082023066000	Implementation of CGI bucket:\n\ndiff against HEAD: http://www.apache.org/~jorton/mod_cgi-HEAD.diff\ndrop-in replacement for 2.0 mod_cgi.c: http://www.apache.org/~jorton/mod_cgi.c\n\none known issue: fail gracefully if script closes both stderr and stdout\n\nFurther testing welcome.
22030	Jeff Trawick	1082027766000	Any reason not to commit to HEAD and get more eyes on it?\n\n(I'll try to do some detailed testing in next 36hr either way.)\n
22030	Joe Orton	1082033674000	OK can do, will resolve that last issue first though.
22030	Rob Brown	1082084714000	Joe, you're a total genious!  I patched my httpd.spec file as follows: \n \n---- snip ---- \n=================================================================== \n--- httpd.spec  18 Nov 2003 00:52:34 -0000      1.16 \n+++ httpd.spec  16 Apr 2004 02:27:23 -0000 \n@@ -33,6 +33,8 @@ \n Source31: migration.css \n Source32: html.xsl \n Source33: README.confd \n+# Add Joe Orton's awesome CGI Bucket feature so large STDERR output won't \nchoke anymore! \n+Patch0: http://www.apache.org/~jorton/mod_cgi-HEAD.diff \n # build/scripts patches \n Patch1: httpd-2.0.40-apctl.patch \n Patch2: httpd-2.0.36-apxs.patch \n@@ -128,6 +130,9 @@ \n fi \n  \n %build \n+ \n+patch modules/generators/mod_cgi.c < $RPM_SOURCE_DIR/mod_cgi-HEAD.diff \n+ \n # update location of migration guide in apachectl \n %{__perl} -pi -e 's:/@docdir/@:%{_docdir}/%{name}-%{version}:g' / \n        support/apachectl.in \n---- snap ---- \n \nAnd then I rebuilt the package and upgraded the rpm.  (I couldn't use the \nstandard rpm '%patch' because I think Joe forgot to include the \n'http-2.0.49/modules/generators/' prefix in the diff headers in his patch \nfile.)  After restarting, all my problems immediately disappeared.  I'm \nputting this on my PRODUCTION servers right now.  (I never close STDERR in any \nof my CGIs anyway.) \n \nThank you! \n 
22030	Alec Edworthy	1082458945000	For what it's worth the patch seems to work fine for me. My CGI scripts now\ngenerate the error_log text I would expect and the output appears in the browser\nas expected with no delays. Will this fix (or a patch based upon it) get worked\ninto a proper release sometime in the future?\n\nThanks Joe!\n\nAlec
22030	Joe Orton	1082539719000	Thanks for testing it out.  This will go into a future 2.0 release only if\nenough developers have confidence it is suitable for a 2.0 release: the more\nreports of successful testing here the more confidence will be inspired.
22030	Joe Orton	1083786026000	The fix for this is now committed to HEAD, but needs more testers. \nhttp://www.apache.org/~jorton/ has:\n\n- mod_cgi.c - a drop-in replacement for the 2.0.49 mod_cgi.c\n- mod_cgi-2.0.diff - a diff against the 2.0 mod_cgi.c\n\nPlease post any additional results from testing here.
22030	Nic Doye	1083794859000	The trivial testing I have done so far on RHEL ES 3 with Interchange 5 (which is\nCGI intensive) shows that this patch works perfectly.
22030	Jeff Trawick	1083871233000	*** Bug 28816 has been marked as a duplicate of this bug. ***
22030	Carl Brewer	1085619427000	This has been marked as closed, but is there any news on which release of httpd2\nthat the fix will land in?
22030	Joe Orton	1085649106000	It requires one more developer vote for inclusion in a future 2.0 release.  The\nmore people who test it, the better: there are 14 people on the CC list for this\nbug but only 3 have taken the time to test out the patches so far.
22030	Joe Orton	1086302042000	*** Bug 28025 has been marked as a duplicate of this bug. ***
22030	Andr?? Malo	1086994688000	*** Bug 29533 has been marked as a duplicate of this bug. ***
22030	Joe Orton	1087375409000	This is committed for 2.0.50 now.\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/generators/mod_cgi.c?r1=1.148.2.7&r2=1.148.2.8
22030	Rob Brown	1087427491000	Thank you Joe! \nI've been needing this fix for a long time. \n \n-- Rob 
22030	Joe Orton	1089645580000	*** Bug 28656 has been marked as a duplicate of this bug. ***
22030	Joe Orton	1089747296000	*** Bug 20866 has been marked as a duplicate of this bug. ***
22030	Joe Orton	1093380082000	*** Bug 23528 has been marked as a duplicate of this bug. ***
22030	Joe Orton	1096654316000	*** Bug 19315 has been marked as a duplicate of this bug. ***
22030	David Trusty	1097720398000	I just tried version 2.0.52 and this problem persists.  I am running \nRedhat 9.\n\n
22030	Joe Orton	1097735043000	David, please open a new bug describing the problems you have with 2.0.52,\ninclude  a reproduction case if possible.  The bug covered here was fixed in 2.0.50.
22030	dougapache@claar.org	1145552099000	I have entered a new bug, 39342, that I believe is related to this. In that\ncase, mod_cgi is writing a large amount of data to stdout before attempting to\nread from stdin, which contains a large POST.
22061	Mads Toftum	1059764463000	First of all, you're using a very old version of Apache, please try again with\n1.3.28.\nSecondly we need more information, especially the exact configuration you used\nto provoke the segfault.
22061	Joshua Slive	1059772601000	I think he's just complaining about an innaccuracy in the rewriteguide.\nIt was written before the RedirectMatch directive existed, so it\nthinks there is no other way to redirect a single URL-path like '/'.
22061	Eloi Granado	1059814754000	Just as Joshua Slive has stated, I was 'complaining' about an inaccuracy in the \ndocumentation (this is the reason for me putting it in the documentation component \n:P). \n \nThe version that did segfault was definitively prior to 1.3.28. Cannot send the \nconfig-files, as I found it on a bank I worked for. I remember using the version 1.3.19 \n(and maybe later the 1.3.21-22). I didn't give it any importance because I thought \naliasing the / was a silly thing I shoudn't have attempted to do :P. 
22061	Rich Bowen	1104242787000	While redirecting / does indeed cause a loop, I can't get it to segfault. The\nrewrite guide, although in need of some work, on this point pretty clearly says\n'don't do that', so doesn't seem inaccurate to me. In the absence of further\ndata, I'm inclined to close this as part of my effort to clear away old and\nobsolete bug reports.\n\nThanks.
22061	Eloi Granado	1104261068000	Just as Joshua Slive pointed and confirmed, the bug report had nothing to do  \nwith the segfaults. It was about an inacurate statement in a documentation  \npage (that, by the way, has not been corrected).  \n  \nAnyway, I'll just add some comments on the segfault thing.   \n  \nI remember Apache segfaulted on those Solaris (may be version 7) servers in  \ntwo cases:  \n- Redirecting the / (as I stated, a silly thing to do).  \n- An old/unused child being killed by the master process. The child died from  \nsegfault instead of sigterm.  \n  \nThose segfaults may certainly be caused by some factors external to Apache.  \nThe Apache versions used were certainly old even then, because they were the  \nonly ones supported by BEA Weblogic and Vignette. The OS version wasn't the  \nlatest, either. I'm sorry of neither being able to reproduce them, nor to try  \nit with recent versions of Apache. 
22061	Rich Bowen	1104275892000	Thanks for the additional clarification. I think I understand what you're\ngetting at. Does the following satisfy what you're looking for? :\n\nIndex: rewriteguide.xml\n===================================================================\n--- rewriteguide.xml    (revision 123574)\n+++ rewriteguide.xml    (working copy)\n@@ -180,20 +180,21 @@\n         <dt>Solution:</dt>\n \n         <dd>\n-          <p>We just redirect the URL <code>/</code> to\n-          <code>/e/www/</code>. While is seems trivial it is\n-          actually trivial with <module>mod_rewrite</module>, only.\n-          Because the typical old mechanisms of URL <em>Aliases</em>\n-          (as provides by <module>mod_alias</module> and friends)\n-          only used <em>prefix</em> matching. With this you cannot\n-          do such a redirection because the <directive module='core'\n-          >DocumentRoot</directive> is a prefix of all URLs. With\n-          <module>mod_rewrite</module> it is really trivial:</p>\n-\n+          <p>We redirect the URL <code>/</code> to\n+          <code>/e/www/</code>:\n+          </p>\n+         \n <example><pre>\n RewriteEngine on\n RewriteRule   <strong>^/$</strong>  /e/www/  [<strong>R</strong>]\n </pre></example>\n+\n+    <p>Note that this can also be handled using the <directive\n+    module='mod_alias'>RedirectMatch</directive> directive:</p>\n+\n+    <example>\n+    RedirectMatch ^/$ http://example.com/e/www/\n+    </example>\n         </dd>\n       </dl>\n
22061	Eloi Granado	1104311811000	Perfect. That is just what I meant with the bug report :) Thank you for the \npatience. 
22061	Rich Bowen	1104427460000	Documentation patch applied. Thanks, Eloi.
22104	Andr?? Malo	1059995977000	mod_dav should use bucket brigades when reading PUT data, then all should be fine.\n\nSo changing component to mod_dav and accept this as a bug.\n\nThanks for the report.
22104	Tim Robbins	1060003336000	Created an attachment (id=7641)\nPatch to make mod_dav use bucket brigades when handling PUT requests\n
22104	Tim Robbins	1060003697000	Thanks for the suggestion to use bucket brigades -- I've got compressed uploads \nat least partly working now, but it seems to choke on large requests:\n[Mon Aug 04 23:21:13 2003] [error] [client 192.168.0.144] (55)No buffer space \navailable: Could not get brigade.  [500, #0]\n\nThere are other things I'm not quite sure about in the patch, but I thought I'd \nupload it just to get the ball rolling.
22104	Tim Robbins	1060004393000	Created an attachment (id=7642)\nCall apr_brigade_cleanup() to avoid running out of buffer space\n
22104	Andr?? Malo	1060006188000	Created an attachment (id=7643)\nclean patch I wrote in the meantime :)\n
22104	Andr?? Malo	1060006310000	Yeah, it was probably the missing cleanup. Can you try my patch nevertheless?\n\nIf it works, I'm going to commit it in 2.1 and propose it for backport.
22104	Tim Robbins	1060077888000	This seems to work, thanks! I haven't performed exhaustive testing; I uploaded \na 15MB file, both with and without gzip compression, and verified that the \nfiles were identical and had the same md5sum as the original file.
22104	Andr?? Malo	1060179799000	It's essentially the same patch as yours :)\n\nThanks for testing so far, I'm going to commit now.
22104	Jeff Trawick	1069453958000	fix already committed to Apache 2.1-dev...  sounds like we need to consider it\nfor merge to 2.0.next
22104	Andr?? Malo	1069454178000	It's considered already, but the review you know ... :-))
22104	Joe Orton	1073566729000	Backport now in 2.0 tree courtesy of Justin...
22203	Andr?? Malo	1060266052000	Fixed in 2.1 and proposed for backport into the 2.0 branch.\n\nThanks for the report and thanks for using Apache.
22259	Stas Bekman	1060809987000	The original patch is now committed, should be in effect with 2.0.48
22299	Geoffrey Young	1069686693000	added PatchAvailable keyword\n\n--Geoff
22299	Jeff Trawick	1069687098000	ouch, I didn't search for any UNCONFIRMED reports when attempting to enable the\nPatchAvailable keyword as appropriate :(
22299	Geoffrey Young	1070652994000	sorry, I assumed that non-core people were supposed to enter bugs as UNCONFIRMED\nuntil some core developer confirmed it.  of course, I confirmed it, but I have\ninsufficient karma ;)
22299	Geoffrey Young	1075491944000	fixed in 2.1\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/config.c?r1=1.168&r2=1.169
22348	Joshua Slive	1061829640000	Good point.  I'll fix that.\n\nThanks.
22529	Andr?? Malo	1061232852000	Not a bug. It's by intention. This allows rewriterules to act like alias\n(mapping to a system path). You can avoid this by using the PT flag.\n\nThis however needs to be better documented.\n\nThanks for using Apache.
22529	Joshua Slive	1185956240000	Years later...\n\nDocumentation updated in trunk (but won't likely get back to 1.3).
22684	Lumina	1061756084000	Oups, I mean, last line is :\nAddCharset ISO-8859-16 .iso8859-16 .latin10
22684	Jeff Trawick	1069436067000	I'm going through the bug db to make sure patches are findable.  Please see \nhttp://httpd.apache.org/dev/patches.html\n
22684	Lumina	1069468337000	The page you mentioned do not give a way to create a patch file when using \nWindows XP : I just tried, and the command 'diff' does not exist.\n\nI've downloaded version 2.0.48, and the bug is still there, three months after \nsubmitting it.\n\nThe best I can do now is providing exact files and line numbers for version \n2.0.48.\n\nAffected Files :\n(<)C:/Program Files/Apache Group/Apache2/conf/httpd.default.conf (34949 octets)\n(<)C:/Program Files/Apache Group/Apache2/conf/httpd.conf (34949 octets)\n\n719,723c719,727\n< AddCharset ISO-8859-5  .iso8859-5 .latin5 .cyr .iso-ru\n< AddCharset ISO-8859-6  .iso8859-6 .latin6 .arb\n< AddCharset ISO-8859-7  .iso8859-7 .latin7 .grk\n< AddCharset ISO-8859-8  .iso8859-8 .latin8 .heb\n< AddCharset ISO-8859-9  .iso8859-9 .latin9 .trk\n---\n> AddCharset ISO-8859-5  .iso8859-5 .cyr .iso-ru\n> AddCharset ISO-8859-6  .iso8859-6 .arb\n> AddCharset ISO-8859-7  .iso8859-7 .grk\n> AddCharset ISO-8859-8  .iso8859-8 .heb\n> AddCharset ISO-8859-9  .iso8859-9 .latin5 .trk\n> AddCharset ISO-8859-10 .iso8859-10 .latin6\n> AddCharset ISO-8859-14 .iso8859-14 .latin8\n> AddCharset ISO-8859-15 .iso8859-15 .latin9 .latin0\n> AddCharset ISO-8859-16 .iso8859-16 .latin10\n
22684	Andr?? Malo	1069496017000	Just a note: I strongly suggest <http://unxutils.sourceforge.net/>. These are\n*very* helpful tools. Including diff and patch :-)\n\n...putting the issue on my todo
22684	Lumina	1090809306000	Ok, now it is the third release of Apache that does not address this issue: \n2.0.48, 2.0.49 and 2.0.50. How long does it need to fix an issue with a patch \navailable ? I mean, it is already 11 months I reported this mistake in the \ndefault configuration... :)
22684	Nick Kew	1091446293000	Fix committed to CVS.
22684	Nick Kew	1092668760000	*** Bug 30682 has been marked as a duplicate of this bug. ***
22741	Joe Orton	1066914998000	Thanks for the patch!  This has been committed to the 2.1 tree and will be\nproposed for backport to 2.0.
22805	Radu Greab	1062101406000	Created an attachment (id=7989)\nproposed patch\n
22805	David Wheeler	1063134928000	FWIW, Radu wrote up a really good analysis of the problem here:\n\n  http://marc.theaimsgroup.com/?l=apache-modperl-dev&m=106200188613283&w=2
22805	Jim Jagielski	1066588833000	Fixed in 1.3.29 (ap_bclose changes only)
23130	Paul J. Reder	1063396671000	I just committed a fix based on your patch to the 2.1-dev branch. I have\nsubmitted it for backporting to the 2.0-stable tree. Thank you for your\nsubmission and for using Apache. One request, could you use unified diff format\nin the future for any patches (diff -u). It is the standard format that we all\nuse. Thanks.
23287	Andr?? Malo	1064172708000	Iit cannot change the content-length header, because the data is streamed. Hmm,\nI guess it's not really intended to decompress as a proxy.\nCan you try what happens, if you use mod_header's "RequestHeader unset'\ndirective to remove the headers in question?\n\nI think, mod_proxy should be changed, that if the content-length header is\nremoved, it switches to chunked encoding.... duh, that is only possible with\nHTTP/1.1. Seems there's no simple solution to that problem.\n\nI'm +1 anyway to remove the gzip token from Content-encoding.\n\nAny other ideas?
23287	John N Armstrong	1064203779000	Yes, I think that mod_deflate is rarely used for decompression of the REQUEST -- it's almost always used for compression of the RESPONSE. And, the combination of mod_deflate and proxying the request to a back-end server appears to be problematic.\n\nI tried using mod_headers and the RequestHeader unset command to remove the Content-Encoding: gzip and Content-Length: xxxx headers. The problem with this is that it causes mod_deflate to be be nop-op'ed because he doesn't recognize that the incoming request is compressed without the header.\n\nI considered writing a filter to post-process mod_deflate's output and remove the headers, but that won't work either, because the output is being streamed (as you point out), and the headers will already have been written.
23287	Nick Kew	1094399315000	Hmmm, ...\n\nCan you not use (the mirror of) the workaround I used to recommend for\nmod_proxy_html before updating mod_deflate to support decompression of response\ndata from a proxy?\n\nHeader unset Accept-Encoding\n\nto tell the Client you don't want gzipped data?\n\nI might actually fix this properly, but no promises.
23287	Michael Klepikov	1113932669000	A related problem with servlet requests forwarded to Tomcat via mod_jk: request\ncontent gets decompressed, but I get an end of stream at (the original)\nContent-Length bytes from stream start, resulting in truncated decompressed\ncontent for the servlet.\n\nI do not insist on removing 'gzip' from Content-Encoding or removing\nContent-Length. It's completely OK with me to just ignore Content-Length in my\nservlet and rely on the servlet request end of stream. Servlets have to be able\nto handle chunked requests anyway, so using Content-Length is not good style\nregardless of compression. It's also OK with me to ignore 'gzip' in\nContent-Encoding, as long as I know that Apache handles it for me. But it's not\nOK to get truncated content, I obviously do need full decompressed content in\nthe servlet.
23287	Andr?? Malo	1113933845000	(In reply to comment #4)\n> A related problem with servlet requests forwarded to Tomcat via mod_jk: request\n\nI'm certain, this should be fixed in mod_jk. Could you open a bug report /\nfeature  request at mod_jk's tracker?
23287	Michael Klepikov	1113940399000	Opened http://issues.apache.org/bugzilla/show_bug.cgi?id=34526
23287	Michael Klepikov	1123465562000	William Barker from mod_jk marked 34526 'resolved, wontfix' and insists it's a\nmod_deflate problem. Would it be possible to have a direct discussion among the\ndevelopers responsible for this functionality in mod_deflate and mod_jk? It's\nimportant to get it fixed, wherever the fixes may happen to be...
23287	Nick Kew	1185673596000	Fixed in /trunk/ and proposed for backport\nhttp://svn.apache.org/viewvc?view=rev&revision=560689\n\nThis kind of thing needs round tuits.  But it's still been an inexcusably long\ntime for a real bug.
23287	John N Armstrong	1185796043000	Understand. Well, better late than never, eh? I'd long-since moved on to other projects and forgotten \nabout this. ;-) Thanks for taking care of it.
23287	Nick Kew	1186464125000	http://svn.apache.org/viewvc?view=rev&rev=563464
23287	Jess Holle	1186464791000	Any chance of a backport to Apache 2.2.x?
23287	Ruediger Pluem	1186489818000	(In reply to comment #11)\n> Any chance of a backport to Apache 2.2.x?\n\nIt is already backported to Apache 2.2.x. See Comment 10.
23416	Jeff Trawick	1064913590000	odd... with 2.0.47 and a bogus directory for rewritelog, I get this in error_log:\n\n[Tue Sep 30 05:25:30 2003] [error] (2)No such file or directory: mod_rewrite:\ncould not open RewriteLog file /gobble/log\n
23416	Jeff Trawick	1065789432000	Was your RewriteLog directive in a VirtualHost container or at main scope?\n
23416	Richard Safran	1065795778000	The RewriteLog directive was inside a VirtualHost container.
23416	Andr?? Malo	1065808559000	That'll be fixed in 2.0.48:\n\n<http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/mappers/mod_rewrite.c.diff?r1=1.135.2.14&r2=1.135.2.15&diff_format=h>\n\nI'm going to add a Changelog entry referring to this PR.\n\nThanks for the report and thanks for using Apache.
23421	Martin D??rst	1064521188000	see also bug 14513\nhttp://nagoya.apache.org/bugzilla/show_bug.cgi?id=14513
23421	Tex Texin	1064532846000	The new default value causes corruption for people upgrading to the new \nversion. The mislabeling of Windows-1252 as iso8859-1 can cause the euro symbol \nto be incorrect and result in erroneous financial transactions.\nThe misleading Apache documentation and the change to apply the default charset \ncauses subtle differences which have significant impact. It can also cause non-\nsubtle differences. The fact that web standard calls for http charset to \noverride the charset in the page, means that change will override even pages \nwith self-documenting charset (ie pages that use the meta tag). The old \nbehavior should be restored right away.
23421	Joshua Slive	1064546246000	I'm not enough of an expert in this area to make a decision about it,\nbut the problem with simply removing this directive is that it\ncreates problems with cross-site scripting.  See:\nhttp://httpd.apache.org/info/css-security/\nand links from that page.\n\nIn fact, AddDefaultCharset was originally added to deal with these\nproblems, so simply removing it without addressing the CSS issue\nwould not be smart.\n\n(See also bug 13986 that states\nthat apache shouldn't set a default content-type by default.\nThis issue should probably be addressed along side that one.)
23421	Tex Texin	1064547631000	OK, I think we need a clarification. We are not requesting the command AddDefaultCharset be eliminated. \nWe are requesting that its use in the default configuration to set the charset to iso 8859-1 be eliminated.\n\nAs for the security risk, the significant piece of the referenced document seems to be:\n'In addition, web pages should explicitly set a character set to an appropriate value in all dynamically generated pages. '\n\nWe can all agree with this. The problem is iso 8859-1 is not an appropriate value for the majority of configurations.\nThe article references that this used to be the default for some of the web standards and is no longer the case. \nIt is because it is not the best choice in the majority of cases, even in English speaking markets these days, that it is no longer the default.\nPerhaps a better compromise solution is to at least ask the administrator what the value should be during the installation and \nprovide a list of the most common encodings for them to choose from.\nOr default to UTF-8 and let people know clearly that is what you use.\n
23421	Dietmar Temme	1083765101000	SuSE 9.0 shipped Apache 2.0 with AddDefaultCharset utf8\n\nAs a result any other encoding mentioned in the hmtl/xhtml/xml-source sent to\nthe server was ignored.\n\nThat does not fit the behaviour of Apache talked about on the\ncross-site-scripting page; there it is told that option AddDefaultCharset is\nonly activated if any page-specific encoding is missing. \n\nA mistake in logic, of the behaviour of option AddDefaultCharset ?
23421	Joshua Slive	1083779311000	Apache has absolutely no interest in <meta> tags inside the html.  That comment\nis talking about AddCharset and similar methods of setting the HTTP headers.
23421	Dietmar Temme	1085406951000	To Joshua Slive: Then the faulty behaviour is on the browser's side, insomuch a\nrequest is sent without an complete or appropriate header, i.e. including the\nencoding information. That was my first guess, at Mozilla.\n\nOf course it's presumed that option AddDefaultCharset only is activated if no\nencoding information is available.Or, to extend the view, if no valid/accepted\nencoding is sent in the request, given a list of encodings accepted by the server.\n\nWould that still help the CSS-problem? 
23421	Joshua Slive	1085421490000	Dietmar, I can't decipher what you are trying to say.  But this is not the best\nplace to discuss it.  Please try the users@httpd or dev@httpd mailing list.
23421	Wu Yongwei	1091348505000	Is this issue still not resolved?  I am Chinese and I am strongly on the side of\nthe reporter.\n\nThe problem, I suppose, arises from a problematic standard.  AFAIK, the header\nsent from the server overrides that contained in a meta tag.  Browsers I use all\nconform to this behaviour, and sorrows of non-Western Web developers grow.  For\nChinese, we routinely use\n\n<meta http-equiv='Content-Type' content='text/html; charset=gb2312'>\n\nto mark a page as Chinese.  And this method allows us to place an ISO-8859-1\npage on the same server/directory without worrying about server configurations.\n I even do not know now how to achieve this effect if 'AddDefaultCharset' is\never used.\n\nSecurity is important, but I do not think setting the default charset by the\nSERVER is the right way to go.  Indeed, I think the suggestion to use a default\ncharset has caused more problems than solved (see stories below).  It is the\nserver-side SCRIPT that should take care of this.  And I do not think the\ncomment in the conf file is correct: it really does harm, because setting it\nwill PREVENT Web developer from specifying the charset in their pages, who\nshould really be responsible for such issues.\n\nBy the way, some stories.  Several times I have been called by colleagues\nbecause they cannot make Apache display Chinese characters correctly on a newly\ninstalled box.  I once translated the mission page for webstandards.org, and\nafter a site migration it no longer displayed Chinese.  After several emails the\nnon-Western pages are moved to a special server or directory and it was OK.  Now\nthe page is archived at \n\nhttp://archive.webstandards.org/mission_gb2312.html\n\nAnd it is wrong AGAIN, along with other translations like Japanese!\n\nWhat is the use of security, if it makes things inaccessible?\n\n(Not to mention that it is a wrong response for a security issue.  Even the page\nhttp://www.cert.org/tech_tips/malicious_code_mitigation.html#3\nmentions only the use of a meta tag like the gb2312 example above.)\n\nTo Dietmar:\n\nYour opinions about Accept-Charset are correct only if\n\n1) A Chinese user can set his browser to accept only GB2312;\n2) A Chinese user never need to view ISO-8859-1 pages, or the browser supports\nper-page configuration of Accept-Charset; and\n3) If 'Accept-Charset: gb2312' is sent to the server, the server will not send\nthe default 'charset=ISO-8859-1'.\n\nI do not see any of them holds.
23421	Nick Kew	1091356967000	I agree that shipping with an AddDefaultCharset preset is unsatisfactory,\nand screws up users of servers with unresponsive admins.\n\nCan we simply remove it from the default config to deal with the case of authors\nhaving more clue than their sysops?  I'd be happy with that, but I'm going to\nask for review in other fora where folks have relevant expertise.\n\nActually the solution is already available to users.  There's a bunch of\nAddCharset directives in the default httpd.conf that serve precisely this\npurpose:\nAddCharset ISO-8859-1  .iso8859-1  .latin1\nAddCharset ISO-8859-2  .iso8859-2  .latin2 .cen\nAddCharset ISO-8859-3  .iso8859-3  .latin3\netc.\n\nSo a fix would be to correct errors and omissions in that list, and leave it\nto authors to control their charset using a suffix on the document name.\nOf course that's ugly, but at least it works.\n\nAlso worth noting: mod_proxy_html 2.x will parse META elements in\nHTML and XHTML documents and convert them to real HTTP headers.\nSee http://apache.webthing.com/mod_proxy_html/\n
23421	Nick Kew	1091357430000	I just wrote:\n\n> So a fix would be to correct errors and omissions in that list, and leave it\n> to authors to control their charset using a suffix on the document name.\n> Of course that's ugly, but at least it works.\n\nHmmm, I neglected to add that the ugliness goes away if that's used with \nmod_negotiation: perhaps we shold ship with multivies on by default?\nThe other crucial issue is of course to document it!
23421	Nick Kew	1093523429000	*** Bug 30860 has been marked as a duplicate of this bug. ***
23421	Sebastiaan Hoogeveen	1102605399000	In addition to the principal reasons given earlier there is also a pragmatic\nreason not to use AddDefaultCharset in the default httpd.conf. Sending the\ncharset declaration triggers an obscure bug in MSIE with multipart forms, as\ndocumented at\nhttp://www.interactivetools.com/forum/gforum.cgi?post=34345;sb=post_latest_reply;so=ASC;forum_view=forum_view_collapsed\n(at the bottom).\n\nI know that Microsoft should fix their browser but I spend a lot of time today\ndebugging an old script that didn't work after upgrading to Apache 2 because of\nthis. I think the right thing is not to trigger bugs in a product that is still\nused by so many users by shipping a httpd.conf that contains this as a default.
23421	Martin D??rst	1102658021000	I'm surprised that this bug is still around. The only justification for that\nthat I was able to find in the record is the pointer to the Client Side\nScripting (CSS) issue. However, this is based on a shallow understanding\nof CSS. In order to avoid CSS, just setting whatever character encoding\nis not good enough. A solution requires that the client side gets the\nright character encoding. Of course, declaring iso-8859-1 as a default\ndoesn't work for a huge amount of Web pages. So this default should be\nremoved as quickly as possible, and the documentation for CSS should be\nupdated to make more clear that it's not 'declare an encoding' but\n'declare the right encoding' that is important (also for other reasons\nthan just security).\n\nI can easily provide more information (e.g. a page that shows how use\nof the wrong encoding, such as declaring a page as iso-8859-1 that\nisn't iso-8859-1 can lead to attacks) if contacted directly.
23421	Roy T. Fielding	1102677809000	This was supposed to be fixed a long time ago.  It was for 1.3.\nI am verifying with the group and will remove it from the default\nconfig if there are no objections.
23421	Roy T. Fielding	1102749616000	Fixed in HEAD (2.1.x), may be backported later to 2.0.x.\n\nsvn rev 111582
23421	Joe Orton	1105375338000	*** Bug 33028 has been marked as a duplicate of this bug. ***
23501	Jeff Trawick	1069436159000	I'm going through the bug db to make sure patches are findable.  Please see \nhttp://httpd.apache.org/dev/patches.html\n
23501	Takashi Sato	1183592669000	*** Bug 42349 has been marked as a duplicate of this bug. ***
23501	Takashi Sato	1183592822000	Created an attachment (id=20448)\nfor trunk\n
23501	Joshua Slive	1185965602000	Thanks. Fixed on trunk and 2.2.
23606	Joshua Slive	1065321439000	I agree.  In fact, all examples with '*' should be replaced with\n'*:80'.
23606	Andr?? Malo	1065827659000	done.
23618	Andr?? Malo	1065824298000	It's totally fine ;-)\n\nThanks for the report, it's fixed now in CVS.
23618	Takashi Sato	1195948291000	*** Bug 43773 has been marked as a duplicate of this bug. ***
23642	Jeff Trawick	1069436198000	I'm going through the bug db to make sure patches are findable.  Please see \nhttp://httpd.apache.org/dev/patches.html\n
23642	Jeff Trawick	1069439776000	patch is already committed to 2.1-dev and will likely be in the next 2.0.x release\n\nthanks!\n
23713	P.M.	1065744811000	Created an attachment (id=8519)\nPatch of the typo corrected\n
23713	Cliff Woolley	1065758056000	fixed, thanks!
23724	Jeff Trawick	1065793222000	doc problem
23724	Erik Abele	1066091804000	This is now fixed in all three doc trees. Thanks.
23747	Liam Quinn	1065983566000	Created an attachment (id=8539)\nPatch to use HTML syntax for empty elements\n
23747	Andr?? Malo	1065994787000	Quick note until someone picks it up. We need an option for switching \nbehaviour, because people may use (and do use) their own declaration.\n\nThanks for your report!
23747	Andr?? Malo	1067805613000	Fixed the issue in 2.1 and proposed for backport into the 2.0 branch.\n\nThanks!
23748	Liam Quinn	1065982521000	Created an attachment (id=8538)\nPatch to eliminate the error\n
23748	Andr?? Malo	1065995962000	Hmm. I think, the right fix would be to set\nnew->expiresdefault = NULL\nin create_dir_expires_config and to change the merger accordingly. Your fix \nseems to be just a work around.\n\nThanks for the report and thanks for using Apache!
23748	Liam Quinn	1065999910000	Created an attachment (id=8544)\nAlternate patch that uses NULL for expiresdefault\n
23748	Jeff Trawick	1069454170000	enabling the PatchAvailable keyword\nupdated doc on submitting patches is at http://httpd.apache.org/dev/patches.html\n
23748	Paul J. Reder	1069455941000	*** Bug 24459 has been marked as a duplicate of this bug. ***
23748	Paul J. Reder	1069458368000	I have tested and committed this patch to the 2.1-dev branch of Apache and\nsubmitted it for a vote for backporting into the 2.0 stable branch.\n\nThank you for using Apache and for taking the time to track down a fix and\nsubmit a patch.
23748	Paul J. Reder	1069458397000	I have tested and committed this patch to the 2.1-dev branch of Apache and\nsubmitted it for a vote for backporting into the 2.0 stable branch.\n\nThank you for using Apache and for taking the time to track down a fix and\nsubmit a patch.
23748	Allan Edwards	1119472329000	*** Bug 21907 has been marked as a duplicate of this bug. ***
23795	Jeff Trawick	1067286394000	The problem is apparently that each thread is using times() syscall to retrieve\ninfo on CPU usage for entire process, and mod_status is joyfully adding up all\nthe values :)  What we really need is to pick the times() info that was\nretrieved most recently by some thread in the process.\n\nI'll attach a patch in a sec that seems to resolve the problem for me.  It would\nbe helpful if you could try it out.\n\nNote that in the extended status table the same CPU seconds will be reported for\neach thread.  I haven't done anything about that.  Perhaps '=' or some other\nsymbol should be printed for threads other than the first one.\n
23795	Jeff Trawick	1067286443000	Created an attachment (id=8758)\nproposed patch for bogus CPU% with threaded MPM\n
23795	David Rees	1067369359000	I tried out the patch, it does appear to generate correct overall CPU usage\nstatistics.\n\nInterestingly, I don't get the same CPU times for each thread in a worker as you\nsuggested, it looks like each thread reports the CPU usage at the time of the\nlast request for the worker thread group.\n\nI agree that it would be a good idea to only display the CPU time once for each\nthread group, it would be less confusing.
23795	Jeff Trawick	1067370928000	>Interestingly, I don't get the same CPU times for each thread in a worker as you\n>suggested, it looks like each thread reports the CPU usage at the time of the\n>last request for the worker thread group.\n\nYeah, I realized later that was an erroneous claim, caused by a lack of common\nsense and not enough data points :)\n\nI need to do a little more testing, such as create a looper module and see if\nCPU% is still sane, then commit to 2.1 and request merge to stable.\n
23795	Jeff Trawick	1067461306000	fixed in 2.1-dev; I'll propose it for merging to 2.0.x once folks have had a\nchance to compla^H^H^H^H^H^Hlook over it\n\nbtw, more code was needed to keep working on linuxthreads (old Linux pthreads\nimplementation); also, I chose to keep displaying CPU time per thread in\nextended status table...  it provides additional hints with normal thread\nlibraries and it is unique information with linuxthreads\n
23795	Jeff Trawick	1071362586000	fix committed to stable branch for 2.0.next\n
23798	Joshua Slive	1067647674000	Thanks for the note.  I've updated the content-negotiation docs.\n\nI didn't specifically blame MSIE because, although its behavior\nis annoying, it probably is technically 'correct'.\n\nIt will appear in the next round of doc updates.
23836	Jeff Trawick	1066932317000	A different patch was committed to 2.1-dev and has been approved for stable branch.
23850	Joshua Slive	1066400411000	I'm very skeptical you've identified a bug here for several reasons:\n\n1. I've never heard of any problem remotely like this before,\nand these features are used frequently.\n\n2. The fact that you are using <Limit GET POST> shows that you\nare not following recommended practices for apache configuration,\nand therefore there could be many other things wrong with your config.\n\nI suggest you start with an absolutely default install of apache\nwith no extra modules and no config modifications except the\nones you suggest below.  If it still doesn't work, you can reopen\nthis bug, but be sure to provide more details about what is\nin your logs, the exact OS version, etc.\n\nThanks for using Apache!
23850	TTSG Internet Services, Inc.	1067736305000	Hi,\n\nOk, we did some investigation. \n\n1) Download/uncompress/untar source\n2) Compile with gcc 3.2.3 with just ./configure;make;make install\n3) Create a directory under htdocs called testing, put in an .htaccess of :\n\nAuthDBMUserFile /local/wwwcust/passes/sample\nAuthDBMGroupFile /dev/null\nAuthName Members_Only\nAuthType Basic\n Satisfy Any\n order deny,allow\n deny from all\n allow from 24.193.48.116\n allow from 202.139.152\n allow from 210.80.149\n allow from 216.183.31.224/27\n allow from 209.88.233.224/27\n allow from 209.88.69.192/27\n allow from 209.135.126\n allow from 64.8.218\n allow from 63.201.23\n allow from 217.145.67.0/25\n allow from 62.39.85\n allow from 216.231.111.14\nrequire valid-user\n\n4) Edit the stock httpd.conf where it depicts the default document root like\n<Directory /usr/local/etc/httpd/htdocs> and change the 'AllowOverride None' to\n'AllowOverride All'. Start server\n5) From 216.231.111.14 attempt to access the directory, it will ask for an id/pass\n6) Change it to 216.231.111.14/32, it works.\n\nDelete all directories and configs. \n\nStart the instructions again, except in step 2 , change it to 'CC=gcc -m32'\ninfront of the ./configure;make;make install\nAt step 5, it will let you in immediately.\n\n\nSo, it seems, in 64 bit mode it has issues, but not 32 bit.\n\nWe can reproduce this on mutiple machine that we own, and others own.
23850	Joshua Slive	1067742209000	Interesting.  I assume that it doesn't matter if you remove the\nAuth*/Require/Satisfy directives and just test mod_access?\n\nI don't have a solaris system handy to test on, but if someone does,\nI'm sure they'd be interested in your exact OS/patch level.
23850	TTSG Internet Services, Inc.	1067805060000	With only the following in .htaccess:\n\n\norder deny,allow\ndeny from all\nallow from 216.231.113.11\nallow from 24.193.48.116\n\n\nI see the same symptoms, coming from the 24.* address I get in (Outside our\nnetwork) , from 216.* (local subnet) I get forbidden, if I add the /32 it works\nfine.\n\nThis server is running Solaris 9, kernel patch level 112233-07, apache 1.3.28\ncompiled with 64-bit gcc3.2.3 with a standard build , using gnu make 3.80 (also\nbuilt 64-bit).
23850	Joe Orton	1067814112000	What's the result of running:\n\n$ cd srclib/apr/test\n$ make testall\n$ ./testall -v testipsub\n\nfrom the 64-bit build tree?\n
23850	TTSG Internet Services, Inc.	1067815160000	Hi,\n\nI find no 'apr' directory anywhere in the Apache 1.3.X tree when I untar it.\n\nThanks, Tuc/TTSG Internet Services, Inc.
23850	Joe Orton	1078697464000	This was found and fixed independently by Henning Brauer from the OpenBSD team;\nthe fix is checked in here for the next 1.3 release; thanks for the report.\n\nhttp://cvs.apache.org/viewcvs.cgi/apache-1.3/src/modules/standard/mod_access.c?r1=1.46&r2=1.47\n\n
23902	Erik Abele	1073775731000	Makes sense to me too, so I've added this to the mime.types file of all three versions currently in \ndevelopment. Thanks for using Apache.
23956	Jeff Trawick	1066689442000	Thanks for the patch.  Note that to get a change in the independent mod_ssl that\nworks with Apache 1.3, talk to the folks that maintain it (www.modssl.org).  It\nseems clear from your description what we need to do with 2.1 and 2.0.\n
23956	Joe Orton	1069794811000	Committed to HEAD, will propose for backport to 2.0.  Thanks for the patch.\n\nhttp://cvs.apache.org/viewcvs/httpd-2.0/modules/ssl/ssl_engine_vars.c.diff?r1=1.27&r2=1.28
23998	Joe Orton	1066828770000	Thanks for the report.  Yes, ap_rgetline is stripping any trailing spaces.  The\nproxy should just fix it and not be so noisy - I'll attach a patch.
23998	Joe Orton	1066839258000	Created an attachment (id=8666)\nfix for trailing space handling\n
23998	Marco Muishout	1066921181000	I tested the fix that was supplied and everything works OK. I attached two \nerror log files - one showing the warning, and one which shows the warning is \ngone. \nBoth error log files were recorded while requesting the default application jsp \nin out environment, with the apache mod_proxy instance running in debug mode.
23998	Marco Muishout	1066921253000	Created an attachment (id=8690)\nApache error log file, including 'warning' bug\n
23998	Marco Muishout	1066921297000	Created an attachment (id=8691)\nApache error log file, bug fixed using supplied patch (no more warning)\n
23998	Jeff Trawick	1069454360000	fyi... fix already in 2.1-dev, recently approved for merge into stable branch\nfor 2.0.next\n
23998	Erik Abele	1070077418000	As Jeff already noted, this is fixed.
24165	Andr?? Malo	1067729740000	Fixed in CVS, thanks.
24219	Andr?? Malo	1067731469000	The docs are correct. It's a bug in mod_setenvif's optimizer ...\nI'm investigating.
24219	Andr?? Malo	1067733600000	Fixed in 2.1 and proposed for backport into the 2.0 stable branch.\n(<http://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/metadata/mod_setenvif.c.diff?r1=1.43&r2=1.44>)\n\nThanks for the report and thanks for using Apache!
24228	Jeff Trawick	1069816159000	USLOCK stuff axes from 2.* documentation\nother minor cleanups applied to that section\n\nThanks for your report and thanks for using Apache!
24232	Thom May	1067531037000	I'm just testing a patch for this problem.
24232	Thom May	1067538002000	This patch has been committed to httpd-2.1 and will shortly be proposed as a\nbackport to 2.0
24232	Jeff Trawick	1070520714000	fix merged into stable branch for 2.0.49
24417	Chris Adams	1069449557000	Created an attachment (id=9232)\nPatch for 2.0.48 to use localtime (including updated documentation)\n
24417	Uli Zappe	1069452406000	Chris,\n\nI'm not sure why you moved the modification in the code of rotatelogs to the place you did. Are \nyou sure this will work, especially on days when DST is switched on or off? I don't have the \nopportunity to test this right now, but it's obviously important that the behavior is right on these \ndays.\n\nAnyway, the following is obviously wrong in your version of the patch:\n\n+            if (strcmp(argv[3], 'loc') == 0) {\n+                use_local = 0;\n\nshould be\n\n+            if (strcmp(argv[3], 'loc') == 0) {\n+                use_local = 1;\n\nor is there something I just didn't get?
24417	Chris Adams	1069874253000	Yes, you got the obvious typo.  I did fix this, but I didn't upload the right\nversion (and didn't catch it right away).\n\nI also updated the documentation in my patch to note that it does not affect the\nlog rotation time math (i.e. if you say '86400', it will still be rotated at\n00:00:00 UTC); it just affects the time formatting done with strftime(3) to use\nthe local time zone.  What I do is set my log rotation time to be 3600, and then\nuse a filename like 'access_log.%Y-%m-%d' (so it re-determines the filename\nevery hour, but it only changes at 00:00:00 local time).\n\nI did it this way because the patch is much simpler (more likely to be\nacceptable), but I see how this could just make things more confusing, as it\nchanges the behavior of the option.  Sorry about that.\n
24417	Uli Zappe	1069875861000	Chris wrote:\n> I also updated the documentation in my patch to note that it does not affect\n> the log rotation time math (i.e. if you say '86400', it will still be rotated at\n> 00:00:00 UTC);\n\nBut that's exactly the behavior I wanted to avoid because it makes syncing with cron jobs so \ndifficult.\n\n> What I do is set my log rotation time to be 3600, and then\n> use a filename like 'access_log.%Y-%m-%d' (so it re-determines the filename\n> every hour, but it only changes at 00:00:00 local time).\n\nWhich is kind of confusing. If you plan to rotate once a day, 86400 should work for you, even if you \nuse the 'local' option.\n\n> I did it this way because the patch is much simpler (more likely to be\n> acceptable)\n\nWell, my patch isn't *that* complicated, is it? And it does exactly what it should, in an intuitive way. \nI think the foremost consideration should be what is simple for the *user*. 
24417	Jeff Trawick	1087387639000	Ken Coar recently committed an equivalent feature to 2.1-dev, which I presume\nwill be backported to stable branch for a future 2.0.x release.  Please have a look:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/support/rotatelogs.c?r1=1.32&r2=1.34\n
24417	Uli Zappe	1087402780000	> Ken Coar recently committed an equivalent feature to 2.1-dev, which I presume\n> will be backported to stable branch for a future 2.0.x release.  Please have a look:\n\nKen's patch won't work correctly on the days when DST is switched on or off, because he puts the \ntest for the local time offset (utc_offset = lt.tm_gmtoff;) outside of the 'for (;;)' loop. Therefore, the \ntime offset will only be set once after the start of the rotatelogs process, and will not be updated \nafter a switch of DST occurs.\n\nKen himself writes in his comment: 'NB: Using -l in an environment which changes the GMT offset \n(such as for BST or DST) can lead to unpredictable results!', suggesting he has indeed not tested his \npatch on days when the switch occurs. However, unless you intend to use DST there's no point at all \nin using local time instead of a fixed offset from GMT.\n\n<Sigh> Why don't you just use the patch I committed? It's thoroughly tested, especially on days \nwhen the DST switch occurs, and proven to work in a production environment for almost two years \nnow.
24417	Jeff Trawick	1087765926000	I don't know why the patch here wasn't used.  When Ken's patch was posted to the\ndeveloper's mailing list I pointed out this patch/PR.\n\nRegardless, I pointed out your recent comments here to Ken and he integrated\nyour comment.  See \n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/support/rotatelogs.c\n\n(I'm just the middleman here ;) )\n
24417	Uli Zappe	1087778978000	Jeff, thanks! As far as I can see, the new code by Ken should work. Therefore I close this report. :-)
24417	Jeff Trawick	1087815809000	Thanks for your review, and I'm sorry about the confused path to a solution for\nthis issue!\n
24437	Jess Holle	1068057668000	It turns out that the Microsoft LDAP SDK escapes these characters on its own!\n\nI found the filter escape code in mod_auth_ldap_build_filter in mod_auth_ldap.c\nand observed that its input and output was exactly what I'd expect.  I also note\nthat it's output is what is passed to the LDAP SDK.\n\nI commented out the escape code (in the simplest fashion, i.e. yes, I could use\nstrncpy at this point) and then (and only then) am able to authenticate with /,\n), (, and * in my user name.\n\nI assume this is a Microsoft LDAP SDK feature as my other LDAP SDK experience\nsuggests the escaping done by mod_auth_ldap is required.\n\nAll the same, I believe we should #if out this filter code when using the\nMicrosoft LDAP SDK -- as it only currently serves to prevent that which it is\nintended to allow.\n\nMy change is to add the comments in the code excerpt below taken from\nmod_auth_ldap.c (sorry, I'm not creating a patch as strncpy would be better,\netc, etc):\n\n    filtbuf_end = filtbuf + FILTER_LENGTH - 1;\n    for (p = user, q=filtbuf + strlen(filtbuf);\n         *p && q < filtbuf_end; *q++ = *p++) {\n/* Microsoft LDAP SDK does this automatically (!); doing this here causes\ndouble-escaping!!!\n   The following code block must therefore be removed when using Microsoft's\nLDAP SDK.\n*/\n/*\n        if (strchr('*()//', *p) != NULL) {\n            *q++ = '//';\n            if (q >= filtbuf_end) {\n\t        break;\n\t    }\n        }\n*/\n    }\n
24437	Will Rowe	1068830598000	\n  I believe your patch is correct, however we need to use a #ifdef to make\n  this determination, to prevent clashes with folks building under OpenLDAP\n  or the Netscape LDAP sdk.\n
24437	Jess Holle	1068831830000	Yes, that's a big reason why I did not provide a patch -- I had not taken the\ntime to investigate the proper #ifdef's, etc, to use.
24437	Graham Leggett	1085102165000	Patch committed to v2.1.0-dev\n\nPlease test if this solves this problem.\n
24437	Jess Holle	1085151393000	Doh!\n\nI'm sure that will work as it is identical to my fix apart from a proper #if block.\n\nI should have taken the 2 extra minutes when I patched this on my own copy to\nlook in apr_ldap.h and see\n  #define APR_HAS_MICROSOFT_LDAPSDK   1\non Windows and done a proper #if block around this.\n\nThanks for rounding out this fix and getting it in.  A merge back to 2.0 would\nbe good too :-)
24437	Graham Leggett	1085181745000	Fixed in v2.0.50-dev.\n
24437	Jess Holle	1096054071000	As the person who provided the patch, I must regretfully re-open this SPR.\n\nThe patch works great *except* when the character immediately following the / is\na valid hexidecimal character.  I'm not sure how to handle this case with the\nMicrosoft LDAP SDK.\n\nHopefully we're missing some simple 'behave correctly' flag on the Microsoft\nLDAP SDK...
24437	Jess Holle	1096668179000	Created an attachment (id=12919)\nPatch to address remaining issues (/[0-9,a-f], e.g. /a, etc)\n
24437	Jess Holle	1096668257000	I discovered Microsoft documentation at\nhttp://msdn.microsoft.com/library/default.asp?url=/library/en-us/adsi/adsi/search_filter_syntax.asp\nthat essentially states 'RFC 1960 says...', followed by an accurate quote of\nthis IETF RFC, followed by section titled 'Special characters' where they state\na completely different means by which they require you to handle all the special\ncharacters from the IETF RFC -- without actually stating that they're requiring\nother syntax than that indicated by the RFC much less why they require this!\n\nI produced a patch wherein the Microsoft documentation is obeyed when using\ntheir LDAP SDK.  This seems to fix the remaining issues, so I've attached the\npatch (see above).
24437	Graham Leggett	1096817481000	Is it possible to create a patch for v2.1 also? The patch does not apply cleanly\nto mod_authnz_ldap.c, not sure why.\n
24437	Jess Holle	1096894528000	Created an attachment (id=12930)\nPatch against HEAD rather than against 2.0.52\n
24437	Jess Holle	1096894711000	I've attached a patch against mod_authnz_ldap.c as requested.\n\nNote that I've only tested this on Windows against Microsoft's LDAP at this\npoint (the problematic case).  After pre-processing, there should be no\ndifferences in the code for any other platform resulting from my changes.
24437	Graham Leggett	1096936479000	Committed to HEAD, backport proposed to v2.0
24437	Graham Leggett	1106347720000	The LDAP code in v2.0 is effectively abandoned, as it's too difficult to fix at\nthis point (most of the fixes have involved major rewrites and have gone in\nhttpd v2.1 and apr v1.1).\n\nIf this is broken in httpd v2.1, please reopen this bug.\n
24437	Jess Holle	1106348894000	I guess I'll check again in 2.2 whenever it is 'stable'.\n\nI have to support a redistribution of a stable 2.x release, so at this time that\nwould be 2.0.52.  Thus I'll keep applying my patch to 2.0.x.
24450	Jeff Trawick	1068212790000	thanks for the patch!\nfix for random dirname problem now committed to 2.1-dev\n\nsomebody has fixed the missing 2.0.48 choice in the meantime\n\nre instructions for gprof:\n\nMy guess is that [almost] nobody has done this since 1.3 days and there may not\nbe skills right now to document it properly...  also, I don't know if there may\nbe limitations of gprof that can break it with Apache 2 on some platforms (e.g.,\nif libpthread is referenced due to thread-capable libapr).\n\nYou'll probably need to investigate further to get this resolved, though it\nwould be worth posting a query to dev@httpd to see if anybody has gotten it\nworking recently.  Perhaps see if gprof works with Apache 1.3 on your box first.\n If not, then that simpler, better understood case should be resolved first.\n\nAt least one small issue is fixed.
24450	Erik Abele	1068607025000	I'm closing this bug now but feel free to re-open it if you encounter further issues. Thanks for \nusing Apache.
24483	Yutan	1068187593000	This problem is mod_usertrack.\nEnable this option is dump core!!\n\nCookieTracking on\n
24483	Cliff Woolley	1068189499000	Well, we did change mod_usertrack in this version... but in all our testing it \nworked for us.  Can you please give us a backtrace so that we can try to figure \nout what's going on?  See http://httpd.apache.org/dev/debugging.html .\n\nThanks,\nCliff
24483	Yutan	1068219436000	backtrace report on spot_cookie(mod_usertrack.c)\n\nBreakpoint 3, spot_cookie (r=0x8188050) at mod_usertrack.c:204\n204         cookie_dir_rec *dcfg = ap_get_module_config(r->per_dir_config,\n(gdb) n\n210         if (!dcfg->enabled || r->main) {\n(gdb)\n214         if ((cookie_header = apr_table_get(r->headers_in,\n(gdb)\n218             if (!ap_regexec(dcfg->regexp, cookie_header, NUM_SUBS, regm, 0))\n {\n(gdb)\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x080a495b in regexec (preg=0x0,\n    string=0x8189040 'Apache=hostname.or.jp.1067634189379628; sheet=%u901A%\nu5E38%u30D5%u30A9%u30F3%u30C8; abcdefgh.html=11', nmatch=3,\n    pmatch=0xbfbff940, eflags=0) at pcreposix.c:269\n269     rc = pcre_exec(preg->re_pcre, NULL, string, (int)strlen(string), 0, \noptions,\n\n-------\nBreakpoint 3, spot_cookie (r=0x8188050) at mod_usertrack.c:204\n204         cookie_dir_rec *dcfg = ap_get_module_config(r->per_dir_config,\n(gdb) s\n210         if (!dcfg->enabled || r->main) {\n(gdb) s\n214         if ((cookie_header = apr_table_get(r->headers_in,\n(gdb) s\napr_table_get (t=0x8188218, key=0x80d051c 'Cookie') at apr_tables.c:481\n481         if (key == NULL) {\n(gdb) s\n485         hash = TABLE_HASH(key);\n(gdb) s\n486         if (!TABLE_INDEX_IS_INITIALIZED(t, hash)) {\n(gdb) s\n489         COMPUTE_KEY_CHECKSUM(key, checksum);\n(gdb) s\n490         next_elt = ((apr_table_entry_t *) t->a.elts) + t->index_first[hash];\n;\n(gdb) s\n491         end_elt = ((apr_table_entry_t *) t->a.elts) + t->index_last[hash];\n(gdb) s\n493         for (; next_elt <= end_elt; next_elt++) {\n(gdb) s\n494             if ((checksum == next_elt->key_checksum) &&\n(gdb) s\n493         for (; next_elt <= end_elt; next_elt++) {\n(gdb) s\n494             if ((checksum == next_elt->key_checksum) &&\n(gdb) s\n496                 return next_elt->val;\n(gdb) s\n501     }\n(gdb) s\nspot_cookie (r=0x8188050) at mod_usertrack.c:218\n218             if (!ap_regexec(dcfg->regexp, cookie_header, NUM_SUBS, regm, 0))\n {\n(gdb) s\nap_regexec (preg=0x0,\n    string=0x8189040 'Apache=hostname.or.jp.1067634189379628; sheet=%\nu901A%u5E38%u30D5%u30A9%u30F3%u30C8; abcdefgh.html=11', nmatch=3,\n    pmatch=0xbfbff940, eflags=0) at util.c:398\n398         return regexec(preg, string, nmatch, pmatch, eflags);\n(gdb) s\nregexec (preg=0x0,\n    string=0x8189040 'Apache=hostname.or.jp.1067634189379628; sheet=%\nu901A%u5E38%u30D5%u30A9%u30F3%u30C8; abcdefgh.html=11', nmatch=3,\n    pmatch=0xbfbff940, eflags=0) at pcreposix.c:233\n233     int options = 0;\n(gdb) s\n242     int *ovector = NULL;\n(gdb) s\n243     int allocated_ovector = 0;\n(gdb) s\n245     if ((eflags & REG_NOTBOL) != 0) options |= PCRE_NOTBOL;\n(gdb) s\n246     if ((eflags & REG_NOTEOL) != 0) options |= PCRE_NOTEOL;\n(gdb) s\n255     if (nmatch > 0)\n(gdb) s\n257         if (nmatch <= SMALL_NMATCH)\n(gdb) s\n259           ovector = &(small_ovector[0]);\n(gdb) s\n269     rc = pcre_exec(preg->re_pcre, NULL, string, (int)strlen(string), 0, opti\nons,\n(gdb) s\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x080a495b in regexec (preg=0x0,\n    string=0x8189040 'Apache=hostname.or.jp.1067634189379628; sheet=%\nu901A%u5E38%u30D5%u30A9%u30F3%u30C8; abcdefgh.html=11', nmatch=3,\n    pmatch=0xbfbff940, eflags=0) at pcreposix.c:269\n269     rc = pcre_exec(preg->re_pcre, NULL, string, (int)strlen(string), 0, opti\nons,\n(gdb) s\n\nProgram terminated with signal SIGSEGV, Segmentation fault.\nThe program no longer exists.\n\n
24483	Yutan	1068220353000	value of called to pcre_exec (from spot_cookie)\n\n269     rc = pcre_exec(preg->re_pcre, NULL, string, (int)strlen(string), 0, \noptions,\n\n(gdb) printf '%d/n',preg\n0\n(gdb) printf '%d/n', preg->re_pcre\nError accessing memory address 0x0: Bad address.\n(gdb) printf '%s/n', string\nApache=hostname.or.jp.1067634189379628; sheet=%u901A%u5E38%u30D5%u30A9%u30F3%\nu30C8; abcdefgh.html=11\n(gdb) printf '%d/n', strlen(string)\n113\n(gdb) printf '%s/n',options\nError accessing memory address 0x0: Bad address.\n\n
24483	Yutan	1068221300000	On httpd-2.0.47 will running...\n\nBreakpoint 1, spot_cookie (r=0x8186050) at mod_usertrack.c:198\n198         cookie_dir_rec *dcfg = ap_get_module_config(r->per_dir_config,\n(gdb) s\n204         if (!dcfg->enabled || r->main) {\n(gdb)\n208         if ((cookie = apr_table_get(r->headers_in,\n(gdb)\napr_table_get (t=0x8186218, key=0x80cf7dc 'Cookie') at apr_tables.c:481\n481         if (key == NULL) {\n(gdb)\n485         hash = TABLE_HASH(key);\n(gdb)\n486         if (!TABLE_INDEX_IS_INITIALIZED(t, hash)) {\n(gdb)\n489         COMPUTE_KEY_CHECKSUM(key, checksum);\n(gdb)\n490         next_elt = ((apr_table_entry_t *) t->a.elts) + t->index_first[hash];\n;\n(gdb)\n491         end_elt = ((apr_table_entry_t *) t->a.elts) + t->index_last[hash];\n(gdb)\n493         for (; next_elt <= end_elt; next_elt++) {\n(gdb)\n494             if ((checksum == next_elt->key_checksum) &&\n(gdb)\n493         for (; next_elt <= end_elt; next_elt++) {\n(gdb)\n494             if ((checksum == next_elt->key_checksum) &&\n(gdb)\n496                 return next_elt->val;\n(gdb)\n501     }\n(gdb)\nspot_cookie (r=0x8186050) at mod_usertrack.c:212\n212             if ((value = ap_strstr_c(cookie, dcfg->cookie_name))) {\n(gdb)\n215                 value += strlen(dcfg->cookie_name) + 1;  /* Skip over the '=\n' */\n(gdb)\n216                 cookiebuf = apr_pstrdup(r->pool, value);\n(gdb)\napr_pstrdup (a=0x8186018,\n    s=0x81873b7 'hostname.or.jp.1067634189379628; sheet=%u901A%u5E38%\nu30D5%u30A9%u30F3%u30C8; abcdefgh.html=11') at apr_strings.c:111\n111         if (s == NULL) {\n(gdb)\n114         len = strlen(s) + 1;\n(gdb)\n115         res = apr_palloc(a, len);\n(gdb)\napr_palloc (pool=0x8186018, size=107) at apr_pools.c:620\n620         size = APR_ALIGN_DEFAULT(size);\n(gdb)\n621         active = pool->active;\n(gdb)\n624         if (size < (apr_size_t)(active->endp - active->first_avail)) {\n(gdb)\n625             mem = active->first_avail;\n(gdb)\n626             active->first_avail += size;\n(gdb)\n628             return mem;\n(gdb)\n679     }\n(gdb)\napr_pstrdup (a=0x8186018,\n    s=0x81873b7 'hostname.or.jp.1067634189379628; sheet=%u901A%u5E38%\nu30D5%u30A9%u30F3%u30C8; line-index.html=11') at apr_strings.c:116\n116         memcpy(res, s, len);\n(gdb)\n117         return res;\n(gdb)\n118     }\n(gdb)\nspot_cookie (r=0x8186050) at mod_usertrack.c:217\n217                 cookieend = strchr(cookiebuf, ';');\n(gdb)\n218                 if (cookieend)\n(gdb)\n219                     *cookieend = '/0';      /* Ignore anything after a ; */\n(gdb)\n222                 apr_table_setn(r->notes, 'cookie', cookiebuf);\n(gdb)\napr_table_setn (t=0x81869a8, key=0x80cf7cd 'cookie',\n    val=0x8187980 'hostname.or.jp.1067634189379628')\n    at apr_tables.c:584\n584         COMPUTE_KEY_CHECKSUM(key, checksum);\n(gdb)\n585         hash = TABLE_HASH(key);\n(gdb)\n586         if (!TABLE_INDEX_IS_INITIALIZED(t, hash)) {\n(gdb)\n587             t->index_first[hash] = t->a.nelts;\n(gdb)\n588             TABLE_SET_INDEX_INITIALIZED(t, hash);\n(gdb)\n589             goto add_new_elt;\n(gdb)\n640         t->index_last[hash] = t->a.nelts;\n(gdb)\n641         next_elt = (apr_table_entry_t *) table_push(t);\n(gdb)\napr_array_push_noclear (arr=0x81869a8) at apr_tables.c:158\n158         if (arr->nelts == arr->nalloc) {\n(gdb)\n169         ++arr->nelts;\n(gdb)\n170         return arr->elts + (arr->elt_size * (arr->nelts - 1));\n(gdb)\n171     }\n(gdb)\napr_table_setn (t=0x81869a8, key=0x80cf7cd 'cookie',\n    val=0x8187980 'hostname.or.jp.1067634189379628')\n    at apr_tables.c:642\n642         next_elt->key = (char *)key;\n(gdb)\n643         next_elt->val = (char *)val;\n(gdb)\n644         next_elt->key_checksum = checksum;\n(gdb)\n645     }\n(gdb)\nspot_cookie (r=0x8186050) at mod_usertrack.c:224\n224                 return DECLINED;    /* There's already a cookie, no new one\n*/\n(gdb)\n228     }\n(gdb)\n0x0809f5f5 in ap_run_fixups (r=0x8186050) at request.c:114\n114                               (request_rec *r), (r), OK, DECLINED)\n(gdb)\nfix_encoding (r=0x8186050) at mod_negotiation.c:3077\n3077        const char *enc = r->content_encoding;\n(gdb)\n3078        char *x_enc = NULL;\n(gdb)\n3083        if (!enc || !*enc) {\n(gdb)\n3084            return DECLINED;\n(gdb)\n3117    }\n\n...etc...\n
24483	Manni Wood	1068224118000	Looks like there is a bug in the cookie finding part of mod_usertrack introduced\nby my changes to the most recent mod_usertrack: If 'CookieTracking on' is in\nhttpd.conf, 'CookieName Apache' also has to be in there. (Or, you can have the\nvalue of CookieName be whatever you like; but CookieName *has* to be set to\ncircumvent the bug I introduced.) I'll be working on a fix for this in the next\nfew days, but for now the workaround should work. --Manni Wood
24483	Yutan	1068233258000	Is it a light initialization mistake?\nDump core was avoidable. Thanks.\n\n----\nAn easy patch... (not test...It moves for the time being.)\n\nmod_usertrack.c : line 254:\n\nstatic void *make_cookie_dir(apr_pool_t *p, char *d)\n{\n    cookie_dir_rec *dcfg;\n    dcfg = (cookie_dir_rec *) apr_pcalloc(p, sizeof(cookie_dir_rec));\n    dcfg->cookie_name = COOKIE_NAME;\n    dcfg->cookie_domain = NULL;\n    dcfg->style = CT_UNSET;\n    dcfg->enabled = 0;\n+    dcfg->regexp_string = (char *)apr_palloc(p, 25 + strlen(COOKIE_NAME) * 2);\n+    apr_snprintf(dcfg->regexp_string, 25 + strlen(COOKIE_NAME) * 2\n+        , '^%s([^;]+)|;[ /t]+%s=([^;]+)', COOKIE_NAME, COOKIE_NAME);\n+    dcfg->regexp=ap_pregcomp(p, dcfg->regexp_string, REG_EXTENDED);\n    return dcfg;\n}\n
24483	Yutan	1068304354000	Since it was thought that abnormalities occurred in all OS's as long as the \nsource code was seen, Plathome was changed into All.\n
24483	Manni Wood	1068350991000	The following is my first cut at a patch. It solves all of the problems, but it\nhas not yet been assessed by anyone on the apache developer's list.\n\nTake the patch that follows, copy it to a file called\nmod_usertrack_2.0.48.patch, copy mod_usertrack_2.0.48.patch to\nhttpd-2.0.48/modules/metadata, then run patch -p0 < mod_usertrack_2.0.48.patch\nand recompile.\n\n-Manni\n\n--- mod_usertrack-old.c 2003-11-08 01:42:11.000000000 -0500\n+++ mod_usertrack.c     2003-11-08 23:02:28.000000000 -0500\n@@ -104,7 +104,7 @@\n #include 'http_config.h'\n #include 'http_core.h'\n #include 'http_request.h'\n-\n+#include 'http_log.h'\n  \n module AP_MODULE_DECLARE_DATA usertrack_module;\n  \n@@ -211,6 +211,14 @@\n         return DECLINED;\n     }\n  \n+    /* Check to be sure there is a regexp available; it may not have\n+       compiled, leaving dcfg->regexp null. */\n+    if (dcfg->regexp == NULL) {\n+        ap_log_error(APLOG_MARK, APLOG_ERR, APR_SUCCESS, r->server, 'The\nregular expression that will be used to find the usertrack cookie in the cookie\nheader could not be compiled. Disabling mod_usertrack.');\n+        dcfg->enabled = 0;\n+        return DECLINED;\n+    }\n+\n     if ((cookie_header = apr_table_get(r->headers_in,\n                                        (dcfg->style == CT_COOKIE2\n                                         ? 'Cookie2'\n@@ -260,6 +268,21 @@\n     dcfg->cookie_domain = NULL;\n     dcfg->style = CT_UNSET;\n     dcfg->enabled = 0;\n+\n+    /* The goal is to end up with this regexp,\n+     * ^COOKIE_NAME=([^;]+)|;[ /t]+COOKIE_NAME=([^;]+)\n+     * with COOKIE_NAME\n+     * obviously substituted with the real cookie name defined\n+     * by the COOKIE_NAME macro. This regexp will get replaced\n+     * by the regexp in set_cookie_name() if the CookieName is\n+     * used in httpd.conf. */\n+    dcfg->regexp_string = apr_pstrcat(p, '^', COOKIE_NAME,\n+                                      '=([^;]+)|;[ /t]+', COOKIE_NAME,\n+                                      '=([^;]+)', NULL);\n+\n+    /* Remember that ap_pregcomp could return null, so\n+       we will have to deal with this later in spot_cookie(). */\n+    dcfg->regexp = ap_pregcomp(p, dcfg->regexp_string, REG_EXTENDED);\n     return dcfg;\n }\n  
24483	Bojan Smojver	1068440204000	BTW, the segfault happens for me when Netscape and RFC2109 cookies are set.\nSetting CookieName to Apache gets rid of the problem.\n\nIf RFC2965 cookies are set, the problem is not the segfault, but rather the fact\nthat cookie simply isn't found. Therefore, every new connection generates yet\nanother cookie (as visible in the log). libapreq2 also sees the cookie as a\ndifferent one every time. Therefore, the session upkeeping cannot be done at all.\n\nIn any event, setting CookieName to Apache does not work around the above\nproblem for RFC2965 cookies. Not sure if the patch does...
24483	Manni Wood	1068528448000	Bojan Smojver, I recommend you use CookieStyle Netscape or CookieStyle Cookie\n(or the synonymous CookieStyle 2109) in httpd.conf, not CookieStyle Cookie2 (or\nthe synonymous CookieStyle RFC2965).\n\nI watched HTTP network traffic through Ethereal, and noted that while Apache\ncorrectly sends 'Cookie2:' headers, Mozilla does not accept them. This is why\nyou see a new cookie each time in your logs: Apache is not finding the cookie\nbecause your browser is not accepting 'Cookie2:' headers.\n\nThe following is my second try at a patch. It's more elegant than my first\npatch. It solves all of the problems (I tested it with or without the CookieName\ndirective, and with CookieStyle set to Apache, Cookie, and Cookie2 -- though\nMozilla doesn't yet accept Cookie2 headers, so I couldn't test cookie\ndetection). Like my previous patch, this patch\nhas not yet been assessed by anyone on the Apache developer's list.\n\nTake the patch that follows, copy it to a file called\nmod_usertrack_2.0.48.patch, copy mod_usertrack_2.0.48.patch to\nhttpd-2.0.48/modules/metadata, then run patch -p0 < mod_usertrack_2.0.48.patch\nand recompile.\n\n-Manni\n\nBojan Smojver, I recommend you use CookieStyle Netscape or CookieStyle Cookie\n(or the synonymous CookieStyle 2109) in httpd.conf, not CookieStyle Cookie2 (or\nthe synonymous CookieStyle RFC2965).\n\nI watched HTTP network traffic through Ethereal, and noted that while Apache\ncorrectly sends 'Cookie2:' headers, Mozilla does not accept them. This is why\nyou see a new cookie each time in your logs: Apache is not finding the cookie\nbecause your browser is not accepting 'Cookie2:' headers.\n\nThe following is my second try at a patch. It's more elegant than my first\npatch. It solves all of the problems (I tested it with or without the CookieName\ndirective, and with CookieStyle set to Apache, Cookie, and Cookie2 -- though\nMozilla doesn't yet accept Cookie2 headers, so I couldn't test cookie\ndetection). Like my previous patch, this patch\nhas not yet been assessed by anyone on the Apache developer's list.\n\nTake the patch that follows, copy it to a file called\nmod_usertrack_2.0.48.patch, copy mod_usertrack_2.0.48.patch to\nhttpd-2.0.48/modules/metadata, then run patch -p0 < mod_usertrack_2.0.48.patch\nand recompile.\n\n-Manni\n\n--- mod_usertrack-old.c\t2003-11-10 23:28:19.000000000 -0500\n+++ mod_usertrack.c\t2003-11-11 00:16:15.000000000 -0500\n@@ -199,6 +199,20 @@\n  * which has three subexpressions, $0..$2 */\n #define NUM_SUBS 3\n \n+static void set_and_comp_regexp(cookie_dir_rec *dcfg, \n+                                apr_pool_t *p,\n+                                const char *cookie_name) \n+{\n+    /* The goal is to end up with this regexp, \n+     * ^cookie_name=([^;]+)|;[/t]+cookie_name=([^;]+) \n+     * with cookie_name obviously substituted either\n+     * with the real cookie name set by the user in httpd.conf, or with the\n+     * default COOKIE_NAME. */\n+    dcfg->regexp_string = apr_pstrcat(p, '^', cookie_name, '=([^;]+)|;[ /t]+',\ncookie_name, '=([^;]+)', NULL);\n+\n+    dcfg->regexp = ap_pregcomp(p, dcfg->regexp_string, REG_EXTENDED);\n+}\n+\n static int spot_cookie(request_rec *r)\n {\n     cookie_dir_rec *dcfg = ap_get_module_config(r->per_dir_config,\n@@ -260,6 +274,11 @@\n     dcfg->cookie_domain = NULL;\n     dcfg->style = CT_UNSET;\n     dcfg->enabled = 0;\n+\n+    /* In case the user does not use the CookieName directive,\n+     * we need to compile the regexp for the default cookie name. */\n+    set_and_comp_regexp(dcfg, p, COOKIE_NAME);\n+\n     return dcfg;\n }\n \n@@ -345,18 +364,10 @@\n {\n     cookie_dir_rec *dcfg = (cookie_dir_rec *) mconfig;\n \n-    /* The goal is to end up with this regexp,\n-     * ^cookie_name=([^;]+)|;[ /t]+cookie_name=([^;]+)\n-     * with cookie_name\n-     * obviously substituted with the real cookie name set by the\n-     * user in httpd.conf. */\n-    dcfg->regexp_string = apr_pstrcat(cmd->pool, '^', name,\n-                                      '=([^;]+)|;[ /t]+', name,\n-                                      '=([^;]+)', NULL);\n-\n     dcfg->cookie_name = apr_pstrdup(cmd->pool, name);\n \n-    dcfg->regexp = ap_pregcomp(cmd->pool, dcfg->regexp_string, REG_EXTENDED);\n+    set_and_comp_regexp(dcfg, cmd->pool, name);\n+\n     if (dcfg->regexp == NULL) {\n         return 'Regular expression could not be compiled.';\n     }\n
24483	Steve Revilak	1068583769000	Similar behavior exists in version 1.3.29 (Solaris 7); 'CookieTracking On' with \nno 'CookieName' results in a SIGSEGV.  Explicitly setting CookieName as \nsuggested in 'Additional Comments From Manni Wood 2003-11-07 16:55' appears to \nbe a successful workaround for 1.3.29 as well.\n\n#\n# Debugger trace of mod_usertrack segfault on apache 1.3.29, Solaris 7\n# ('CookieTracking on', no CookieName set in httpd.conf\n#\nBreakpoint 1, spot_cookie (r=0xe7950) at mod_usertrack.c:295\n295         cookie_dir_rec *dcfg = ap_get_module_config(r->per_dir_config,\n#\n#\n# show cookie_dir_rec\n#\n#\n(gdb) print *dcfg\n$8 = {enabled = 1, style = CT_NETSCAPE, format = CF_NORMAL, \n  cookie_name = 0x1 <Address 0x1 out of bounds>, \n  cookie_domain = 0x1 <Address 0x1 out of bounds>, \n  prefix_string = 0x190 <Address 0x190 out of bounds>, regexp_string = 0x0, \nregexp = 0x0}\n#\n#\n# Step further ...\n#\n#\n(gdb) s\n301         if (!dcfg->enabled) {\n(gdb) s\n305         if ((cookie_header = ap_table_get(r->headers_in,\n(gdb) s\n309             if (!ap_regexec(dcfg->regexp, cookie_header, NUM_SUBS, regm, \n0)) {\n#\n#\n# Show parameters passed to ap_regexec.  cookie_header appears\n# to hold data; dcfg->regexp is a null pointer\n#\n#\n(gdb) print cookie_header\n$9 = 0xe7360 'Apache=172.19.30.174.114851068582299525'\n(gdb) print dcfg->regexp\n$11 = (regex_t *) 0x0\n#\n#\n# Stepping into ap_regexec ...\n#\n#\n(gdb) s\n\nProgram received signal SIGSEGV, Segmentation fault.\n0xff1e88e0 in __regexec_C () from /usr/lib/libc.so.1\n#\n#\n# show backtrace\n#\n#\n#\n(gdb) bt\n#0  0xff1e88e0 in __regexec_C () from /usr/lib/libc.so.1\n#1  0x4412c in ap_regexec ()\n#2  0xfe591090 in spot_cookie (r=0xe7950) at mod_usertrack.c:309\n#3  0x20130 in run_method ()\n#4  0x20290 in ap_run_fixups ()\n#5  0x409e4 in process_request_internal ()\n#6  0x40f90 in ap_internal_redirect ()\n#7  0x401e4 in ap_die ()\n#8  0x402b8 in decl_die ()\n#9  0x4069c in process_request_internal ()\n#10 0x40aa0 in ap_process_request ()\n#11 0x33380 in child_main ()\n#12 0x3363c in make_child ()\n#13 0x33858 in startup_children ()\n#14 0x3431c in standalone_main ()\n#15 0x34f90 in main ()\n\n\n$ httpd -V\n\n$ /d/apache/bin/httpd -V\nServer version: Apache/1.3.29 (Unix)\nServer built:   Nov 11 2003 10:26:38\nServer's Module Magic Number: 19990320:15\nServer compiled with....\n -D EAPI\n -D EAPI_MM\n -D EAPI_MM_CORE_PATH='logs/httpd.mm'\n -D HAVE_MMAP\n -D USE_MMAP_SCOREBOARD\n -D USE_MMAP_FILES\n -D HAVE_FCNTL_SERIALIZED_ACCEPT\n -D HAVE_SYSVSEM_SERIALIZED_ACCEPT\n -D HAVE_PTHREAD_SERIALIZED_ACCEPT\n -D DYNAMIC_MODULE_LIMIT=64\n -D HARD_SERVER_LIMIT=2048\n -D HTTPD_ROOT='/d/apache-1.3.29-20031117'\n -D SUEXEC_BIN='/d/apache-1.3.29-20031117/bin/suexec'\n -D DEFAULT_PIDLOG='logs/httpd.pid'\n -D DEFAULT_SCOREBOARD='logs/httpd.scoreboard'\n -D DEFAULT_LOCKFILE='logs/httpd.lock'\n -D DEFAULT_ERRORLOG='logs/error_log'\n -D TYPES_CONFIG_FILE='conf/mime.types'\n -D SERVER_CONFIG_FILE='conf/httpd.conf'\n -D ACCESS_CONFIG_FILE='conf/access.conf'\n -D RESOURCE_CONFIG_FILE='conf/srm.conf' \n\n
24483	Manni Wood	1068591862000	That's right, Steve. When I introduced my mod_usertrack patch (and, sadly, bug)\nto mod_usertrack for the latest 2.0.x release, I also back-ported it to the\nlatest 1.3.x release, so the bug will be the same for 1.3.x as for 2.0.x, and\nthe workaround will be the same, as you have already discovered.\n\nI'm waiting for advice on the 2.0.x patch you see below from a developer who's\ncloser to the ASF than I am. Once I get an all clear, I'll submit the fix to the\nApache developer's mailing list as a 2.0.x patch as well as a back-ported 1.3.x\npatch.\n\n-Manni 
24483	Erik Abele	1068605692000	*** Bug 24384 has been marked as a duplicate of this bug. ***
24483	Cliff Woolley	1069655404000	manni: latest patch is looking good so far.  i'll give it a closer look \ntomorrow.  sorry i couldn't get it taken care of at apachecon last week... my \nnotebook's hard drive crashed!  doh!!  =)\n\nfyi, i put a notice on http://httpd.apache.org/ about this problem since lots \nof people seem to be hitting it.
24483	Will Rowe	1069884537000	\n  Please tag such reports with the FAQ keyword as well :)\n
24483	Yutan	1072668686000	I'm somewhat busy, and did'nt see and become precocious.\nChecked with Mr. Manni Wood's patch.\nSince the same bug was checked also by the old Sun machine, Plathome was \nchanged into All.\n
24483	Jim Jagielski	1073917112000	Patch backported for 1.3, passes tests and posted to list.
24483	Erik Abele	1074544700000	*** Bug 26203 has been marked as a duplicate of this bug. ***
24483	Erik Abele	1074544789000	Fix committed to 2.1, 2.0 and 1.3:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/metadata/mod_usertrack.c#rev1.42\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/metadata/mod_usertrack.c#rev1.39.2.3\nhttp://cvs.apache.org/viewcvs.cgi/apache-1.3/src/modules/standard/mod_usertrack.c#rev1.60\n
24483	Cliff Woolley	1074552440000	Um, it looks like Jim committed the fix for this bug to 1.3, but it hasn't \ngotten committed yet to 2.0 or 2.1 (for no particular reason than I never got \naround to it).  Reopening until that happens.
24483	Erik Abele	1074552880000	Oh yeah, thanks Cliff, you're right. I was blindly looking at the places where the problem was \nintroduced :( 
24483	Manni Wood	1074610497000	Thanks, guys, for helping patch this. --Manni
24483	Andr?? Malo	1080202440000	Fixed in 2.0.49. Please upgrade.
24483	Andr?? Malo	1080434926000	*** Bug 28000 has been marked as a duplicate of this bug. ***
24483	Andr?? Malo	1082065061000	Changes on a closed fixed bug are not that clever. Please give more details if\nyou want to reopen it. Thanks.
24483	Richard W.M. Jones	1143289808000	mod_usertrack is segfaulting for me on Apache 1.3.33 (Debian package\n1.3.33-6 on AMD64).\n\nCookieTracking on --> child processes segfault\n\nSetting CookieName makes no difference.\n\nThe same Debian package recompiled for i386 works.  It only fails on AMD64.\n\nstrace is not very informative.\n\nThe stack trace from the segfault is:\n\n#0  0x00000000004317da in regcomp ()\n#1  0x000000000043133d in regcomp ()\n#2  0x0000000000430954 in regcomp ()\n#3  0x00000000004305f1 in regcomp ()\n#4  0x00002aaaac522a70 in ?? () from /usr/lib/apache/1.3/mod_usertrack.so\n#5  0x000000000040ecc1 in ap_cleanup_method_ptrs ()\n#6  0x00000000004203ca in ap_some_auth_required ()\n#7  0x0000000000420555 in ap_process_request ()\n#8  0x00000000004196ce in ap_child_terminate ()\n#9  0x000000000041991d in ap_child_terminate ()\n#10 0x0000000000419996 in ap_child_terminate ()\n#11 0x000000000041a329 in ap_child_terminate ()\n#12 0x000000000041a805 in main ()\n\n(Sorry, no symbols in Debian packages - I will try to get those next).\n\nRich.
24483	Richard W.M. Jones	1143290982000	This is the full stack trace.  It's different from the one above ...  I think\nbecause I've now got the cookie and it's trying to parse it.\n\n#0  0x00000000004317da in sstep (g=0x66b9b0, start=-2039141192980765773,\n    stop=34, bef=8, ch=132, aft=8) at engine.c:909\n#1  0x000000000043133d in sslow (m=0x7fffffbc6410,\n    start=0xe3b383e38983e3b3 <Address 0xe3b383e38983e3b3 out of bounds>,\n    stop=0x83edf0 'Apache=10.0.1.138.132001143290662991;\n__utma=170107067.1695268367.1143290799.1143290799.1143290799.1;\n__utmb=170107067; __utmc=170107067;\n__utmz=170107067.1143290799.1.1.utmccn=(direct)|utmcsr=(direct'..., startst=35,\n    stopst=34) at engine.c:738\n#2  0x0000000000430954 in sdissect (m=0x7fffffbc6410,\n    start=0xe3b383e38983e3b3 <Address 0xe3b383e38983e3b3 out of bounds>,\n    stop=0x83edf0 'Apache=10.0.1.138.132001143290662991;\n__utma=170107067.1695268367.1143290799.1143290799.1143290799.1;\n__utmb=170107067; __utmc=170107067;\n__utmz=170107067.1143290799.1.1.utmccn=(direct)|utmcsr=(direct'...,\n    startst=120993912, stopst=34) at engine.c:371\n#3  0x00000000004305f1 in smatcher (g=0x66b9b0,\n    string=0x8 <Address 0x8 out of bounds>, nmatch=3, pmatch=0x7fffffbc64c0,\n    eflags=0) at engine.c:157\n#4  0x00002aaaac522a70 in spot_cookie (r=0x83a8d0) at mod_usertrack.c:310\n#5  0x000000000040ecc1 in run_method (r=0x83a8d0, offset=-1987845197,\n    run_all=1) at http_config.c:327\n#6  0x00000000004203ca in process_request_internal (r=0x83a8d0)\n    at http_request.c:1293\n#7  0x0000000000420555 in ap_process_request (r=0x83a8d0)\n    at http_request.c:1314\n#8  0x00000000004196ce in child_main (child_num_arg=8628432)\n    at http_main.c:4873\n#9  0x000000000041991d in make_child (s=0x5540b0, slot=0, now=1143290662)\n    at http_main.c:4997\n#10 0x0000000000419996 in startup_children (number_to_start=5)\n    at http_main.c:5079\n#11 0x000000000041a329 in standalone_main (argc=8552640,\n    argv=0xe3b383e38983e3b3) at http_main.c:5411\n#12 0x000000000041a805 in main (argc=2, argv=0x7fffffbc67c8)\n    at http_main.c:5768\n\nmod_usertrack.c line 310 is the second line here (the one\ncontaining ap_regexec ...)\n\n    if ((cookie_header = ap_table_get(r->headers_in, 'Cookie'))) {\n        if (!ap_regexec(dcfg->regexp, cookie_header, NUM_SUBS, regm, 0)) {\n            char *cookieval = NULL;\n            /* Our regexp,\n             * ^cookie_name=([^;]+)|;[ /t]+cookie_name=([^;]+)\n             * only allows for $1 or $2 to be available. ($0 is always\n             * filled with the entire matched expression, not just\n             * the part in parentheses.) So just check for either one\n             * and assign to cookieval if present. */\n            if (regm[1].rm_so != -1) {\n                cookieval = ap_pregsub(r->pool, '$1', cookie_header,\n                                       NUM_SUBS, regm);\n            }\n            if (regm[2].rm_so != -1) {\n                cookieval = ap_pregsub(r->pool, '$2', cookie_header,\n                                       NUM_SUBS, regm);\n            }\n            /* Set the cookie in a note, for logging */\n            ap_table_setn(r->notes, 'cookie', cookieval);\n\n            return DECLINED;    /* There's already a cookie, no new one */\n        }\n    }\n    make_cookie(r);\n    return OK;                  /* We set our cookie */\n
24483	Richard W.M. Jones	1143291172000	(gdb) frame 4\n#4  0x00002aaaac522a70 in spot_cookie (r=0x83a8d0) at mod_usertrack.c:310\n310             if (!ap_regexec(dcfg->regexp, cookie_header, NUM_SUBS, regm, 0)) {\n(gdb) print cookie_header\n$1 = 0x83edd8 'Apache=10.0.1.138.132001143290662991;\n__utma=170107067.1695268367.1143290799.1143290799.1143290799.1;\n__utmb=170107067; __utmc=170107067;\n__utmz=170107067.1143290799.1.1.utmccn=(direct)|utmcsr=(direct'...\n(gdb) print regm\n$2 = {{rm_so = -1, rm_eo = 0}, {rm_so = 0, rm_eo = 0}, {rm_so = 0, rm_eo = 0}}\n(gdb) print NUM_SUBS\n$3 = 3\n(gdb) print dcfg->regexp\n$4 = (regex_t *) 0x73bf20\n(gdb) print *dcfg->regexp\n$5 = {re_magic = 62053, re_nsub = 2, re_endp = 0x0, re_g = 0x66b9b0}\n
24483	Joe Orton	1168319523000	The issue for which this bug was re-opened is AFAICT only the crash in regcomp()\net al on x86_64 - which is a different bug, bug 31858.  Marking CLOSED again.
24643	Jeff Trawick	1068669250000	What's the issue with SMP systems?  Do you mean that the box where it failed is\nSMP?  What commands are you using to build Apache?  What Linux is it?\n
24643	Joe Orton	1068671144000	It fails with a parallel make i.e. make -j2 with GNU make... HEAD has this change:\n\n# Needed to allow exports.c to be generated in a parallel build successfully\n.NOTPARALLEL: $(top_builddir)/server/exports.c\n\nI'm not sure whether this is really needed or whether the paths to exports.c\njust need to be fixed to be either absolute or not all through that Makefile, it\nseems confused.
24643	Sviatoslav Sviridov	1068718655000	Sorry for not very accurate report,\nyes, it fails when make satrted as 'make -j2'.\n\nAnd it seems that adding\n\n.NOTPARALLEL: $(top_builddir)/server/exports.c\n\nalso helps. I hope, it's better solution. I'm not so experienced in Makefiles,\nso I think you'll do it better than me.\nThanks.
24643	Joe Orton	1070378174000	Created an attachment (id=9357)\nunfixes for server/Makefile.in\n
24643	Joe Orton	1070378487000	Attached what looks like the right fix to me (for HEAD); awaiting review before\ncommitting.
24643	Joe Orton	1073917910000	Fixed for 2.0.49 - thanks for the report.
24734	Jeff Trawick	1069023186000	just curious: when you say 'It's no longer possible' you're comparing 1.3 with\n2.0.48, right?\n
24734	Markus Julen	1069061815000	Yes, it works with 1.3 (1.3.26 was the latest I checked it on).\n\nIt doesn't work with 2.0.47 and .48 in .htaccess files (mod_env), but setting it in an html file works \n(mod_include).
24734	Jeff Trawick	1069201170000	Thanks for the response.  I expect to commit the fix in next 24h or so.
24734	Jeff Trawick	1069386750000	Thanks for your efforts!  The fix is now in Apache 2.1-dev and has been proposed\nfor merging into the stable branch (2.0.next).\n
24734	Jeff Trawick	1070520549000	now merged into stable branch for 2.0.49
24801	Jess Holle	1085158825000	P.S.  I believe this issue might may still be masked by an undersized shared\nmemory block even though bug #24800 appears to be fixed in 2.0.49.\n\nFor instance with:\n\n  LDAPCacheEntries 2150\n  # Next line was necessary last I checked as 0 caused issues with active cache\n  LDAPOpCacheEntries  1\n  LDAPSharedCacheSize 865000\n  LDAPSharedCacheFile logs/mod_ldap_cache\n\nI get a child process crash one I get to somewhere between 2151 and 2155\ndistinct users.\n\nFinally, I'm pretty sure I verified that this issue exists on Solaris and AIX as\nwell -- but I clearly forgot to note it here.
24801	Graham Leggett	1085163029000	Trying to look at this now, although I'm not that familiar with the cache code.\nDo you have an example of a stacktrace where the crash is occuring?\n\nI'm trying to work out why the problem would be in cache cleanup rather than in\nadding to the cache - maybe it's an edge case somewhere in the cleanup?\n
24801	Joe Orton	1085171253000	It's a long-standing bug that the shared memory caching code does not check for\nthe apr_rmm_*alloc functions returning NULL, so it will of course die horribly\nif the rmm segment fills up and the code tries to allocate more:\n\nreturn (void *)apr_rmm_addr_get(cache->rmm_addr, apr_rmm_calloc(cache->rmm_addr,\nsize));\n
24801	Jess Holle	1085172236000	That is a separate bug -- which I believe has been fixed in/by 2.0.49 -- at\nleast my test case for it no longer failed there.\n\nThis bug is about the case where the physical shared memory bytes are sufficient\nbut the specified logical cache size (i.e. # of entries) is not.\n\nIn this case, the cache should simply purge older entries.  Instead it crashes\n(attempting to do this).  I've been meaning to generate a stack trace, but have\nnot managed yet.
24801	Graham Leggett	1085191589000	Created an attachment (id=11633)\nAdd checking for NULL in *_rmm_* functions\n
24801	Graham Leggett	1085191617000	Does this patch make any difference for you?\n
24801	Graham Leggett	1085193800000	In util_ald_cache_insert(), it attempts to add an item to the cache. There is no\ncheck for whether the cache is full, because it is assumed that on the edge case\n(of the very last cache entry being allocated) util_ald_cache_purge() will run,\nwhich again is assumed to bring down the cache size.\n\nSo in this case, it looks like util_ald_cache_purge() is not bringing down the\ncache size, so on the next entry we overflow.\n\nTry this patch and see if it makes a difference - it checks for overflow before\nwe add, not after. The purge code is probably still broken, but at least we\nwon't segfault.
24801	Graham Leggett	1085193859000	Created an attachment (id=11634)\nAdd sanity check so that we don't overflow if purge fails for any reason\n
24801	Graham Leggett	1085351374000	Just committed the above patches to the v2.1.0-dev tree, as they stomp on the\nsegfaults.\n\nThe cache problem remains however, if the cache sizes at set to 1, mod_auth_ldap\nstarts returning auth failures.\n
24801	Jess Holle	1085429246000	I applied the patch provided to 2.0.49 sources (the latest I had readily\navailable) and get a crash with the following traceback (on Windows).  Note this\nwas for user 2161 with a cache size of 2150.  Also note that this executable\nalso includes the latest patches for util_ldap.c [for authenticated LDAP server\naccess] and mod_auth_ldap.c [for avoiding double-escaping with Microsoft's LDAP\nSDK].\n\nutil_ldap_dn_compare_node_compare(void * 0x00815b98, void * 0x04d4de80) line 91\n+ 12 bytes\nutil_ald_cache_fetch(util_ald_cache * 0x00d8008c, void * 0x04d4de80) line 351 +\n17 bytes\nutil_ldap_cache_checkuserid(request_rec * 0x6fb51341, util_ldap_connection_t *\n0x007dd1e8, const char * 0x0078ced0, const char * 0x007799c8, int 7991832, char\n* * 0x00000002, const char * 0x00000000, const char * 0x04d4def0, const char * *\n0x007dee59, const char * * * 0x04d4dee4) line 766 + 22 bytes\nmod_auth_ldap_check_user_id(request_rec * 0x6ff10e5f) line 334\nap_run_check_user_id(request_rec * 0x007dd1e8) line 69 + 31 bytes\nap_process_request_internal(request_rec * 0x6ff0d6f8) line 193 + 6 bytes\nap_process_request(request_rec * 0x007dd1e8) line 245\nap_process_http_connection(conn_rec * 0x6ff0423f) line 250 + 6 bytes\nap_run_process_connection(conn_rec * 0x007c8ab8) line 42 + 31 bytes\nap_process_connection(conn_rec * 0x007c8ab8, void * 0x007c89e8) line 175 + 6 bytes\nworker_main(long 2013300156) line 718\nMSVCRT! 780085bc()\nKERNEL32! 7c581af6()\n\nOnce I let this process die a new child process is created and the test set (of\n2500 users) works fine.\n\nFor testing this sort of thing, I recommend just exporting a single user (with\npassword) from LDAP and using this export as a template to programmatically\ncreate many users all the same attributes except for the user name.  You can\nthen use a simple program, script, or even Ant to attempt to fetch an\nauthenticated resource on behalf of each user in turn.
24801	Graham Leggett	1085507697000	Patches to fix segfaults in the cache code were applied to v2.1.0-dev and\nv2.0.50-dev. Testing this by reducing the cache sizes to a size of 1 show that\nthe segfaults are gone, but the mod_auth_ldap module is returning an auth fail\nwhen it shouldn't, and the cache gets full and stays full.\n\nI have created a new bug report for this: 29207.\n\n\n*** This bug has been marked as a duplicate of 29207 ***
24801	Jess Holle	1089389673000	> Note that the last time I tested the cache entry overflow it still\n> crashed when I through 2500 unique user login attempts at a 2150\n> entry cache.  This is more representative of our real use cases\n> than 5 unique users against a single user entry cache or the like\n> and I've not had a chance to (or much interest in) testing this\n> particular case.\n\nI've built an Apache 2.0.50 from sources for Windows (to get HTTPS support, of\ncourse, plus tiny extensions to mod_deflate and sockopt -- which is missing\nsend-buffer-size configurability on Windows) and re-ran the test noted above.\n\nI get a 100% repeatable crash at around user 2160, i.e. the buffer overflow is\n*not* fixed, at least not on Windows.  [I can test Solaris and AIX when I get\nthose binaries built.]\n\nIn short, this bug is *not* fixed in 2.0.50.
24801	Jess Holle	1095785467000	Created an attachment (id=12817)\nFix to util_ald_cache_purge() to relink lists properly\n
24801	Jess Holle	1095785672000	As per the last comment, I have found the problem behind this bug:\nutil_ald_cache_purge() simply never relinked the linked list entries during\ncache purge.  Instead it freed various elements in the linked list without\nupdating any linked list pointers, thus begging for trouble as the memory is\nreused, etc...\n\nAlso, I know this has been resolved as 'duplicate', but the fix I have found\nproves that the problem was not limited to 'duplicate'' bug 29207.  I am thus\nreopening this until someone commits my patch.
24801	Brad Nicholes	1096480360000	The final patch for this bug that fixes the util_ald_cache_purge()relink \nproblem has been backported and posted.  See \ndist/httpd/patches/apply_to_2.0.52.
24801	Graham Leggett	1096820266000	*** Bug 29207 has been marked as a duplicate of this bug. ***
24805	Herbert G. Fischer	1069199793000	Correction:\n\nAfter stoping Apache, the pipe log programs stops too, but Apache forks\nanother set of them\nbefore stoping itself.\n\n# apachectl start\n# ps axuww\n\nUSER       PID %CPU %MEM   VSZ  RSS TTY      STAT START   TIME COMMAND\nroot     18785  1.0  0.7 22832 7732 ?        S    21:52   0:00\n/usr/local/httpd-2.0.48/bin/httpd -k start\napache   18788  0.0  0.7 22856 7772 ?        S    21:52   0:00\n/usr/local/httpd-2.0.48/bin/httpd -k start\napache   18789  0.0  0.7 22856 7772 ?        S    21:52   0:00\n/usr/local/httpd-2.0.48/bin/httpd -k start\napache   18790  0.0  0.7 22856 7772 ?        S    21:52   0:00\n/usr/local/httpd-2.0.48/bin/httpd -k start\napache   18791  0.0  0.7 22856 7772 ?        S    21:52   0:00\n/usr/local/httpd-2.0.48/bin/httpd -k start\napache   18792  0.0  0.7 22856 7772 ?        S    21:52   0:00\n/usr/local/httpd-2.0.48/bin/httpd -k start\nroot     18786  0.0  0.0  1480  268 ?        S    21:52   0:00\n/usr/local/sbin/cronolog /usr/local/sites/portal/logs/access.%Y-%m-%d.log\nroot     18787  0.0  0.0  1480  268 ?        S    21:52   0:00\n/usr/local/sbin/cronolog /usr/local/sites/default/logs/access.%Y-%m-%d.log\n\n# apachectl stop\n# ps axuww\n\nroot     18819  0.0  0.0  1480  268 ?        S    21:54   0:00\n/usr/local/sbin/cronolog /usr/local/sites/default/logs/access.%Y-%m-%d.log\nroot     18820  0.0  0.0  1480  268 ?        S    21:54   0:00\n/usr/local/sbin/cronolog /usr/local/sites/portal/logs/access.%Y-%m-%d.log
24805	Herbert G. Fischer	1069337255000	I created a small C program that captures all signals and logs to a file which\nsignal it received. This program only stops with SIGKILL.\n\nI put it as a piped log program on httpd.conf to test what apache is doing with\nthem.\n\nAfter running apachectl start, apache runs twice each piped log. I've put two\ncustom logs with piped logs on httpd.conf and apache started 4 piped log instances.\n\nhere are the logs after apache starts:\n\npid 9146 started at Thu Nov 20 11:58:51 2003\npid 9146 received signal 15\npid 9147 started at Thu Nov 20 11:58:51 2003\npid 9147 received signal 15\npid 9149 started at Thu Nov 20 11:58:52 2003\npid 9150 started at Thu Nov 20 11:58:52 2003\n\nApache starts a set of these piped log programs and send SIGTERM to them. After,\napache starts them again.\n\nAfter calling apachectl stop, here are the logs:\n\npid 9146 started at Thu Nov 20 11:58:51 2003\npid 9146 received signal 15\npid 9147 started at Thu Nov 20 11:58:51 2003\npid 9147 received signal 15\npid 9149 started at Thu Nov 20 11:58:52 2003\npid 9149 received signal 15\npid 9150 started at Thu Nov 20 11:58:52 2003\npid 9150 received signal 15\n\nApache sent SIGTERM to the last two instances of my piped log programs.\n\nI think that the bug is related to how Apache treats piped log programs crashes.\n When calling apachectl stop, apache kills all piped log programs with SIGTERM\nbut the crash-safe code of piped log programs starts all piped log programs\nagain, leaving them running before apache really stops.\n\nPlease! I need help here! Nobody is helping! I'm starting to consider not\ntesting Apache 2 anymore if nobody helps me on this problem.
24805	Jeff Trawick	1069343227000	I am sorry you are frustrated, and I am very empathetic.  Please note that\nsomething is happening with this PR, but it is not at all obvious to the casual\nobserver.\n\nThe piped log program respawning issue appears to be related to a mod_cgid\ndaemon respawning issue that has prevented the cgid daemon respawning logic to\nbe merged into stable.\n\nWhat we're working on is a way for other child logic such as piped log\nmanagement and cgid daemon management to be able to query whether or not the\nserver is terminating.  That info is needed to avoid re-spawning the child at\ntermination.  See the thread 'ap_get_server_state()' on dev@httpd.  Respawning\nlogic is just one use for ap_get_server_state(), so there probably isn't any\nexplicit text describing the relationship in that thread.
24805	Jeff Trawick	1069343424000	another note in case certain developers see this and think I am ignoring their\ncomments :)\n\nreplace 'ap_get_server_state()' references in my previous update to this PR with\n'new flavor of ap_mpm_query(), or something else that gives the state of the server'\n
24805	Jeff Trawick	1069365446000	you didn't mention what MPM you're using...  I added some general support to\nprefork thus far to fix this type of problem, and also changed the piped log\nsupport to use this logic...  changes for worker and other MPMs will come later\n\nI'll attach a patch for 2.0.48 and prefork MPM in a moment...  if you're using\nprefork, please try it out...  the symptoms I get seem to vary from platform to\nplatform (sometimes I can't see any symptom, sometimes Apache tries to start the\npiped log program but something has been corrupted and prevents it from\nstarting, etc.)
24805	Jeff Trawick	1069365533000	Created an attachment (id=9220)\nkeep apache from trying to restart piped loggers at termination\n
24805	Herbert G. Fischer	1069367468000	I don't know what MPM is. Can you tell me, so I can tell you what MPM I'm using.\n\nI found that all this problem doesn't happen on a IBM PPC 7046-B50 PowerPC 604r\nwith SuSE 7.3 PPC.
24805	Jeff Trawick	1069373159000	If you don't know which MPM, that probably means you're using the default\n(prefork).  You can display the MPM via 'apachectl -V'.  Here is how prefork looks:\n\n$ /usr/local/apache2047/bin/apachectl -V | grep MPM\n -D APACHE_MPM_DIR='server/mpm/prefork'\n\nHere is how worker looks:\n\n$ ph/2.0.47/built/bin/apachectl -V | grep MPM\n -D APACHE_MPM_DIR='server/mpm/worker'\n\nIncidentally, I too had a system that had no apparent ill symptom (RedHat 6.1 on\na Pentium III 500MHz).  I suspect that many (most?) people aren't noticing any\nsuch problem with piped loggers, at least on a regular basis.\n
24805	Herbert G. Fischer	1069381127000	Yes... It's prefork. If I can switch this to another thing, what do you\nrecommend ? I pretend to try to see if this problem is solved for now.\n\nhere is my apachectl -V output:\n\nServer version: Apache/2.0.48\nServer built:   Nov 18 2003 21:28:26\nServer's Module Magic Number: 20020903:4\nArchitecture:   32-bit\nServer compiled with....\n -D APACHE_MPM_DIR='server/mpm/prefork'\n -D APR_HAS_SENDFILE\n -D APR_HAS_MMAP\n -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)\n -D APR_USE_SYSVSEM_SERIALIZE\n -D APR_USE_PTHREAD_SERIALIZE\n -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT\n -D APR_HAS_OTHER_CHILD\n -D AP_HAVE_RELIABLE_PIPED_LOGS\n -D HTTPD_ROOT='/usr/local/httpd-2.0.48'\n -D SUEXEC_BIN='/usr/local/httpd-2.0.48/bin/suexec'\n -D DEFAULT_PIDLOG='logs/httpd.pid'\n -D DEFAULT_SCOREBOARD='logs/apache_runtime_status'\n -D DEFAULT_LOCKFILE='logs/accept.lock'\n -D DEFAULT_ERRORLOG='logs/error_log'\n -D AP_TYPES_CONFIG_FILE='conf/mime.types'\n -D SERVER_CONFIG_FILE='conf/httpd.conf'\n\n\nThis are the hardware configuration of both machines I've experienced problems:\n\nIntel P4 Xeon 2.2 Ghz - 2GB RAM\nIntel P4 1.6 - 512MB RAM\n\nBoth are running optimized kernels for P4.\n\nI was thinking on something... but I cannot see if it's absurd... \nBoth machines are very fast, and both are using Slack 9.1\nAs Apache 2 have multithread support, can the speed affect Apache ou some system\nlib for multithread ??\n\nTks!
24805	Herbert G. Fischer	1069381401000	Also:\n\nI need to use PHP within these servers. So, I going to have problems on changing\nthe MPM to worker or another else ??
24805	Jeff Trawick	1069382136000	I'm not suggesting you switch to worker MPM ;)  I originally didn't know which\nMPM you were using and wanted to point out that the patch doesn't fix the worker\nscenario, only the prefork scenario.  Now we know you're using prefork, so keep\nyour configuration, apply the patch, and do make && make install and hopefully\nthis problem will be resolved for you. \n
24805	Herbert G. Fischer	1069416379000	I see.\n\nI tested with MPM worker and PHP+ZTS and It worked correctly. No respawning\npiped log programs.\n\nThis setup it stable ?? Can I leave that ?
24805	Jeff Trawick	1069417249000	The PHP folks recommend to NOT use PHP with a threaded Apache 2 MPM such as\nworker, because they offer interfaces to a lot of 3rd party libraries and cannot\nensure that such calls are thread-safe.\n\nI don't know how to evaluate whether or not your PHP usage is subject to such\nproblems.  Unless the PHP folks can help you evaluate your situation, I'd\nrecommend using the prefork MPM.\n
24805	Herbert G. Fischer	1069418014000	Thanks for you help. I'm getting back to prefork with your patch applied. But\nI'm not giving up.\n\nIf you need anything to help debug this problem, as I have it, please, tell me.\n\nAnd thanks for the patch!
24805	Jeff Trawick	1069426642000	*** Bug 19035 has been marked as a duplicate of this bug. ***
24805	Jeff Trawick	1069468144000	*** Bug 19981 has been marked as a duplicate of this bug. ***
24805	Jeff Trawick	1071352965000	*** Bug 23109 has been marked as a duplicate of this bug. ***
24805	Jeff Trawick	1071354124000	Fix committed to 2.1-dev.  Hopefully it can be committed to stable branch before\ntoo terribly long.\n
24805	Jeff Trawick	1071364935000	*** Bug 19846 has been marked as a duplicate of this bug. ***
24805	David Rees	1071542250000	Just want to confirm that this patch does appear to fix the bug for me, I no\nlonger have stale cronolog processes sitting around after stopping or restarting\nApache.
24805	Peter Bieringer	1071674633000	My problem was the same David Rees wrote about, I can also confirm that it is\nsolved now.\n\nPlease push it into 2.0.49
24805	Herbert G. Fischer	1071680605000	The patch solved my problem too. Thanks!\nI recommend this onto the next Apache release.
24805	Jeff Trawick	1071683410000	Thanks for the reports, folks!  I have indicated with the merge request that it\nwas tested successfully by our users.\n
24884	yuk	1069752430000	I found an old issue (http://www.apacheweek.com/issues/96-08-30)... seems to be \nan old problem:\n\n<cut....>\n\nResponses can also contain a definite time when the document will expire, in \nthe Expires HTTP header. There are some cases where the expiry time of a \ndocument might change, even if the document itself has not changed. So a 304 \nstatus message can include an updated expires time, which the browser should \nuse to replace the expires time in it's cached copy of the file. Currently \nApache does not send out the expires header on 304 status, which is required by \nHTTP/1.1. The problem with not sending out the expires header is that the \nbrowser still keeps the old expiry time, so it thinks the document has expired \nstraight away. This will be fixed in the next release. \n\n<cut....>\n\nIs there a work-around?\n\nThanks,\nFabio\n
24884	Paul J. Reder	1069779931000	I am currently working on this problem. There is not currently a workaround that\nI know of. I know what the problem is (only certain filters are run in the error\npath and expires is not one of them). I am currently working on a solution to\nthe problem. Thank you for reporting this and for using Apache.
24884	Joshua Slive	1070320043000	*** Bug 25123 has been marked as a duplicate of this bug. ***
24884	Marc Jauvin	1070323339000	The solution lies somewhere within the following:\n\nmod_expires only register with 'ap_register_output_filter'...\n\nand within 'modules/http/http_protocol.c', we do this (flushing the output filter):\n\nAP_DECLARE(void) ap_send_error_response(request_rec *r, int recursive_error)\n{\n    int status = r->status;\n    int idx = ap_index_of_response(status);\n    char *custom_response;\n    const char *location = apr_table_get(r->headers_out, 'Location');\n\n    /* At this point, we are starting the response over, so we have to reset\n     * this value.\n     */\n    r->eos_sent = 0;\n\n    /* and we need to get rid of any RESOURCE filters that might be lurking\n     * around, thinking they are in the middle of the original request\n     */\n\n    r->output_filters = r->proto_output_filters;\n
24884	Paul J. Reder	1071250431000	This PR has been fixed in the 2.1-dev branch and has been suggested for\nbackporting to the 2.0 stable branch. Thank you for using Apache and for\nsubmitting this report.
24884	yuk	1071274632000	I can't use '-dev' version...\nI'll wait for the 2.0.49 (I hope).\n\nThank you very much for your work!!\n\nBye
24922	Kirill K	1069633158000	Today i've added desired IP directly into proxy_ftp.c and though now Apache \ntries to open desired IP, i'm getting segfault (11) just like in this bug:\nhttp://nagoya.apache.org/bugzilla/show_bug.cgi?id=14976\n\nSeems like it still not fixed in 2.0.48.\n
24922	Will Rowe	1069883850000	\n  Seriously doubt that this is an identical segfault, Kirill.  Why not attach\n  a backtrace of the crash dump?  And why would you complain about segfaults\n  in a modified module if you didn't post the patch you attempted to use???\n\n  Please, more details - we don't read minds and would love to look closer at\n  these issues :)\n
24922	Kirill K	1069941712000	Sorry, never did things like that :) Here goes the backtrace: \n(gdb) bt\n#0  0x283572c6 in memcpy () from /usr/lib/libc.so.5\n#1  0x0000000c in ?? ()\n#2  0x28349d3f in strchr () from /usr/lib/libc.so.5\n#3  0x2834cad5 in __vfprintf () from /usr/lib/libc.so.5\n#4  0x2833cd35 in sprintf () from /usr/lib/libc.so.5\n#5  0x284ff596 in ap_proxy_ftp_handler () \nfrom /opt/apache/modules/mod_proxy_ftp.so\n#6  0x74662f2f in ?? ()\nCannot access memory at address 0x3a707466\n\nI'll try to collect more info tomorrow, but need to re-compile apache for that.
24922	Kirill K	1070035044000	one more dump:\n(gdb) bt full\n#0  apr_palloc (pool=0x280d11d0, size=8) at apr_pools.c:640\n        active = (struct apr_memnode_t *) 0x280d2a80\n        node = (struct apr_memnode_t *) 0x2\n        mem = (void *) 0x0\n        free_index = 671945168\n(gdb)\n\n(after i've recompiled apache with -g option)
24922	Pascal Terjan	1079951996000	Created an attachment (id=10892)\nA quick patch that made reverse ftp work fine for me\n
24922	Graham Leggett	1085177341000	Patch applied to v2.1.0-dev, awaiting backport to v2.0
24922	Jeff Trawick	1088859599000	committed to 2.0.51-dev\n\nthanks again for the patch!
24991	Larry Toppi	1071005743000	Created an attachment (id=9470)\nFixed EOS bucket leak in proxy_http.c\n
24991	Jeff Trawick	1071006741000	the patch looks simple (and correct) enough...  \n\nany idea if the short-circuit test for EOS just above this leaks that bucket too?\n\nI'm referring to this logic:\n\nif (APR_BUCKET_IS_EOS(APR_BRIGADE_FIRST(bb))) {\n                break;\n            }\n\nIt looks to me like that simple brigade will get leaked in that condition.\n\nI'm re-opening the bug and adding the PatchAvailable keyword; until somebody\ncommits your fix to 2.1-dev, it should be visible by everybody as something to\nwork on.\n
24991	Cliff Woolley	1071009474000	> I'm referring to this logic:\n> if (APR_BUCKET_IS_EOS(APR_BRIGADE_FIRST(bb))) {\n>                 break;\n>             }\n> It looks to me like that simple brigade will get leaked in that condition.\n\nNot necessarily completely leaked, though it might live longer than one could \nhope for.  As long as the bucket remains in its brigade, the bucket and brigade \nwill get killed off when the pool associated with the brigade is cleaned up.
24991	Jeff Trawick	1071010297000	Thanks for clarifying, Cliff!\n\nI'm +1 for the patch.  That was my only dangling question.\n
24991	Jeff Trawick	1071086252000	thanks for the patch!\n\ncommited to 2.1-dev, proposed for merging to stable branch for 2.0.next\n
24991	Jeff Trawick	1071361099000	patch now committed to stable branch for 2.0.next\n
25036	Jonathan Wakely	1069885090000	Created an attachment (id=9314)\nChange section number in ab and apachectl man pages\n
25036	Andr?? Malo	1077315251000	Thanks!
25040	Justin Erenkrantz	1071254388000	I think Fitz has it reversed.\n\nmod_auth_digest needs to use the uri of r->main, not of the subreq because the hashed nonce will \nbe off of the original request's URI.  Right now, I think it's using the subreq's uri (i.e. r->uri), but \nthat isn't what the user sent.  Hence, it can't compute the 'same' hash.
25040	Sander Striker	1071255196000	Actually, I think it shouldn't be doing anything other than checking if\nthe subreq uri is in the same directory/location block (or, in the\nsame auth domain), and if so, just copy what was done for the main\nrequest.
25040	Josh Dady	1074089930000	My subversion server already had a modified mod_auth_digest, so I went digging.\nIt looks like the subreq is already using fields of the main request to check the\ndigest, with one exception -- digest_header_rec does not have a method field.\nWhen I get these authentication failures, the subreq method doesn't match the main\nreq's method.  I added that field, set it to r->method in\nparse_hdr_and_update_nc(), and modified old_digest() and new_digest() to use\nresp->method instead of r->method, and that fixed the problem.
25040	Josh Dady	1074096264000	Created an attachment (id=9946)\nThe changes described above in patch form (and stripped of other local changes)\n
25040	Erik Abele	1074539186000	Just adding the PatchAvailable keyword...
25040	Justin Erenkrantz	1075404166000	Committed to httpd-2.1 as r1.82 of modules/aaa/mod_auth_digest.c.  Proposed for\nbackport to 2.0.  Will be included in the next release.\n\nThanks!
25090	Paul Querna	1117768324000	Fixed in r179689
25101	Tomasz Kepczynski	1070271592000	Created an attachment (id=9338)\nPolish HTTP error messages\n
25101	Joshua Slive	1070292234000	Thanks.  Given that members of the docs project don't speak Polish,\nwe need to have someone review the accuracy of this translation before\nwe can commit it.\n\nIf you could recruit another fluent Polish speaker to read your\ntranslation, assure that it matches the English original, and then\npost a message here to that effect, then we can commit your translation.
25101	Tomasz Kepczynski	1070351654000	Created an attachment (id=9355)\nSpelling and content corrections for Polish error messages\n
25101	Juliusz Czarnogorcew	1070352080000	Translation looks fine & matches the original
25101	Jeff Trawick	1071761513000	Your second patch has been committed to Apache httpd 2.1-dev, and I'll request\nthat it be merged into the stable branch for the 2.0.next release.\n\nThanks for your contribution, and thanks for using Apache.
25268	Heiko Recktenwald	1070798659000	Sorry, wrong component,\n\nH.
25268	Erik Abele	1073775818000	Now finally committed to all three versions currently in development. Thanks.
25269	Heiko Recktenwald	1070798996000	Sorry, wrong OS,\n\nH.
25269	Erik Abele	1073775878000	Committed to the 1.3, 2.0 and 2.1 trees. See also #25268.
25414	Erik Abele	1071078579000	Adding 'PatchAvailable' to the keywords field.
25414	Jeff Trawick	1071096066000	patch trivia: when I cut and pasted from a Mozilla display of your patch in this\nPR, I ended up with an extra space on the three lines in your patch which were\nsupposed to represent blank lines...  the patch wouldn't apply, of course... \nmoral of the story: use an attachment\n\nfix committed to 2.1-dev\n
25420	Erik Abele	1071110817000	Thanks, fixed. I changed it to 'This will be' to be consistent with the 1.3 docs ;)
25460	Geoffrey Young	1071187951000	Created an attachment (id=9526)\ndisallow -D0, fail <IfDefine >, <IfModule >, etc.\n
25460	Geoffrey Young	1071188076000	added PatchAvailable keyword.\n\nit would be nice it both the keyword and attachment fields were present on the\ninitial bug entry form - this will be the third email in a 1 minute span for a\nnew bug report.
25460	Paul Querna	1101705346000	Committed to httpd trunk in svn revision 106879.
25477	Joshua Slive	1071244861000	The ScriptAliasMatch could very well be the problem here.  Try removing it and\nadding a 'SetHandler cgi-script' into the <Directory> block.\n
25477	Robert Heller	1071245823000	OK, using SetHandler seems to fix it.\n\nSo the problem seems to be with ScriptAliasMatch (or at the very least there is\na documentation bug).\n
25477	Joshua Slive	1071247188000	No bug in ScriptAlias.\n\nThe problem is that mod_suexec is tied directly to mod_userdir.  You circumvented\nmod_userdir by using ScriptAlias.\n\nThis should probably be mentioned in the 'Using suexec' section of suexec.html.\n
25477	Joshua Slive	1080003899000	*** Bug 27840 has been marked as a duplicate of this bug. ***
25477	Joshua Slive	1080014009000	I have updated the suexec docs to mention the requirement of going through\nmod_userdir.\n\nThanks for using Apache!
25520	Jeff Trawick	1071751424000	A thread mutex should be good enough for handling the buffer and possibly\nflushing.  Each process would be atomically appending a set of complete trace\nrecords to the file, and that doesn't have to be handled explicitly by\nmod_log_config.  With buffered logs there will be a much higher incidence of out\nof order records, but that can happen already.\n\nI wonder if the big picture is that for a threaded MPM config you're better off\nshoving everything to a piped logger to handle in its simple way rather than\nadding serious mutex contention to the web server.  Still, the code to make it\nfunctionally correct is relatively simple so it should be implemented and the\nuser should get to decide which is more appropriate.\n
25520	Jeff Trawick	1074298674000	fix just committed to Apache 2.1-dev...  I'll propose it for backport once folks\nhave had a chance to look at it\n\nThanks for your report, and thanks for using Apache!\n
25635	Andr?? Malo	1075046432000	FYI: Fixed in 2.1\n\nThanks for the report and thanks for using Apache.
25659	David Blake	1071856147000	Created an attachment (id=9646)\nPatch to fix memory leak in ssl_util_algotypeof().\n
25659	David Blake	1071856190000	PatchAvailable
25659	Jeff Trawick	1071936657000	Thanks for your patch submission!\n\nAren't BOOL, TRUE, and FALSE Windows-only features?  I believe that this should\nuse int, 1, and 0 for portability.\n
25659	Jeff Trawick	1071936803000	ugg, ignore last comment :)  I didn't realize until looking at your next patch\nthat mod_ssl defines these odd types when the platform doesn't define it...\n
25659	Sander Temme	1124126678000	This patch does exactly what the OpenSSL applications code does: free the pubkey after use. The check on \nthe incoming parameter is necessary because the other time this function gets  called, it is fed a key that \nis used after the function call. \n\n+1 on this patch. 
25659	Martin Kraemer	1127234577000	+1 on this patch too. I committed a slightly modified patch.
25714	P.M.	1072145772000	Created an attachment (id=9676)\nPatch to correct typo\n
25714	Jeff Trawick	1072185868000	Thanks for the fix, now committed to 2.1-dev as well as stable branch for 2.0.next!\n
25772	Greg Wilkins	1072519623000	I think enhancement request 18579 may also be related to this type of Cisco Router.
25772	Andr?? Malo	1073947330000	I've added the variable in 2.1 (main development branch) and proposed it for\nbackport into 2.0 and 1.3.
25772	Andr?? Malo	1075319570000	Finally included into 2.0 and 1.3, so it will appear in the next releases.\n\nThanks for using Apache.
25867	Rob Meyer	1073071111000	Created an attachment (id=9772)\nPatch for ssl-std.conf.in to make seeding configuration always valid\n
25867	Mads Toftum	1073127761000	There is already some mention of this in the FAQ:\nhttp://httpd.apache.org/docs-2.0/ssl/ssl_faq.html#entropy\n\nMaybe it is too early for me to read patches, but your patch\nappears to move the SSLRandomSeed outside <IfDefine SSL> which\nwould generally be a bad thing since the loading of mod_ssl in\na dso default config has:\n<IfDefine SSL>\nLoadModule ssl_module modules/mod_ssl.so\n</IfDefine>\nSo you'd run into startup errors whenever starting without -DSSL
25867	Rob Meyer	1073150435000	Whoops. I've got a static mod_ssl, and the only place IFDefine appeared in the\ndefault config files was in ssl-std.conf wrapping the whole thing. Didn't\nrealize it was used in shared mod_ssl configurations, and that is definitely\ngoing to cause a problem. Looks like this only applies to static mod_ssl\ncompliations, and that a different fix is needed.\n\nI'm not very familiar with the apache codebase, but it would seem that the real\nfix is to not initialize mod_ssl at all if SSL is not defined at runtime. That\nwould solve the problem and would make the most sense. If you're not asking for\nssl to be turned on, then it probably should not get initialized (which then\nrequires the directives that get explicitly excluded when you run the server\nwithout -DSSL, leading to this little catch 22). Maybe I'll poke around and see\nif this possible (probably take me a while though).\n\nAs for the FAQ, right now, when someone asks this question, they get told to\nlook at the FAQ, and even if they read and understand this item completely,\nthere is still more to it. Currently in the affected configuration, you can\nchange SSLRandomSeed all you like; it never gets read out of the config file.\nYou either need to move it out of the IFdefine, or recompile the server with a\ndifferent default random socket.\n\nSo the quickest interim solution would just be to tack this on in the FAQ right\nin the section you mention:\n\n'When mod_ssl is compiled into your httpd statically, you must start it with the\n-DSSL flag (or use 'apachectl startssl'), otherwise the SSLRandomSeed directive\nwill be ignored, and the compiled-in default will be used.'\n\nI do think that just a plain start command without -DSSL should work to start\nhttpd without SSL support, since starting with SSL support may not always be\ndesireable (or possible if the person starting the server doesn't know the\npassphrase for the key).
25867	Mads Toftum	1073150863000	Using IfDefine SSL doesn't make sense in the same way \nfor a static module as it does for the dso version.\nMy suggested fix would be to wrap everyting that is\nnow wrapped in IfDefine SSL in an IfModule instead \n(except the LoadModule and possibly the example https\nvhost).
25867	Rob Meyer	1073151663000	Everything is wrapped in an Ifmodule:\n\n<IfModule mod_ssl.c>\n    conf/ssl.conf\n</IfModule>\n\nBut that's alaways included since mod_ssl is static. But then since SSL is not\ndefined, everything in ssl.conf is ignored, leaving out the Seed config, causing\nit to revert to the compiled-in default. So what we need is for the\nSSLRandomSeed directives to always get loaded when mod_ssl is static, but not\nwhen it's dynamic...\n\n...Wait, shouldn't my first patch be okay then? Because in a dynamic situation\nif the mod_ssl module isn't loaded the bit I changed is already wrapped in an\nIFModule, so it should get loaded at all. If the modules not loaded, none of the\nssl config gets run...\n\n
25867	Mads Toftum	1073156152000	Well, that's what I get for relying on my memory ;)\nYour patch shouldn't do any harm in the dso case.\nI'm +1 on the change.
25867	Erik Abele	1073229123000	Yep, this logic looks correct to me. I've committed a slightly changed version of your patch to the \n2.1 tree and proposed it for backport to the 2.0 tree.\n\nSee http://cvs.apache.org/viewcvs.cgi/httpd-2.0/docs/conf/ssl-std.conf.in?r1=1.4&r2=1.5
25867	Erik Abele	1074535767000	Finally backported to 2.0 and thus in the next release. Thanks!
25870	Erik Abele	1073080785000	This is not a bug with mod_autoindex but rather a bug in the documentation.\n\nmod_autoindex uses ap_str(case)cmp_match which expects a shell-style wildcard expression (or a \nfull filename), in your case something like 'IndexIgnore *.m3u' and *not* partial filenames or \nextensions as stated in the documentation.
25870	Joshua Slive	1080003302000	Fixed docs.\n\nThanks for using Apache.
25875	Andr?? Malo	1073137266000	Added a sentence with regard to the issue.\n\nThanks for your report and thanks for using Apache.
25917	Andr?? Malo	1074017957000	Fixed in 2.1. Now any valid response code can be given via the R flag. It\nimplies [L] and the substitution pattern will be dropped (except for redirects).
25917	Joachim Selke	1149679235000	(In reply to comment #1)\n> Fixed in 2.1. Now any valid response code can be given via the R flag.\n\nI wonder why this is not mentioned in the documentation of mod_rewrite.\n<http://httpd.apache.org/docs/2.2/en/mod/mod_rewrite.html> tells about status\ncodes 300-400 only. I think the new feature should be mentioned there.
25917	Joachim Selke	1170477286000	The documentation still does not mention this feature. Instead it tells that\nonly status code in the range 300-400 are possible options for the 'R=....' flag.\n\nI reopened this bug and changed the affected component to Documentation.
25917	Joshua Slive	1185968227000	Docs fixed. Thanks.
26002	Andr?? Malo	1073953064000	Fixed in 2.1 and proposed for backport into 2.0 and 1.3 branches.\n\nThanks for the report and thanks for using Apache.
26002	Andr?? Malo	1076023335000	*** Bug 26693 has been marked as a duplicate of this bug. ***
26079	Andr?? Malo	1075317318000	Fixed in 2.1 and proposed for backport into the stable branches. (removed rpm\ncompletely).\n\nThanks for the report and thanks for using Apache.
26390	Graham Leggett	1085103540000	At the moment, the LDAPTrustedCA directive is only valid in the global context.\n\nOpenLDAP supports setting the CA certs per connection, but I am not sure whether\nthe Netware, Microsoft or Netscape SDKs do. This won't be practical until more\ninfo can be found on the other SDKs.\n
26390	Graham Leggett	1085170072000	Comment from dev@httpd.apache.org:\n\nBrad Nicholes wrote:\n>    This is something that I have been wanting to do for sometime but\n> haven't given it much thought until now.  I talked to some of our Novell\n> LDAP engineers to get a better perspective on this.  According to them,\n> per-session certificates will not work in Novell LDAP and they also\n> believe that it doesn't work for Netscape or Microsoft either.  They\n> also had some concerns about OpenLDAP as well and although per-session\n> certificates appear to be supported, they weren't sure how well it\n> actually worked.  \n>   Just looking at the code in the util_ldap_post_config() routine and\n> how each of them set up the certificates, I wouldn't expect Netscape,\n> Novell or Microsoft SDK's to support per-session certificates.  The\n> Netscape SDK and the Novell SDK use the same function to initialize the\n> SSL libraries, but even though the current util_ldap code for Novell\n> isn't written this way, the Novell SDK allows the user to configure a\n> list of certificates rather than a single certificate by calling\n> ldapssl_add_trusted_cert().  The Netscape SDK probably allows for the\n> same thing through their CERT7 database file which is required.  The\n> Microsoft SDK appears to pull its certificate from the registry so I\n> have no idea if it even allows for multiple certificates.  All of these\n> methods appear to be global rather than per-session.  \n>   My feeling is that about the best we could do is to allow the\n> LDAPTrustedCA and LDAPTrustedCAType directives to be callable from\n> within a virtualhost configurtion and keep a list of certificates that\n> can then be passed to the LDAP libraries during the post_config.  But\n> this would really only make sense for OpenLDAP and Novell.  Since\n> Netscape requires a CERT7 database file, it wouldn't know how to handle\n> multiple files and these directives are NOOPs for Microsoft.  Then it\n> might lead the administrator to believe that certain virtual hosts are\n> using certain certificates when in fact that wouldn't be the case.  All\n> virtual hosts would use all specified certificates.\n
26390	Graham Leggett	1085188588000	Resolved to keep these directives global in scope for now, commit a fix to\nv2.1.0-dev to throw an error if an attempt is made to place these directives\ninside virtualhosts.\n
26390	Graham Leggett	1085504027000	Due to limitations in the LDAP libraries, CA cert settings are server wide.\nv2.1.0-dev and v2.0.50 will throw an error if an attempt is made to define these\ndirectives inside a virtualhost.\n
26462	Andr?? Malo	1077390327000	Yep, your config would be of interest.\n\nThanks.
26462	Andr?? Malo	1081630558000	(I've received the config via mail)\n\nSorry for the long delay.\n\nHowever, the problem is, that you're using the same name for the maps, which\nconfuses the rewritemap cache. The problem is fixed now in 2.1 and I'm going to\npropose it for backport into 2.0 and 1.3 branches.\n\nI've uploaded a patch for 1.3 here:\n<http://www.apache.org/~nd/mod_rewrite-confusion-1.3.patch>.\n\nThanks for the report and thanks for using Apache.
26462	Andr?? Malo	1093037073000	The fix will be in 1.3.32.
26467	Kevin Stange	1101359786000	I've been pouring over Google search results trying to figure out the cause of\nan extremely similar bug which seems to affect the 1.3.x branch of the Apache\nHTTP server also.  Has there been any movement on this issue.  Is it likely\n1.3.x would also have this problem?
26467	Joe Orton	1101380085000	Yes, this bug also affects 1.3.
26467	Will Yardley	1116005680000	Created an attachment (id=15021)\nKill hung child httpd procs\n\nThis little script (requires Proc::ProcessTable) is a hack to find child\nprocesses other than the root one that have been around since before the last\nrotatelogs process. Just in case it's useful to anyone else... can run from\ncron.
26467	Will Yardley	1116005996000	> processes other than the root one that have been around since before the last\n> rotatelogs process.\n\nSorry... s/last/first/
26467	Jeff Trawick	1116009963000	FWIW, I'm playing with a patch to prevent the hang.  Hopefully I can commit to\n2.1 this weekend.\n\nChanging rotatelogs to snarf up all entries from these gracefully dying children\nwould be nice, but first order of business is to prevent the hang occurring,\nsince it can occur with any piped logger, and it shouldn't depend on how\nreliable the piped logger is.  I can't reproduce the hang when I take care to\nclose the read side of the logger pipe in the MPM children (i.e., the processes\nwhich serve requests and which would write to the logger pipe).\n
26467	Jeff Trawick	1116170650000	I just posted a patch and further comments to dev@httpd.\n\n[PATCH] PR 26467 child process can hang when piped logger goes away
26467	Jeff Trawick	1116211725000	A fix to avoid the hang has been committed to 2.1-dev and hopefully will be in\n2.0.next.\n\nI stuck a patch for 1.3.x at http://people.apache.org/~trawick/pr26467_13.txt\n\nThis 1.3 patch appears to Do The Right Thing, but YYMV.  I haven't tested it in\ndetail.\n
26467	Kevin Stange	1116482187000	I have patched the version of Apache 1.3 I am running on two web servers that\nuse piped loggers and I can already see that the symptoms of this problem are\ngone.  There are no hanging PIDs being leftover at all anymore.  I had a script\nthat went through and killed the ones that were clearly hanging previously, and\nI've modified it to only tell me if any would be killed for hanging.  None have\ncome up yet, which would certainly never happen in the past even for the short\ntime I've been running with the patch.\n\nThis is certainly not proof that the 1.3 patch is perfect or that it doesn't\ncause any other problems, but it definitely does the right thing as best I can tell.\n\nWhat's the chances something like this could land in 1.3.34?
26467	Jeff Trawick	1116504618000	Regarding the 1.3 patch:\nThanks for the feedback.  I need to make sure it does the right thing on\nnon-Unix, then I'll add it to 1.3 STATUS file, asking for approval to commit for\n1.3.next.\nOn Unix, just looking at the processes with lsof it is easy to see that it is\ndoing the right thing and there should be no worries.\n
26467	Jeff Trawick	1119967247000	The 2.x fix has now been merged into the stable 2.0.x branch for the upcoming\n2.0.55 release.\n
26467	Joe Orton	1126863405000	The hang is now fixed for 2.0.55, so marking this fixed.  Avoiding the problem\ncompletely (i.e. not forcibly killing piped loggers at restart) is a slightly\ndifferent issue.
26467	Matthew Sullivan	1136995434000	Can someone clarify this bug for me?  We'd been having a hang about every 2-14 \ndays that started once we turned on the DisableWin32AcceptEx option.  We \nnoticed that the hang occurred after the child process restarted for whatever \nreason.  Usually this was not triggered by a graceful restart, but \noccasionally it was.  Meaning it would show up in the logs, but a person \ndidn't usually choose to do a restart, something else caused it.\n\nWe figured the build up of rotatelogs had something to do with the problem, as \nthere were a ton of rotatelogs.exe sitting in there.  I noticed this bug \nmentioned in the 2.0.55 release and tried the upgrade.  We've been pretty \nstable since.  It hung once during a graceful restart after 29 days, and has \nbeen up for 26 days since.\n\nI'm confident this bug was causing the hang, but still notice a tremendous \nnumber of rotatelogs.exe.  After a fresh reboot, there are about 6 \nrotatelogs.exe is the process list.  After 26 days on Parent Server Generation \n14, we have 40+ rotatelogs.exe sitting in the process list.\n\nWhen we hang, there's no way to recover without rebooting Windows.  At least \nnot that I'm aware of.  Apache seems to hang, tying up the socket(s), and \nstopping and starting apache fails.\n\nMy concern is the number of accumulating rotatelogs, and the fact that we \nstill hung after a month under similar circumstances during a graceful \nrestart.  Of course once a month is better than every couple of days.  I just \nwanted to share what we have been experiencing with this bug, and it's \napparent patch, and see if anyone could clarify what we are experiencing, if \nit is/was related to this bug, and why we still see so many rotatelogs.
26467	Joe Orton	1152866113000	*** Bug 40041 has been marked as a duplicate of this bug. ***
26552	Jeff Trawick	1075731113000	Try this patch.  The files which get created by 'make' will get removed\nby 'make clean', not some combination of 'make distclean' and 'make extraclean'.\n\nIndex: server/Makefile.in\n===================================================================\nRCS file: /home/cvs/httpd-2.0/server/Makefile.in,v\nretrieving revision 1.88\ndiff -u -r1.88 Makefile.in\n--- server/Makefile.in\t9 Jan 2004 12:19:55 -0000\t1.88\n+++ server/Makefile.in\t2 Feb 2004 14:10:10 -0000\n@@ -1,8 +1,7 @@\n \n CLEAN_TARGETS = gen_test_char test_char.h gen_uri_delims uri_delims.h /\n-\tApacheCoreOS2.def buildmarked.c\n-DISTCLEAN_TARGETS = httpd.exp\n-EXTRACLEAN_TARGETS = export_files exports.c export_vars.h\n+\tApacheCoreOS2.def buildmarked.c httpd.exp export_files /\n+\texports.c export_vars.h\n \n SUBDIRS = mpm\n \n
26552	Mathieu Fenniak	1075735073000	The supplied patch fixes the problem.
26552	Jeff Trawick	1075740001000	thanks for your quick test!   fix committed to 2.1-dev\n\nonce any review comments are resolved, I'll propose merging it into the stable\nbranch for 2.0.next\n
26552	Joe Orton	1087817836000	*** Bug 29707 has been marked as a duplicate of this bug. ***
26554	Peter Watkins	1075480971000	Created an attachment (id=10162)\npatch for support/ab.c to provide requested capability\n
26554	Jeff Trawick	1075728614000	An alternate design: Don't build default User-Agent header field if User-Agent\nwas specified via the existing command-line option -H.\n
26554	Peter Watkins	1075746402000	Created an attachment (id=10188)\nJeff Trawick's alternate logic (use -H)\n
26554	Peter Watkins	1075747111000	Jeff, that certainly works (a quick read of RFC 1945 suggests that the\nUser-Agent header can come later in the request message, so moving the\nUser-Agent to after the Accept request header appears to be RFC-compliant), and\nI've attached another patch implementing this. \n\nI think I prefer the -U plan though, as\n * it's less fragile (strstr() is case-sensitive & the more users type, the\ngreater chance of error) \n * this general idea, whether implemented as -U or special handling of -H,\nrequires the -h usage() information to be updated, and requires about the same\namount of code changes (so there's not much 'economy' argument against -U)\n * [weak argument] adding -U is backwards-compatible (doesn't alter the order of\nheaders or change the behavior of -H in any situations)\n\nBut I'd be happy either way, as either approach gives users more flexibility.\n\nThanks.\n
26554	Jeff Trawick	1075814566000	comments/opinions from other developers would of course be appreciated ;)\n
26554	Arvind Srinivasan	1172549929000	I believe that my revised patch for \nhttp://issues.apache.org/bugzilla/show_bug.cgi?id=31268\nincorporates the fix this bug as well.
26554	Sander Temme	1176119718000	Fixed in r526872. I went with Arvind's patch as a general fix for -H command-line switch behaviour. \nSpecify -H 'User-Agent: foobar/1.0' to ab to override the default User-Agent setting. 
26562	David Blake	1075735026000	I posted two patches to fix memory leaks in issues 25659 and 25667.  I don't \nknow if they are directly related to what you are seeing but I haven't received \nany feedback on whether anyone else has tried them out.  Let me knoe if you \nthink they may be related.
26562	Ken Avery	1075738420000	David,\n\nI tried both of the bug fixes you posted (25659, 25667) and they did not help, \nI suspect the problem is related to the way threads handle memory verses \nforked processes.\n\nKen
26562	Ken Avery	1075760981000	FYI - I am seeing multiples of 8K chuncks of memroy disapear at a time. I \ndon't know if this helps?
26562	Cliff Woolley	1075761287000	That would most likely be a heap bucket not being freed somewhere.
26562	Joe Orton	1079521119000	I'm still unable to reproduce this on Linux.  Can you post the mod_ssl\nconfiguration you're using?
26562	Ken Avery	1079535415000	Here is the ssl.conf file:\n\n#\n# This is the Apache server configuration file providing SSL support.\n# It contains the configuration directives to instruct the server how to\n# serve pages over an https connection. For detailing information about these \n# directives see <URL:http://httpd.apache.org/docs-2.0/mod/mod_ssl.html>\n#\n#   For the moment, see <URL:http://www.modssl.org/docs/> for this info. \n#   The documents are still being prepared from material donated by the\n#   modssl project.\n# \n# Do NOT simply read the instructions in here without understanding\n# what they do.  They're here only as hints or reminders.  If you are unsure\n# consult the online docs. You have been warned.  \n#\n<IfDefine SSL>\n\n#   Until documentation is completed, please check http://www.modssl.org/\n#   for additional config examples and module docmentation.  Directives\n#   and features of mod_ssl are largely unchanged from the mod_ssl project\n#   for Apache 1.3.\n\n#\n# When we also provide SSL we have to listen to the \n# standard HTTP port (see above) and to the HTTPS port\n#\n# Note: Configurations that use IPv6 but not IPv4-mapped addresses need two\n#       Listen directives: 'Listen [::]:443' and 'Listen 0.0.0.0:443'\n#\nListen 443\n\n##\n##  SSL Global Context\n##\n##  All SSL configuration in this context applies both to\n##  the main server and all SSL-enabled virtual hosts.\n##\n\n#\n#   Some MIME-types for downloading Certificates and CRLs\n#\nAddType application/x-x509-ca-cert .crt\nAddType application/x-pkcs7-crl    .crl\n\n#   Pass Phrase Dialog:\n#   Configure the pass phrase gathering process.\n#   The filtering dialog program ("builtin' is a internal\n#   terminal dialog) has to provide the pass phrase on stdout.\nSSLPassPhraseDialog  builtin\n\n#   Inter-Process Session Cache:\n#   Configure the SSL Session Cache: First the mechanism \n#   to use and second the expiring timeout (in seconds).\n#SSLSessionCache        none\n#SSLSessionCache        shmht:logs/ssl_scache(512000)\n#SSLSessionCache        shmcb:logs/ssl_scache(512000)\nSSLSessionCache         dbm:logs/ssl_scache\nSSLSessionCacheTimeout  300\n\n#   Semaphore:\n#   Configure the path to the mutual exclusion semaphore the\n#   SSL engine uses internally for inter-process synchronization. \nSSLMutex  file:logs/ssl_mutex\n\n#   Pseudo Random Number Generator (PRNG):\n#   Configure one or more sources to seed the PRNG of the \n#   SSL library. The seed data should be of good random quality.\n#   WARNING! On some platforms /dev/random blocks if not enough entropy\n#   is available. This means you then cannot use the /dev/random device\n#   because it would lead to very long connection times (as long as\n#   it requires to make more entropy available). But usually those\n#   platforms additionally provide a /dev/urandom device which doesn't\n#   block. So, if available, use this one instead. Read the mod_ssl User\n#   Manual for more details.\nSSLRandomSeed startup builtin\nSSLRandomSeed connect builtin\n#SSLRandomSeed startup file:/dev/random  512\n#SSLRandomSeed startup file:/dev/urandom 512\n#SSLRandomSeed connect file:/dev/random  512\n#SSLRandomSeed connect file:/dev/urandom 512\n\n##\n## SSL Virtual Host Context\n##\n\n<VirtualHost _default_:443>\n\n#  General setup for the virtual host\nDocumentRoot '/Apache2/htdocs'\nServerName new.host.name:443\nServerAdmin you@your.address\nErrorLog logs/error_log\nTransferLog logs/access_log\n\n#   SSL Engine Switch:\n#   Enable/Disable SSL for this virtual host.\nSSLEngine on\n\n#   SSL Cipher Suite:\n#   List the ciphers that the client is permitted to negotiate.\n#   See the mod_ssl documentation for a complete list.\nSSLCipherSuite ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL\n\n#   Server Certificate:\n#   Point SSLCertificateFile at a PEM encoded certificate.  If\n#   the certificate is encrypted, then you will be prompted for a\n#   pass phrase.  Note that a kill -HUP will prompt again.  Keep\n#   in mind that if you have both an RSA and a DSA certificate you\n#   can configure both in parallel (to also allow the use of DSA\n#   ciphers, etc.)\nSSLCertificateFile /Apache2/conf/ssl.crt/server.crt\n#SSLCertificateFile /Apache2/conf/ssl.crt/server-dsa.crt\n\n#   Server Private Key:\n#   If the key is not combined with the certificate, use this\n#   directive to point at the key file.  Keep in mind that if\n#   you've both a RSA and a DSA private key you can configure\n#   both in parallel (to also allow the use of DSA ciphers, etc.)\nSSLCertificateKeyFile /Apache2/conf/ssl.key/server.key\n#SSLCertificateKeyFile /Apache2/conf/ssl.key/server-dsa.key\n\n#   Server Certificate Chain:\n#   Point SSLCertificateChainFile at a file containing the\n#   concatenation of PEM encoded CA certificates which form the\n#   certificate chain for the server certificate. Alternatively\n#   the referenced file can be the same as SSLCertificateFile\n#   when the CA certificates are directly appended to the server\n#   certificate for convinience.\n#SSLCertificateChainFile /Apache2/conf/ssl.crt/ca.crt\n\n#   Certificate Authority (CA):\n#   Set the CA certificate verification path where to find CA\n#   certificates for client authentication or alternatively one\n#   huge file containing all of them (file must be PEM encoded)\n#   Note: Inside SSLCACertificatePath you need hash symlinks\n#         to point to the certificate files. Use the provided\n#         Makefile to update the hash symlinks after changes.\n#SSLCACertificatePath /Apache2/conf/ssl.crt\n#SSLCACertificateFile /Apache2/conf/ssl.crt/ca-bundle.crt\n\n#   Certificate Revocation Lists (CRL):\n#   Set the CA revocation path where to find CA CRLs for client\n#   authentication or alternatively one huge file containing all\n#   of them (file must be PEM encoded)\n#   Note: Inside SSLCARevocationPath you need hash symlinks\n#         to point to the certificate files. Use the provided\n#         Makefile to update the hash symlinks after changes.\n#SSLCARevocationPath /Apache2/conf/ssl.crl\n#SSLCARevocationFile /Apache2/conf/ssl.crl/ca-bundle.crl\n\n#   Client Authentication (Type):\n#   Client certificate verification type and depth.  Types are\n#   none, optional, require and optional_no_ca.  Depth is a\n#   number which specifies how deeply to verify the certificate\n#   issuer chain before deciding the certificate is not valid.\n#SSLVerifyClient require\n#SSLVerifyDepth  10\n\n#   Access Control:\n#   With SSLRequire you can do per-directory access control based\n#   on arbitrary complex boolean expressions containing server\n#   variable checks and other lookup directives.  The syntax is a\n#   mixture between C and Perl.  See the mod_ssl documentation\n#   for more details.\n#<Location />\n#SSLRequire (    %{SSL_CIPHER} !~ m/^(EXP|NULL)/ /\n#            and %{SSL_CLIENT_S_DN_O} eq 'Snake Oil, Ltd.' /\n#            and %{SSL_CLIENT_S_DN_OU} in {'Staff', 'CA', 'Dev'} /\n#            and %{TIME_WDAY} >= 1 and %{TIME_WDAY} <= 5 /\n#            and %{TIME_HOUR} >= 8 and %{TIME_HOUR} <= 20       ) /\n#           or %{REMOTE_ADDR} =~ m/^192/.76/.162/.[0-9]+$/\n#</Location>\n\n#   SSL Engine Options:\n#   Set various options for the SSL engine.\n#   o FakeBasicAuth:\n#     Translate the client X.509 into a Basic Authorisation.  This means that\n#     the standard Auth/DBMAuth methods can be used for access control.  The\n#     user name is the "one line' version of the client's X.509 certificate.\n#     Note that no password is obtained from the user. Every entry in the user\n#     file needs this password: "xxj31ZMTZzkVA'.\n#   o ExportCertData:\n#     This exports two additional environment variables: SSL_CLIENT_CERT and\n#     SSL_SERVER_CERT. These contain the PEM-encoded certificates of the\n#     server (always existing) and the client (only existing when client\n#     authentication is used). This can be used to import the certificates\n#     into CGI scripts.\n#   o StdEnvVars:\n#     This exports the standard SSL/TLS related "SSL_*' environment variables.\n#     Per default this exportation is switched off for performance reasons,\n#     because the extraction step is an expensive operation and is usually\n#     useless for serving static content. So one usually enables the\n#     exportation for CGI and SSI requests only.\n#   o CompatEnvVars:\n#     This exports obsolete environment variables for backward compatibility\n#     to Apache-SSL 1.x, mod_ssl 2.0.x, Sioux 1.0 and Stronghold 2.x. Use this\n#     to provide compatibility to existing CGI scripts.\n#   o StrictRequire:\n#     This denies access when 'SSLRequireSSL' or 'SSLRequire' applied even\n#     under a 'Satisfy any' situation, i.e. when it applies access is denied\n#     and no other module can change it.\n#   o OptRenegotiate:\n#     This enables optimized SSL connection renegotiation handling when SSL\n#     directives are used in per-directory context. \n#SSLOptions +FakeBasicAuth +ExportCertData +CompatEnvVars +StrictRequire\n<Files ~ '/.(cgi|shtml|phtml|php3?)$'>\n    SSLOptions +StdEnvVars\n</Files>\n<Directory '/Apache2/cgi-bin'>\n    SSLOptions +StdEnvVars\n</Directory>\n\n#   SSL Protocol Adjustments:\n#   The safe and default but still SSL/TLS standard compliant shutdown\n#   approach is that mod_ssl sends the close notify alert but doesn't wait for\n#   the close notify alert from client. When you need a different shutdown\n#   approach you can use one of the following variables:\n#   o ssl-unclean-shutdown:\n#     This forces an unclean shutdown when the connection is closed, i.e. no\n#     SSL close notify alert is send or allowed to received.  This violates\n#     the SSL/TLS standard but is needed for some brain-dead browsers. Use\n#     this when you receive I/O errors because of the standard approach where\n#     mod_ssl sends the close notify alert.\n#   o ssl-accurate-shutdown:\n#     This forces an accurate shutdown when the connection is closed, i.e. a\n#     SSL close notify alert is send and mod_ssl waits for the close notify\n#     alert of the client. This is 100% SSL/TLS standard compliant, but in\n#     practice often causes hanging connections with brain-dead browsers. Use\n#     this only for browsers where you know that their SSL implementation\n#     works correctly. \n#   Notice: Most problems of broken clients are also related to the HTTP\n#   keep-alive facility, so you usually additionally want to disable\n#   keep-alive for those clients, too. Use variable 'nokeepalive' for this.\n#   Similarly, one has to force some clients to use HTTP/1.0 to workaround\n#   their broken HTTP/1.1 implementation. Use variables 'downgrade-1.0' and\n#   'force-response-1.0' for this.\nSetEnvIf User-Agent '.*MSIE.*' /\n         nokeepalive ssl-unclean-shutdown /\n         downgrade-1.0 force-response-1.0\n\n#   Per-Server Logging:\n#   The home of a custom SSL log file. Use this when you want a\n#   compact non-error SSL logfile on a virtual host basis.\nCustomLog logs/ssl_request_log /\n          '%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x /'%r/' %b'\n\n</VirtualHost>                                  \n\n</IfDefine>\n\n
26562	Ken Avery	1079537632000	BTW - Check your log file to see if there is a SIGNAL 11 SEGFAULT that will \ncause Apache to restart the threads and make it appear that everything is OK.
26562	Ken Avery	1079537731000	Here is some more info from on our Linux Heads:\n\nWhile attempting to locate the cause for what appears to be a memory \nconsumption problem in the SSL code, the server segmentation faults. The first \nworker child & all of its child threads continue to consume memory while the \nparent stays the same or gets a little smaller.  The child threads never give \nthe memory back unless restarted.  Please advise if this is an expected \nbehavior.\n\nRunning with 'SSLSessionCache none' doesn't consume memory (and doesn't seg \nfault), but it performs poorly when using 2048 bit keys.\n\nI observed the segmentation fault issue in mod_ssl while running the small \nscript listed below.  Based on the stack information the issue appears to be \nin shmcb_cton_memcpy() during an attempt to remove a session id.  The server \nkeeps on reponding, but all the child threads die and are restarted. I am not \nsure what is happening, but the following variables seem to get corrupted:\n\nThe stack trace shows these are supposed to be:\n\nsrc_offset=6402 \nsrc_len=10240\n\nInside the frame they have these values:\n\n(gdb) print src_offset (in edi register)\n$55 = 3183473748  \n(gdb) print src_len    (in edx register) \n$56 = 3183464512\n\nThe configuration file, and my initial debug session are attached.\n\nApache error_log\n...\n[Mon Mar 15 11:21:33 2004] [notice] Apache/2.0.48 configured -- resuming \nnormal operations [Mon Mar 15 11:25:28 2004] [error] server reached MaxClients \nsetting, consider raising the MaxClients setting [Mon Mar 15 11:38:29 2004] \n[notice] child pid 1065 exit signal Segmentation fault (11) [Mon Mar 15 \n12:06:28 2004] [notice] child pid 1154 exit signal Segmentation fault (11) \n[Mon Mar 15 12:44:49 2004] [notice] child pid 1258 exit signal Segmentation \nfault (11) [Mon Mar 15 13:04:40 2004] [notice] child pid 1315 exit signal \nSegmentation fault (11) [Mon Mar 15 13:17:29 2004] [notice] child pid 1363 \nexit signal Segmentation fault (11) [Mon Mar 15 13:45:12 2004] [notice] child \npid 1401 exit signal Segmentation fault (11) ...\n\nOS RedHat 7.3 \n\ngcc-2.96-113\nglibc-2.2.5-43\nopenssl-0.9.6b-35.7\n\nApache 2.0.48 Build Script:\n\n./configure  --with-program-name=leakd --with-port=9200 --with-mpm=worker --\nenable-ssl=shared --enable-maintainer-mode / --enable-proxy=shared --enable-\ncgi=shared --enable-setenvif=shared --enable-cgi=shared --enable-access=shared \n/ --enable-rewrite=shared --enable-dir=shared --enable-actions=shared --enable-\nmime=shared --enable-proxy_connect=shared / --enable-proxy_http=shared --\nenable-negotiation=shared --enable-alias=shared --enable-env=shared --enable-\ndir=shared / --enable-mod-actions=shared --enable-log-config=shared --enable-\nimap=shared --enable-headers=shared / --enable-layout=webserver --disable-\nautoindex --disable-userdir --disable-usertrack --disable-cgid / --disable-\nasis --disable-auth --disable-auth_digest --disable-auth_dbm --disable-\nauth_anon --disable-dav / --disable-dav_fs --disable-vhost_alias --disable-\nunique_id --disable-speling --disable-cern_meta --disable-include / --disable-\nexpires --enable-status=shared --enable-info=shared\n\nldd leakd:\n\n        libssl.so.2 => /lib/libssl.so.2 (0x40024000)\n        libcrypto.so.2 => /lib/libcrypto.so.2 (0x40052000)\n        libaprutil-0.so.0 => /usr/webserver/lib/libaprutil-0.so.0 (0x40119000)\n        libgdbm.so.2 => /usr/lib/libgdbm.so.2 (0x4012d000)\n        libdb-3.3.so => /lib/libdb-3.3.so (0x40133000)\n        libexpat.so.0 => /usr/lib/libexpat.so.0 (0x401c2000)\n        libapr-0.so.0 => /usr/webserver/lib/libapr-0.so.0 (0x401e1000)\n        libpthread.so.0 => /lib/libpthread.so.0 (0x40200000)\n        librt.so.1 => /lib/librt.so.1 (0x40215000)\n        libm.so.6 => /lib/libm.so.6 (0x40226000)\n        libcrypt.so.1 => /lib/libcrypt.so.1 (0x40247000)\n        libnsl.so.1 => /lib/libnsl.so.1 (0x40274000)\n        libdl.so.2 => /lib/libdl.so.2 (0x40288000)\n        libc.so.6 => /lib/libc.so.6 (0x4028c000)\n        /lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x40000000)\n\n\nSimple script on external machine downloads copies of the stock Apache \nindex.html.en page under both unsecure & secure sites:\n\n#!/bin/sh\ncounter=0\nlimit=32000\nwhile [ '$counter' -lt '$limit' ]\ndo\n  wget -O - http://myboxaddr:9200\n  wget -O - https://myboxaddr:9201\n  counter="expr $counter + 1"\n  echo 'Count=> $counter'\ndone\n
26562	Joe Orton	1079540257000	Hmmm, haven't seen shmcb segfaults in a while.  Tried any different SSLMutex\nsettings, e.g. 'SSLMutex default'?  Can you file a separate bug on that, and\ninclude the backtrace for the shmcb segfaults.\n
26562	Ken Avery	1079968170000	After tagging memory and running tests over the weekend it appears that calls \nto OPENSSL_malloc in the following files failed to release memory by calling \nthe corresponding OPENSSL_free:\n\nbn_bind.c - 494,788 outstanding OPENSSL_malloc\nbn_lib.c  - 123,673 outstanding OPENSSL_malloc\n\nI am not sure how this relates to the Apache/mod_ssl threaded MPMs; though, it \ndoes appear to be a problem.\n\nAny ideas?
26562	Ken Avery	1080054688000	I have narrowed it down to the function BN_BLINDING_new in the file \ncrypto/bn/bn_blind.c, the memory allocated for the BN_BLINDING structure never \ngets freed. I am assuming that the BIGNUM structures allocated with BN_new \ninside of BN_BLINDING never gets freed also.\n\nHere are my test results after running 24 hours monitoring the OPENSSL_malloc \nand OPENSSL_free calls:\n\n1. BN_BLINDING ??? allocations 53,615, frees 0, outstanding 53,615 \n2. BN_new ??? allocations 8,347,200, frees 8,127,872 outstanding 219,328 \n3. I also track the heap and it grows proportional to the lack of BN frees
26562	Joe Orton	1080057632000	The patches released to enable RSA blinding in OpenSSL initially had\nthread-safety issues; the fixes for those issues may well have introduced leaks...\n\nTry reproducing using a vanilla OpenSSL 0.9.6m release: if it's still a problem,\nreport the bug back at openssl.org.  It seems unlikely this is a mod_ssl issue\nnow, agreed?\n\n\n
26562	Ken Avery	1080144738000	The blinging leak is fixed in OpenSSL 0.9.7d - mod_ssl still has a huge leak in \nthe threaded MPMs using session caching
26562	Madhusudan Mathihalli	1080324021000	Can you try the following patch ?\nIt seems to fix the mem leak on HP-UX atleast :)\n\nRCS file: /home/cvs/httpd-2.0/modules/ssl/ssl_engine_init.c,v\nretrieving revision 1.126\ndiff -u -r1.126 ssl_engine_init.c\n--- ssl_engine_init.c   5 Mar 2004 02:44:40 -0000       1.126\n+++ ssl_engine_init.c   25 Mar 2004 23:27:02 -0000\n@@ -450,7 +450,7 @@\n          * to ignore process local-caching and\n          * to always get/set/delete sessions using mod_ssl's callbacks.\n          */\n-        cache_mode = SSL_SESS_CACHE_SERVER|SSL_SESS_CACHE_NO_INTERNAL_LOOKUP;\n+        cache_mode = SSL_SESS_CACHE_SERVER|SSL_SESS_CACHE_NO_INTERNAL;\n     }\n \n     SSL_CTX_set_session_cache_mode(ctx, cache_mode);\n
26562	Andr?? Malo	1082893121000	Is this fixed in CVS or not? If not, it's not fixed.
26562	Joe Orton	1083239401000	Yes, this is fixed in HEAD and for 2.0.50.
26562	Andr?? Malo	1085513395000	Thanks.
26602	Graham Leggett	1085104179000	At the moment, the path is passed as is to the SDK functions directly, without\nbeing modified at all. For this to work, util_ldap would have to resolve the\nrelative link against ServerRoot before passing the filename.\n
26602	Brad Nicholes	1086818984000	I have replace the call to apr_pstrdup() with ap_server_root_relative() which \nshould allow relative paths to be resolved against ServerRoot.  It has also \nbeen proposed for backport.
26602	Brad Nicholes	1086976323000	Patch has been backported to the 2.0 branch
26602	gregaryh@juno.com	1093038892000	This does not appear to be fixed as of 2.0.49. When using a relative path to\nServerRoot in the httpd.conf file it did not throw any errors or give any\nindication in the logs that it was not parsing the file. On the contrary it\nseemed to indicate all was well. I have posted the out put in another bug\n(possible dup?) #22711
26602	Brad Nicholes	1093040785000	This was broken in 2.0.49.  The fix wasn't back ported until 2.0.50
26602	Brad Nicholes	1093041058000	*** Bug 22711 has been marked as a duplicate of this bug. ***
26767	Andr?? Malo	1077389915000	Fixed.\n\nThanks for your care and thanks for using Apache.
27106	Joe Orton	1077706541000	Ouch! Thanks for the report, the fix is here:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_io.c?r1=1.117&r2=1.118\n\nthis change will be proposed for inclusion in the next 2.0 release.
27106	Mark Cox	1078308501000	The Common Vulnerabilities and Exposures project (cve.mitre.org) has assigned\nthe name CAN-2004-0113 to this issue.
27106	Joe Orton	1078841499000	There was a minor bug in the patch posted previously; the better fix is below:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_io.c?r1=1.100.2.11&r2=1.100.2.12
27106	zedis	1078902772000	adfgsdfg
27189	Joe Orton	1095860334000	Thanks for the report.  The simple solution is 'don't use ScoreBoardFile, it is\ncompletely unnecessary'. \n\nA fix for this is in HEAD, nonetheless.
27271	Michael Grossniklaus	1077831560000	Created an attachment (id=10575)\nApache Configuration File\n
27271	Michael Grossniklaus	1077870747000	Could it be a caching problem of mod_ldap?
27271	Denis Gervalle	1077929793000	You have answered the question yourself. When a user enter wrong credentials,\nthe cached connection is seen by the ldap server as an anonymous connection and\nby the  cache of ldap_util as a bind connection to 'cn=LDAPUser...', so it is\nreused for other authentication connection without success since anonymous\nconnection has no access to an Active Directory users list.\nSee bug 27134 for details and a patch to try.\nLet us known if you succeed with that patch.
27271	Graham Leggett	1085093471000	Please try the patch at http://nagoya.apache.org/bugzilla/show_bug.cgi?id=27748\nand tell me if it fixes this problem. This patch has been applied to v2.1.0-dev,\nand awaits backporting to v2.0.50-dev.\n
27271	Graham Leggett	1098037308000	Is this bug still present, or can I close it?\n
27271	Jari Ahonen	1098711660000	Graham,\n\nI think this was fixed in 2.0.50. I just tested with 2.0.52 and password\nprompting works like it should.
27271	Graham Leggett	1098712207000	Will close - thanks for confirming this for me!\n
27313	Joe Orton	1078419859000	Just confirm: you only see this bug using HEAD not 2.0.48?
27313	Alexis Huxley	1078477199000	I saw this problem in HEAD (Jan 15 2004 17:00 GMT).\n\nI saw it also in earlier HEADs, my guess is, since about six months ago. It's \na little difficult to judge with what version it started happening because it \nonly started happening once my pages starting getting more hits. \n\nBut, yes, I have only experienced it in HEADs, and not official releases,\nbut then I *only* install HEADs becaause I've been reinstalling latest \napache2 HEAD at the same time as each new Subversion release comes out.\n\nI've since installed HEAD (Feb 28 21:?? GMT). I will be sure to add a comment\nregarding its behaviour in a couple of weeks.
27313	Joe Orton	1078584874000	Thanks for the detailed report - this should be fixed by the following change:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/mpm_common.c?r1=1.117&r2=1.118
27424	Paul Querna	1079479891000	Created an attachment (id=10822)\nUpdates docs with the proper URL\n
27424	Andr?? Malo	1081032507000	Mostly fixed. Thanks Paul.
27428	Joe Orton	1078841432000	This is fixed in the forthcoming 2.0.49 release; thanks for the report.
27525	Jeff Trawick	1078783572000	Just to verify that we know which getaddrinfo call is failing, please try the\ntest program gawild.c, which I'll attach in a sec.  It *should* run like this:\n\n[trawick@sol9 platform_test]$ gcc -Wall -o gawild gawild.c -lsocket -lnsl\n[trawick@sol9 platform_test]$ ./gawild \nit worked\n[trawick@sol9 platform_test]$
27525	Jeff Trawick	1078783621000	Created an attachment (id=10713)\ngetaddrinfo(255.255.255.255)\n
27525	Jeff Trawick	1079868707000	Please re-open bug when you get a chance to try attached program on the Solaris\nbox with the problem and report the results.  Thanks!\n
27525	Nicolas Cohen	1083187619000	I have the same problem on Solaris 9, httpd 2.0.49. I tried the program and the \noutput is:\ngetaddrinfo->1\n\nAny clue?
27525	Jeremy Laidman	1083734690000	I've run the tool on two sun sparc systems with different results.\n\n  fwa$ ~/gawild\n  it worked\n  fwa$ uname -a\n  SunOS fwa 5.8 Generic_108528-23 sun4u sparc SUNW,Sun-Fire-480R\n\n  tii$ ~/gawild\n  getaddrinfo->1\n  fwa$ uname -a\n  SunOS tii 5.8 Generic_108528-23 sun4u sparc SUNW,Sun-Fire-V210\n\nI wouldn't expect it'd be a hardware issue.  As expected, apache runs fine on \none of them but not the other.\n
27525	Jeff Trawick	1083756720000	In a different PR, it was suggested that it can fail when DNS is disabled but\nwork otherwise.  Is that possibly the case, or is there a difference in DNS\nsearch order between the two machines?\n\nI think we need to change APR to deal with this consistently.\n
27525	Joe Orton	1083763072000	I can't find that PR now, but yes, this is reproducible when /etc/nsswitch.conf\nhas 'hosts: files' not the normal 'hosts: files dns'.
27525	Arieh Markel	1102619880000	(In reply to comment #0)\n> Hello,\n> i am trying to startssl on Sun-sparc Solaris 9 machine with Apache2.0.48\n> It gives the follwing error.\n> \n> [Tue Mar 09 19:40:37 2004] [crit] [Tue Mar 09 19:40:37 2004] file vhost.c, line \n> 232, assertion 'rv == APR_SUCCESS' failed\n> Abort - core dumped\n> \n> it works fine with 'start' option.\n> i have installed the Sun recommened Patch cluster.\n> \n> Can u suggest something.\n> \n> Regards,\n> Dheerajk.\n\n(In reply to comment #7)\n> I can't find that PR now, but yes, this is reproducible when /etc/nsswitch.conf\n> has 'hosts: files' not the normal 'hosts: files dns'.\n\nI verified that it also fails when:\n\n           hosts:     nis [NOTFOUND=return] files\n\nIt fails with:\n\n           hosts:     files nis [NOTFOUND=return] files\n\nIt works with:\n\n           hosts:     files dns nis [NOTFOUND=return] files
27525	Joe Orton	1105376241000	Someone marked this as fixed; this case should at least be handled gracefully\nwithout an abort() so it's not really fixed.
27525	K Venkatasubramaniyan	1106920762000	This is a very annoying and unintuitive situation. We are using mod_ssl with\nApache 2.0.52 in Solaris 9/x86 and as we turned on the SSL it just occured and\nstarted dumping core. We also turned off the ServerName directive hoping that it\nwill make it go away but still continued.\n\nNeed some graceful error message at the least.
27525	Joe Orton	1109353810000	*** Bug 21682 has been marked as a duplicate of this bug. ***
27525	Joe Orton	1109354037000	*** Bug 28537 has been marked as a duplicate of this bug. ***
27525	Luis Londono	1120082285000	This happens when the VirtualHost entry contains _default_.  If I change it to\nan actual IP it works!
27525	Joe Orton	1123252871000	*** Bug 35646 has been marked as a duplicate of this bug. ***
27525	Joe Orton	1126696893000	*** Bug 36650 has been marked as a duplicate of this bug. ***
27525	Joe Orton	1130520727000	In 2.1.x the assert()s in vhost.c now fail gracefully with a configuration error\nfor cases where the system resolver is not configured properly.  Probably not\nworth a backport to 2.0.x since it's just an error case and relatively rare.
27525	Joe Orton	1165822260000	*** Bug 30901 has been marked as a duplicate of this bug. ***
27525	Joe Orton	1182221851000	*** Bug 30901 has been marked as a duplicate of this bug. ***
27525	Mick Ly	1194844010000	Regardsing this issue we find that if we change _default_ in the\nvirtualhostsetion of http.conf to an IP Address this issue does not happen.\nWhere does _default_ get it's address from (dns? etx/hosts?) ?? 
27525	Mick Ly	1194844147000	On our server when we change _default_ to an IP Address it no longer core dumps,\nwhere does _default_ get populated from?\n
27525	Thomas Dehn	1200543341000	This bug is indeed caused by a Solaris bug, namely by\nhttp://bugs.opensolaris.org/view_bug.do?bug_id=4944187\nwhich causes the getaddrinfo('255.255.255.255',...) to fail.\n\nBug 4944187 is scheduled to be fixed in the following forthcoming Solaris 10\npatches:\n\n125553-03 SunOS 5.10: libnsl and nfsmapid patch\n125554-03 SunOS 5.10_x86: libnsl and nfsmapid patch\n\nThese two patches still have to pass the patch test cycle.
27525	HWS	1201485148000	Even if the behaviour of Solaris getaddrinfo must be considered faulty, apache\ncould easily account for this misbehaviour, since the function find_adresses\ncomes in two versions in srclib/apr/network_io/unix/sockaddr.c, the first\ncalling call_resolver and, from there, getaddrinfo; the second treating\naddresses 0.0.0.0 and 255.255.255.255 specially and otherwise calling\ngethostbyname or gethostbyname_r. Thus, there is an simply way to fix this:\nin srclib/apr/configure, change the test address for getaddrinfo (line numbers\nfor httpd-2.2.8):\n@@ -46266,7 +46266,7 @@\n     memset(&hints, 0, sizeof(hints));\n     hints.ai_family = AF_UNSPEC;\n     hints.ai_socktype = SOCK_STREAM;\n-    error = getaddrinfo('127.0.0.1', NULL, &hints, &ai);\n+    error = getaddrinfo('255.255.255.255', NULL, &hints, &ai);\n     if (error) {\n         exit(1);\n     }\nThen the test would fail in faulty Solaris and the second version of\nfind_adresses be used.
27542	Alexander Prohorenko	1078909909000	As I discovered, it looks like mod_proxy problem, but not mod_rewrite one.
27542	Alexander Prohorenko	1078912755000	Actually, as it comes from the debug logs mod_proxy tries to do other \nconnections after it receives 'Connection refused' or 'Operation timed out', \nbut somehow hangs up with 'Invalid argument' parameter.\n\n[Wed Mar 10 02:56:24 2004] [error] [client 3.10.112.130] (61)Connection \nrefused: proxy connect to 3.22.185.120 port 80 failed\n[Wed Mar 10 02:56:24 2004] [error] [client 3.10.112.130] (22)Invalid argument: \nproxy connect to 3.10.112.131 port 80 failed\n[Wed Mar 10 02:56:24 2004] [error] [client 3.10.112.130] (22)Invalid argument: \nproxy connect to 3.22.185.108 port 80 failed\n[Wed Mar 10 02:56:24 2004] [error] [client 3.10.112.130] (22)Invalid argument: \nproxy connect to 3.22.185.99 port 80 failed\n
27542	Alexander Prohorenko	1078922294000	Likely I fixed this.  I'd much appreciate if this will be commited to the \nsource tree - I am not happy applying patches every time when I rebuild a \nsystem. :)\n\n--- proxy_http.c.orig   Wed Mar 10 05:34:43 2004\n+++ proxy_http.c        Wed Mar 10 05:35:00 2004\n@@ -278,6 +278,8 @@\n         i = ap_proxy_doconnect(sock, &server, r);\n         if (i == 0)\n             break;\n+       /* Even if the connection was unsuccesful we should reinit the socket */\n+       sock = ap_psocket_ex(p, PF_INET, SOCK_STREAM, IPPROTO_TCP, 1);\n         j++;\n     }\n #endif\n
27542	Jeff Trawick	1078922473000	noting that a patch is available for review\n\nre-opening; not considered resolved/fixed/whatever until a fix is in CVS
27542	Jeff Trawick	1078923782000	patch looks good here; when it gets applied the fix needs to be propagated to\nthe '#ifdef SINIX_D_RESOLVER_BUG' path\n\nwhile not absolutely required, it would be reasonable to go ahead and close the\nnow-unusable socket via ap_pclosesocket() rather than wait for pool cleanup; \n
27550	Andres Salomon	1078870307000	Created an attachment (id=10733)\npatch to link against external libpcre\n
27550	Andres Salomon	1078870339000	Created an attachment (id=10734)\npatch to rename internal pcre functions\n
27550	Joe Orton	1078876650000	*** Bug 26088 has been marked as a duplicate of this bug. ***
27550	OpenMacNews	1092120768000	hi all,\n\nthis problem's been around for awhile ... for at least a couple of years!\n\thttp://groups.google.com/groups?hl=en&lr=&ie=UTF\n-8&scoring=d&q=pcre+apache+%22multiple+definitions+of+symbol%22&btnG=Search\n\nit keeps getting reported primarily to the php boards, and repeatedly referred *back* as an Apache bug.\n\nbottom line:\n\t\n######################################################################\nAndres' patch (http://nagoya.apache.org/bugzilla/showattachment.cgi?attach_id=10734) \nseems to fix the problem.  can this get integrated into HEAD & the 2.0.50 RELEASE?\n######################################################################\n\non OSX, for quite awhile, i've been able to get around it by buildg httpd with its internal/included \npcre39, building an external build of pcre39, and linking php against the external lib via the LDFLACGS \n& CPPFLAGS\n\nhowever, with recent (for me, since yesterday)  httpd-head, building php --with-apxs aagain causes \nconflicts with apache's included pcre.  any inclusion/combination of any other (later) version, OR the \ninclusion of the php config param '--with-pcre-regex=...' results in 'make' errors/failures.\n\nreading thru Andres' patch submission here, i tried the 'replace-namespace' patch (link above).  per \nAndres, it seems to do the trick for Debian ...\n\nas for me, with patch applied in OSX, i'm now able to successfully build httpd w/ internal pcre -- now in \nits own namespace -- and build php500 --with-pcre against an external build of pcre45.\n\nhere _my_ 'recipe' for success ...\n\nthree 'pieces':\n(1) pcre 45\n(2) httpd 2.0.50 (there's a few other issues i'm having with latest HEAD, so i dropped back to 2.0.50 for \nthis)\n(3) php 500 release\n\nalso:\n\t% uname -v\n\t\tDarwin Kernel Version 7.5.0: Thu Aug  5 19:26:16 PDT 2004; root:xnu/xnu-517.7.21.obj~3/\nRELEASE_PPC \n\t% glibtool --version\n\t\tltmain.sh (GNU libtool) 1.5.8 (1.1220.2.117 2004/08/04 14:12:05)\n\t% automake --version\n\t\tautomake (GNU automake) 1.9\n\t% autoconf --version\n\t\tautoconf (GNU Autoconf) 2.59\n\t% gcc --version\n\t\tgcc (GCC) 3.3 20030304 (Apple Computer, Inc. build 1666)\n\t% /usr/local/ssl/bin/openssl version\n\t\tOpenSSL 0.9.7d 17 Mar 2004\n\n\n############################################################\npcre-4.5\nwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-4.5.tar.gz\ngnutar zxf pcre-4.5.tar.gz\ncd /usr/ports/pcre-4.5\nunsetenv CFLAGS CPPFLAGS CXX CXXFLAGS LDFLAGS LDDLFLAGS LD_PREBIND LINGUAS LC_ALL LANG\nglibtoolize --force --copy && aclocal && autoconf\n./configure /\n--prefix=/usr/local/pcre45 /\n--enable-shared --disable-static\nmake\nmake install\n\n############################################################\nhttpd-2.0.50\n\nwget ftp://apache.secsup.org/pub/apache/dist/httpd/httpd-2.0.50.tar.gz\ngnutar zxf httpd-2.0.50.tar.gz\ncd /usr/ports/httpd-2.0.50\n\ncurl -f -L -o patch.pcre.txt 'http://nagoya.apache.org/bugzilla/showattachment.cgi?attach_id=10734'\npatch -p2 < patch.pcre.txt\nunsetenv CFLAGS CPPFLAGS CXX CXXFLAGS LDFLAGS LDDLFLAGS LD_PREBIND LC_ALL LANG LINGUAS\n./buildconf\n\n# enable linking against dlcompat's libdl\n=============================================================\n(EDITOR) /usr/ports/httpd-2.0.50/srclib/apr/configure\n@10433\n---\tenable_dlopen=no\n+++\tenable_dlopen=yes\n\tenable_win32_dll=no\n=============================================================\n\n./configure /\n--with-mpm=worker /\n--enable-layout=Darwin --with-port=80 /\n--enable-mods-shared=all --enable-so --disable-static /\n--sysconfdir=/etc/apache2 /\n--enable-dav --enable-dav-fs --enable-dav-lock /\n--enable-ssl --with-ssl=/usr/local/ssl /\n--disable-suexec /\n--with-z /\n--enable-cgi /\n--enable-proxy /\n--enable-proxy-connect /\n--enable-proxy-ftp /\n--enable-proxy-http /\n--enable-logio /\n--enable-authn-dbm --enable-authz-dbm /\n--with-imap\n\n\n# these lib links won't pick up from cmd line ... do it manually for now\n=============================================================\n(EDITOR) /usr/ports/httpd-2.0.50/build/config_vars.mk\n\tEXTRA_CFLAGS = -g -O2\n\tEXTRA_CXXFLAGS =\n---\tEXTRA_LDFLAGS = -L/usr/local/lib  -L/usr/local/ssl/lib\n+++\tEXTRA_LDFLAGS = -bind_at_load -L/usr/local/lib  -L/usr/local/ssl/lib\n---\tEXTRA_LIBS = -lssl -lcrypto\n+++\tEXTRA_LIBS = -lssl -lcrypto -lz -ldl -lexpat\n=============================================================\n\nmake\nmake install\n\n#################################################################\nphp-5.0.0\nwget http://us2.php.net/distributions/php-5.0.0.tar.gz\ngnutar zxf php-5.0.0.tar.gz\n\nunsetenv CFLAGS CPPFLAGS CXX CXXFLAGS LDFLAGS LDDLFLAGS LD_PREBIND EXTRA_LDFLAGS \nEXTRA_LIBS LC_ALL LANG LINGUAS ;/\nsetenv LC_ALL C ;/\nsetenv LANG C ;/\nsetenv CPPFLAGS '-I/usr/local/ssl/include -I/usr/local/pcre45/include -I/usr/local/include' ;/\nsetenv LDFLAGS '-bind_at_load  -L/usr/local/ssl/lib -lssl -lcrypto -L/usr/local/pcre45/lib -lpcre'\n\n=============================================================\n(EDITOR) /usr/ports/php-5.0.0/configure.in\n---\tAC_PROG_RANLIB\n+++\tAC_PROG_LIBTOOL\n=============================================================\n\ncd /usr/ports/php-5.0.0\nautoconf\nranlib /usr/local/pgsql/lib/libpq.a\n\n./configure /\n--disable-debug /\n--prefix=/usr --with-layout=PHP /\n--with-config-file-path=/etc/php5 --sysconfdir=/etc/php5 /\n--enable-shared --disable-static /\n--libdir=/System/Library/PHP /\n--includedir=/usr/include /\n--mandir=/usr/local/man /\n--localstatedir=/var/php4 /\n--with-db4=/usr /\n--with-pgsql=/usr/local/pgsql --without-mysql /\n--enable-cli --with-pear=/System/Library/PHP /\n--disable-cgi /\n--with-apxs2=/usr/sbin/apxs /\n--disable-dmalloc /\n--with-tsrm-pthreads /\n--enable-shmop --enable-sockets /\n--enable-inline-optimization /\n--enable-xml --enable-libxml --with-libxml-dir=/usr /\n--with-java=/Library/Java/Home /\n--with-openssl=/usr/local/ssl --with-openssl-dir=/usr/local/ssl /\n--with-zlib --with-zlib-dir=/usr /\n--with-imap=/usr/local/imap --enable-mailparse /\n--with-imap-ssl=/usr/local/ssl /\n--with-mcrypt --with-mhash /\n--with-gmp=/usr/local /\n--with-gd=/usr/local/gd /\n--with-png-dir=/usr/local /\n--with-jpeg-dir=/usr/local /\n--with-tiff-dir=/usr/local /\n--enable-magic-quotes /\n--enable-calendar /\n--disable-mbstring /\n--with-kerberos=/usr /\n--with-freetype-dir=/usr/X11R6 /\n--with-xpm-dir=/usr/X11R6 /\n--enable-exif /\n--enable-ftp /\n--enable-bcmath /\n--with-pcre-regex=/usr/local/pcre45\n\nmake\nmake install\n\ncheers,\n\nrichard
27550	Paul Querna	1093850842000	*** Bug 23952 has been marked as a duplicate of this bug. ***
27550	Richard W.M. Jones	1094303212000	This bug is really important to fix.  I can't get my mod_caml module\nworking with Apache 2.0 until it's fixed.  This prevents a significant\nuserbase from migrating to Apache 2.\n\nMy duplicate bug report contains some other information: Bug 23952
27550	Alan Schmitt	1094554858000	I just had this problem as well, trying to install a Caml based wiki. If I add\nthe 'LoadModule caml_module modules/mod_caml.so' to my httpd.conf file, apache\njust keeps segfaulting.\n\nUnfortunately this is on a server where we need apache2, so this means that\nuntil this fix is integrated, I cannot use mod_caml (and every other mod that\nneed a recent pcre library, it seems).
27550	Nick Kew	1095376958000	Adding PatchAvailable keyword
27550	OpenMacNews	1095474806000	just building httpd2.0.51 ...\n\nit seems this bug is STILL not resolved.\n\nthere's a demonstrated, working patch (cref: Andreas, below) that fixed the issue in 2.0.50, and \n(seemingly) applies to 2.0.51 as well ... \n\nis there a particular reason why this known/reported/fixed issue is NOT being integrated?\n\nthx,\n\nrichard
27550	Joe Orton	1095492125000	There are some subtle issues with this: \n\n1) with an httpd built to use an external pcre, the include/pcre.h which gets\ninstalled does not match the pcre which is actually used.  It's possible that\nsome third-party modules will depend on this.\n\n2) Renaming both the reg* and pcre_* functions is a binary compatibility issue.
27550	OpenMacNews	1096566749000	hi,\n\ni'm back again!\n\ni'm building httpd 2.0.52 + php 5.0.2 on OSX 10.3.5\n\nthe ONLY way i'm able to get httpd & php to 'play nice' together -- avoiding later/'downstream' pcre \nconflicts -- is to make sure that they're built using the SAME version of pcre.\n\nthere are two options to that end ...\n\n(a)\n        build httpd w/ INTERNAL pcre (v3.9)\n        build external pcre3.9\n        build php 502 against pcre3.9/external\n\n(b)\n        apply Andreas' patch to httpd (*luckily* the patch still works against 2.0.52 ...)\n        build external pcre5.0\n        build httpd 2.0.52 against pcre5.0/external\n        build php 5.0.2 against pcre5.0/external\n\n(a), of course, locks PHP into the use of pcre3.9 ... which is simply not acceptable/tenable for a variety \nof other apps that need >= v4.5\n\nso, (b) is really the only functional option here ...\n\nacknowledging 'possible subleties' from  Joe's reference above, the php issue is neither subtle, nor \nsimply possible ... others as well (cref above) are noting problems with, e.g., mod_caml that requires a \nmore recent pcre.\n\nwhat need to be done to get this solution addressed/integrated?  even ASSIGNED would be a good start!\n\nthis has been an unaddressed issue problem for QUITE awhile ...\n\nrichard
27550	Richard W.M. Jones	1096567230000	Agree with the previous comment.\n\nmod_caml cannot use anything except an external, modern PCRE, so somehow\nlinking it against Apache's ancient version of PCRE is a non-starter,\neven if it were possible.\n\nThis bug is a showstopper for a variety of important modules, so it\nshould be fixed (particularly, since there's even a patch to do it).
27550	Richard W.M. Jones	1100078184000	Created an attachment (id=13377)\nAmended version of patch by Andres Salomon, with typo fixed by Paul Argentoff\n
27550	Richard W.M. Jones	1100078248000	The following notes were sent to me by Paul Argentoff to\naccompany the preceeding patch.\n\n  - - - - - -\n\nThis is patch by Andres Salomon <dilinger@voxel.net>, with typo fixed by Paul\nArgentoff <argentoff@rtelekom.ru>\n\nThis patch fixes problems seen by apache modules attempting to run regex\nstuff, and getting apache's internal pcre implementation.  It contains\ntwo parts; the first (the autoconf stuff) checks if libpcre is installed\non the host system.  If it is, that pcre is used to build apache2.  If\nit's not, apache2 compiles its own pcre, and statically links against\nit.  \n\nThe second part of this patch forces pcre to be used.  Apache, by\ndefault, calls the posix regex functions (reg{exec,comp,free,error})\ninternally.  If glibc was sane, this would be fine.  Unfortunately, it's\nnot.  So, when apache calls these regex functions, it's anyones guess as\nto whether it will use glibc's regex functions, or the pcre regex\nfunctions.  The glibc regex functions segfault (within glibc) on my\nsystem.  So, to ensure sanity, we force use of pcre regex functions.\n\nI need to do a bit more testing w/ apache's internal pcre, but for\ndebian's purposes (pcre in /usr), it works fine.\n
27550	Owen Gunden	1101169823000	Pleeeeeeeeeeeeease incorporate this fix?  I'll bake you cookies!
27550	Andres Salomon	1102370468000	Ok, I've created a new patch that should supercede both other patches.  This\npatch checks for regex support via libc, and will use that if found.  If the\nlibc doesn't support POSIX.2 regex functions, it will then check for\nan external pcre; if found, it links against that.  If it doesn't find\nthat, it finally falls back to compiling and linking against its own\ninternal pcre library.\n\nThis patch is also significantly smaller than my other two patches, as it\ndoesn't require any widespread symbol changes.  I've tested compilation\nwith and without regex.h and pcre-dev.  Testers whose libc specifically lacks\nregex support are requested (all testers welcome, of course :)\n\nI'll follow up w/ fixes as necessary.
27550	Andr?? Malo	1102370666000	We won't use any POSIX regex stuff. The PCRE is used on purpose...
27550	Andres Salomon	1102370832000	Created an attachment (id=13661)\nmore intelligent patch to link against PCRE\n\nPatch against apache 2.0.52; use libc's regex functions, falling back to\nexternal pcre, and finally building internal pcre only if absolutely necessary.
27550	Andres Salomon	1102370984000	(In reply to comment #17)\n> We won't use any POSIX regex stuff. The PCRE is used on purpose...\n\nWhy not?  What specifically is broken regarding the libc-provided POSIX regex\nstuff?  And, why not test for breakage, instead of unconditionally using PCRE\nwhen   it's probably not even necessary?
27550	Andr?? Malo	1102371277000	Consistency among the various installations and way more power.
27550	Andres Salomon	1102373211000	In that case, instead of using the POSIX functions, we should probably just be\nusing the PCRE functions...
27550	Andr?? Malo	1102373758000	That's a good point and I personally agree. This should be discussed on dev@\nanyway. The best would be with a patch backhand :)
27550	Joe Orton	1102374420000	More than that, httpd *cannot* use a real POSIX regex implementation rather than\nPCRE: even the default config actually uses some of the Perl extensions to the\nregex grammar (the '(?:' stuff IIRC?).
27550	Joe Orton	1108140441000	This is all now done on the trunk based on Andres' patches - thanks a lot!\n\nAgain, it can't really be backported to 2.0, unfortunately, because it changes\nthe module interface.
27550	OpenMacNews	1108141485000	hi,\n\n> Again, it can't really be backported to 2.0, unfortunately, because it changes the module interface.\n\nso iiuc, then, we've two options at this point:\n\n(1) STABLE 2.0.x release source + Andres' patches (assuming/hoping they continue to apply ...)\n(2) UNSTABLE cvs source, w/ functionality included.\n\ni.e., no STABLE solution until 2.1 release ... \n\nam i correct?\n\nthanks for the update!\n\nrichard
27550	apache@mailinator.com	1108337528000	(In reply to comment #25)\n\nI just tried the most recent patch with Apache 2.0.53 and make failed:\n\nlibtool: link: cannot find the library "/Users/me/Desktop/webserver/httpd-2.0.53/srclib/pcre/\nlibpcre.la'\nmake[2]: *** [htpasswd] Error 1\nmake[1]: *** [all-recursive] Error 1\nmake: *** [all-recursive] Error 1
27550	Joe Orton	1108395945000	(In reply to comment #25)\n> > Again, it can't really be backported to 2.0, unfortunately, because it\nchanges > > the module interface.\n> \n> so iiuc, then, we've two options at this point:\n\nYes, that's correct.
27550	apache@mailinator.com	1109175140000	If anyone else is following this, the 2.1.3 alpha is out now, and it solved my problems.
27550	Joe Orton	1109353554000	*** Bug 28781 has been marked as a duplicate of this bug. ***
27550	Konstantin Andreev	1116881947000	I have applied most recent Andres' patch (id=13661) against most recent current\nstable Apache - 2.0.54. Patched sources compile cleanly, but at run-time Apaches\ncrashes/segfaults immediately after parsing any regex in config file.\n\nHere are some details: in my system this patch selects glibc's implementation of\nregex. If there are not regexes in config file, then apache starts successfully.\nIf there is regex in config file, it compiles without problem. Using gdb,\n\n(gdb) break regcomp\n(gdb) r\n(gdb) bt\n#0  0x403bf852 in regcomp () from /lib/libc.so.6\n#1  0x08071714 in ap_pregcomp (p=0x809b0a8, pattern=0x80d3bd0 '^//.ht',\ncflags=135085008) at util.c:268\n#2  0x0807ca4e in filesection (cmd=0xbffff990, mconfig=0x80d3bd0, arg=0x80d3bc1\n'') at core.c:1837\n#3  0x0806b5f1 in invoke_cmd (cmd=0x808e2e8, parms=0xbffff990,\nmconfig=0x80b59f0, args=0x80d2b90 '~ /'^//.ht/'>')\n    at config.c:797\n#4  0x0806bf06 in ap_walk_config (current=0x80d2b70, parms=0xbffff990,\nsection_vector=0x80b58e0) at config.c:1060\n#5  0x0806cd2f in ap_process_config_tree (s=0x80d3bd8, conftree=0x80d3bd0,\np=0x809b0a8, ptemp=0x80d3bd0)\n    at config.c:1643\n#6  0x0806fa6b in main (argc=5, argv=0xbffffab4) at main.c:539\n\nBut, shortly, segfaults occurs:\n(gdb) cont\nContinuing.\n\nProgram received signal SIGSEGV, Segmentation fault.\ntrie_node_alloc (p=0x809b0a8, parent=0x809b518, c=95 '_') at util_filter.c:113\n113                 if (c == parent->children[i].c) {\n(gdb) bt\n#0  trie_node_alloc (p=0x809b0a8, parent=0x809b518, c=95 '_') at util_filter.c:113\n#1  0x080766a3 in register_filter (name=0x809b518 'core_in', filter_func=\n      {out_func = 0x807ed90 <core_input_filter>, in_func = 0x807ed90\n<core_input_filter>}, filter_init=0, ftype=0, \n    reg_filter_set=0x809b518) at util_filter.c:217\n#2  0x08080611 in register_hooks (p=0x809b0a8) at core.c:4509\n#3  0x0806fb4f in main (argc=5, argv=0xbffffab4) at main.c:578
27550	Andres Salomon	1116884969000	This should be fixed in apache-2.1; Joe Orton incorported my patch into it, plus\nadded some additional fixes.  If you're going to use 2.0, don't use my patches\n(I'm not keeping them up-to-date); use Debian's.  Adam Conrad backported Joe's\nchanges for 2.0, and they're being kept up-to-date.\n\nftp://ftp.debian.org/debian/pool/main/a/apache2/\n\napt-get source apache2, or grab the patch out of the .diff.gz.
27719	Jeff Trawick	1079896076000	fixed, thanks for the report!\n
27731	Joe Orton	1079526078000	Created an attachment (id=10827)\ncatch bad vhost configuration\n
27731	Joe Orton	1079526216000	It's a misconfiguration if you enable name-based vhosting for a specific port,\nbut then define no VirtualHosts for that port; with the above patch applied you\nshould get a warning but the server will work correctly.
27731	Joe Orton	1082061541000	Fixed on HEAD using the above patch; thanks for the report.
27731	Joe Orton	1098872045000	*** Bug 31915 has been marked as a duplicate of this bug. ***
27731	Joe Orton	1159256545000	*** Bug 36234 has been marked as a duplicate of this bug. ***
27731	Joe Orton	1159876485000	*** Bug 40374 has been marked as a duplicate of this bug. ***
27748	William Leumas	1080246201000	This is linked against OpenLDAP stable 2.1.25.  Is there a way to perhaps turn\noff the cache, to see if that is what is causing the problem?  I have written a\nperl script that watches the log for this error and immediately cross-checks\nLDAP for the user, if the user exists it restarts Apache.  We are seeing about\n30 restarts a day.
27748	William Leumas	1080758212000	Created an attachment (id=11078)\nfix for ldap rebinding failures\n
27748	William Leumas	1080758371000	The problem is in the poor way the ldap session is managed (which could cause\nother severe problems, if individual users cannot browse the tree, and it should\nbe re-considered).  Kurt Olsen has found this problem and come up with a quick\nfix (see patch).  Note: this also relates to bug# 17274.  Kurt's description:\n\n--------------\nIn the file util_ldap.c, in the function util_ldap_cache_checkuserid, when a\nuser tries to authenticate the module takes these steps:\n\n1) check the cache, returning success or failure if results cached.\n2) open a connection via the function util_ldap_connection_open, using the ldc\nstruct.\n   if ldc->bound = 1, then don't do anything in util_ldap_connection_open.\n3) do a search to validate, and locate the dn for, the username provided.\n4) verify that there is only 1 result of the search in #3.\n5) verify that the password is non empty.\n6) rebind with the dn found in step 3 with the password provided, using the ldc\nstruct.\n   if there is a failure then return failure status.\n   on success update cache and return success status.\n\nThe problem is that the ldc used in #6 is the same ldc used to lookup a user's\ndn in the tree.  So if the password is incorrect then the ldap_simple_bind_s\nused to verify the password will have screwed up the ldc->ldap binding.\nThe next time this ldc struct is used, the ldc->bound value is set to 1, but\nthe actual valid bind has been hosed. One simple fix is to add an 'ldc->bound = 0;'\ninto the two tests for failure after the ldap_simple_bind_s. This causes\nthe util_ldap_connection_open to re-bind with the proper DN prior to looking\nup users.\n\nEven in the case where the users are logging in correctly, there is still\nthe problem that when user A authenticates the ldc->ldap bind is now bound\nwith his username and password. If user A doesn't have rights to search the\ntree, then when user B comes along at a later point in time the search for\nuser B's dn in the tree will fail. The correct fix would be to create an\nutil_ldap_connection_t *foo; that would be used for testing provided passwords,\nbut would not have an impact on the ldc struct used for searching and what not.\n\nKurt Olsen
27748	Andr?? Malo	1081032117000	Not fixed in the code yet...\nadding Patchavailable keyword.
27748	Kurt Olsen	1082065006000	Additional bugs with this issue and some of them also have fixes:\n\n17274\n17599\n18661\n21787\n24595\n24683 (probably, commentary is old)\n27134\n27271\n\nAnd\n\n28413 may be the same thing, but it's not really clear except that they\nexperience failures against AD.\n\nI think that the comment that a connection should be marked as unbound after any\nuser bind is the proper solution. The patch included in this report only marks\nunbound upon auth failures. Adding an ldc->bound = 0; at line 847 in util_ldap.c\n(release 2.0.49) should fix both issues I have addressed in my re-explanation of\nthe problem.
27748	Graham Leggett	1085092621000	The attached patch has been committed to v2.1.0-dev, and is included against\nv2.0.49.\n\nPlease test and tell me whether this fixes the problem.\n
27748	Graham Leggett	1085093263000	Created an attachment (id=11618)\nRollup of LDAP fixes to v2.1.0 against v2.0.49\n
27748	Graham Leggett	1085093348000	The attachment includes bnicholes fix:\n\n    *) mod_ldap calls ldap_simple_bind_s() to validate the user\n       credentials.  If the bind fails, the connection is left\n       in an unbound state.  Make sure that the ldap connection\n       record is updated to show that the connection is no longer\n       bound.\n
27748	Graham Leggett	1085102231000	*** Bug 25764 has been marked as a duplicate of this bug. ***
27748	Graham Leggett	1085149210000	*** Bug 17599 has been marked as a duplicate of this bug. ***
27748	Graham Leggett	1085150978000	*** Bug 21787 has been marked as a duplicate of this bug. ***
27748	Graham Leggett	1085151008000	*** Bug 24595 has been marked as a duplicate of this bug. ***
27748	Graham Leggett	1085153429000	*** Bug 27134 has been marked as a duplicate of this bug. ***
27748	Graham Leggett	1085154689000	*** Bug 24683 has been marked as a duplicate of this bug. ***
27748	Graham Leggett	1085158691000	*** Bug 18661 has been marked as a duplicate of this bug. ***
27748	Graham Leggett	1085181526000	Fixed in v2.0.50-dev.
27748	Albert Lunde	1085431416000	I repeated my test set-up that I'd been using under bug 27134, with the roll-up\npatch 11618 from bug 27748. This was on Red Hat Linux 9.0, building Apache from\npatched 2.0.49 sources (not Red Hat sources)\n\nThis uses two test data sets with 11 valid username/password pairs and some\npseudo-random failures. One data set walks through the usernames in nearly\nserial order (because this will tend to show the worst-case usage of the\nconnection pool). This makes 103 requests. The other data set uses a more random\nseries of usernames. This makes 804 requests.\n\nThe results look good.\n\nI'm now getting no unexpected authentication results, and socket usage looks\nsimilar to Denis Gervalle's previous patch.\n\nI still have the warning 'LDAP cache: Unable to init \nShared Cache: no file', but I suppose that's a different issue.\n\nI did the tests first with the default settings of\n\nStartServers         5\nMinSpareServers      5\nMaxSpareServers     10\nMaxClients         150\nMaxRequestsPerChild  0\n\nFor comparison, I set up a low process number test with:\n\nStartServers         1\nMinSpareServers      1\nMaxSpareServers     1\nMaxClients         150\nMaxRequestsPerChild  0\n\nand high process number test with:\n\nStartServers         10\nMinSpareServers      10\nMaxSpareServers     20\nMaxClients         150\nMaxRequestsPerChild  0\n\nAll the tests give correct results (authentication works or fails as expected).\n\nI looked at sockets in use with 'netstat -an' on the LDAP server.\n\nWith the default prefork process config:\nthe serial data set left 9 sockets to the LDAP server in use at the end;\nthe random data set left 4 sockets in use at the end\n\nWith the 'low process' config:\nthe serial data set left 1 socket in use at the end;\nthe random data set left 0 sockets in use at the end\n\nWith the 'high process' config\nthe serial data set left 14 sockets in use at the end;\nthe random data set left 11 sockets in use at the end;\n\nI'm guessing that if I could get rid of the 'Unable to init \nShared Cache' warning I'd get results more like the 'low\nprocess' config. Can anyone suggest another fix/bug that\napplies to that issue?\n
27751	Ken Avery	1079544460000	Here is inforamtion from one of our developers:\n\nWhile attempting to locate the cause for what appears to be a memory \nconsumption problem in the SSL code, the server segmentation faults. The first \nworker child & all of its child threads continue to consume memory while the \nparent stays the same or gets a little smaller.  The child threads never give \nthe memory back unless restarted.  Please advise if this is an expected \nbehavior.\n\nRunning with 'SSLSessionCache none' doesn't consume memory (and doesn't seg \nfault), but it performs poorly when using 2048 bit keys.\n\nI observed the segmentation fault issue in mod_ssl while running the small \nscript listed below.  Based on the stack information the issue appears to be \nin shmcb_cton_memcpy() during an attempt to remove a session id.  The server \nkeeps on reponding, but all the child threads die and are restarted. I am not \nsure what is happening, but the following variables seem to get corrupted:\n\nThe stack trace shows these are supposed to be:\n\nsrc_offset=6402 \nsrc_len=10240\n\nInside the frame they have these values:\n\n(gdb) print src_offset (in edi register)\n$55 = 3183473748  \n(gdb) print src_len    (in edx register) \n$56 = 3183464512\n\nThe configuration file, and my initial debug session are attached.\n\nApache error_log\n...\n[Mon Mar 15 11:21:33 2004] [notice] Apache/2.0.48 configured -- resuming \nnormal operations [Mon Mar 15 11:25:28 2004] [error] server reached MaxClients \nsetting, consider raising the MaxClients setting [Mon Mar 15 11:38:29 2004] \n[notice] child pid 1065 exit signal Segmentation fault (11) [Mon Mar 15 \n12:06:28 2004] [notice] child pid 1154 exit signal Segmentation fault (11) \n[Mon Mar 15 12:44:49 2004] [notice] child pid 1258 exit signal Segmentation \nfault (11) [Mon Mar 15 13:04:40 2004] [notice] child pid 1315 exit signal \nSegmentation fault (11) [Mon Mar 15 13:17:29 2004] [notice] child pid 1363 \nexit signal Segmentation fault (11) [Mon Mar 15 13:45:12 2004] [notice] child \npid 1401 exit signal Segmentation fault (11) ...\n\nOS RedHat 7.3 \n\ngcc-2.96-113\nglibc-2.2.5-43\nopenssl-0.9.6b-35.7\n\nApache 2.0.48 Build Script:\n\n./configure  --with-program-name=leakd --with-port=9200 --with-mpm=worker --\nenable-ssl=shared --enable-maintainer-mode / --enable-proxy=shared --enable-\ncgi=shared --enable-setenvif=shared --enable-cgi=shared --enable-access=shared \n/ --enable-rewrite=shared --enable-dir=shared --enable-actions=shared --enable-\nmime=shared --enable-proxy_connect=shared / --enable-proxy_http=shared --\nenable-negotiation=shared --enable-alias=shared --enable-env=shared --enable-\ndir=shared / --enable-mod-actions=shared --enable-log-config=shared --enable-\nimap=shared --enable-headers=shared / --enable-layout=webserver --disable-\nautoindex --disable-userdir --disable-usertrack --disable-cgid / --disable-\nasis --disable-auth --disable-auth_digest --disable-auth_dbm --disable-\nauth_anon --disable-dav / --disable-dav_fs --disable-vhost_alias --disable-\nunique_id --disable-speling --disable-cern_meta --disable-include / --disable-\nexpires --enable-status=shared --enable-info=shared\n\nldd leakd:\n\n        libssl.so.2 => /lib/libssl.so.2 (0x40024000)\n        libcrypto.so.2 => /lib/libcrypto.so.2 (0x40052000)\n        libaprutil-0.so.0 => /usr/webserver/lib/libaprutil-0.so.0 (0x40119000)\n        libgdbm.so.2 => /usr/lib/libgdbm.so.2 (0x4012d000)\n        libdb-3.3.so => /lib/libdb-3.3.so (0x40133000)\n        libexpat.so.0 => /usr/lib/libexpat.so.0 (0x401c2000)\n        libapr-0.so.0 => /usr/webserver/lib/libapr-0.so.0 (0x401e1000)\n        libpthread.so.0 => /lib/libpthread.so.0 (0x40200000)\n        librt.so.1 => /lib/librt.so.1 (0x40215000)\n        libm.so.6 => /lib/libm.so.6 (0x40226000)\n        libcrypt.so.1 => /lib/libcrypt.so.1 (0x40247000)\n        libnsl.so.1 => /lib/libnsl.so.1 (0x40274000)\n        libdl.so.2 => /lib/libdl.so.2 (0x40288000)\n        libc.so.6 => /lib/libc.so.6 (0x4028c000)\n        /lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x40000000)\n\n\nSimple script on external machine downloads copies of the stock Apache \nindex.html.en page under both unsecure & secure sites:\n\n#!/bin/sh\ncounter=0\nlimit=32000\nwhile [ '$counter' -lt '$limit' ]\ndo\n  wget -O - http://myboxaddr:9200\n  wget -O - https://myboxaddr:9201\n  counter="expr $counter + 1"\n  echo 'Count=> $counter'\ndone\n
27751	Jeff Potter	1079567276000	I added some log messages to the code, and turned on debugging.  I attempted to \nusing either SSLMutex  file:logs/ssl_mutex  or  SSLMutex  default.  It takes \nlonger with SSLMutex default to seg fault, but the stack trace is basically the \nsame.  The debug error_log traces are available for both test runs if you want \nthem. \n\nFinally the src_offest & src_len variables are not changing.  GDB just doesn't \nreset the registers when you move back in the stack frame.
27751	Geoff Thorpe	1079722555000	It seems to me that src_offset and src_len are getting corrupted somehow, but it's not \nobvious to me where or how this is happening. The versions you're using of redhat, \nglibc, gcc (etc) are a little dated. and though I'm reluctant to dismiss the issue as \nbeing old tools, it would certainly be something to consider - if you're able to build \nusing a different gcc or mess with the optimisation levels, that might hint as to whether \nthis is compiler sensitive or something more macabre. \n \nAlso, is it possible to insert some debugging lines in the last two frames around the \nproblem area to dump the exact values being passed around? I'm curious how and \nwhere those values are getting mangled. As/when you hit a segfault, it would be useful \nto have something to help pinpoint where the corruption was introduced. (Another \npossible hint: could those 'corrupt' values actually be some unsigned representation \nof a negative - indicating a possible bug in the 'cyclic' logic?) I've added myself to the \nCC line for this ticket, please let me know how you get on with this. \n 
27751	Jeff Potter	1079972462000	Logging messages were added into the function to print out the values for \nsrc_len and src_offset, and they were actually not changing.  The seg fault is \nin memcpy() frame #0. When you move back to frame #1 to examine things, gdb 5.2-\n2 does not reload the registers.  Local variables were created inside the \nfunction, and assigned the values src_offset & src_len upon entry. The end \nresult was the same (seg fault).  It could be the tools, but everything is fine \nfor 15-20 minutes.  The function is called 305 times before a failure with the \nlast three calls shown below: \n\nCALLER == shmcb_remove_session_id()\nCALLED == shmcb_cyclic_cton_memcpy()\n\n[Wed Mar 17 17:13:20 2004] [info] CALLER: header->cache_data_size=7190  \nsrc_offset=3972 src_len=10240\n[Wed Mar 17 17:13:20 2004] [info] CALLED: buff_size=7190 src_offset=3972, \nsrc_len=10240\n[Wed Mar 17 17:13:20 2004] [info] CALLER: header->cache_data_size=7190  \nsrc_offset=7166 src_len=10240\n[Wed Mar 17 17:13:20 2004] [info] CALLED: buff_size=7190 src_offset=7166, \nsrc_len=10240\n\n\nI have two debug traces.
27751	Geoff Thorpe	1080062869000	Ouch, ok - I have this gloomy sense that I'm about to dive back into apache code ... \n \nI notice you're on apache 2.0.48 ... I could try to help track the problem in that version \nand worry about migrating it (if applicable) to cvs after, but to avoid the potential for \nlogjams with other issues already fixed, are you able to move to 2.0.49, or better still, \nCVS (head or 2.0.**-stable)? At the least, have you diffed the ssl module source \nagainst later releases or CVS to check if any fixes have already been made that might \ncover this? \n \nWhatever you do w.r.t. apache versions - please email me a copy of the first few \npages of a *trace* log during startup (this should give me all the shmcb geometry \nsettings), and then the last few pages leading up to your first crash. I noticed from the \ninfo you've already provided that you are caching sessions around ~10Kb, which \nwould indicate that you're using client-authentication and probably with some biggish \ncerts (or longish cert-chains). My hunch is that this is triggering some wrap-around \nissue, either in the cyclic logic itself or in the use of variables of insufficient size. \n \nPlease mail me the details privately, no point drowning the bugzilla database. As/when \nI have potential suggestions/fixes, how should we handle that? Can I send you diffs to \ntry? Can I shell to a box where this can be reproduced? Thanks again for the detailed \nreport. 
27751	Joe Orton	1086124559000	Geoff's fix for this is now committed to HEAD and the 2.0 branch - thanks for\nthe report, and thanks to Geoff for tracking it down.
27793	Jeff Trawick	1079867921000	I just committed this change to 2.1-dev and have proposed it for merging\nback to 2.0.50-dev:\n\nIndex: support/logresolve.c\n===================================================================\nRCS file: /home/cvs/httpd-2.0/support/logresolve.c,v\nretrieving revision 1.22\ndiff -u -r1.22 logresolve.c\n--- support/logresolve.c        9 Feb 2004 20:40:52 -0000       1.22\n+++ support/logresolve.c        21 Mar 2004 11:12:02 -0000\n@@ -90,7 +90,9 @@\n \n \n /* maximum line length */\n+#ifndef MAXLINE\n #define MAXLINE 1024\n+#endif\n \n /* maximum length of a domain name */\n #ifndef MAXDNAME\n\nYou can define MAXLINE to whatever you want outside of logresolve.c.  Something\nlike this should take care of it:\n\nCPPFLAGS='-DMAXLINE=99999' ./configure --other-opts\n
27811	Joshua Slive	1079991516000	Fixed in all versions.\n\nThanks for using Apache!
27834	Pascal Terjan	1079952584000	Created an attachment (id=10894)\nA patch to add / using Location: when on a directory\n
27834	Pascal Terjan	1079952624000	This patch should be improved by preserving ; and following options and maybe\nother stuff
27834	Pascal Terjan	1104182906000	Created an attachment (id=13844)\nPatch to add / (before ; if there is one)\n
27834	Pascal Terjan	1177305836000	This 3 years old bug is still there in 2.2.4.\nIs there any hope than someone have a look at it ?
27834	Ruediger Pluem	1204029602000	Backported to 2.2.x as r631360 (http://svn.apache.org/viewvc?rev=631360&view=rev).
27862	Jeff Trawick	1080001704000	1.3 seems to have same problem\n\n
27862	Andr?? Malo	1081028720000	Looks correct.\n\nI'm going to suggest inclusion into 2.0 and 1.3.\n2.1 doesn't suffer from the issue, because the cache code was totally rewritten.
27862	Andr?? Malo	1093635116000	FYI: The fix will be in 1.3.32 and 2.0.51.\n\nThanks!
27866	Andr?? Malo	1081026922000	It's already (read as) a long using strtol.\n\nI'm wondering if should use strtoll if available. Any ideas?
27866	Joe Orton	1081031684000	Interesting: yes, it should probably use apr_atoi64 and check for overflow if\nsizeof(apr_int64_t) > sizeof(apr_off_t) .
27866	Joe Orton	1081098202000	Created an attachment (id=11125)\nsupport Content-Length as large as apr_off_t\n
27866	Joe Orton	1081098306000	Attached the patch I'm testing.  This only helps in 2.0, of course, if you're\nusing a platform where apr_off_t is a 64-bit integer type.
27866	Joe Orton	1085496031000	Fixed on HEAD.  If you're really after >2Gb file support on a platform with a\n32-bit off_t, that's not going to happen in a 2.0.x release.\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/http/http_protocol.c?r1=1.479&r2=1.480
27886	Jeff Trawick	1080486272000	what does 'ServerRoot directive of my default server' mean?  default VirtualHost\ncontainer, or the main settings outside of any VirtualHost directive?\n\nlooking at the mod_cgid code I can't see why mod_cgid wouldn't be influenced by\nthe main ServerRoot setting (outside of any VirtualHost container), so I want to\nbe sure what 'default server' means\n\nnote that there is a loosely-related mod_cgid bug: if you have ScriptSock\ndirective inside VirtualHost, some funky stuff can happen; in fact mod_cgid\nshould disallow that, as there is no cgid daemon per virtual host, and thus\nthere is only one socket
27886	Jeff Trawick	1080524709000	ignore previous comment; problem is easy to see ;)
27886	Rolf Sponsel	1080524917000	Funny, I was just about to clarify :-)\n\nBest Regards,\nRolf Sponsel
27886	Jeff Trawick	1080529079000	Fixed in 2.1-dev.\n\nThanks for your report, and thanks for using Apache!\n
27928	Bojan Smojver	1080173241000	Created an attachment (id=10967)\nOutput filter simplification for mod_logio\n
27928	Andr?? Malo	1081025823000	Thanks Bojan, applied to 2.1 and proposed for backport.
27951	Vincent Deffontaines	1080235888000	Created an attachment (id=10995)\nPatch against modules/metadata/mod_headers.c\n
27951	Vincent Deffontaines	1080235929000	Created an attachment (id=10996)\nSuggested documentation update if patch is accepted.\n
27951	Andr?? Malo	1081186553000	Thanks. I've committed the change to HEAD (which your patch wasn't against, so\nI've modified it to match ;).
27985	Andr?? Malo	1080345838000	Hrm. That is a problem. mod_rewrite now treats the result string\n'proxy:http://www.apache.org/' as a relative path, which was a bug fix in 2.0.49\n(for some other example, but ...).\n\nFrankly speaking, your rules depend on unsupported API internals, so you cannot\nexpect that they work forever.\n\nAnyway: Can you try what happens if you just take the rules out of the <Proxy>\ncontainer? (That's even the next problem, mod_rewrite was never designed for use\nwithin <Proxy>).
27985	Sven Koch	1080347688000	> Frankly speaking, your rules depend on unsupported API internals\n\nI didn't even know that this setup was unsupported ;)\n\nIt worked with only minor changes (<Location proxy:*> changed to <Proxy *>) from\na  very old apache 1.3 through 2.0.48 without problems.\n\nI will try your suggestion on monday, when I can reach my test-box again.\n
27985	Sven Koch	1080568392000	I just tried your suggestion of placing the RewriteRules outside of <Proxy>:\n\nThe Rules are tested only for local connections, not for connections proxied\nthrough the apache. Thus they are called exactly when I don't need any rewriting.\n\nI'm back to apache 2.0.48 for now.\n
27985	Andr?? Malo	1080585498000	Well, thanks. I'm investigating how to fix it somehow.
27985	Andr?? Malo	1080598017000	I've nailed the problem in 2.1 and proposed it for backport into the 2.0 branch.\n\nIf you want to to try it out, here's a patch against 2.0:\n<http://cvs.apache.org/~nd/mod_rewrite.c.patch>
27985	Sven Koch	1080749715000	Just a small follow-up:\n\nYour patch fixes my problems with 2.0.49, the rewrite/filter rules are working\nagain.\n\nThanks a lot.\n
27985	Andr?? Malo	1080845595000	Thanks for the feedback :-)
27985	Sven Koch	1089713940000	This bug is in 2.0.50 too, and the same patch as for 2.0.49 still fixes it.\n
27985	Andr?? Malo	1093592544000	Well, the fix was finally reviewed and will be in 2.0.51.
28047	Andr?? Malo	1081034711000	Fixed in 2.1 and proposed for backport into the 2.0 stable branch.\n\nThanks for the report and thanks for using Apache.
28063	Jeff Trawick	1080677892000	2.0.49 code has same issues
28063	Jeff Trawick	1080870501000	The first part of the patch is clearly needed.\n\nCan you verify that you had a crash that required the second change?  No problem\nhere with a bit of defensive programming in case the code above changes, but\nsince threads_created and hash table entries are created in lock step, I don't\nsee how there could be no hash entry.  Curious!\n\n\n
28063	Eider Oliveira	1081168031000	I don't know why, but it crashed for me in this line. When I was looking into\nthe code, I've found the first wrong line and subimitted both of them.\nI think it is related with pool cleanups.
28063	Jeff Trawick	1092481195000	Nobody chimed in with an explanation for exactly why the 'if (score_idx !=\nNULL)' is needed, so I would prefer not to commit that.  However, that's no\nreason to hold up the other fix, which should have been committed long ago.\n\nPlease re-open the PR if you find out why the extra check was needed.\n\nThanks for your fix!\n
28112	Paul Querna	1117769213000	I think this makefile is a relic of the days before mod_ssl was part of httpd. \nShould we just remove the docs about it?
28112	Tony Stevenson	1193988982000	This has been fixed in 2.0.  The update was applied to 2.2, and trunk already.\n\nhttp://svn.apache.org/viewvc?rev=591348&view=rev\n\nThe changes should be visible within an hour or two.\n\nCheers,\nTony\n
28145	Edward Rudd	1093845947000	Created an attachment (id=12564)\ngenerated config_vars.mk\n
28145	Edward Rudd	1093846012000	It's APR_INCLUDEDIR and APU_INCLUDEDIR that are not generated correctly.
28145	Joe Orton	1118788603000	Thanks for the report; now fixed on the trunk:\nhttp://svn.apache.org/viewcvs?rev=190392&view=rev
28167	Joe Orton	1086618578000	Any luck with the testing?
28167	Brian Pinkerton	1086621383000	Yes -- it worked well.  I'm no longer working for the company, though.  I'll get someone to send me \nthe diffs so I can post them.
28167	Brian Pinkerton	1086641077000	Here are the diffs from .48.  Very straightforward.  This server is in heavy use and we haven't seen \nany problems with it yet, and graceful restarts close the main socket correctly.\n\n==== //depot/httpd-2.0.48-src/server/listen.c#2 (text) ====\n\n\n@@ -387,6 +387,11 @@\n     return num_open ? 0 : -1;\n }\n\n+void ap_close_listeners()\n+{\n+\t(void) close_listeners_on_exec(0);\n+}\n+\n int ap_setup_listeners(server_rec *s)\n {\n     ap_listen_rec *lr;\n\n\n\n==== //depot/httpd-2.0.48-src/server/mpm/worker/worker.c#2 (text) ====\n\n\n@@ -857,6 +857,9 @@\n         }\n     }\n\n+\t/* bp: stop listening to the main socket(s) */\n+\tap_close_listeners();\n+\t\n     ap_queue_term(worker_queue);\n     dying = 1;\n\n
28167	Paul Querna	1099540414000	note to self: Investigate adding this to the Event MPM.
28167	Paul Querna	1117764621000	close enough to a .patch
28167	Joe Orton	1124917771000	This has been fixed on the trunk.\n\nhttp://svn.apache.org/viewcvs?rev=239711&view=rev
28167	Colm MacCarthaigh	1124919863000	And then fixed for worker in;\n\nhttp://svn.apache.org/viewcvs?rev=239740&view=rev
28174	Joshua Slive	1080966456000	Hmmm... Why don't you just use ErrorDocument to customize the error\nresponses.  That way you can have whatever you want.\n\nThe ServerAdmin should really be used only as a fallback when all\nelse has failed.  And in that case, giving a URL (especially if it\nis on the same server) could be a big mistake.\n\nBut the real argument here is why add complexity when there is\nalready a way to accomplish what you want?
28174	Rolf Sponsel	1080992999000	That is all fine - as long as - the only place where ServerAdmin is used/shown\non a page is on the customized error pages AND does not use it for anything\nelse, neither now nor in the future.\n\nIf this is NOT the case, IMHO this would be a minor, but useful, modification.\nIt only requires that the argument to 'ServerAdmin' is checked for whether it's\nan URL, i.e. contains a string sequence '://'; otherwise the argument is\nprepended with that same 'mailto://' prefix as today. Not much of complexity it\nseems to me - is there?\n
28174	Joshua Slive	1081012366000	Well, as I mentioned, one point of the ServerAdmin is to have a contact\nif all else fails.  Using a webpage for that sounds like a bad idea.\nie: 500 server error, please see this other page, which also generates\na 500 server error.
28174	Rolf Sponsel	1081013487000	What can I say?\n\nI think you need to re-read my initial posting one more time. No offence please!\n\nAs I wrote in my initial posting:\n\n'... Thus there would be no need to expose an email address for this purpose. Of\ncourse, such an URL should ideally point to another server, because this server\nmight present the errror response page (showing that 'serveradmin' url due to\nnot being able to process such a form. But that decision should of course be\nleft to the administrator to decide on.'\n\nI think your 'last post' doesn't present anything new in addition to what\nalready has been pointed out before - right?\n\nI accepting new ideas and suggestions from others, then fine. Then I don't have\nto waste my time. There are a lot of other software projects that welcome my\ncontributions and ideas.\n\nI have suggested this new feature due to having identified it's usefulness, and\nbecuse it would be useful to me, it might(!?) be useful to others to.\n\n\n\n
28174	Joshua Slive	1081032086000	Calm down a little Rolf.  I thought we were discussing the merits of the\nidea.  If I thought it was a hopeless idea, I would have closed the bug\nreport.\n\nPersonally, I don't see a big benefit from this, and I do think it\nwould be too tempting for people to put a URL on the same server.  But\nsome of the developers may disagree.\n\nOf course, ideas are much likely to be acted upon if they come with\npatches.
28174	Andr?? Malo	1081633963000	To come to an end: I've the changed the two lines of code ;-)
28174	Rolf Sponsel	1081636352000	I'm happy to see that it didn't require any major changes to accomplish.\nI hope this will be useful to others too.\n\nThank You!\n\nBest Regards,\nRolf Sponsel\n
28204	Paul Querna	1089444031000	Patch commited to 2.1 CVS.\n\nThanks for using Apache!\n\n-Paul Querna
28218	Andr?? Malo	1081606163000	Thanks. Indeed it exists also in 2.x (even in more places).\nIt's fixed now in 2.1 and proposed for backport into the stable branches.\n\nThanks for the report and thanks for using Apache.
28218	Andr?? Malo	1086216623000	The fix will be in the next stable versions. (1.3.32 and 2.0.50).
28287	Andr?? Malo	1082835903000	Uhm, there's a message written into the error log, but unfortunately it may be\nwrong.\nAfter an accompanying APR patch (to determine the setuid bit) this is fixed in\n2.1 now.
28287	Andr?? Malo	1086217779000	Fixed in latest APR/httpd.
28310	Paul Querna	1089444198000	Do we want to change this?\n\nI assume SSL is not enabled for crypto reasons?\n\nWhy is mod_proxy not enabled?
28310	M. 'Alex' Hankins	1089930547000	I recently compiled 2.0.50.  None of ssl, deflate, proxy, proxy_http, cache,\nmem_cache, nor disk_cache were enabled with the --enable-mods-shared=all.  (I\nsuspect there are other modules as well.)\n\nThe documentation for the configure step says that --enable-mods-shared=all\nenables all modules.  It seems reasonable to me that it would compile mod_ssl\niff I specified --with-ssl and mod_deflate iff I specified --with-z.
28310	Paul Querna	1117769321000	This is s documentation bug, until we get the nerve to change what this really\nmeans.
28310	Vincent Bray	1185502716000	The missing modules are documented on the wiki[1]. I'll translate that page for \n/manual/programs/configure.html once I've cleaned it up (it references old module names still).\n\n[1] http://wiki.apache.org/httpd/ConfigAllMods
28310	Tony Stevenson	1193993016000	Florian,\n\nThis has been fixed in /trunk/[1] and back-ported to /2.2/[2]\n\n[1]http://svn.apache.org/viewvc?rev=591370&view=rev\n[2]http://svn.apache.org/viewvc?rev=591365&view=rev\n\nThese changes should be visible within a few hours.\n\nThanks,\nTony\n
28310	Florian Effenberger	1194020594000	Thanks a lot!
28459	Andr?? Malo	1082394541000	Thanks :-)\n\n&excl; is not defined by the W3C, so I've just replaced it by !.
28459	Rolf Sponsel	1082403683000	As we dealing with these things; there is actually another related issue.\n\nI'm not sure if it's a Mozilla only thingie though, or if it's a general one.\nTheses spanish sentences - of course - use have the inverted exclamationmark\n(i.e. an '!' upside down), in these files represented by '&iexcl;'. Although\nthis probably generally does work when used in web-pages rendered with standard\ncompliant browsers; this does not work, i.e. it gets rendered litterally as\n'&iexcl;', when used in the <TITLE> - at least not for Mozilla. Would that be a\nbug in the implementation of the standard in Mozilla or another oversight (in\nApache)?\n\nBest Regards,\nRolf Sponsel\n\n\nPs. Pardon me re-opening an already fixed bug, but I thought it was that related\nthat I didn't wan't to file a separate report for it. Ds.\n
28459	Andr?? Malo	1082406559000	No problem. Still an error at our side :-(. We encoded the title again. Fixed in\nCVS now.\n\nThanks again.
28492	Andr?? Malo	1082455196000	That is by intention in order to avoid infinite loops. It just needs to be\nbetter documented.
28492	Henning Schmiedehausen	1082469713000	Sorry to bother you, but IMHO this is still a bug.\n\nWe e.g. have a scenario where this include link points to an NFS mounted\ndirectory which can change due to failover reasons. This is how I found the\nproblem. Basically I have a Include '/virtual/foo/*.conf' and the foo can be\ndynamically change doing a failover and a httpd restart. Our current solution\nrewrites the config files using sed and is awkward at best (pun intended).\n\nCan we have an IncludeFollowLinksYesIveReadTheManualAndKnowAboutPossibleLoops\ndirective? :-)  (Would you accept patches?)\n\nFor content we have 'FollowSymLinks'.Why not the same thing for the configuration? 
28492	Andr?? Malo	1082532123000	I've finally found a way to stop include directive recursion (by using the pool\ncontext). So I no longer see a need for the symlink stopper at all, hence I'm\ngoing to patch it out. (just replacing ap_is_rdirectory with ap_is_directory in\nap_process_resource_config and process_resource_config_nofnmatch).\n\nThe recursion stopper is currently in 2.1 and proposed for backport into 2.0.
28492	Henning Schmiedehausen	1082538158000	Thanks a lot! This will really help me with our HA environments and future\nreleases of the httpd.
28492	Andr?? Malo	1093634085000	FYI: The fix will be in 2.0.51.
28492	Andr?? Malo	1094577158000	*** Bug 31099 has been marked as a duplicate of this bug. ***
28523	Andr?? Malo	1082585393000	done in 2.1 and proposed for backport.\nThanks for nagging :)
28523	Guenter Knauf	1082594977000	isnt then also a fix needed to the prototypes in ./include/http_protocol.h ?\n
28523	Edward Rudd	1082608062000	yeah.. Just checked CVS and I  do believe the prototypes should be updated in\nthe http_protocol.h file as well..
28523	Andr?? Malo	1082666809000	done.
28529	Andr?? Malo	1082615568000	Then it's cool. And it works like expected. Thanks for the info.
28529	Joshua Slive	1082640299000	I was under the impression that AccepEx was automatically disabled for\nWin9x-based platforms.  Is that not the case?
28529	Andr?? Malo	1082664915000	Hmm, no. And I see no reason why it should?
28529	Joshua Slive	1082666050000	I could be wrong (since I've never done an inch of windows socket programming),\nbut I thought that acceptex was not available on win9x.\n\n[Googling...]\n\nYes, this page\nhttp://msdn.microsoft.com/library/default.asp?url=/library/en-us/winsock/winsock/acceptex_2.asp\nseems to confirm that.  And I thought that windows mpm used to automatically\ndisable it for win9x.
28529	Andr?? Malo	1082667367000	My apologies, you're right. The Win32DisableAcceptEx thing dropped the automatic\nselection. Well...
28529	Joshua Slive	1082729319000	*** Bug 27920 has been marked as a duplicate of this bug. ***
28529	Andr?? Malo	1086986984000	Fixed in 2.0.50-dev.
28573	Rich Bowen	1101095901000	Should be fixed now. Committed revision 106144 with a patch. table1 and table2\nwere also affected.
28581	Joshua Slive	1115173567000	Thanks, this is now fixed.
28581	Joshua Slive	1117041861000	Actually, I backed this out and removed the error doc, because it can't provide\nas much info as the internal error doc can.
28673	Rodney Crossman	1085563519000	Confirmed errors building mod_deflate from 2.0.50dev and 2.1dev from May 23 for\nnetware.  Works fine with zlib 1.1.4
28673	Nick Kew	1089533254000	Works fine for me with zlib 1.2.1 on Linux, with both 2.0.49 and 2.1.0.\n\nYou used --with-z='/usr/local/zlib-1.2.1' ; I didn't - because 1.2.1 is my\ninstalled zlib.  So I wonder if what you've seen is a config problem?\n\nRegarding the confirmation on netware, we've had some relevant patches recently\nfrom the netware folks.  Perhaps you could check if you[anyone] still have a\nproblem?
28673	sebastien	1089548964000	I corrected my problem myself by replacing #ifdef HAVE_ZUTIL_H, but if i am \nthe only one with this 'problem', it doesnt matter.\nmaybe it's a config problem with zlib :)
28673	Bernd	1096552013000	I get the same error with 2.0.52 under the following circumstances:\n\nI have the zlib-devel-1.1.4 package installed on my system (SuSE Linux 8.2).\nThis comes with the file zutil.h installed in /usr/lib. Although this is a\nfile considered internal to zlib, it is obviously used by some applications\n(like apache). This is probably the justification for it being installed.\n\nNow, I want to use a newer zlib with my httpd.\nI installed zlib 1.2.1 myself in $HOME/gnu. The 'make install' in\nthe zlib sources does not install zutil.h (as the zlib authors consider it\ninternal to zlib)! \n\nNow, if I configure apache with --with-z=$HOME/gnu, the apache configure script\nwill find zlib.h under that path, but will find the preinstalled zutil.h from\nthe old zlib 1.4.1 in /usr/include !!\nThis mix will lead to the compile error.\n\nI am helping myself with manually copying the new zutil.h to\n$HOME/gnu/include.\n\nIf apache really needs zutil.h, the configure script should only look for it\nunder the path given with --with-z, if that has been passed.\n\nThe real solution though is probably not to use zutil.h at all. Some discussion\nabout this seems to have taken place:\nhttp://www.mail-archive.com/dev@httpd.apache.org/msg01883.html
28673	Joe Orton	1097581416000	Thanks for the report - this is now fixed on HEAD:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/filters/mod_deflate.c?r1=1.58&r2=1.59\n\n
28732	Ville Skytt	1083523333000	Created an attachment (id=11404)\nSpelling fixes etc\n
28732	Jeff Trawick	1083727877000	commited to 2.1-dev and 2.0.50-dev\n\nthanks for your submission!\n
28898	Joe Orton	1084301734000	Can you precisely describe the issues you see on platforms with a 32-bit size_t\nand a 64-bit off_t?
28898	dankogai@dan.co.jp	1084501997000	Joe Orton,\n\nThank you for your response.  This is what happens;\n\nls -l /ring/ftp/4gb-test.dmg \n-rw-r--r--  1 root  mirror  4699983872 May 11 22:45 /ring/ftp/4gb-test.dmg\n\nHEAD http://localhost/4gb-test.dmg\n200 OK\nConnection: close\nDate: Fri, 14 May 2004 02:26:47 GMT\nAccept-Ranges: bytes\nServer: Apache\nContent-Length: 405016576\nContent-Type: application/octet-stream\nETag: '6-18241000-557d0100'\nLast-Modified: Tue, 11 May 2004 13:45:08 GMT\nClient-Date: Fri, 14 May 2004 02:26:46 GMT\nClient-Peer: 210.159.71.23:80\n\nAs you see,\n\n* Content-Length: shows only lower 32-bit thereof\n* File transfer fails accordingly (only 405,016,576 bytes of actual\n4,699,983,872 bytes gets downloaded in the example above).\n\nDan the Truncated Man\n\n\n
28898	Joe Orton	1084533612000	Interesting.  That's a bug, but I can't reproduce it with HEAD on a 32-bit Linux\nusing apr_off_t = off64_t, apr_size_t = size_t.\n\n$ HEAD http://localhost:8900/big/bigfile | grep Content-Length\nContent-Length: 3145728000\n\nso it's something more subtle.  Does the correct file size get logged to\naccess_log if you GET the file?  Does autoindex show the correct size for the\nfile in a directory listing?
28898	Joe Orton	1084533839000	BTW, your HEAD test was with 2.0, I presume.  1.3 uses long rather than off_t\nfor file sizes everywhere, so you're always limited by sizeof(long) in 1.3 even\nif sizeof(off_t) == 64.
28898	dankogai@dan.co.jp	1084598793000	> $ HEAD http://localhost:8900/big/bigfile | grep Content-Length\n> Content-Length: 3145728000\n\nI don't think it's big enough.  It's definitely larger than MAX_INT but well\nwithin UMAX_INT, which nicely fits in 32-bit.\n\n3145728000 = 0xbb80_0000 < 0xffff_ffff\n\nFYI to make large files quickly (and sparsely), you can go like\n\n  perl -e 'truncate shift, shift' file size\n\nor\n\n  truncate -s size file\n\nif your platform has trucate(1).\n\n> BTW, your HEAD test was with 2.0, I presume.\n\nCorrect. 1.3.x hardcodes them all 'long' while 2.0.x uses apr_*.\n\nDan the Truncated Man\n\n
28898	dankogai@dan.co.jp	1084599784000	> Does the correct file size get logged to access_log if you GET the file?  \n\nWith my (quick & dirty) patch, yes.  w/o, no.\n\n> Does autoindex show the correct size for the file in a directory listing?\n\nYes, with or without the patch.\n\n dvd.dmg                 12-May-2004 00:07  4.4G  \n\nDan\n
28898	Joe Orton	1084668693000	Well, since off_t is signed any size >2Gb would fail, if at all... it works the\nsame here for me using >4Gb sizes too (again, using HEAD with\napr_off_t==off64_t, which should be equivalent to a FreeBSD system with\napr_off_t==off_t where sizeof(off_t) == 8).\n\nSo I don't know what bug you're seeing here, it would be great if you could\ndebug it, i.e. work out if apr_stat() is determining the size correctly, and\nwork on up...
28898	dankogai@dan.co.jp	1084721831000	> Well, since off_t is signed any size >2Gb would fail, if at all... \n> it works the same here for me using >4Gb sizes too\n\nThe problem is sizeof(apr_off_t) > sizeof(apr_size_t) in those platforms while\nthere are many places where apr_off_t objects are computed against apr_size_t\nobjects.  We already have learned that forcibily making apr_size_t 64-bit off-t\nfixes the problem (in some platforms).\n\nOh, I have chenged the summery from '2GB' to '4GB' to be more precise.\n\n> it would be great if you could debug it\n\nYikes.  I know HOW it went wrong but WHERE to fix is another problem.  Since it\nis size-related, that may even lead to changes in *.h, meaning API changes and\nthat'way too much for me. \n \n> i.e. work out if apr_stat() is determining the size correctly, \n> and work on up...\n\nThat's not the only problem.  Anywhere apr_off_t is used in conjunction w/\napr_size_t are vulnerable.  i.e apr_bucket_read().\n\nDan the Apache *User* (and love to stay that way)\n\n
28898	dankogai@dan.co.jp	1084727743000	In Mac OS X, I later found that while Content-Length: header was correct w/ the\nprevious patch, the actual file transfer gets trucated.  The following patch to\nemulate_sendfile() in server/core.c fixes that (YOU STILL NEED MY PREVIOUS PATCH). \n\nI wonder why FreeBSD did work. Maybe because it was tested w/ truncated (sparse)\nfile.  There on Mac OS X I have used the actual DVD image file for testing uI\nalso applied byte-to-byte exhaustive file comparison as well as md5 sum to make\nsure the transferred file is identical to the original.\n\nThat explains reason why my patch did not quite work on Linux.  On Linux\nAPR_HAS_SENDFILE is set and emulate_sendfile() is never used.\n\nDan the Typedefed Man\n\n--- httpd-2.0.49/server/core.c  Tue Mar  9 07:54:20 2004\n+++ httpd-2.0.49-x/server/core.c        Mon May 17 02:00:53 2004\n@@ -2949,7 +2949,7 @@\n                                      apr_size_t length, apr_size_t *nbytes)\n {\n     apr_status_t rv = APR_SUCCESS;\n-    apr_int32_t togo;        /* Remaining number of bytes in the file to send */\n+    apr_off_t togo;        /* Remaining number of bytes in the file to send */\n     apr_size_t sendlen = 0;\n     apr_size_t bytes_sent;\n     apr_int32_t i;\n
28898	Joe Orton	1084734145000	Ah, nice work, yes, I see the issue here too with 'EnableSendfile off'. \n\nCan you try this patch - *without* your apr_off_t = size_t hack:\n\nhttp://www.apache.org/~jorton/ap_splitlfs.diff
28898	dankogai@dan.co.jp	1084779319000	> Can you try this patch - *without* your apr_off_t = size_t hack:\n\nYay!  Seems like it's working now.  Both HEAD and GET works fine.  Maybe we\nstill need to check on (HTTP/1.1) partial transfers but this is a significant\nprogress.  Thank you so much!\n\nDan the Untruncated Man\n
28898	dankogai@dan.co.jp	1084807367000	Joe,\n\nI am just curious if subbuckets also needs to turn off mmap (just to be sure). \nHere's the patch AGAINST YOURS that does that.\n\nDan the Munmapped Man\n\n--- server/core.c       Tue May 18 00:16:34 2004\n+++ server/core.c.old   Tue May 18 00:15:37 2004\n@@ -3488,11 +3488,6 @@\n             while (fsize > AP_MAX_SENDFILE) {\n                 apr_bucket *ce;\n                 apr_bucket_copy(e, &ce);\n-#if APR_HAS_MMAP\n-               if (d->enable_mmap == ENABLE_MMAP_OFF) {\n-                   (void)apr_bucket_file_enable_mmap(ce, 0);\n-               }\n-#endif\n                 APR_BRIGADE_INSERT_TAIL(bb, ce);\n                 e->start += AP_MAX_SENDFILE;\n                 fsize -= AP_MAX_SENDFILE;\n
28898	Joe Orton	1084820635000	That patch is reversed... hmmm, probably.  Actually it won't make any\ndifference, since the file buckets are only mmap'ed if they are smaller than\n4Mb, and here we're creating 16Mb buckets.
28898	Joe Orton	1095082897000	The patch is now committed for 2.1.  Thanks for the report.
29003	Andr?? Malo	1084820211000	Agreed. This disturbes me all the time, too :-)
29003	Edward Rudd	1085110965000	I see several ways of solving this issue.\n1) Create an Ifsymbol directive which is analogous to IfModule except it\nsearches mod_so's internal dynamically loaded modules (moduleinfo structs).\n2) Similar to 1 and have IfModule call a function in mod_so (via an optional\nfunction) to search mod_so's internal list of dynamically loaded modules.\n3) Alter the STANDARD20_MODULE_STUFF macro to take one paramter which is the\n*filename* to register.. (ie.. for sapi_apache2.c sepcify mod_php4.so instead)\nThis can be setup as a NAMED macro and have the standard one call the NAMED with\n__FILE__ to retain backword compatability.\n4) provide an function to be called by a modules register_hook function to\nregister alternate names and have the ap_find_linked_module search this list as\nwell.\n
29003	Edward Rudd	1085110976000	Created an attachment (id=11620)\nPatch for solutions 1 and 2\n
29003	Edward Rudd	1085111031000	Created an attachment (id=11621)\npatch for solution number 3.\n
29003	Edward Rudd	1085111196000	Set PatchAvailable\n\nI still need to work up a patch for solution number 4.\n
29003	Andr?? Malo	1085527436000	Created an attachment (id=11670)\nMixed variant\n
29003	Andr?? Malo	1085527531000	I've attached a patch against HEAD partially based on yours which leaves it all\nto <IfModule>, but also resolves the static stuff.\n\nOpinions?
29003	Edward Rudd	1085689322000	Created an attachment (id=11685)\nUpdated patch switching mod_so.c to use the ap_module_symbol_t structure\n
29003	Edward Rudd	1085689429000	It looks good.. and solves the issues I brought up before.. my updated patch\njust has mod_so use ap_module_symbol_t instead of it's privately declared\nversion of that structure (moduleinfo) no need to have two copies of the same\nstructure.\n\nI think this solves the issue completely, I'm up for bringing it up for a vote\non dev@httpd.\n
29003	Andr?? Malo	1085690628000	+1.\n\n(plus that the build processes for win32 and netware need to be updated).
29003	Edward Rudd	1085775957000	Created an attachment (id=11690)\nwin32 patches\n
29003	Andr?? Malo	1086388971000	Committed, since nobody cried.\nThe build is broken now on Netware, but I assume, it will be fixed soon.
29098	Will Rowe	1150960391000	apr_cpystrn takes a buffer length and must null terminate, your patch is\nquite correct.  thank you!  applied with commit 416288
29098	Matt Lewandowsky	1152105113000	Will Rowe has posted a zipfile containing compiled mod_isapi modules which\ninclude the patch correcting this bug (for use with 2.0.58 and 2.2.2), for\ntesting purposes. It is available at:\n\nhttp://people.apache.org/~wrowe/mod_isapi-416293.zip\n\nYou may read his full email to the dev@httpd.apache.org list here:\n\nhttp://marc.theaimsgroup.com/?l=apache-httpd-dev&m=115206683718140&w=2\n\nIf you test this version of mod_isapi, please post your feedback to the\ndev@httpd.apache.org list. Your feedback will help ensure that there are no\nregressions or other issues in this version of mod_isapi.
29106	Andr?? Malo	1085444180000	Fixed in 2.1 and suggested for backport into the 2.0 branch.\n\nThanks for the report and thanks for using Apache.
29106	Andr?? Malo	1086528310000	The fix will be in version 2.0.50.
29148	Joe Orton	1085172320000	Neat tool! Thanks for the report, fixed by:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/dav/main/mod_dav.c?r1=1.106&r2=1.107
29216	Graham Leggett	1096820897000	Fix committed to HEAD.
29216	Graham Leggett	1097684520000	Backported to v2.0.53.\n
29310	Tom Alsberg	1086017483000	The URL was bad, I fixed it now.\n
29310	Tom Alsberg	1086160452000	Created an attachment (id=11721)\nPatch to add AllowOverrideOpts directive\n
29310	Paul Querna	1086161268000	Created an attachment (id=11722)\nAdds AllowOverrideOpts against 2.1-CVS\n
29310	Paul Querna	1086161394000	+1 - Tested w/ the patch for 2.1 and a cursory code review.\n\nOnly issue I see is the naming of the directive. AllowOrderrideOpts vs\nAllowOverrideOptions vs SomthingMuchShorterPlease.
29310	Andr?? Malo	1086162529000	Without a closer look at the patch for now ...\nWhat about not to introduce a new directive, but extending AllowOverride, like\n\nAllowOverride Options=Indexes,MultiViews\n\n?
29310	Tom Alsberg	1086163263000	That (AllowOverride Options=) is a possibility too, shouldn't be too difficult\nto change it to work this way.  I'm not sure what's better, though...  It is\nafter all quite a different context (specific to one directive, different\nfunction checking it...), so perhaps that would mean complicating AllowOverride\na bit too much for specifics.\n\nIf that's preferred, I could (am willing to) modify the patch to work this way.\n
29310	Tom Alsberg	1088932160000	Created an attachment (id=12022)\nPatch for httpd 2.0.50 with syntax AllowOverride Options=\n
29310	Paul Querna	1089787216000	Slightly modified patch Commited to 2.1 CVS.\n\nThanks for helping with Apache,\n\n-Paul Querna
29318	Joe Orton	1086096103000	Thanks for the report.  Fixed on HEAD:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/filters/mod_deflate.c?r1=1.48&r2=1.49\n\nand backport which does the same for 2.0:\n\nhttp://cvs.apache.org/~jorton/ap_deflate.diff\n\nThis should prevent the massive memory consumption with large responses\nregardless of DeflateWindowSize setting.
29318	David Greenaway	1086175504000	Confirmed fixed.\n\nThanks Joe! :)
29518	Joshua Slive	1089658263000	Fixed.  Thanks for the note.
29696	Jeff Trawick	1087736978000	Fix committed to 2.1-dev, and I'll propose it for merging into stable branch for\n2.0.next.\n\nThanks for the fix, and thanks for using Apache httpd!\n
29732	Charlie Cox	1087995402000	I like the 'See Also' reference. \n\nAlternatively, we could revise the description for *Match directives in the Core\nFeatures document. For example, we could modify the <LocationMatch> as follows:\n--\nDescription: Applies the enclosed directives only to perl-compatible regular\nexpression matching URL's\n--\n\nI also have a suggestion for the 'Configuration Sections' document:\n(under 'Wildcards and Regular Expression')\n--\nIf even more flexible matching is required, each container has a perl-compatible\nregular-expression (regex) counterpart\n--\n\nThis brings the perl-compatible statement to the first occurance of the words\n'regular expression', which will make it stand out more. \n\nA link here to the PCRE library would be more obvious than a link to the glossary. 
29732	Joshua Slive	1089657791000	I've fixed the directive-dict to say 'Perl-compatible' and to reference the\nglossary.  Changing every directive that uses a regular expression would be a\nmajor undertaking.  If you'd like to work on that, please feel free to come over\nto the docs project and help out:\nhttp://httpd.apache.org/docs-project/
29740	Max Bowsher	1087919802000	Created an attachment (id=11910)\nThe same patch as inline, but attached to avoid line-wrapping\n
29740	Sergey A. Lipnevich	1088265295000	We have had similar problems trying to build APR, APU, and then HTTPD all by\nthemselves, in Source Mage GNU/Linux. Our patches are here:\n\nhttp://codex.sourcemage.org/test/libs/apr/build.diff\nhttp://codex.sourcemage.org/test/libs/apr-util/build.diff
29740	Paul Querna	1099538008000	most reasonable places have the APR headers installed to /usr/include/apr-{0,1}\ndon't they?
29740	Max Bowsher	1099571407000	Replying to Paul Querna above:\n\nInstalling to <prefix>/include is the default in apr. For httpd to be\nincompatible with the default build and install of apr seems rather wrong to me.\n\nBesides, just because the bug won't affect some environments doesn't mean it\nshouldn't be fixed, especially when fixing it only requires a tiny patch, which\nI have already written and attached to the bug.
29740	Max Bowsher	1099571523000	Replying to Sergey A. Lipnevich above:\n\nAFAICS your patches are about an entirely unrelated issue.
29740	Graham Leggett	1099572195000	APR must be able to find it's headers if they are installed in /usr/include or\nin /usr/include/apr-{0,1}, which is where APR v1.0 seems to want to put them.\n\nFixing this bug allows httpd v2.1 to be built as an RPM again.\n
29740	Justin Erenkrantz	1107477578000	Applied in r151255.  Thanks!
29755	Paul Querna	1099538938000	Changed in 2.1 CVS.\n\nThanks for using Apache!
29755	Sami J. M??kinen	1100555256000	Uh, the following hit us:\n\nhttp://ken.coar.org/burrow/index?entry=511\n\nin short, mod_usertrack really should set the cookie\nheader in err_headers_out, NOT headers_out.\n\nThe headers in headers_out will not get sent\nif the request ends in a redirect. Sigh.\n\nFurthermore, register_hooks should look like this:\n\nstatic void register_hooks(apr_pool_t *p)\n{\n    /* fixup before mod_proxy, so that the proxied url will not\n     * be escaped accidentally by our fixup.\n     */\n    static const char * const aszSucc[]={ 'mod_rewrite.c', 'mod_proxy.c',\n                                          'mod_alias.c', NULL };\n    ap_hook_fixups(spot_cookie, NULL, aszSucc, APR_HOOK_FIRST);\n}
29755	Sami J. M??kinen	1100556257000	Sigh.\n\nI just checked Apache 2.0.52 source. It should be fixed.\nA simple and suitable patch is attached below:\n\n*** mod_usertrack_orig.c        2004-11-15 22:54:20.000000000 +0200\n--- mod_usertrack.c     2004-11-15 22:57:57.000000000 +0200\n***************\n*** 145,151 ****\n                                   NULL);\n      }\n  \n!     apr_table_addn(r->headers_out,\n                     (dcfg->style == CT_COOKIE2 ? 'Set-Cookie2' : 'Set-Cookie'),\n                     new_cookie);\n      apr_table_setn(r->notes, 'cookie', apr_pstrdup(r->pool, cookiebuf));   /*\nlog first time */\n--- 145,151 ----\n                                   NULL);\n      }\n  \n!     apr_table_addn(r->err_headers_out,\n                     (dcfg->style == CT_COOKIE2 ? 'Set-Cookie2' : 'Set-Cookie'),\n                     new_cookie);\n      apr_table_setn(r->notes, 'cookie', apr_pstrdup(r->pool, cookiebuf));   /*\nlog first time */\n***************\n*** 439,445 ****\n  \n  static void register_hooks(apr_pool_t *p)\n  {\n!     ap_hook_fixups(spot_cookie,NULL,NULL,APR_HOOK_MIDDLE);\n  }\n  \n  module AP_MODULE_DECLARE_DATA usertrack_module = {\n--- 439,450 ----\n  \n  static void register_hooks(apr_pool_t *p)\n  {\n!     /* fixup before mod_proxy, so that the proxied url will not\n!      *      * escaped accidentally by our fixup.\n!      */\n!     static const char * const aszSucc[]={ 'mod_rewrite.c', 'mod_proxy.c',\n!                                         'mod_alias.c', NULL };\n!     ap_hook_fixups(spot_cookie, NULL, aszSucc, APR_HOOK_FIRST);\n  }\n  \n  module AP_MODULE_DECLARE_DATA usertrack_module = {\n
29755	Paul Querna	1112828682000	This has beend fixed in 2.1.x, and not backported to 2.0.x.  I didn't feel it\nwas important enough to backport to 2.0.x.
29889	Kim Scarborough	1101245864000	At Apachecon it was suggested to me that I comment on this bug to try to get\nsomebody to look at it. So I am. Can this please be added to the MIME types file?
29889	Dave Hodder	1105887363000	I've attached a diff to bug 26505 which should update both the WordPerfect and\nPalm OS media types.
29889	Roy T. Fielding	1188472560000	Committed to trunk.\n
29962	Joe Orton	1089291139000	Yes, this is a problem with the byterange filter in 2.0, it will buffer the\nentire response in memory.\n
29962	Filip Sneppe	1090852429000	I am just wondering if there is currently *any* workaround for this ?\nA directive that disables byterange support ?\nBecause, isn't this a serious security issue in itself ? It means\nany user that can send http requests to an apache proxy can DoS it\nby sending even a limited number of specially crafted requests that\ndownload some large files somewhere...
29962	Andr?? Malo	1090856428000	You can DoS any HTTP server very easy. One could say, that's part of the\nprotocol ;-)\n\nAnyway,\n\nRequestHeader unset Range\n\nor somehting like this should work for you.
29962	Nick Kew	1090861183000	Don't forget\n\nHeader unset Accept-Ranges\n\nso the server isn't telling porkies about its capabilities
29962	Tyler	1096401161000	I appear to be experiencing a similar problem when my users submit files to the\nserver.  I've noticed that a submitted assignment (POST), which has an attached\nword document, appears to cause one of the apache processes to inflate to\nbetween 300 - 750 megabytes in size.  This does not appear to be equal to the\nsize of the attachment.
29962	Tyler	1097005073000	I hunted down the problem, it was an error in a purchased PHP script that loaded\nthe entire contents of our of our db tables into memory (which is now\napproaching the 800 megabytes threshhold).  However, when the script terminated\nthat memory was not being released by Apache 2.0.51.
29962	Joe Orton	1118788864000	The byterange filter memory consumption issue is now fixed for 2.1.5.\n\nhttp://svn.apache.org/viewcvs?rev=188797&view=rev
29962	dswhite42@yahoo.com	1124400584000	Created an attachment (id=16102)\nByterange patch for Apache 2.0.x\n\nI hope Joe won't mind if I post a version of the patch which he modified to\nwork with the Apache 2.0.x branch.  Thanks, Joe!
29962	Joe Orton	1124793407000	Now merged for 2.0.55.  Thanks for the report.
29962	Brady Bowen	1125063072000	\nI'm not sure that this has been fixed, I've downloaded the patch and have it\napplied yet, it still runs amuck.  I checked on my server this morning, and\nthere sat a process in apache holding onto 635MB of data.  Maybe this bug is\noccuring somewhere else.  I am in no way capable of tracking that down, but I do\nknow it's still occuring.\n
29964	Joe Orton	1089284663000	Created an attachment (id=12060)\nssl_io_input_read fix\n
29964	Joe Orton	1089284696000	Thanks for the report and analysis.  Can you try the patch attached above?
29964	Francis Wai	1089315044000	\nThanks for the quick response.\n\nWe thought about this before I submitted the bug report. We thought APR_EOF or \nAPR_EGENERAL or in fact any return code other than APR_SUCCESS would have been \nsufficient to prevent Apache from spinning out of control.\n\nWe could not decide on either, however. We are not super familiar with the \nApache/mod_ssl code and, more important, this is the most exercised part of \nthe server as far as we're concerned. It is important that the return code \ndoes what it is supposed to do _and_ does not cause any un-expected side-\neffect.\n
29964	Joe Orton	1089747621000	APR_ECONNRESET, APR_EGENERAL or APR_EOF would all be reasonable choices.  Doing\nany of these would clearly be better than the status quo; opt for APR_EGENERAL\nto be conservative.\n\nI couldn't reproduce the issue here from in brief attempt, so if you could\nconfirm that the patch does fix the issue that would be helpful.
29964	Francis Wai	1089747918000	\nWe patched Apache as suggested and it does fix the problem. We're in the \nprocess of conducting more thorough tests and if anything unexpected crops up, \nI'll report here.\n\nThanks for the response.\n
29964	Joe Orton	1092230755000	The fix checked in is slightly different:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_io.c?r1=1.124&r2=1.125\n\nthis will be proposed for backport for the next 2.0 release.  This issue has\nbeen assigned CVE CAN-2004-0748.
30033	Nick Kew	1089542598000	I've no idea who works on mod_isapi, but I think this bug report really needs an\nexample that demonstrates the problem.  From the description, I'd have thought\nyou could construct a HelloWorld-sized example?
30033	Dr. Martin Luckow	1089543818000	Sample:\n\nDWORD WINAPI HttpExtensionProc(LPEXTENSION_CONTROL_BLOCK ecb) {\n  char* buffer = 'HTTP/1.1 200 OK/r/nDate: Sun, 11 Jul 2004 09:10:58 \nGMT/r/nContent-length: 0/r/n/r/n';\n  unsigned long bufferSize = strlen(buffer);\n\n  if (!ecb->WriteClient(ecb->ConnID,buffer,&bufferSize,HSE_IO_SYNC)) {\n    return HSE_STATUS_ERROR;\n  }; // if\n  return HSE_STATUS_SUCCESS_AND_KEEP_CONN;\n};\n\nIIS: WriteClient works, the header is 'nph-'sent.\nApache: WriteClient fails.
30033	John Taylor	1090323907000	I had a look at the code in mod_isapi.c, I changed line 687 from\n\napr_cpystrn(newstat + 8, stat, statlen + 1);\nto\napr_cpystrn(newstat + 8, stat, statlen);\n\nand that seemed to fix the problem for me. For the example above Apache would\ntry to process the header line 'Status: 200 OK/r/nD', and points out that 'D' is\nnot a valid header.
30033	Rick Strahl	1103555293000	I don't think this is actually the problem. \n\nI use WriteClient to dump out a complete HTTP response which includes header \nand body in the first chunk that gets passed to WriteClient. The header might \nlook like this:\n\n<pre>\nHTTP/1.1 200 OK\nContent-type: text/html; charset=utf-8\nContent-Length: 3042\n\n... some HTML text goes here.\n</pre>\n\nThis works perfect with IIS, but not with Apache. I get the same 87 error as \nmentioned above. There's definitely more going on here than just an extra \ncharacter in the header block...
30033	Matt Lewandowsky	1149054927000	Created an attachment (id=18374)\nPatch to not clobber the ISAPI's response code.\n\nI've attached a patch to 2.2.2's mod_isapi.c which should correct this\nbehavior. I've run it against a suite of ISAPI extensions, all of which give\ntheir correct responses as far as I can tell.\n\nWhat seems to be the issue is that ap_scan_script_header_err_strs likes to\nreturn 0 (or some other value which is not the HTTP status). The current\nmod_isapi sticks this result in as the HTTP status. Needless to say, this is\nquite unexpected. Since mod_isapi's send_response_header already gets the\ncorrect value, there's no reason that I can see to second-guess it.\n\nIf someone can review this trivial patch for sanity, I'd appreciate it. I can't\nfind any breakage, but I assume that someone did that for a reason.
30033	Matt Lewandowsky	1149064796000	Created an attachment (id=18375)\nMore correct patch, cribbed from mod_cgi\n\nOn the advice of wrowe, I've attached a more correct patch which cribs from\nmod_cgi. As a rule, we probably don't want to use the return from\nap_scan_script_header_err_strs. But if it's non-zero, we should.\n\nThe last patch neglected a case, as well. This one should catch everything.\n\nAgain, I ran it through its paces and was able to get a variety of responses.
30033	Will Rowe	1149142338000	See bug 16637 for an interrelated issue.
30033	Matt Lewandowsky	1149220794000	Created an attachment (id=18392)\nComplete logic overhaul for send_response_header\n\nThis updated patch completely replaces the HTTP response status logic in\nsend_response_header. It likely should correct the issue mentioned in bug 16637\nas well.
30033	Will Rowe	1150958602000	\n  This looks great.  Please review trunk, I've refactored this a bit to make\n  the interrelations between r->status and dwStatus a bit clearer.\n
30033	Will Rowe	1150959795000	\n  I hate when I can't track this stuff down.  The commit to trunk which is\n  expected to resolve this is 416272
30033	Matt Lewandowsky	1152105087000	Will Rowe has posted a zipfile containing compiled mod_isapi modules which\ninclude the patch correcting this bug (for use with 2.0.58 and 2.2.2), for\ntesting purposes. It is available at:\n\nhttp://people.apache.org/~wrowe/mod_isapi-416293.zip\n\nYou may read his full email to the dev@httpd.apache.org list here:\n\nhttp://marc.theaimsgroup.com/?l=apache-httpd-dev&m=115206683718140&w=2\n\nIf you test this version of mod_isapi, please post your feedback to the\ndev@httpd.apache.org list. Your feedback will help ensure that there are no\nregressions or other issues in this version of mod_isapi.
30134	Nick Kew	1089954754000	Does this still happen if you take mod_rewrite out of the setup and use\nProxyPass instead?
30134	M. 'Alex' Hankins	1090347108000	Yes, I still get what seems to be the same segfault (according to gdb) if I\nreplace these config lines:\n\nRewriteEngine on\nRewriteRule /(.*) https://some.eroom6.iis.server.com/$1 [P]\n\nwith this one:\n\nProxyPass / https://some.eroom6.iis.server.com/
30134	Joe Orton	1092231029000	This backtrace is a little strange:\n\n#1  0xfeafef54 in char_buffer_read (buffer=0x1649ac,\n    in=0x2000 <Address 0x2000 out of bounds>, inl=8192) at ssl_engine_io.c:348\n\nwhich means either stack corruption by memcpy or in got passed in as a pointer\nto address 8192 somehow.\n\nCan you, from gdb against a core dump, check:\n\nup 2 (into ssl_io_input_read)\nprint *inctx\ninfo locals\nprint buf\nprint len\n\n\n
30134	Stephan Tesch	1092657268000	Hi Joe, \n \nI do suffer from the same bug. Attached is the info you requested. If you need \nadditional testing, please say so. I cleared some info from the contents of \nbuffer to not disclose critical information. I hope that's ok and doesn't \nhinder your debugging process. \n \nRegards, Stephan \n \nProgram received signal SIGSEGV, Segmentation fault. \n0xfedf060c in memcpy () from /usr/platform/SUNW,UltraAX-i2/lib/libc_psr.so.1 \n(gdb) where full \n#0  0xfedf060c in memcpy () \n   from /usr/platform/SUNW,UltraAX-i2/lib/libc_psr.so.1 \nNo symbol table info available. \n#1  0x00048060 in char_buffer_read (buffer=0x196d54, \n    in=0x196d60 'Cet-Cookie: s'..., \n    at ssl_engine_io.c:348 \nNo locals. \n#2  0x00048448 in ssl_io_input_read (inctx=0x196d38, \n    buf=0x196d60 'Cet-Cookie: s'..., \n    len=0xffbeafa4) at ssl_engine_io.c:561 \n        wanted = 8192 \n        bytes = 1533728 \n        rc = 8192 \n#3  0x00048714 in ssl_io_input_getline (inctx=0x196d38, \n    buf=0x196d60 'Cet-Cookie: s'..., \n    len=0xffbeafa4) at ssl_engine_io.c:712 \n        pos = 0x173ea0 '' \n        status = 1666360 \n        tmplen = 1 \n        offset = 1533728 \n(gdb) up 2 \n#2  0x00048448 in ssl_io_input_read (inctx=0x196d38, \n    buf=0x196d60 'Cet-Cookie: s'..., \n    len=0xffbeafa4) at ssl_engine_io.c:561 \n561 \n(gdb) print *inctx \n$1 = {ssl = 0x173db8, bio_out = 0x172210, f = 0x198d68, rc = 0, \n  mode = AP_MODE_GETLINE, block = APR_BLOCK_READ, bb = 0x198d80, cbuf = { \n    length = 1, value = 0xffffffff <Address 0xffffffff out of bounds>}, \n  pool = 0x16fea8, \n  buffer = 'Cet-Cookie: s'..., \n  filter_ctx = 0x17e058} \n(gdb) info locals \nwanted = 8192 \nbytes = 1533728 \nrc = 8192 \n(gdb) print buf \n$2 = 0x196d60 'Cet-Cookie: s'..., \n(gdb) print len \n$3 = (apr_size_t *) 0xffbeafa4 \n \n 
30134	Joe Orton	1092658545000	Ah ha, that's crucial info, thanks.\n\nIt looks like the cause is: ssl_io_input_read is called with inctx->mode ==\nSPECULATIVE (this only normally happens in the proxy IIRC); ssl_io_input_read\ncalls char_buffer_read, which executes the case where it does:\n\n        buffer->value = NULL;\n        buffer->length = 0;\n\nand ssl_io_input_read then screws up the inctx->cbuf for good.\n\n            /* We want to rollback this read. */\n            inctx->cbuf.value -= bytes;\n            inctx->cbuf.length += bytes;\n\ncbuf = { length = 1, value = 0xffffffff <Address 0xffffffff out of bounds>}, \n\nper your backtrace.\n\n
30134	Joe Orton	1092746886000	Created an attachment (id=12459)\nproposed fix\n
30134	Joe Orton	1092746975000	The patch attached above should fix the segfaults, I'm not yet sure if this is\nthe cleanest or most correct fix.
30134	Joe Orton	1092776601000	The fix checked in should be equivalent:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_io.c?r1=1.125&r2=1.126\n\nThis issue has possible security implications; it's been assigned CVE\nCAN-2004-0751 (cve.mitre.org).  Thanks for the report and for the debugging.
30190	Phil Pennock	1092601084000	Now I have a bugzilla account I'm actually doing something about this.  This\nbites me frequently, hence the vote.  If the pnm tools aren't installed, but\ngif2png is, then:\n\n$ gif2png -tw *.gif small/*.gif | xargs gif2png -ghnrsO\n\nExpected output from command-line is one stderr message from the first gif2png\ninvocation, noting the animated GIF (which is the reason for doing things this way).\n
30190	Andr?? Malo	1092602395000	I see the problem, that there are just a few browsers that actually support\ntransparent png images, resp. some browsers have real problems with them.\nPerhaps we should just put the conversion script snippets somewhere into the docs?
30190	Phil Pennock	1092604548000	The problem is that the PNGs are shipped at all without transparency.  Since the\nPNGs aren't actually used by default, can't they be fixed so that anyone who\nchooses to use them at least gets full PNGs which don't look so bad in\nmod_autoindex that they put people off using PNGs?\n\nIt looks as though MSIE is the one fly in the ointment:\n  http://www.libpng.org/pub/png/pngstatus.html\nbut according to that, cells which aren't completely opaque are rendered as\ncompletely transparent; since the Apache images don't use blending but have\npixels either transparent or with colour (AFAIK), for this purpose is there\nactually a problem?\n\nI just checked with my fiancee's MSIE 6.0 and the few icons used in one of my\nmod_autoindex pages rendered just fine; that's with the transparent PNGs\nrendered by the example command-line which I gave.  In fact, I've just created a\nweb-page using all the PNG icons (except those in small) and they _all_ rendered\nfine.\n\nIf anyone wants to test more widely, there seems to be a decent testbed at:\n  http://entropymine.com/jason/testbed/pngtrans/\nbut that covers a much more general case than the Apache icons, which require a\nmuch simpler subset of PNG rendering functionality.
30190	Neale Pickett	1102712277000	Created an attachment (id=13727)\nTransparent PNG icons\n\nTransparent PNG icons, converted from the transparent GIFs from the 2.0.52\nsource distribution.
30190	Neale Pickett	1102712823000	Created an attachment (id=13728)\nTransparent PNG icons\n\nNew version with the small directory included
30190	Neale Pickett	1102713055000	Sorry for all the new comments, I'm unfamiliar with bugzilla.\n\nI've attached a tarball of transparent PNG icons.  These were converted from the\nGIFs distributed with 2.0.52 using 'giftopng -O'.  They are slightly (a few\nbytes per icon) larger than the old, non-transparent ones, and as far as I can\ntell display just fine in all browsers (even IE).\n\nPlease consider moving these icons into CVS so they may one day be distributed.\n I'm getting tired of having to convert the GIFs by hand every time I install a\nnew version of Apache :)\n\nThanks
30190	Thijs Kinkhorst	1163310657000	I can indeed still reproduce it. I hope it can be fixed; as said the icons now\ndisplay badly in *any* browser while that could be reduced to only some (by now\nalready older) browers.\n\nThe following snippet when using ImageMagick solves it:\n\nfor i in *.png; do convert ${i%png}gif $i;done\n\nThanks.
30190	Neale Pickett	1188217075000	Come on guys, it's been 3 years and we've provided you three different ways to \nfix this.
30190	Will Rowe	1188273632000	Thanks for the ImageMagick pointer (although I had to resort to GraphicsMagick\nsince ImageMagick was generating corrupt .png's).\n\nNote I used the -quality 100 to avoid any lossy optimization.
30190	Neale Pickett	1188294898000	(In reply to comment #9)\n\nThanks, Will!  You are my PNG hero.
30278	Paul Querna	1090545904000	is utf8 your default charset type?\nWhat is 'AddDefaultCharset' set to in your httpd.conf?
30278	Igor Fedulov	1090546969000	It's set to UTF-8, i.e. from httpd.conf:\n\nAddDefaultCharset UTF-8
30278	R??diger Pl??m	1091631861000	Does this only happen with css files or also with other files?\nWhat is your setting for DefaultType ?\nIs it unset or text/plain?\n\nI had a similar problem with mod_jk and mod_cache / mod_disk_cache. I would\nguess that they are related. See also\nhttp://nagoya.apache.org/bugzilla/show_bug.cgi?id=30398.
30278	Igor Fedulov	1091633769000	Here are my answers:\n1. DefaultType is set to 'text/plain'\n2. Images from cache also come out with 'Content-Type: text/plain; charset=UTF-8'\n\nLooks like what you are describing in your issue is exactly the same thing, I\nwonder if I can try your patch to see if it will fix the problem.
30278	R??diger Pl??m	1091652530000	No, you cannot use my patch as I patched mod_jk to solve my problem. You\nneed a patch for mod_disk_cache. But as I mentioned in 30398, I was not quite\nsure if this problem is a bug in mod_jk or mod_cache / mod_disk_cache\n(BTW: mod_mem_cache does not have this problem). After I read this report here\nI am quite sure that it is a bug in mod_disk_cache and that it should be fixed\nthere.\nmod_disk_cache.c already contains the needed code in write_headers, but\nit is executed too late. So I just moved this piece of code and created an\nappropriate patch for this which I will attach.\n\nI removed my patch from my mod_jk and added my patch to mod_disk_cache and\nmy problem from 30398 remains silent. I hope that this patch will also solve\nyour problem. A short feedback on your experience with the patch would be much\nappreciated.\n\nBTW: If you have any problems with mod_cache storing Cookies unintentional, or\nwith other weird HTTP header caching behaviour you may find the following links\nuseful:\n\nhttp://nagoya.apache.org/bugzilla/show_bug.cgi?id=30399\nhttp://nagoya.apache.org/bugzilla/show_bug.cgi?id=30419\n
30278	R??diger Pl??m	1091652585000	Created an attachment (id=12339)\nproposed solution patch to mod_disk_cache.c\n
30278	Igor Fedulov	1091655781000	I've tested this patch and it works perfectly. After either image or .css file\nis cached headers contain proper Content-Type thus allowing for proper display\nin strict HTML validating browsers! Thanks!\n\nHere is the output from the original wget commands:\n\n1. First request for a resource:\n16:36:57 (328.88 KB/s) - "common.css' saved [10440/10440]\n \nHTTP/1.1 200 OK\nDate: Wed, 04 Aug 2004 21:36:56 GMT\nServer: Apache/2.0.50 (Fedora)\nContent-Length: 10440\nLast-Modified: Fri, 23 Jul 2004 12:56:12 GMT\nAccept-Ranges: bytes\nContent-Type: text/css\nVary: Accept-Encoding,User-Agent\nKeep-Alive: timeout=30, max=100\nConnection: Keep-Alive\n\n2. Next request for the same resource:\n16:36:59 (463.42 KB/s) - "common.css' saved [10440/10440]\n \nHTTP/1.1 200 OK\nDate: Wed, 04 Aug 2004 21:36:59 GMT\nServer: Apache/2.0.50 (Fedora)\nAccept-Ranges: bytes\nContent-Length: 10440\nLast-Modified: Fri, 23 Jul 2004 12:56:12 GMT\nContent-Type: text/css\nAge: 4\nKeep-Alive: timeout=30, max=100\nConnection: Keep-Alive
30278	R??diger Pl??m	1092827593000	*** Bug 29016 has been marked as a duplicate of this bug. ***
30278	R??diger Pl??m	1096374376000	Created an attachment (id=12879)\nPatch against 2.0.51\n
30278	Justin Erenkrantz	1096393369000	A variant of the 'patch against 2.0.51' has been committed to HEAD as\nmodules/experimental/mod_disk_cache.c rev 1.63.\n\nThanks!
30278	Graham Leggett	1097685521000	Backported to v2.0.53.\n
30308	Rich Bowen	1104101523000	Thanks. Example has been added in latest svn, and will be in the next release.\nShould also be on the website RSN.
30370	Paul Querna	1098079775000	Can you please try the mod_disk_cache that is part of 2.0.52 or CVS HEAD?\n\nThere have been many fixes for it recently.
30370	Taisuke Yamada	1149473506000	Though not sure if it is the same cause, I'm having exactly the same issue and \nI think I have tracked down the bug. I've reviewed the code in latest snapshot \nand believe this bug still exists both in 2.0 and 2.2 (I have verified it with \n2.0 tree). Also, this could also be a bug in mod_mem_cache.c.\n\nThe cause of this bug is that cached entry never gets removed from cache \nrepository maintained by mod_*_cache. There's a issue in \ncache_storage.c:cache_select_url method that incorrectly(?) handles cache-\n>stale_handle. Here's the code:\n\n  fresh = ap_cache_check_freshness(h, r);\n  if (!fresh) {\n    if (info && info->etag) {\n       ...\n       cache->stale_handle = h;\n    }\n    else if (info && info->lastmods) {\n      ...\n      cache->stale_handle = h;\n    }\n    return DECLINED;\n  }\n  ...\n  cache->handle = h;\n\nAs you can see, even when cache has expired, there's a case when cache-\n>stale_handle does not get set. Because of this, following part of the code in \nmod_cache.c:cache_save_filter is never executed:\n\n  if (cache->stale_handle) {\n    if (r->status == HTTP_NOT_MODIFIED) {\n      ...\n    }\n    else {\n      /* Oh, well.  Toss it. */\n      cache->provider->remove_entity(cache->stale_handle);\n      /* Treat the request as if it wasn't conditional. */\n      cache->stale_handle = NULL;\n    }\n  }\n\nSo when cache->stale_handle is not set, above remove_entity is never called, \nmeaning (expired) cache remains in cache repository.\n\nNow, because obsolete cache remains, following code in \nmod_cache.c:cache_save_filter fails with mod_mem_cache:\n\n  /* no cache handle, create a new entity */\n  if (!cache->handle) {\n    rv = cache_create_entity(r, url, size);\n    ...\n  }\n\n  if (rv != OK) {\n    /* Caching layer declined the opportunity to cache the response */\n    ...\n\nLooking into mod_mem_cache.c:create_entity, there's a following code:\n\n  tmp_obj = (cache_object_t *) cache_find(sconf->cache_cache, key);\n  ...\n  if (tmp_obj) {\n    /* This thread collided with another thread loading the same object\n     * into the cache at the same time. Defer to the other thread which\n     * is further along.\n     */\n    cleanup_cache_object(obj);\n    return DECLINED;\n  }\n\nSo mod_mem_cache.c:create_entity (incorrectly) returns a 'thread conflict' \nerror when obsolete cache remains in cache repository. And due to this return \ncode, mod_cache.c:cache_save_filter skips caching.\n\nTo fix (or workaround) this issue, cache_storage.c:cache_select_url can be \nfixed as follows:\n\n  fresh = ap_cache_check_freshness(h, r);\n  if (!fresh) {\n    cache->stale_headers = apr_table_copy(r->pool, r->headers_in);\n    cache->stale_handle = h;\n\n    /* Make response into a conditional */\n    /* FIXME: What if the request is already conditional? */\n    if (info && info->etag) {\n      /* if we have a cached etag */\n      apr_table_set(r->headers_in, 'If-None-Match', info->etag);\n    }\n    else if (info && info->lastmods) {\n      /* if we have a cached Last-Modified header */\n      apr_table_set(r->headers_in, 'If-Modified-Since', info->lastmods);\n    }\n    return DECLINED;\n  }\n\nSimilar fix can be done with Apache 2.2 as well.\n\nI'm now looking into caching behavior of mod_disk_cache.c, as unlike \nmod_mem_cache.c, it seems it does not check for thread-level conflict.\nAfter all review is done, I'll send in a patch.\n
30370	Taisuke Yamada	1149474458000	> Though not sure if it is the same cause, I'm having exactly the same issue ...\n\nAfter reading first poster's message again, I guess my issue isn't exactly the \nsame issue. My issue is that mod_cache never refreshes cached entry once \ninitial cache expired. So access_log goes on like below:\n\n  'GET /real/hello.php HTTP/1.0' 200 <-- query to backend\n  'GET /hello.php HTTP/1.0' 200      <-- caches and returns cached response\n  'GET /hello.php HTTP/1.0' 200      <-- cached response\n  'GET /hello.php HTTP/1.0' 200      <-- cached response\n  'GET /hello.php HTTP/1.0' 200      <-- cached response\n  ...                                <-- time passes and expires\n  'GET /real/hello.php HTTP/1.0' 200 <-- query to backend\n  'GET /hello.php HTTP/1.0' 200      <-- don't cache and pass-thru response\n  'GET /real/hello.php HTTP/1.0' 200 <-- query to backend\n  'GET /hello.php HTTP/1.0' 200      <-- don't cache and pass-thru response\n  'GET /real/hello.php HTTP/1.0' 200 <-- query to backend\n  'GET /hello.php HTTP/1.0' 200      <-- don't cache and pass-thru response\n  ...\n\nI'm doing a reverse proxied configuration, and here's an excerpt from \nhttpd.conf:\n\n  <VirtualHost *:8080>\n   CacheEnable mem /\n   CacheIgnoreHeaders Set-Cookie\n   MCacheSize 65535\n   MCacheMaxObjectCount 8192\n   MCacheMaxObjectSize 65535\n\n   ProxyPass        / http://127.0.0.1/real/\n   ProxyPassReverse / http://127.0.0.1/real/\n   ProxyPreserveHost On\n   ProxyTimeout 5\n  </VirtualHost>\n\nAnd the content of hello.fphp is:\n\n  <?php\n  header('Expires: ' . date(DATE_RFC822, time() + 10));\n  print_r($_SERVER);\n  ?>\n\nAs you can see, this should expire in 10 seconds after cache is\nmade, and it does work as expected. But it never gets cached\nafter its first expiration, probably due to apache issue I posted above.\n
30370	Ruediger Pluem	1149506711000	Thanks for the report. Please use httpd 2.2.x for caching since it contains many\nfixes and improvements since the days of the experimental cache module of 2.0.x.\nNevertheless I think that the problem you describe is also present in 2.2.x.\nCould you please give the attached patch a try? It is against trunk, but it\nshould also work against 2.2.x.
30370	Ruediger Pluem	1149506753000	Created an attachment (id=18401)\nPatch against trunk\n
30370	Taisuke Yamada	1149521231000	Thanks for the patch!\n\nYour patch worked perfectly though I had to make following\nchange to adapt it to 2.0:\n\n- irv = cache->provider->remove_url(h, r->pool);\n+ irv = cache->provider->remove_url(url);\n\nYes, I know 2.2 is now the recommended version (especially\nwhen using caching feature), but for now, I need to go with\n2.0 due to support issue.\n
30370	Ruediger Pluem	1165150359000	Committed to trunk as r481886 (http://svn.apache.org/viewvc?view=rev&rev=481886).
30370	Ruediger Pluem	1188702045000	Proposed for backport as r571936 (http://svn.apache.org/viewvc?rev=571936&view=rev).
30370	Ruediger Pluem	1188891651000	Backported to 2.2.x as r572626 (http://svn.apache.org/viewvc?rev=572626&view=rev).
30385	Paul Querna	1099536948000	PHP has a thing at the end of their make saying this is safe to ignore. Any\nreason we can't ignore it too?
30385	Joe Orton	1099555817000	./modules/ldap/util_ldap.c:            st->lock_file   =\nap_server_root_relative(st->pool, tmpnam(NULL));\n\nit may be safe but it's totally wacky since tmpnam returns filenames with a /tmp\nprefix.  The APR tmpfile interface should be used instead.\n
30385	Graham Leggett	1099567432000	Is the APR tmpfile interface available in v0.9 of APR?
30385	Joe Orton	1099568377000	Actually since this is just for a mutex, the right thing to do is to pass a NULL\nfilename parameter to apr_global_mutex_create if no CacheFile is specified,\nrather than some random temporary filename.
30385	Graham Leggett	1106350820000	According to the APR docs for apr_global_mutex_create():\n\nfname \tA file name to use if the lock mechanism requires one. This argument\nshould always be provided. The lock code itself will determine if it should be used.\n\nSo the compiler claims tmpnam() is evil, but all the alternatives involve\nactually opening a file, which isn't what we need.\n\nDoes APR have a temp file creation function? Are the APR docs above about the\nargument always being provided correct, or is it really safe to pass NULL to\nthis function on all platforms?\n
30385	Sander Temme	1106456327000	APR now has apr_file_mktemp(): \n\nhttp://docx.webperf.org/group__apr__file__io.html#ga50\n\nI assume this does the right thing on the various platforms. 
30385	Graham Leggett	1106489394000	apr_file_mktemp() opens a file, apr_global_mutex_create() needs a filename, not\nan actual file.\n\nIdeally apr_global_mutex_create() should be able to just accept NULL and\ninternally use apr_file_mktemp(), rather than insisting on a temp file name from\nthe calling application.\n\nRegards,\nGraham\n--
30385	Joe Orton	1106828949000	It actually does do precisely that in all the Unix implementations. \nAlternatively using a serverroot-relative filename\n'logs/<something-unique>.<pid>' should work as well.
30385	Joe Orton	1128447791000	Fixed in 2.1.x releases, probably not worth a backport.
30399	R??diger Pl??m	1091356659000	Hi,\n\nmeanwhile I wrote a patch to mod_cache / mod_disk_cache / mod_mem_cache that\nintroduces the new server config directive CacheStoreCookies. By default this\ndirective is set to 'On' thus leaving everything as it currently behaves\nin 2.0.50. Setting CacheStoreCookies to 'Off' prevents the Set-Cookie headers\nfrom being stored by the cache. This way I can configure the behaviour that\nI need in my special case.\n\nRegards\n\nR??diger Pl??m
30399	R??diger Pl??m	1091356731000	Created an attachment (id=12295)\nCacheStoreCookies Patch\n
30399	R??diger Pl??m	1092828527000	My patch has a little different implementation approach compared to the patch of\n23687. Also the patch for the documentation is currently missing. I will add\nthis when I find time or someone gets interested in my version of the patch.
30399	R??diger Pl??m	1096374264000	Created an attachment (id=12877)\nPatch against 2.0.51\n
30399	R??diger Pl??m	1097830525000	Created an attachment (id=13097)\nMore general approach patch against 2.0.52.\n
30399	R??diger Pl??m	1097830722000	After a discussion on the developer list the new patch has a more general\napproach and replaces the previous CacheStoreCookies directive with the more\ngeneral CacheIgnoreHeaders directive which allows to prevent arbitrary headers\nfrom being stored, not just cookies.
30399	Justin Erenkrantz	1100481018000	CacheIgnoreHeaders is now in 2.1 and will be incorporated in a future release.\n\nThanks!
30399	R??diger Pl??m	1110319248000	Created an attachment (id=14434)\nPatch against 2.0.53\n
30464	R??diger Pl??m	1091624943000	Created an attachment (id=12327)\nSolution proposal patch\n
30464	R??diger Pl??m	1093336077000	Currently my patch is missing the according patch of the mod_rewrite\ndocumentation. As my patch is a backport (even from the coding point of view as\nI compared my patch and an actual CVS snapshot of Apache 2.1) of the same\nfunctionality offered by Apache 2.1 I simply backported the according paragraph\nfor the Apache 2.1 documentation of mod_rewrite.xml. So the contents of the\ndocumentation patch I will attach has been written by one of the Apache 2.1\nmod_rewrite contributors / authors.
30464	R??diger Pl??m	1093336112000	Created an attachment (id=12515)\nDocumentation patch\n
30464	Joe Orton	1093340402000	Thanks for the patch.\n\nThis has been proposed for backport to 2.0.  It can't be done by including\nmod_ssl.h, since that fails if mod_ssl is not enabled in 2.0, so the optional\nfunction declarations have to be duplicated.
30464	Joe Orton	1093340578000	For references, the proposed patches are:\n\nhttp://www.apache.org/~jorton/mod_rewrite-2.0-sslvar.diff\nhttp://www.apache.org/~jorton/mod_ssl-2.0-ishttps.diff
30464	R??diger Pl??m	1093343563000	Thanks for the feedback and the references. You are right it is not possible to\ninclude mod_ssl.h in Apache 2.0 without enabling it via configure. I did not\nnotice that as I compile my Apache always with mod_ssl. So I included mod_ssl.h\nto avoid the duplication of the optional function declarations.\nIt is nice to hear that this feature should be backported to Apache 2.0. Do you\nalready know a release of Apache 2.0 in which this will be included?
30464	Joe Orton	1093346539000	The backport requires votes from two additional developers, so it depends when\npeople have time to review the changes.
30464	Joe Orton	1093615830000	Now committed for 2.0.51.
30464	R??diger Pl??m	1093616194000	Thats very good news. Thanks.
30487	Jeff Trawick	1091703613000	As far as we can tell, this problem is due to a bug in the native AIX compiler\nwhen building Apache at -O2.\n\nA special patch will resolve this; go to\nhttp://www.apache.org/~trawick/aixstatus.html and search for 'optimization problem'.\n\nPlease re-open if this patch does not resolve the problem.
30487	alexei bozrikov	1091705755000	Well, I've been reading about this as well (perl, for example, does not even \ncompile with '-O2', while it does with '-O2 -qstrict'). I have tried 'xlc_r -O' \nwith Apache as well to no avail, while 'cc_r' compiles equally well with '-O' \nand '-O2' and I could not see any difference in Apache behavior so far (at \nleast with PHP5/MySQL CGI scripts). To me looks more like a difference in set \nof default libraries to link with. \nMaybe this deserves to be put in some sort of README for Apache, since both AIX \n5.1 and C for AIX 6.0 are fairly recent products.\nAn excerpt from 'man xlc':\n[quote]\n-O        Optimize generated code.\n-O2       Same as -O.\n[unquote]\n\nActual 'httpd' binaries do not compare, when compiled with '-O' and '-O2'.\nMaybe IBM does not tell all the truth...\n\nregards\n\nAlexey
30487	Jeff Trawick	1091708349000	Yes, putting it in README.platforms is a good idea; I'll do that.
30487	alexei bozrikov	1091708946000	Yes, I have applied the 'optimize bug' patch, but I forgot to mention it in my \ninitial report, thanks for pointing it out. "Apache AIX status' document \nmentions 'xlc' as working (with '-O') when called as 'xlc_r' or 'xlC_r'. Seems \nthat in C for AIX V6.0 this behavior had changed and it is better to resort \nto 'cc_r'. I guess the case could be closed :-)\n\nAlexei
30487	Jeff Trawick	1094655513000	okay, I can verify that with xlc 5.0.2.5 I don't need the patch if I use CC=cc_r\nCFLAGS=-O2 but I do need the patch if I use CC=xlc_r CFLAGS=-O2\n\nthe difference in xlc_r and cc_r behavior can be seen in /etc/vac.cfg, which\nspecifies what libraries and other options are used based on the wrapper (CC)\n\nthe difference is in the default options\n  cc_r has -qlanglvl=extended,-qnoro,-qnoroconst\n xlc_r has -qansialias\n\nall other options, libraries, stubs, and library paths are the same\n\nI've updated README.platforms to point out\n  stable location of the server/core.c patch\n  xlc_r -O2 needs the patch\n  cc_r  -O2 doesn't need the patch\n\nThanks for your research on this topic!\n\n(I'll update my unofficial notes on AIX + Apache2 shortly.)
30585	Joe Orton	1092225437000	Thanks for the report.  Should we credit Ulf Harnhammar for the fix in the\nCHANGES file?
30585	Swedish IT Incident Centre	1092315984000	Please credit me/us as 'Ulf Harnhammar (SITIC)'.
30585	Joe Orton	1093292433000	Thanks for the patch; this has been committed to HEAD:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_kernel.c?r1=1.108&r2=1.109
30592	Graham Leggett	1098036645000	The URL handling follows the RFC for LDAP URL handling, and is controlled by the\nLDAP library being used - which may or may not allow what you describe.\n\nIn v2.1 of httpd, which now uses apr v1.0, the URL handling is no longer done by\nthe LDAP library, but by custom code in apr-util instead, making this possible.\n\nWill have to check RFC implications first though.\n
30592	Brad Nicholes	1098108053000	I have already been looking into this one.  The issue is that the URL_parse \nfunction assigns the port value to the first :port that it find in the URL.  \nIt uses that port in the ldap_init() call which becomes the default port for \nany host that does not also specify a port.  The solution is to always pass \nthe default ports (ie. 389 or 636) in the ldap_init() calls in apr_ldap_init\n().  This will cause the default ports to be used if the host does not specify \na port.  LDAP will do the right thing for any other host:port in the URL.
30592	Brad Nicholes	1098729666000	There are 2 patches for this bug, one in apr_ldap_url.c and the other in \nutil_ldap.c.  The parsing function in apr_ldap_url.c was assuming that the \nhost string would only contain a single host.  Therefore it truncated the host \nportion of the URL after the first :port that it found.  If the last host in \nthe URL also specified a :port, then it assumed that all hosts could be \nreachable on the same port.\n\nOnce this was fixed then util_ldap.c needed to call apr_ldap_init() always \nspecifying the default ports for LDAP and LDAPS.  If the host string also \nincludes ports, they will override any port specified in the port parameter. \n\nBoth of these fixes have been committed to HEAD and need to be backported.  
30592	Brad Nicholes	1098748496000	As Graham mentioned above, the ldap url parsing in 2.0 is handled by the LDAP \nlibraries.  ldap_parse_url() truncates the host list after the first host:port \nis found.  There appears to be some inconsistencies between the different \nSDK's with regards to this function.  To fix this issue in 2.0, at least the \nrecent patches to apr_ldap_url.c would have to be backported and all of the \nplatforms would have to use the apr version of ldap_parse_url() rather than \nthe LDAP library version.
30592	Graham Leggett	1106348876000	I am assuming that the patches have been applied. If not, please reopen this bug.\n
30723	Jeff Trawick	1092828387000	Thanks for your fix, and thanks for using Apache.\n\nI've committed the fix to Apache 2.1-dev and have also proposed that it be\nmerged into the next 2.0.x release.\n
30732	Nick Kew	1092867584000	I just checked a default Not Found (404) page.  It is valid HTML 2.0 (though\nonly by accident).\n\nEither it's a content negotiation issue (what language are you seeing pages in?)\nor you have misunderstood valid HTML.
30732	Andr?? Malo	1092868139000	I don't think it was by accident ;)
30732	Nick Kew	1092870725000	It is by accident.\n\nIt contains XHTML syntax <hr />.  That is an SGML abbreviated form that is valid\nonly due to a defect in the HTML specs (see for example\nhttp://valet.webthing.com/page/parsemode.html for explanation).  Any truly\ncompliant browser will display the closing '>' as text after the horizontal\nrule.  Since that is clearly not the intention, it is relying on tag-soup parsing.\n\nReplace that with HTML <hr> and it becomes valid without relying on SHORTTAGS.
30732	Andr?? Malo	1092894293000	Oh, this was modified by someone who didn't know better. *That* is the accident\n;-) (and a bug).
30732	Noah	1092909927000	A <hr /> tag is only valid in an XHTML document.\n\nIf the document is XHTML it should also technical be served with the correct\nMIME type 'text/application-xml' not 'text/html'. This however is the subject of\nmuch debate and it is generaly safer to leave it as 'text/html' untill browsers\nreliably know what to do with it.
30732	Andr?? Malo	1092913048000	As Nick already said, <hr /> *is* valid HTML (because of shorttags). But it's a\nbug though, since not intended to be there.
30732	Andr?? Malo	1095280150000	Fixed in 2.1 and proposed for backport.
30732	Graham Leggett	1095960706000	Backported to v2.0.\n
30919	Rici Lake	1093730640000	Created an attachment (id=12561)\npatch for mod_info (head)\n
30919	Paul Querna	1094178824000	A Patch based on the one here has been committed to CVS HEAD / 2.1.0.\n\nThanks for the Patch,\n\n-Paul Querna
30920	Joe Orton	1096540025000	Thanks for the report.  The fix has been checked in for the next 1.3 release:\n\nhttp://cvs.apache.org/viewcvs.cgi/apache-1.3/src/main/http_core.c?r1=1.337&r2=1.338\n
31036	Ulf Harnhammar	1094227302000	This also affects Apache 1.3.x.\n\n// Ulf Harnhammar\n
31036	Andr?? Malo	1094244883000	Thanks Folks.\n\nWe've created other patches based on the 2.1 code, which don't cut the value\nstring. It would be nice, if you could review/test them.\n\nI've uploaded the diffs here:\n\nhttp://www.apache.org/~nd/dbmmap_1.3.patch\nhttp://www.apache.org/~nd/dbmmap_2.0.patch
31036	Ulf Harnhammar	1094483305000	I have reviewed and tested your patches, and I didn't find any problems with \nthem.\n\n// Ulf Harnhammar (SITIC)\n
31036	Joe Orton	1095067274000	If this code is supposed to be robust against arbitrary values of dbmval.dsize\nthe this:\n\n  apr_pstrmemdup(r->pool, dbmval.dptr, dbmval.dsize);\n\nstill doesn't seem like a good idea.  But I don't know how much validation the\nparticular apr_dbm implementations will give you on .dsize.
31036	Andr?? Malo	1095068195000	Hmm, I don't understand ... why?
31036	Joe Orton	1095068894000	See how the pstrmemdup implementation behaves if passed in n=ULONG_MAX.  But\nregardless.\n
31036	Andr?? Malo	1095070122000	only if apr_size_t == ulong.\nGood question... I think, much of our code relies on apr_size_t being big enough.
31036	Graham Leggett	1097686501000	The fix at http://www.apache.org/~nd/dbmmap_2.0.patch got 4 votes for backport\nto v2.0.53, and the backport has been committed.\n\nHas this fix been applied to v2.1?\n
31036	Andr?? Malo	1097688227000	It's *taken* from 2.1 ;-)
31036	Graham Leggett	1097689392000	Cool :) Didn't see a link in STATUS to the commit though, only an external link\nto the patch - just making sure :)\n
31036	Graham Leggett	1097691984000	Patch already applied to v1.3. Closing and marking as fixed.\n
31083	Joe Orton	1095871006000	Thanks for the report.  Fixed as you suggest:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/ssl/ssl_engine_io.c?r1=1.126&r2=1.127\n
31128	Edward Rudd	1098058084000	Yup I am encoutering this bug too in 2.0.52..\n\nThe issue is in ap_cache_providers_list when it iterates through the 'disabled'\nurls, all the urllen's are 0 in line 86 of cache_control.c.\n\nThey are set correclt when tehy are assigned in the the command handler..
31128	Edward Rudd	1098060556000	Created an attachment (id=13129)\nPatch to fix the issue\n
31128	Paul Querna	1098061017000	Patch applied to CVS Head.
31128	Graham Leggett	1098539175000	Patch backported to httpd v2.0.53.\n
31128	Paul Querna	1104203491000	*** Bug 32849 has been marked as a duplicate of this bug. ***
31183	Julian Reschke	1095010583000	Created an attachment (id=12710)\ntest case (needs JScript/Windows; but can easily rewritten for other environments)\n
31183	Joe Orton	1095019606000	Is it crashing using all three If headers formats? I couldn't reproduce from a\nquick test here (on Unix).  Can you get a backtrace out of the server?
31183	Julian Reschke	1095019895000	Yes, all of them, it seems.\n\nHow do I get the backtrace?
31183	Joe Orton	1095020709000	Never mind, I've reproduced it.  \n\nIt's a NULL pointer dereference in fs/lock.c:\n\n\t    /* the lock was refreshed. return the lock. */\n\t    newlock = dav_fs_alloc_lock(lockdb, ip->key, dp->locktoken);\n\t    newlock->is_locknull = !resource->exists;\n\ndp is NULL at time of invocation.
31183	Joe Orton	1095028104000	Thanks for the report, Julian.  This is what I committed:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/modules/dav/fs/lock.c?r1=1.32&r2=1.33\n\nif you could re-run your tests with that patch applied that would be great.  It\npasses the litmus test I added.
31183	Joe Orton	1095756601000	This is fixed in 2.0.51, thanks again.
31183	CELL	1190072097000	(In reply to comment #0)\n> Sending a LOCK refresh request to an indirectly locked resource crashes the \nserver.\n> Steps to reproduce:\n> MKCOL x\n> PUT x/y\n> LOCK x\n> try to refresh the lock through x/y, so\n> LOCK x/y\n> (Test case will be attached separately).\n\n
31226	Nick Kew	1095247435000	AddOutputFilterbyType is known to be broken.  Use mod_filter instead:\nhttp://httpd.apache.org/docs-2.1/mod/mod_filter.html\n
31226	frederic bregier	1095250925000	Thank you for your note on the broken AddOutputFilterByType.\nI read the manual page of mod_filter.\nFirst, it is only valid with Apache 2.1. \nIs it enough stable for this use (reverse proxy and deflate) for production ?\n\nSecond, I try to think what could be the syntax of the filter.\n\nFilterDeclare compressed Content-Type\nFilterProvider compressed deflate $text/html\n# is it deflate or mod_deflate ?\nFilterProvider compressed deflate $text/plain\nFilterProtocol compressed 'change=yes'\n<Location /application>\nFilterChain compressed\n</Location> \n\nBut I miss a point. What about the proxy definition ?\nIs the proxy (proxypass and reverse) applied before this filter,\nor should I make another Filter with the final filterchain as\nFilterChain proxyfied compressed ?\nTherefore, how can I specify the directives for this filter \n(proxypass and reverse) ?\nWhat about special mod_deflate directives (deflatecompressionlevel for \ninstance) ?\n\nAlso there is the registering of the modules with ap_register_output_filter.\nIs is done with all standard modules and with what names ?\n(for mod_proxy, mod_deflate ?)\n\nI know now this module is new, so I can understand that the manual is not \ncompleted.\nThank you again
31226	Nick Kew	1095254553000	This is not really a support forum.  Please direct support questions somewhere\nmore appropriate, such as the apache-users mailinglist or a suitable webservers\nnewsgroup.\n\nBut in brief,\n (1) it works fine with 2.0\n (2) your filter syntax looks fine to me\n (3) It doesn't affect your proxy setup or your mod_deflate directives.  Stop\nlooking for complexity where there is none!
31226	frederic bregier	1095336704000	Thank you for this help.\nFor everyone having the same problem and looking in this bug,\nI place the solution that works for me.\nWith standard proxy and deflate directives, I placed the following\n\nFilterDeclare compressed Content-Type\nFilterProvider compressed deflate $text/html\nFilterProvider compressed deflate $text/plain\nFilterProvider compressed deflate $text/css\n#FilterProtocol compressed deflate 'change=yes'\nFilterChain compressed\n\nI had to download spcifically the mod_filter.c through\nyour web page, Nick (http://www.apache.org/~niq/)\nsince it is not in Apache sources (neither 2.0 or 2.1).\nI understand since the first release is of august 2004.\n\nI comment FilterProtocol since it produces an error\nin apache ('FilterProtocol: No such filter').\nI try with and without 'deflate'.\n\nWell, at this time, it seems to work as intended.\nSince it is a quite new module, I have to test it intensively\nsince it is for production later on.\n\nThank you ! Bug closed !\n\n
31226	Nick Kew	1129890515000	*** Bug 14335 has been marked as a duplicate of this bug. ***
31226	Ruediger Pluem	1129894782000	(In reply to comment #1)\n> AddOutputFilterbyType is known to be broken.  Use mod_filter instead:\n\nThe question to me is: Why is it broken? While having a look a PR14335 I found\nout that the reason for this 'brokenness' seems to be the following lines from\nap_add_output_filters_by_type in core.c:\n\n    /* We can't do anything with proxy requests, no content-types or if\n     * we don't have a filter configured.\n     */\n    if (r->proxyreq != PROXYREQ_NONE || !r->content_type ||\n        !conf->ct_output_filters) {\n        return;\n    }\n\nDoes anybody remember the reason why we cannot do anything on proxied resources?\nThis change had been made in r94028 about 3,5 years ago by Bill Stoddard.\n
31226	Ruediger Pluem	1129895189000	(In reply to comment #4)\n\n[..cut..]\n\n> I had to download spcifically the mod_filter.c through\n> your web page, Nick (http://www.apache.org/~niq/)\n> since it is not in Apache sources (neither 2.0 or 2.1).\n\nIt is part of httpd 2.1 and was protmoted from its experimental state to be a\nregular module a while ago. The configure switch for mod_filter is --enable-filter.\n\n[..cut..]
31226	Joe Orton	1129898104000	I looked at that a while back and nobody could work out why the check is there\neither.  If the check was removed basic things seem to work fine.\n\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200409.mbox/%3c20040916161122.GA16320@redhat.com%3e\n\nremoving it in 2.2/trunk and seeing what breaks seems reasonable.
31226	Ruediger Pluem	1129909939000	I just committed Joe's patch to the trunk (r327179):\nhttp://svn.apache.org/viewcvs.cgi/httpd/httpd/trunk/server/core.c?rev=327179&r1=306495&r2=327179\nIt fixes the problem.
31226	Ruediger Pluem	1130084487000	Commited to 2.2.x branch (r327793):\nhttp://svn.apache.org/viewcvs.cgi/httpd/httpd/branches/2.2.x/server/core.c?rev=327793&r1=307031&r2=327793
31226	Joe Orton	1165823132000	*** Bug 41146 has been marked as a duplicate of this bug. ***
31226	Bill McGonigle	1165831193000	Created an attachment (id=19243)\npatch against 2.0.54\n\nadding patch here per Joe Orton on bug 41146.\n\nAs noted there, this patch has been applied to a production 2.0.54 server\n(fedora core 4) which has served about 14 million deflated pages through the\nproxy without problems.\n
31247	Joe Orton	1095264671000	Do you have CGI script which output a lot of data? The byterange filter will\nconsume memory proportional to output for such scripts, bug 29962.\n\nFrom gdb can you:\n\nprint *b\nprint *(struct cgi_bucket_data *)b->data\n\nif you do:\n\nup\nup\nprint *f->r\n\nyou should be able to see which particular CGI script has triggered the segfault.
31247	Tyler	1095270740000	Output from print *b:\n\n$1 = {link = {next = 0x8311a10, prev = 0x8311d80}, type = 0x40855520,\n  length = 4294967295, start = -1, data = 0x8327440,\n  free = 0x805ea74 <apr_bucket_free>, list = 0x8311720}\n\nOutput from print *(struct cgi_bucket_data *)b->data:\n\n$2 = {pollset = 0x8327448, r = 0x8321968}\n\nThanks for the tip on identifying which script was being run, it turns out it\ndied in an index.html file that uses SSI to include output from two different\nCGI scripts.  However, that page is not seg faulting everytime it is visited. \nAlso it died before the server created a log of the request.
31247	Joe Orton	1095278369000	Thanks.  Can you also do 'print *((struct cgi_bucket_data *)b->data)->r' from\nthat same scope?  May be significant about SSI being involved, I'll try and\nreproduce like that.
31247	Tyler	1095356949000	print *((struct cgi_bucket_data *)b->data)->r:\n\n$1 = {pool = 0x746e6574, connection = 0x7079542d, server = 0x74203a65,\n  next = 0x2f747865, prev = 0x6c6d7468, main = 0x6863203b,\n  the_request = 0x65737261 <Address 0x65737261 out of bounds>,\n  assbackwards = 1397308788, proxyreq = 943205711, header_only = 825047349,\n  protocol = 0xa0d0a0d <Address 0xa0d0a0d out of bounds>,\n  proto_num = 1735223612,\n  hostname = 0x63727320 <Address 0x63727320 out of bounds>,\n  request_time = 7306916042975945277,\n  status_line = 0x656e2f73 <Address 0x656e2f73 out of bounds>,\n  status = 1869573239, method = 0x65662f6b <Address 0x65662f6b out of bounds>,\n  method_number = 1920300129, allowed = 3275079475987754341,\n  allowed_xmethods = 0x64616568, allowed_methods = 0x672e7265,\n  sent_bodyct = 539125353, bytes_sent = 1685221218,\n  mtime = 738064979063566949, chunked = 1768176650,\n  range = 0x6c632076 <Address 0x6c632076 out of bounds>, clength = 1030976353,\n  remaining = 1634035234, read_length = 1852402804, read_body = 171844203,\n  read_chunked = 1746952508, expecting_100 = 1030120818,\n  headers_in = 0x74746822, headers_out = 0x2f2f3a70,\n  err_headers_out = 0x2e777777, subprocess_env = 0x656d6f68,\n  notes = 0x6b726f77,\n  content_type = 0x2e737265 <Address 0x2e737265 out of bounds>,\n  handler = 0x2f67726f <Address 0x2f67726f out of bounds>,\n  content_encoding = 0x2d696763 <Address 0x2d696763 out of bounds>,\n  content_languages = 0x2f6e6962,\n  vlist_validator = 0x72616573 <Address 0x72616573 out of bounds>,\n  user = 0x672f6863 <Address 0x672f6863 out of bounds>,\n  ap_auth_type = 0x67632e6f <Address 0x67632e6f out of bounds>,\n  no_cache = 1031094121, no_local_copy = 1986290532,\n  unparsed_uri = 0x69666f66 <Address 0x69666f66 out of bounds>,\n  uri = 0x76646f64 <Address 0x76646f64 out of bounds>,\n  filename = 0x61686366 <Address 0x61686366 out of bounds>,\n  canonical_filename = 0x6e7a647a <Address 0x6e7a647a out of bounds>,\n  path_info = 0x70666666 <Address 0x70666666 out of bounds>,\n  args = 0x70666866 <Address 0x70666866 out of bounds>, finfo = {\n    pool = 0x643d6b26, valid = 1718576225, protection = 645097064,\n    filetype = 1030517365, user = 1868981862, group = 2036752742,\n    inode = 1835427939, device = 7600496621405104228, nlink = 2053339491,\n    size = 1852072292, csize = 2054712934, atime = 8753443414512138598,\n    mtime = 8747250956752020324, ctime = 7018993500102620004,\n    fname = 0x787a6968 <Address 0x787a6968 out of bounds>,\n    name = 0x68637066 <Address 0x68637066 out of bounds>,\n    filehand = 0x73646166}, parsed_uri = {\n    scheme = 0x68786664 <Address 0x68786664 out of bounds>,\n    hostinfo = 0x76616963 <Address 0x76616963 out of bounds>,\n    user = 0x6b7a787a <Address 0x6b7a787a out of bounds>,\n    password = 0x6b647864 <Address 0x6b647864 out of bounds>,\n    hostname = 0x633d6226 <Address 0x633d6226 out of bounds>,\n    port_str = 0x636b787a <Address 0x636b787a out of bounds>,\n    path = 0x26706368 <Address 0x26706368 out of bounds>,\n    query = 0x74263d61 <Address 0x74263d61 out of bounds>,\n    fragment = 0x7861633d <Address 0x7861633d out of bounds>,\n    hostent = 0x636d786e, port = 25455, is_initialized = 1, dns_looked_up = 1,\n    dns_resolved = 1}, used_path_info = 1633908846,\n  per_dir_config = 0x617a6170, request_config = 0x573e226e,\n  htaccess = 0x646c756f, output_filters = 0x756f7920,\n  input_filters = 0x766f4c20, proto_output_filters = 0x6f742065,\n  proto_input_filters = 0x726f5720, eos_sent = 1919295595}\n
31247	Joe Orton	1095778207000	Can you give a condensed example of the SSI page which did trigger this?  Just\nto confirm, you are using an unpatched 2.0.50 built directly from source?\n\nThe backtrace is actually quite confusing.  It references functions from the new\nCGI bucket type, but these are only actually used by the CGI handler, not when\nan SSI page invokes CGI scripts directly, so they shouldn't be in the picture at\nall.\n\n
31247	Tyler	1095862265000	Some updates/corrections:\n\n1) Yes, it's been compiled from source, without any patches.\n\n2) There are two separate cgi scripts on our index page, one does banner\nrotation for a banner, it is included four times (once each for 4 banners), the\nother creates a list of links based on the amount bid for placement, it's\nincluded twice.  The first script uses a text file db, while the second script\nuses MySQL.  Both are included with virtual includes.  Here's a sample of one of\nthe sections with the includes (I can't give you the scripts themselves, they\nwere purchased from someone else).\n\n<!--#include virtual='/cgi-bin/ads/run.cgi?id=homeworkersa2'-->\n<!-- homeworkersa2 -->\n</CENTER>\n<!--#include\nvirtual='/cgi-bin/search/include.cgi?keywords=main&desc=1&url=1&cost=1&show=1&include=1'\n-->\n<CENTER>\n<!--#include virtual='/cgi-bin/ads/run.cgi?id=homeworkersa3'-->\n<IMG SRC='/images/spacer.gif' WIDTH='160' HEIGHT='5'>\n<!--#include virtual='/cgi-bin/ads/run.cgi?id=homeworkersa4'-->\n<!-- homeworkersa4 -->\n</CENTER>\n\n<hr class='green'>\n\n<!--#include\nvirtual='/cgi-bin/search/include.cgi?keywords=main&start=1&bt=10&desc=1&url=1&cost=1&show=9&include=1'\n-->\n\n3) I tried the advice in bug 29962, it didn't help at all.  I'm still getting\nprocesses that bloat up to a huge size and I don't think it's related to sending\nlarge files through the server.  We only have a two scripts that I know of that\nsend out large files and neither one appears to be accessed as often as these\nprocesses appear (I often have to restart apache multiple times during the day,\nit take as little as 5 minutes or as long as several hours to nearly exhaust all\navailable memory).\n\n4) We've upgraded to 2.0.51 as of this morning, I'm still seeing the memory\nproblem and the segmentation faults.  I'm going to attempt to create another\ncore dump with the new httpd.
31247	Joe Orton	1095865137000	Created an attachment (id=12835)\npossible fix\n
31247	Joe Orton	1095865269000	OK, I think I see what's happening, but I haven't got a reproduction case, so\ntesting with the above patch would be good.
31247	Tyler	1096040762000	I've applied the patch but I'm still getting Segmentation Faults and the memory\ngrowth, and I haven't been able to produce a core dump to examine yet.
31247	Joe Orton	1096216445000	The patch committed which fixes the issue triggered in the given segfault was:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/util_filter.c?r1=1.100&r2=1.101\n\nso if you could try that and still get more segfaults, please try and get new\ncore dumps.  (Please open a new bug for any new issues)\n\nThanks for the report and debugging help.
31247	Tyler	1096313051000	It looks like the fix has worked, I don't seem to be able to generate any more\ncore files, and the number of segmentation faults has dropped significantly. \nInstead of 6-10 per day, we seem to now be averaging 1 a day (probably on an\nunrelated issue).
31247	Joe Orton	1096388956000	Thanks Tyler.
31247	Tyler	1096397917000	Actually, I think I should be thanking you for the quick fix.  :)
31268	Daniel Rench	1095364082000	Created an attachment (id=12753)\npatch to add hostname override option to ab\n
31268	Paul Querna	1095396559000	This seems invalid to me.\n\nWe can send the Host: Header as part of the address... but specifying it again\nwith a special flag just seems wrong.
31268	Jeff Trawick	1095423377000	I've had to add same feature (host to connect to != host in Host request header\nfield) to specialized testing clients so that I could do some automated vhost\ntesting without hacking the system.\n\nAny other opinions from the crowd?
31268	Daniel Rench	1095437965000	I also considered doing something along the lines of the enhancement request\n#26554 method for overriding the 'User-Agent:' header. Maybe a better way?
31268	Paul Querna	1095438263000	hmm. Yes, I would condier a generic method to set any Header in a Key = Value\nFormat to be better than specific methods for each header.
31268	Arvind Srinivasan	1170728892000	Created an attachment (id=19526)\nPatch to override headers using the existing -H option\n\nHave attached a patch using which one can override the value of the Host,\nUser-Agent and/or Accept header that ab tacks onto requests, by specifying an\nalternate value for the header using the existing -H option.
31268	Sander Temme	1170750953000	-1 on implementation, but +1 on concept. Arvind, I think your solution is pretty elegant, and am in \nfavor of using the existing -H option to override the headers in question. However, you are no longer \nsending the Accept: and User-Agent headers to POST Requests when they are not overridden. \n\nAlso, the logic regarding the overridable headers in the if (posting <= 0) block is hard to read because \nof the inversion (only print the headers when their opt_foo is NOT set). Perhaps you can pull the part \nwhere you construct these headers outside the if (posting <= 0) block (bonus: you avoid duplicating \nthe logic), use proper if () statements instead of the ? operator and put a comment on both branches of \nthe if() to tell the reader what is going on like /* Header not overridden, print default */ and /* Header \noverridden, no need to send because it is already in the hdrs string */. \n\nWould you like to fix the above and resubmit?
31268	Arvind Srinivasan	1170794352000	\nThanks for your feedback. I'll address the issues you've pointed out and resubmit.
31268	Arvind Srinivasan	1170813960000	Created an attachment (id=19535)\nRevised patch to override headers using the existing -H option\n\nThe attached patch address the following issues that were identified with the\nprevious revision of this patch:\n* POST requests send an Accept: and User-Agent: header when they are not\noverridden\n* Logic regarding the overrideable headers has been pulled outside the if\n(posting <= 0) block\n* Uses if () statements (with appropriate comments) instead of the ? operator
31268	Sander Temme	1172791361000	+1 to Arvind's revised patch. 
31268	Arvind Srinivasan	1174026764000	Thanks for reviewing the patch Sander.\n\nThe patch also fixes http://issues.apache.org/bugzilla/show_bug.cgi?id=26554
31268	Sander Temme	1176119540000	Committed in r526872. Thanks Arvind for your patch. 
31431	Graham Leggett	1096822229000	Fixed in HEAD, waiting for backport to v2.0.
31431	Graham Leggett	1097683857000	Backported to v2.0.53.\n
31440	Andreas Krennmair	1096310925000	Created an attachment (id=12871)\nfix to the htpasswd salt generation weakness\n
31440	Andreas Krennmair	1096310991000	This attached patch would lead to a more random MD5 salt:\n\n$ ./htpasswd -m -c /tmp/htpasswdtest2 b\nNew password: \nRe-type new password: \nAdding password for user b\n$ cat /tmp/htpasswdtest2\nb:$apr1$iOJN8Jax$rQLDvG0ALByOBtHgN2wk7/\n$
31440	Peter Watkins	1201255834000	Created an attachment (id=21429)\npatch against httpd-2.2.8 to resolve weak PRNG seeding\n\nAndreas, I think you're on the right track, but your patch only adds the\nappearance of greater randomness. The core problem here is poor seeding of the\nPRNG. Every salted output from htpasswd starts with using time() to feed\nsrand(). Even with your patch, htpasswd will always use the same seed at the\nany given time.\n\nThe most important thing that needs to change is the calls to srand(). Here's a\npatch that keeps your nice 48-bit padding and adds better seeding. If the user\nsets a RANDOM_SEED environment variable, htpasswd will use that file/device. If\nnot, it will try to use /dev/urandom. If it cannot use /dev/urandom or the user\nprovides an unusable file/device name, it will fall back to using time() but\nwill print a warning to STDERR. Also (untested!) if the user is on a platform\nwith 32-bit integers, htpasswd will re-seed the PRNG as needed, to improve the\nchances of a true 48-bit salt.\n\n-Peter\n
31440	Peter Watkins	1201291016000	Created an attachment (id=21433)\npatch for httpd 1.3.39\n\nsame idea, but for the 1.3.x codebase
31440	Andreas Krennmair	1201446309000	> Andreas, I think you're on the right track, but your patch only adds the\n> appearance of greater randomness. The core problem here is poor seeding of the\n> PRNG. Every salted output from htpasswd starts with using time() to feed\n> srand(). Even with your patch, htpasswd will always use the same seed at the\n> any given time.\n\nThis is not a matter of randomness (or at least that was not my point), it's a\nmatter of how the salt of the hash looks like. With the old method (which I\nfixed with my patch from 2004), an attacker could base a precomputation attack\non the assumption that the salt only has 32 bits, even though the format would\nallow up to 48 bits of salt. \n\nOf course, even with 32 bits of salt, a precomputation still seems quite\ninfeasible, but it still doesn't exhaust the possible maximum of 48 bits of salt\n(which obviously must have been in the mind of the original authors, otherwise\nthey would have spread the 32 bits of rand() to 6 bytes instead of 8 bytes). And\nthat was the original point of my patch.
31440	Peter Watkins	1201520764000	Any attacker who has the same PRNG as the system where htpasswd runs would be\nfoolish to blindly precompute even a 32 bit apr1 dictionary. 32 bits of time()\nrepresents 136 years worth of htpasswd execution with the current srand() code.\nIn a given month, there are less than 22 bits worth of salt when using\nsrand(time(NULL)), 17 bits in a day, 12 bits in an hour, 6 bits in a minute, 0\nin a second. 29 bits is all it takes to stretch back to the beginning of Apache,\nbefore the apr1 MD5 algorithm appeared in 1.3.6 -- even with your improvement. \n\nTo 'fix' htpasswd so it takes full advantage of the apr1 spec's 48 bits of salt,\nit is necessary to fix the srand() problem, too. With your generate_salt() and\nmy seed_prng(), htpasswd finally produces nicely random 48-bit salts for apr1.\n\n
31440	Andreas Krennmair	1201521590000	You are right, I stand corrected. Now if only somebody could apply the patches\nto SVN trunk...
31440	Paul Querna	1203409704000	Using generate_salt instead of to64 makes sense.....\n\nThe second patch to use better PRNG seeding, we should just use the APR APIs for randomness, apr_generate_random_bytes:\nhttp://apr.apache.org/docs/apr/1.2/group__apr__random.html
31440	Paul Querna	1203412158000	Committed improved salt string generation in r629159:\nhttp://svn.apache.org/viewvc?view=rev&revision=629159\n\nCommitted improved rand seed generation in r629164:\nhttp://svn.apache.org/viewvc?view=rev&revision=629164\n\n
31448	Joe Orton	1096377158000	Thanks for the report.  Can you try this patch for apxs.in:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/support/apxs.in?r1=1.62&r2=1.63\n
31448	Alfred Perlstein	1096379050000	Thank you for the quick turnaround... This fixed passing CFLAGS, but now it's\ntrying to link the module standalone and barfing:\n\n~/work/tourserve/itour2 % make all    \n/usr/local/apache2/bin/apxs -c  -Wc,-O -Wc,-pipe -Wc,-g\n-Wc,-I/usr/home/bright/work/tourserve/itour2/../include -Wc,-I/usr/local/include\n-Wc,-I/usr/home/bright/work/tourserve/itour2/../keys -Wc,-Wall\n-Wc,-Wno-format-y2k -Wc,-W -Wc,-Wmissing-prototypes -Wc,-Wpointer-arith\n-Wc,-Wreturn-type -Wc,-Wcast-qual -Wc,-Wwrite-strings -Wc,-Wswitch\n-Wc,-Wcast-align -Wc,-Wno-uninitialized -Wc,-Werror\n-Wc,-I/usr/local/apache2/include -Wc,-DAPACHE_2 -Wc,-I../libfetch -Wc,-g\n-Wc,-I/usr/home/bright/work/tourserve/itour2/../include -Wc,-I/usr/local/include\n-Wc,-I/usr/home/bright/work/tourserve/itour2/../keys  -Wl,-L/usr/local/lib\n-Wl,-L../libfetch -Wl,-L/usr/local/lib -Wl,../libfetch/libfetch.a -o\nmod_itour.so ../itour//mod_itour.c\n/usr/local/apache2/build/libtool --silent --mode=compile gcc -prefer-pic \n-DAP_HAVE_DESIGNATED_INITIALIZER -D_REENTRANT -D_THREAD_SAFE -g -O2\n-I/usr/local/apache2/include  -I/usr/local/apache2/include  \n-I/usr/local/apache2/include -I/usr/local/include -O -pipe -g\n-I/usr/home/bright/work/tourserve/itour2/../include -I/usr/local/include\n-I/usr/home/bright/work/tourserve/itour2/../keys -Wall -Wno-format-y2k -W\n-Wmissing-prototypes -Wpointer-arith -Wreturn-type -Wcast-qual -Wwrite-strings\n-Wswitch -Wcast-align -Wno-uninitialized -Werror -I/usr/local/apache2/include\n-DAPACHE_2 -I../libfetch -g -I/usr/home/bright/work/tourserve/itour2/../include\n-I/usr/local/include -I/usr/home/bright/work/tourserve/itour2/../keys  -c -o\n../itour//mod_itour.lo ../itour//mod_itour.c && touch ../itour//mod_itour.slo\n/usr/local/apache2/build/libtool --silent --mode=link gcc -o mod_itour.so\n-L/usr/local/lib -L../libfetch -L/usr/local/lib ../libfetch/libfetch.a  -rpath\n/usr/local/apache2/modules -module -avoid-version    ../itour//mod_itour.lo\n/usr/lib/crt1.o(.text+0x81): In function "_start':\n: undefined reference to "main'\n../itour//mod_itour.o(.text+0x494): In function "create_server_config':\n../itour//mod_itour.c:254: undefined reference to "apr_palloc'\n../itour//mod_itour.o(.text+0x4b3):../itour//mod_itour.c:259: undefined\nreference to "ap_add_version_component'\n../itour//mod_itour.o(.text+0x4d5):../itour//mod_itour.c:260: undefined\nreference to "ap_log_error'\n../itour//mod_itour.o(.text+0x515): In function "itour_conf_master':\n../itour//mod_itour.c:275: undefined reference to "apr_pstrdup'\n../itour//mod_itour.o(.text+0x53c):../itour//mod_itour.c:276: undefined\nreference to "ap_log_error'\n../itour//mod_itour.o(.text+0x5ad): In function "itour_conf_timeout':\n../itour//mod_itour.c:291: undefined reference to "ap_log_error'\n../itour//mod_itour.o(.text+0x664): In function "itour_dbadd':\n../itour//mod_itour.c:363: undefined reference to "ap_log_error'\n../itour//mod_itour.o(.text+0x6dc): In function "itour_dbcheck':\n../itour//mod_itour.c:386: undefined reference to "ap_log_error'\n../itour//mod_itour.o(.text+0x701):../itour//mod_itour.c:392: undefined\nreference to "apr_psprintf'\n../itour//mod_itour.o(.text+0x754):../itour//mod_itour.c:397: undefined\nreference to "ap_log_error'\n../itour//mod_itour.o(.text+0x7b1):../itour//mod_itour.c:404: undefined\nreference to "ap_log_error'\n../itour//mod_itour.o(.text+0x7e8):../itour//mod_itour.c:408: undefined\nreference to "ap_log_error'\n../itour//mod_itour.o(.text+0x83b):../itour//mod_itour.c:416: undefined\nreference to "ap_log_error'\n../itour//mod_itour.o(.text+0x866):../itour//mod_itour.c:421: undefined\nreference to "apr_table_set'\n../itour//mod_itour.o(.text+0x898):../itour//mod_itour.c:426: undefined\nreference to "ap_rprintf'\n../itour//mod_itour.o(.text+0x8e9): In function "itour_remotequery':\n../itour//mod_itour.c:437: undefined reference to "ap_log_error'\n../itour//mod_itour.o(.text+0x984):../itour//mod_itour.c:458: undefined\nreference to "apr_table_set'\n../itour//mod_itour.o(.text+0x9a3):../itour//mod_itour.c:462: undefined\nreference to "ap_rprintf'\n../itour//mod_itour.o(.text+0x9e5): In function "itour_status_handler':\n../itour//mod_itour.c:470: undefined reference to "ap_log_error'\n../itour//mod_itour.o(.text+0xa75): In function "itour_register_hooks':\n../itour//mod_itour.c:537: undefined reference to "ap_hook_handler'\ncollect2: ld returned 1 exit status\napxs:Error: Command failed with rc=65536\n.\n*** Error code 1\n\nNote this is a FreeBSD 6.0 box.
31448	Joe Orton	1096379781000	If you must pass an '-o' option to apxs, it must be like '-o mod_foo.la'\notherwise you'll confuse libtool.  Can you try that?\n
31448	Joe Orton	1096382223000	I fixed apxs to handle '-o mod_foo.so' correctly too:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/support/apxs.in?r1=1.63&r2=1.64\n\nThese changes will be proposed for backport for a future 2.0.x release.  You\ndon't have to escape -I and -D options using '-Wc,-I', by the way, apxs\nunderstands those already.
31448	Alfred Perlstein	1096383021000	Well, here's the problem with that... :)\n\nI'm actually compiling in a seperate directory and using the VPATH/PATH\nfeature of make to locate my sources.  Even if I manually specify the source\nfile as ../itour/mod_itour.c apxs and libtool conspire to dump files out into\n../itour/ instead of the current working directory.\n\nAlso... why do I need to say '-o mod_so.la'?  What I really want is 'mod_so.so'.\n\nThis won't work for me.\n\nBasically:\n\nI have:\ntourserve/itour - sources + Apache13 makefile\ntourserve/itour2 - Apache2 makefile\n\nThe apache2 makefile just overrides a couple of knobs and includes the apache13\nmakefile.  But for some reason apxs decides to dump files into my source\ndirectories instead of my current directory.\n\nHere's a fix that prevents it, but only if you give a -o option to apxs, I\nhaven't figured out how to fix it without -o.\n\nBasically this patch just removes any leading pathnames from the source files\nwhen making the object file names:\n\n--- apxs.in     Mon Feb  9 12:59:49 2004\n+++ apxs.new    Tue Sep 28 07:47:18 2004\n@@ -400,13 +400,15 @@\n     my $s;\n     my $mod;\n     foreach $s (@srcs) {\n-        my $slo = $s;\n+        my $ss = $s;\n+        $ss =~ s|.*/||;\n+        my $slo = $ss;\n         $slo =~ s|/.c$|.slo|;\n-        my $lo = $s;\n+        my $lo = $ss;\n         $lo =~ s|/.c$|.lo|;\n-        my $la = $s;\n+        my $la = $ss;\n         $la =~ s|/.c$|.la|;\n-        my $o = $s;\n+        my $o = $ss;\n         $o =~ s|/.c$|.o|;\n         push(@cmds, '$libtool $ltflags --mode=compile $CFG_CC $cflags -I$CFG_IN\nCLUDEDIR $apr_includedir $apu_includedir $opt -c -o $lo $s && touch $slo');\n         unshift(@objs, $lo);\n@@ -419,12 +421,9 @@\n\n\nAlso, why do I need a '-o mod_foo.la', all i really want is 'mod_foo.o', can't\nthat be fixed?
31448	Alfred Perlstein	1096383455000	Created an attachment (id=12885)\nfix for object files being created in source dirs.\n
31448	Alfred Perlstein	1096383520000	Ok, I fixed it!\n\nThis should be applied, what it does it strip the leading pathnames from derived\nsources so that object files don't wind up in source directories:\n\nThe diff is attached.\n\nhttp://issues.apache.org/bugzilla/showattachment.cgi?attach_id=12885\n\n\n
31448	Joe Orton	1096388857000	WONTFIX to that: VPATH builds are complicated and apxs is supposed to be a\nsimple build tool.  If you want to do a VPATH build then you could symlink the\nsources across and then apxs should work OK.  The .so vs .la thing is fixed per\nmy comment above, too.\n\nThanks for the report.
31448	Joe Orton	1096388920000	(or use a proper Makefile as per the example created by 'apxs -g', that should\nwork with VPATH builds or could be fixed to, at least)
31448	Graham Leggett	1098541862000	http://cvs.apache.org/viewcvs.cgi/httpd-2.0/support/apxs.in?r1=1.62&r2=1.64\ncommitted to httpd v2.0.53.
31472	Jack Repenning	1096487385000	Created an attachment (id=12897)\npatch for magic file docs/conf/magic\n
31472	Jack Repenning	1097003438000	Oops, sorry wrong URL.  The sample 'moov' file is\nhttp://www.repenning.homeip.net/file_14.mov\n\nThere's nothing special about it, though: any QTime movie file will do.\n\n
31472	Jack Repenning	1097005207000	Note that there's also some evidence that this typo affects other file types.  \n\nThat is: there's only one typo, the one for files of type 'moov'.  But it affects parsing of the magic \nfile: mod_mime_magic croaks--really, before it's read the entry, and hence it's not reacting \nspecifically to the fact that the file being touched is 'moov', but rather to the fact that it's not any \nof the *other* types named earlier in the file.  So something amounting to the same problem arises \nfor any file of any type that's completely unknown to the magic file (the reported case is Stuffit! \narchives, which are not described anywhere in the magic file).  \n\nReproducing the false behavior in these cases is harder, I can't provide you a complete recipe: \nthese cases produce the same error_log output as the 'moov', but since they're not described at all, \nthe resulting behavior is not so far from correct.  In our case, we're also providing a .htaccess file \nfor these, which includes MIME info, and the croak in mod_mime_magic seems to mean that \n.htaccess is never consulted, and hence we're not getting the right behavior from these other file \ntypes, either.  I'm not sure of all the steps necessary to set up such a .htaccess file, but I have \nexperimentally confirmed that, if I fix the typo on the 'moov' line, the .htaccess files for StuffIt! files \ncomes back into play, and everything's peachy again.
31472	Joe Orton	1099438627000	Thanks Jack, committed for 2.0.53.
31483	Joshua Slive	1096550611000	It seems quite ambiguous to me if this is really the right thing to do.  Is a\ngzipped svg file still a plain image/xvg+xml or is it an image/xvg+xml with a\ncontent-encoding implied?  I'd tend to believe the latter, in which case it does\nnot make sense to change the mime.types file unless there is also a\ncorresponding AddEncoding directive.\n\nThe svg spec does not seem perfectly clear on this topic.  But I don't see\nanywhere where it says that applications conforming to the spec must understand\ngzipped documents.  So that implies that the gzip is not part of the content\ntype, and we shouldn't change mime.types.\n\nFeel free to provide evidence to the contrary (and reopen the bug if you do so).
31483	Jim Ley	1096560213000	Hi,\n\nThe SVG 1.1 Errata should clarify this issue, svg viewers should be able to \nload gzipped svgz content no matter how it's loaded, svgz does not require a \ncontent-encoding header to be loaded.  Unfortunately we're still waiting for \nthat errata to be published, but you can see details at:\n\nhttp://article.gmane.org/gmane.text.xml.svg.devel/25178/\n\nor on the www-svg mailing list archives.\n\nI think it would be nice to also have AddEncoding for svgz for the non svg user \nagents, but it's not essential
31483	Roy T. Fielding	1188213405000	Added to trunk in rev 570206.
31759	stef	1098118468000	Add-on\nssl request from the client to  the apache, and no ssl between apache and IIS 
31759	Joe Orton	1098127598000	Firstly, please try upgrading to 2.0.52, there have been quite a few mod_ssl\nchanges since 2.0.49.\n\nSecondly, please include the complete error messages logged to error_log.
31759	stef	1098190831000	[Tue Oct 19 14:52:30 2004] [info] (70007)The timeout specified has expired: SSL \ninput filter read failed.\n\n\n
31759	stef	1098194703000	without mod_ssl, i have 70007 return code in the access_log, but nothing in the \nerror_log like in the previous post, except a lot of :\n[Tue Oct 19 15:55:14 2004] [info] (32)Broken pipe: core_output_filter: writing \ndata to the network\n\n\n\n
31759	stef	1098194769000	10.50.8.69 - - [19/Oct/2004:15:31:35 +0200] 'POST /wp_doc_upload.asp?PID=987665 \nHTTP/1.1' 70007 538
31759	stef	1098202529000	I have  same errors with 2.0.50 2.0.52 without mod_ssl .\n\n'POST /wp_doc_upload.asp?PID=987665 HTTP/1.1' 70007 538\n\nwhat is the difference between the 70007 return code in the access_log and the \n(70007) return code in the error_log ?\n\n\n\n  
31759	Joe Orton	1099434982000	There is a bug in mod_ssl somewhere which means that the APR error code 70007 is\nbeing returned in the wrong place, which is why it gets logged in access_log.\n\nBut it's still not clear to me: what actual problems are you seeing other than\nthe oddity in the logging?\n
31759	stef	1102615530000	(In reply to comment #7)\n> There is a bug in mod_ssl somewhere which means that the APR error code 70007 \nis\n> being returned in the wrong place, which is why it gets logged in access_log.\n> But it's still not clear to me: what actual problems are you seeing other than\n> the oddity in the logging?\n\n\nIn the error_log , lot of errors like [info] (70007)The timeout specified has \nexpired: SSL input filter read failed.\n\nIn the access_log : some 70007 : POST /wp_doc_upload.asp?PID=987665 HTTP/1.1' \n70007 23 'https://aa.com/test.asp' 'Mozilla/4.0 (compatible; MSIE 6.0; Windows \nNT 5.0; Hotbar 4.5.1.0)'\n\neach time a 70007 or 500 error occured, ie is out ( blank page ) .\n\nOn version 1.3.31, there are only 500 error code ( asp script time out ), but \nno 70007 error code .\n\n\n
31759	Markus L.	1122904997000	(In reply to comment #8)\n> (In reply to comment #7)\n> > There is a bug in mod_ssl somewhere which means that the APR error code 70007 \n> is\n> > being returned in the wrong place, which is why it gets logged in access_log.\n> > But it's still not clear to me: what actual problems are you seeing other than\n> > the oddity in the logging?\n> \n> \n> In the error_log , lot of errors like [info] (70007)The timeout specified has \n> expired: SSL input filter read failed.\n> \n> In the access_log : some 70007 : POST /wp_doc_upload.asp?PID=987665 HTTP/1.1' \n> 70007 23 'https://aa.com/test.asp' 'Mozilla/4.0 (compatible; MSIE 6.0; Windows \n> NT 5.0; Hotbar 4.5.1.0)'\n> \n> each time a 70007 or 500 error occured, ie is out ( blank page ) .\n> \n> On version 1.3.31, there are only 500 error code ( asp script time out ), but \n> no 70007 error code .\n\nI have log entries with http error code 70007, too, but I don't have any entries\nin the error_log. mod_ssl isn't used. here the errors come from POST requests\n\napache 2.0.54 / php 4.4.0\nLogLevel warn
31759	Joe Orton	1127731949000	This is a bug in the default_handler, not in mod_ssl.\n\nThe default_handler itself returns the ap_pass_brigade return value; the handler\nhook is supposed to return an OK/DECLINED/HTTP_* error code, so this is broken.
31759	Joe Orton	1127850777000	*** Bug 36828 has been marked as a duplicate of this bug. ***
31759	Jo Rhett	1143759308000	Since Joe claims that this is where the logging bug should be followed up, I'm\ncontinuing conversation here.\n\nIf this is the same problem as reported, this problem affects EVERY request, not\njust reverse proxy.  (if not, then Joe referred me incorrectly)\n\nThis is currently affecting roughly 2k log entries per night on my personal colo\nmachine.  It's tens of thousands more on real production websites.  It's a fatal\nflaw in one of Apache's most basic operations -- log the request.\n\nWhat do we need to do to get developers to stop playing with grand new features\nthat aren't crucial to basic operation, and fix the core?
31759	Jeff Trawick	1143807635000	Here's a patch to default handler to try:\n\nIndex: server/core.c\n===================================================================\n--- server/core.c       (revision 386843)\n+++ server/core.c       (working copy)\n@@ -3645,7 +3645,17 @@\n         e = apr_bucket_eos_create(c->bucket_alloc);\n         APR_BRIGADE_INSERT_TAIL(bb, e);\n\n-        return ap_pass_brigade(r->output_filters, bb);\n+        status = ap_pass_brigade(r->output_filters, bb);\n+        if (status == APR_SUCCESS\n+            || c->aborted) { /* broken I/O isn't an HTTP issue, so no\n+                              * error status applies\n+                              */\n+            return OK;\n+        }\n+        else {\n+            /* no way to know what type of error occurred */\n+            return HTTP_INTERNAL_SERVER_ERROR;\n+        }\n     }\n     else {              /* unusual method (not GET or POST) */\n         if (r->method_number == M_INVALID) {\n\n\n>What do we need to do to get developers to stop playing \n>with grand new features that aren't crucial to basic \n>operation, and fix the core?\n\nwhat can you do to help?\n\n    * please refrain from complaining or otherwise expressing frustration via\nthe PR database... that sends a signal to those who volunteer their time that\ntheir effort is inadequate... while that may be true for your problem, overall\nthere are many problems diagnosed and solved via the PR database, and there is\nno benefit from airing your grievance...\n    * continue to submit problem reports... every one is looked at even if there\ndoesn't appear to be any activity on it...\n    * help us out as much as possible with your report... this includes\nproviding relevant documentation when you create the report as well as trying to\nrespond quickly to questions we ask or suggestions we make... if you aren't\nwilling to help us work on your issue, why are we wasting our time in the first\nplace?\n    * use the source... you have access to the source code... you (or someone\nyou know or can hire with the proper skills) have the opportunity to find the\ncode that is causing you a problem and fix it, even if the fix is particular to\nyour environment and not suitable for general distribution\n    * if your company depends on Apache httpd, consider sponsoring a skilled\ndeveloper to get involved in the maintenance and ongoing development of Apache httpd\n    * consider paying for support from one of the companies that sells support\nfor Apache httpd (or servers based on Apache httpd) and contributes to the open\nsource development effort of Apache httpd\n\n
31759	Joe Orton	1143810229000	Thanks Jeff.\n\nI couldn't really convince myself what the correct behaviour was when I looked\nat this before.  If there is a 404 response which suffers from an SSL-layer\nerror, why is it better to log a 500 than a 404; i.e. is it better to just log\nr->status in the non-success case?  The real response code might be a useful\ndiagnostic.
31759	Ruediger Pluem	1143812232000	Also thanks from me Jeff. I guess it is a good idea to log the original return\ncode in the error log in the INTERNAL_SERVER_ERROR case. I think it should be\nsufficient to log this for DEBUG loglevel only. Thoughts?
31759	Jeff Trawick	1143816205000	(based on Joe's comments)\n>If there is a 404 response which suffers from an SSL-layer\n>error, why is it better to log a 500 than a 404\n\nIt isn't, but that doesn't go through this path.  (default handler will return\nHTTP_NOT_FOUND instead of calling ap_pass_brigade() with a file bucket)\n\nbut a filter could have modified r->status to indicate an error (e.g., invalid\nrange)\n\n>i.e. is it better to just log r->status in the non-success case?\n\nAgreed in general.  I'm still nervous about r->status still OK when we get here.\n So that last issue leaves us with this so far:\n\nIndex: server/core.c\n===================================================================\n--- server/core.c       (revision 386843)\n+++ server/core.c       (working copy)\n@@ -3645,7 +3645,16 @@\n         e = apr_bucket_eos_create(c->bucket_alloc);\n         APR_BRIGADE_INSERT_TAIL(bb, e);\n\n-        return ap_pass_brigade(r->output_filters, bb);\n+        status = ap_pass_brigade(r->output_filters, bb);\n+        if (status == APR_SUCCESS\n+            || r->status != HTTP_OK\n+            || c->aborted) {\n+            return r->status;\n+        }\n+        else {\n+            /* no way to know what type of error occurred */\n+            return HTTP_INTERNAL_SERVER_ERROR;\n+        }\n     }\n     else {              /* unusual method (not GET or POST) */\n         if (r->method_number == M_INVALID) {\n\nIf any kind of client communication error occurred, c->aborted should be set, right?\nIf any kind of HTTP error occurred, r->status should have been modified, right?\n\nPerhaps we should log a message here in the other situations but still return\nOK, to make sure that the processing problem doesn't always go unnoticed?\n\n(example of interest to me at the moment: a filter gets APR_EOF from bucket-read\nbecause a file has been truncated during request processing)\n
31759	Jeff Trawick	1143816646000	Ruediger's comments:\n>I guess it is a good idea to log the original return\n>code in the error log in the INTERNAL_SERVER_ERROR case. \n\nAgreed.  Perhaps it is okay not to even return 500 as long as we log something.\n\n>I think it should be sufficient to log this for DEBUG\n>loglevel only. Thoughts?\n\nI think INFO is the appropriate level, just like the expected\n'core_output_filter: writing data to network' messages.  Some of these odd cases\nare probably much less expected than a user hitting the stop button.
31759	Joe Orton	1143818129000	(In reply to comment #16)\n> (based on Joe's comments)\n> >If there is a 404 response which suffers from an SSL-layer\n> >error, why is it better to log a 500 than a 404\n> \n> It isn't, but that doesn't go through this path.  (default handler will return\n> HTTP_NOT_FOUND instead of calling ap_pass_brigade() with a file bucket)\n\ngood point sir\n\n> If any kind of client communication error occurred, c->aborted should be set,\nright?\n> If any kind of HTTP error occurred, r->status should have been modified, right?\n\nBoth sound right to me.\n\n> Perhaps we should log a message here in the other situations but still return\n> OK, to make sure that the processing problem doesn't always go unnoticed?\n> \n> (example of interest to me at the moment: a filter gets APR_EOF from bucket-read\n> because a file has been truncated during request processing)\n\nI'm not sure about this.  It would be better to avoid having such errors logged\nN times by all N filters in the output chain, that kind of thing creates confusion.\n
31759	Jeff Trawick	1143827664000	moving discussion to dev@httpd for the time being...\n
31759	Jo Rhett	1143922519000	The latest patch fails.  Every third or fourth request of plain ol' html files\nin normal HTTP mode generates 500 errors and garbage in the HTTP header.  I\nnever even got to testing SSL or CGI responses.  Plain, simple HTTP fails.\n\nAny chance to get a tested and working patch?
31759	Jo Rhett	1143923344000	FYI I see no discussion in the dev mailing list of this topic.
31759	Ruediger Pluem	1143931987000	(In reply to comment #21)\n> FYI I see no discussion in the dev mailing list of this topic.\n\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200603.mbox/%3ccc67648e0603310853m2e05c13cn9f883821a88aa3e1@mail.gmail.com%3e
31759	Ruediger Pluem	1143932451000	(In reply to comment #20)\n> The latest patch fails.  Every third or fourth request of plain ol' html files\n> in normal HTTP mode generates 500 errors and garbage in the HTTP header.  I\n> never even got to testing SSL or CGI responses.  Plain, simple HTTP fails.\n> \n> Any chance to get a tested and working patch?\n\nPlease use the following patch instead and set the LogLevel to debug:\n\nIndex: server/core.c\n===================================================================\n--- server/core.c       (Revision 390677)\n+++ server/core.c       (Arbeitskopie)\n@@ -3646,6 +3646,20 @@\n         APR_BRIGADE_INSERT_TAIL(bb, e);\n\n         return ap_pass_brigade(r->output_filters, bb);\n+        status = ap_pass_brigade(r->output_filters, bb);\n+        if (status == APR_SUCCESS\n+            || r->status != HTTP_OK\n+            || c->aborted) {\n+            return r->status;\n+        }\n+        else {\n+            /* no way to know what type of error occurred */\n+            ap_log_rerror(APLOG_MARK, APLOG_DEBUG, status, r,\n+                          'default_handler: ap_pass_brigade returned %i',\n+                          status);\n+            return HTTP_INTERNAL_SERVER_ERROR;\n+        }\n+\n     }\n     else {              /* unusual method (not GET or POST) */\n         if (r->method_number == M_INVALID) {\n\nFurthermore please post the garbled HTTP header.\n\n\n\n
31759	Jeff Trawick	1143933926000	About the patch:\n\nIt needs to return OK instead of r->status.  Otherwise, an error is triggered. \nOK will allow r->status to be respected when appropriate.\n\n        if (status == APR_SUCCESS\n            || r->status != HTTP_OK\n            || c->aborted) {\n            return OK; /* r->status will be respected */\n\nWhen returning r->status, you can get a complete 200 response then a 500 error\ndocument ;)\n
31759	Jo Rhett	1143935902000	Confirmed -- that's exactly what we were seeing.  200 return code, with the text\nof the 500 error message at the top or bottom of pages, or in random frame windows.
31759	Jeff Trawick	1144025108000	Here's the patch committed to trunk (as before with the change to return OK\ninstead of r->status):\n\nhttp://svn.apache.org/viewcvs.cgi?rev=390922&view=rev\n
31759	Ruediger Pluem	1144071427000	(In reply to comment #26)\n> \n> http://svn.apache.org/viewcvs.cgi?rev=390922&view=rev\n> \n\nPlease also apply http://svn.apache.org/viewcvs?rev=391025&view=rev as the\nprevious one has a small bug that is fixed by r391025.
31759	Ruediger Pluem	1144582571000	Proposed for backport to 2.2.x as r392700\n(http://svn.apache.org/viewcvs?rev=392700&view=rev) and to 2.0.x as r392701\n(http://svn.apache.org/viewcvs?rev=392701&view=rev)
31759	Ruediger Pluem	1145720038000	Backported to 2.2.x as r393005 (http://svn.apache.org/viewcvs?rev=393005&view=rev).
31759	Ruediger Pluem	1145996644000	*** Bug 39405 has been marked as a duplicate of this bug. ***
31759	Ceri Davies	1158057938000	Will this get backported to 2.0.x?
31759	Ruediger Pluem	1158060424000	This has been backported. It is part of 2.0.56 and later.
31759	Jo Rhett	1158092224000	I thought that this was fixed in 2.2.2 but testing with a PUT handler today\ndemonstrates that it's not fixed everywhere -- result code 70007 has been logged\nhere.\n\n64.13.135.30 - - [12/Sep/2006:11:28:40 -0700] 'PUT\n/polycom/extensions/0004f204217c-app.log HTTP/1.1' 70007 - '-'\n'Polycom-FileManager/1.0 (libcurl/7.12.1 OpenSSL/0.9.7d)\n(SIP-1.6.5:0043;SPIPPolycomSoundPointIP-SPIP_501)' arran.svcolo.com\n\n64.13.135.30 - - [12/Sep/2006:11:30:43 -0700] 'PUT\n/polycom/extensions/0004f204217c-app.log HTTP/1.1' 70007 - '-'\n'Polycom-FileManager/1.0 (libcurl/7.12.1 OpenSSL/0.9.7d)\n(SIP-1.6.5:0043;SPIPPolycomSoundPointIP-SPIP_501)' arran.svcolo.com\n
31759	Ruediger Pluem	1158095945000	It is fixed in the default handler. It is up to each handler to return the\ncorrect value. Simply returning the return value from ap_pass_brigade is wrong\nand leads to this errors. Please fix your PUT handler.
31759	Jo Rhett	1158096437000	The PUT handler is a small 10 line script.  It absolutely doesn't return a code\n70007 or anything other than 0 no matter how it finishes.\n\nThis is not resolved nor fixed.
31759	Nick Kew	1158096879000	(In reply to comment #35)\n> The PUT handler is a small 10 line script.  It absolutely doesn't return a code\n> 70007 or anything other than 0 no matter how it finishes.\n\nYour script isn't the issue.  It's the apache or third-party handler it's running under that wants fixing.\n\nIf it's apache's mod_cgi or mod_cgid, it's an apache bug.  Otherwise you need to look elsewhere.
31759	Jo Rhett	1158101477000	I'm sorry, but I'm confused.  You are saying this isn't an Apache bug... but it\nmight be an Apache bug, report it to them?  Huh?\n\n(yes I'm being a little dense on purpose, but it is honestly confusing)\n\nThis is a bone stock apache configuration.  No external modules.\n\nThis is an Apache bug one way or the other, and reported in the apache\nbugzilla... how is it that you are claiming 'not your bug?'
31759	Nick Kew	1158102204000	(In reply to comment #37)\n> I'm sorry, but I'm confused.  You are saying this isn't an Apache bug... but it\n> might be an Apache bug, report it to them?  Huh?\n\nThe default handler (which *this* bug report references) doesn't handle PUT.  So what you're describing is \neither a different bug or a notabug.  It absolutely cannot be *this* bug, though it could be the same thing \nin another handler.\n\n> This is a bone stock apache configuration.  No external modules.\n\nYou need to tell us what your script is running under.  Is it mod_cgi or mod_cgid?
31759	Jo Rhett	1158103363000	Not cgid.  I assume it's part of mod_cgi.  It's really just\n\nScript  PUT   /path/to/put-handler.pl\n\nTo what extent is this changed if *.pl is handled by \n\nAddHandler cgiwrapper *.cgi *.pl\nAction cgiwrapper /path/to/wrapper\n\nAnd again, it still seems like the it's using the return code (which is very\nOS-dependent) instead of a result code returned by the application.
31759	Ceri Davies	1158173350000	(In reply to comment #32)\n> This has been backported. It is part of 2.0.56 and later.\n\nThanks for the reply.  The reason I asked is that I am seeing the following with\n2.0.59:\n\n68.174.9.93 - - [13/Sep/2006:16:57:24 +0100] 'POST /articles/comment/66\nHTTP/1.1' 70007 607\n'http://typo.submonkey.net/articles/2006/03/09/setting-interface-link-settings-in-suns-openboot'\n'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; MRA 4.3 (build 01218))'\n\nThe target URL of the post is proxied by mod_proxy to a lighttpd backend (which\nis probably not working properly).
31759	Nick Kew	1158175155000	This bug has been fixed.\n\nBut after yesterday's exchange with Jo Rhett, I looked at mod_cgi and \nmod_cgid, and found what appears to be a similar problem in both of them, when \nthey return an error status from the *input* filters if they fail to read a \nrequest body (as in a POST/PUT request).\n\nI've fixed that similar bug - which I think you're both describing - in\nhttp://svn.apache.org/viewvc?view=rev&revision=442758
31759	Jo Rhett	1158175643000	You jumped right to the chase -- I was busy building a test case to prove that\neffect to you.  Looks good!\n\nObviously update this when it hits a release...
31759	Ceri Davies	1158306755000	(In reply to comment #41)\n\n> I've fixed that similar bug - which I think you're both describing - in\n> http://svn.apache.org/viewvc?view=rev&revision=442758\n\nThanks.  I've applied those patches but still see the issue as per the access\nlog extract above.\n
31759	Nick Kew	1158312184000	(In reply to comment #43)\n> (In reply to comment #41)\n> \n> > I've fixed that similar bug - which I think you're both describing - in\n> > http://svn.apache.org/viewvc?view=rev&revision=442758\n> \n> Thanks.  I've applied those patches but still see the issue as per the \naccess\n> log extract above.\n\nAh.  I read your mention of POST as meaning you were using CGI.  But looking \nup at comment #40, it was the proxy, so patching mod_cgi has no effect on you.\n\nI've just looked at mod_proxy in 2.0, and there is indeed the same bug there \nyet again (though it's deeper - in the mod_proxy_http provider).  It's also \nrather more complex, but always (AFAICT) comes from ap_proxy_http_request, \nwhich in fact returns apr_status_t values.  So you can fix it by applying the \nsame fix at line 1899 of proxy_http.c.
31759	Ceri Davies	1158502961000	(In reply to comment #44)\n> (In reply to comment #43)\n> > (In reply to comment #41)\n> > \n> > > I've fixed that similar bug - which I think you're both describing - in\n> > > http://svn.apache.org/viewvc?view=rev&revision=442758\n> > \n> > Thanks.  I've applied those patches but still see the issue as per the \n> access\n> > log extract above.\n> \n> Ah.  I read your mention of POST as meaning you were using CGI.  But looking \n> up at comment #40, it was the proxy, so patching mod_cgi has no effect on you.\n\nI did wonder :)\n> \n> I've just looked at mod_proxy in 2.0, and there is indeed the same bug there \n> yet again (though it's deeper - in the mod_proxy_http provider).  It's also \n> rather more complex, but always (AFAICT) comes from ap_proxy_http_request, \n> which in fact returns apr_status_t values.  So you can fix it by applying the \n> same fix at line 1899 of proxy_http.c.\n\nOK, that seems to have got it, thanks.
31759	Nick Kew	1159442337000	FWIW, I've implemented a higher-level fix, so that if this bug turns up in yet \nmore handlers, apache will handle it internally rather than send a bogus \nresponse to the client.  See\nhttp://svn.apache.org/viewvc?view=rev&revision=448711\nhttp://svn.apache.org/viewvc?view=rev&revision=450808
31759	Ceri Davies	1159444638000	Thanks Nick, that looks like the most sensible fix.
31782	Joshua Slive	1115157337000	Thanks for the interesting example.  I've added it along with some other\ncomments to the htaccess tutorial.
31848	Joe Orton	1098446458000	Created an attachment (id=13182)\npossible fix\n
31848	Joe Orton	1098446529000	Can you try the patch attached above? If it still fails, 'backtrace full' output\nfrom GDB would be useful.
31848	Ren	1098448192000	Thanks Joe, your patch seems to fix the crash.
31848	Joe Orton	1099350399000	Thanks for testing it and the detailed bug report!  Fixed in HEAD, will propose\nfor 2.0.53.
31848	Joe Orton	1100087837000	Fixed for 2.0.53, thanks again for the report.
31875	Nick Kew	1098700305000	Fixed in CVS:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/protocol.c?r1=1.156&r2=1.157\n
32367	Christian von Roques	1101251524000	Created an attachment (id=13527)\nPatch re-adding support for ProxyPass /foo !\n
32367	Paul Querna	1104394333000	ping to a mod_proxy hacker, I am pretty sure this should be committed.\n\nIf no one gets to it, I will take a swing this weekend.
32367	Mladen Turk	1107281906000	Fixed. Thanks Christian.
32443	tao	1101805940000	\n> And, the error.log grows at at a about 18KB/s speed. \nSorry, it should be 18KB/min.\n\n(In reply to comment #0)\n
32443	Janne Hietam	1105377046000	I had the same problem and I did some debugging.\n\nThis happends because ap_pass_brigade returns always APR_SUCCESS on\nap_proxy_http_process_response (from server/core.c).\n\nhere is a quick patch for this:\n\nchange line\n                    if (ap_pass_brigade(r->output_filters, bb) != APR_SUCCESS) {\n\non file modules/proxy/proxy_http.c to:\n\n                    if (ap_pass_brigade(r->output_filters, bb) != APR_SUCCESS ||\nc->aborted) {\n\n\n
32443	Janne Hietam	1105377194000	*** Bug 29644 has been marked as a duplicate of this bug. ***
32443	Joe Orton	1106136676000	Thanks for the patch.  I added the same logic in two other places where it was\nalso needed and committed that.\n\nhttp://svn.apache.org/viewcvs?view=rev&rev=125612 [viewsvn currently disabled]\n
32443	Joe Orton	1106136803000	Created an attachment (id=14046)\nbackported patch\n\nbackported version of patch for submission to 2.0
32443	Joe Orton	1147184137000	*** Bug 39442 has been marked as a duplicate of this bug. ***
32486	Joe Orton	1101997862000	Looks like it's added in both the Fixup and Access hooks.
32486	Paul Querna	1133854317000	Still present in 2.3-trunk.
32486	Joe Orton	1194334533000	This was happening since Upgrade was being added in both main and subrequest. \nFixed on trunk:\n\nhttp://svn.apache.org/viewvc?view=rev&revision=592457
32492	Andy Armstrong	1101999760000	Created an attachment (id=13625)\nMakes BufferedLogs Off work\n
32492	Andr?? Malo	1102000208000	Well, it's more a documentation bug.\n\n(1) that it's not documented at all\n(2) that it's a global setting. Either all logs are buffered or all are not.\nHence turning BufferedLogs Off makes no real sense.
32492	Joshua Slive	1114197242000	*** Bug 34463 has been marked as a duplicate of this bug. ***
32492	Joshua Slive	1114198998000	Documentation fixed.
32529	Joe Orton	1102155443000	Could you:\n\n1) describe the failure you see\n2) reproduce this with the vanilla 2.0.52 release rather than the SuSE package\n
32529	Mitch Frazier	1102181821000	The failure is that if I include a ProxyPass statement from one SSL enabled host\nto another SSL enabled, as soon as I try to access a page that should be proxied\nfrom the other host the child process in apache seg faults and I see nothing in\nmy browser.  Here's a trimmed generic configuration that will generate the problem:\n\nHost 1:\n-------\n    <VirtualHost 1.2.3.4:443>\n        ServerName      host1.domain.com\n\n        DocumentRoot    /srv/www/host1\n\n        SSLEngine                       on\n        SSLProxyEngine                  on\n        SSLCipherSuite                 \nALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL\n        SSLCertificateFile              /etc/apache2/ssl.crt/host1.domain.com.crt\n        SSLCertificateKeyFile           /etc/apache2/ssl.key/host1.domain.com.key\n\n        ProxyPass      /test.html       https://host2.domain.com.:444/test.html\n    </VirtualHost>\n    <Directory /srv/www/host1>\n        Order allow,deny\n        Allow from all\n        AllowOverride All\n    </Directory>\n\nHost 2:\n-------\n    Listen 444\n\n    <VirtualHost 1.2.3.5:444>\n        ServerName      host2.domain.com\n\n        DocumentRoot    /srv/www/host2\n\n        SSLEngine                       on\n        SSLCertificateKeyFile           /etc/apache2/ssl.key/host2.domain.com.key\n        SSLCertificateFile              /etc/apache2/ssl.crt/host2.domain.com.crt\n    </VirtualHost>\n\n    <Directory /srv/www/host2>\n        Order allow,deny\n        Allow from all\n        AllowOverride All\n   </Directory>\n\nIf you browse to https://host1.domain.com/test.html it should be reverse proxied\nfrom https://host2.domain.com/test.html but instead the apache process seg\nfaults.  I suspect that this is SMP related or perhaps related to the x86_64\narchitecture but that's only a suspicion.\n\n\nHere's a backtrace from a core dump:\n\n#0  0x0000002a97a72486 in CRYPTO_get_ex_data () from /usr/lib64/libcrypto.so.0.9.7\n#1  0x0000002a978d766a in SSL_get_ex_data () from /usr/lib64/libssl.so.0.9.7\n#2  0x0000002a977acd40 in ssl_callback_SSLVerify () from\n/usr/lib64/apache2-prefork/mod_ssl.so\n#3  0x0000002a97aa67c2 in X509_verify_cert () from /usr/lib64/libcrypto.so.0.9.7\n#4  0x0000002a978edd0c in ssl_verify_cert_chain () from /usr/lib64/libssl.so.0.9.7\n#5  0x0000002a978e32eb in ssl3_get_server_certificate () from\n/usr/lib64/libssl.so.0.9.7\n#6  0x0000002a978e23dc in ssl3_connect () from /usr/lib64/libssl.so.0.9.7\n#7  0x0000002a978ec245 in SSL_connect () from /usr/lib64/libssl.so.0.9.7\n#8  0x0000002a978e9f10 in ssl23_get_server_hello () from /usr/lib64/libssl.so.0.9.7\n#9  0x0000002a978e992c in ssl23_connect () from /usr/lib64/libssl.so.0.9.7\n#10 0x0000002a978ec245 in SSL_connect () from /usr/lib64/libssl.so.0.9.7\n#11 0x0000002a977aa8dc in ssl_io_filter_connect () from\n/usr/lib64/apache2-prefork/mod_ssl.so\n#12 0x0000002a977aaebe in ssl_io_filter_output () from\n/usr/lib64/apache2-prefork/mod_ssl.so\n#13 0x0000000000433b6a in ap_pass_brigade ()\n#14 0x0000002a9c255f3b in ap_proxy_http_request () from\n/usr/lib64/apache2-prefork/mod_proxy_http.so\n#15 0x0000002a9c25707f in ap_proxy_http_handler () from\n/usr/lib64/apache2-prefork/mod_proxy_http.so\n#16 0x0000002a9c14e3ab in proxy_run_scheme_handler () from\n/usr/lib64/apache2-prefork/mod_proxy.so\n#17 0x0000002a9c14cf9b in proxy_handler () from\n/usr/lib64/apache2-prefork/mod_proxy.so\n#18 0x0000000000427631 in ap_run_handler ()\n#19 0x0000000000427ca9 in ap_invoke_handler ()\n#20 0x0000000000424506 in ap_process_request ()\n#21 0x000000000041fad8 in ap_process_http_connection ()\n#22 0x00000000004316a1 in ap_run_process_connection ()\n#23 0x0000000000431a02 in ap_process_connection ()\n#24 0x0000000000425d22 in child_main ()\n#25 0x0000000000425ee8 in make_child ()\n#26 0x00000000004260b3 in perform_idle_server_maintenance ()\n#27 0x0000000000426621 in ap_mpm_run ()\n#28 0x000000000042cada in main ()\n\nIf I patch openssl as I stated in the original post it fixes the problem.\n\nI'll see if I can duplicate the problem with the stock 2.0.52.  I have to\nproceed with caution since this server is running a number of sites with a lot\nof traffic.
32529	Mitch Frazier	1102181854000	The failure is that if I include a ProxyPass statement from one SSL enabled host\nto another SSL enabled, as soon as I try to access a page that should be proxied\nfrom the other host the child process in apache seg faults and I see nothing in\nmy browser.  Here's a trimmed generic configuration that will generate the problem:\n\nHost 1:\n-------\n    <VirtualHost 1.2.3.4:443>\n        ServerName      host1.domain.com\n\n        DocumentRoot    /srv/www/host1\n\n        SSLEngine                       on\n        SSLProxyEngine                  on\n        SSLCipherSuite                 \nALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL\n        SSLCertificateFile              /etc/apache2/ssl.crt/host1.domain.com.crt\n        SSLCertificateKeyFile           /etc/apache2/ssl.key/host1.domain.com.key\n\n        ProxyPass      /test.html       https://host2.domain.com.:444/test.html\n    </VirtualHost>\n    <Directory /srv/www/host1>\n        Order allow,deny\n        Allow from all\n        AllowOverride All\n    </Directory>\n\nHost 2:\n-------\n    Listen 444\n\n    <VirtualHost 1.2.3.5:444>\n        ServerName      host2.domain.com\n\n        DocumentRoot    /srv/www/host2\n\n        SSLEngine                       on\n        SSLCertificateKeyFile           /etc/apache2/ssl.key/host2.domain.com.key\n        SSLCertificateFile              /etc/apache2/ssl.crt/host2.domain.com.crt\n    </VirtualHost>\n\n    <Directory /srv/www/host2>\n        Order allow,deny\n        Allow from all\n        AllowOverride All\n   </Directory>\n\nIf you browse to https://host1.domain.com/test.html it should be reverse proxied\nfrom https://host2.domain.com/test.html but instead the apache process seg\nfaults.  I suspect that this is SMP related or perhaps related to the x86_64\narchitecture but that's only a suspicion.\n\n\nHere's a backtrace from a core dump:\n\n#0  0x0000002a97a72486 in CRYPTO_get_ex_data () from /usr/lib64/libcrypto.so.0.9.7\n#1  0x0000002a978d766a in SSL_get_ex_data () from /usr/lib64/libssl.so.0.9.7\n#2  0x0000002a977acd40 in ssl_callback_SSLVerify () from\n/usr/lib64/apache2-prefork/mod_ssl.so\n#3  0x0000002a97aa67c2 in X509_verify_cert () from /usr/lib64/libcrypto.so.0.9.7\n#4  0x0000002a978edd0c in ssl_verify_cert_chain () from /usr/lib64/libssl.so.0.9.7\n#5  0x0000002a978e32eb in ssl3_get_server_certificate () from\n/usr/lib64/libssl.so.0.9.7\n#6  0x0000002a978e23dc in ssl3_connect () from /usr/lib64/libssl.so.0.9.7\n#7  0x0000002a978ec245 in SSL_connect () from /usr/lib64/libssl.so.0.9.7\n#8  0x0000002a978e9f10 in ssl23_get_server_hello () from /usr/lib64/libssl.so.0.9.7\n#9  0x0000002a978e992c in ssl23_connect () from /usr/lib64/libssl.so.0.9.7\n#10 0x0000002a978ec245 in SSL_connect () from /usr/lib64/libssl.so.0.9.7\n#11 0x0000002a977aa8dc in ssl_io_filter_connect () from\n/usr/lib64/apache2-prefork/mod_ssl.so\n#12 0x0000002a977aaebe in ssl_io_filter_output () from\n/usr/lib64/apache2-prefork/mod_ssl.so\n#13 0x0000000000433b6a in ap_pass_brigade ()\n#14 0x0000002a9c255f3b in ap_proxy_http_request () from\n/usr/lib64/apache2-prefork/mod_proxy_http.so\n#15 0x0000002a9c25707f in ap_proxy_http_handler () from\n/usr/lib64/apache2-prefork/mod_proxy_http.so\n#16 0x0000002a9c14e3ab in proxy_run_scheme_handler () from\n/usr/lib64/apache2-prefork/mod_proxy.so\n#17 0x0000002a9c14cf9b in proxy_handler () from\n/usr/lib64/apache2-prefork/mod_proxy.so\n#18 0x0000000000427631 in ap_run_handler ()\n#19 0x0000000000427ca9 in ap_invoke_handler ()\n#20 0x0000000000424506 in ap_process_request ()\n#21 0x000000000041fad8 in ap_process_http_connection ()\n#22 0x00000000004316a1 in ap_run_process_connection ()\n#23 0x0000000000431a02 in ap_process_connection ()\n#24 0x0000000000425d22 in child_main ()\n#25 0x0000000000425ee8 in make_child ()\n#26 0x00000000004260b3 in perform_idle_server_maintenance ()\n#27 0x0000000000426621 in ap_mpm_run ()\n#28 0x000000000042cada in main ()\n\nIf I patch openssl as I stated in the original post it fixes the problem.\n\nI'll see if I can duplicate the problem with the stock 2.0.52.  I have to\nproceed with caution since this server is running a number of sites with a lot\nof traffic.\n\n
32529	Mitch Frazier	1102182075000	(In reply to comment #2)\nThis is a duplicate of #3 below.
32529	Mitch Frazier	1102209371000	I am unable to reproduce this bug with a stock 2.0.52 apache on the same system\nwith more or less the same configuration (mainly just a change of port numbers).\n I also am unable to reproduce it with a stock 2.0.48 apache.\n\nFurthermore, even after applying all of the patches (to 2.0.48) that SuSE uses\nto build their RPM and using the same compiler options that they use and I still\ncan't reproduce it.  So either the run-time configuration changes somehow affect\nit or something happens when building the RPM which affects it.  Or maybe I'm\njust going crazy.
32529	Joe Orton	1102283829000	To be clear, you were testing the vanilla 2.0.52 and 2.0.48 sources against the\n*unpatched* version of OpenSSL, not the one you have patched?\n\nCould you try changing the first line of ssl_callback_SSLVerify as follows, instead:\n\n-    SSL *ssl            = (SSL *)X509_STORE_CTX_get_app_data(ctx);\n+    SSL *ssl = X509_STORE_CTX_get_ex_data(ctx,\n+                                         SSL_get_ex_data_X509_STORE_CTX_idx());\n\nI can't really see why that segfault could happen in the first place, though.
32529	Mitch Frazier	1102297781000	(In reply to comment #6)\n> To be clear, you were testing the vanilla 2.0.52 and 2.0.48 sources against the\n> *unpatched* version of OpenSSL, not the one you have patched?\nThat is correct, the unpatched OpenSSL.\n> \n> Could you try changing the first line of ssl_callback_SSLVerify as follows,\ninstead:\n> \n> -    SSL *ssl            = (SSL *)X509_STORE_CTX_get_app_data(ctx);\n> +    SSL *ssl = X509_STORE_CTX_get_ex_data(ctx,\n> +                                         SSL_get_ex_data_X509_STORE_CTX_idx());\nI'll try it, but see below because there may be bigger problems.\n\n> \n> I can't really see why that segfault could happen in the first place, though.\nThe reason that its happening is that in some cases the openssl code is storing\nthe SSL* pointer at an index of 1 rather than 0 (the \nX509_STORE_CTX_get_app_data() macro always uses 0).  I discovered this by\nputting a fprintf statement in the function X509_STORE_CTX_get_ex_new_index() to\nsee what values are being returned as indexes in the\nSSL_get_ex_data_X509_STORE_CTX_idx() function.  Again, this only happens on the\nlive apache server not the test one.\n\nBy looking at the function  SSL_get_ex_data_X509_STORE_CTX_idx() one would\npresume that this would be impossible.  For reference here's the function:\n\nint SSL_get_ex_data_X509_STORE_CTX_idx(void)\n\t{\n\tstatic volatile int ssl_x509_store_ctx_idx= -1;\n\n\tif (ssl_x509_store_ctx_idx < 0)\n\t\t{\n\t\t/* any write lock will do; usually this branch\n\t\t * will only be taken once anyway */\n\t\tCRYPTO_w_lock(CRYPTO_LOCK_SSL_CTX);\n\n\t\tif (ssl_x509_store_ctx_idx < 0)\n\t\t\t{\n\t\t\tssl_x509_store_ctx_idx=X509_STORE_CTX_get_ex_new_index(\n\t\t\t\t0,'SSL for verify callback',NULL,NULL,NULL);\n\t\t\t}\n\n\t\tCRYPTO_w_unlock(CRYPTO_LOCK_SSL_CTX);\n\t\t}\n\treturn ssl_x509_store_ctx_idx;\n\t}\n\n\nAlso for reference, here is a dump of the assembler for this code:\n\nDump of assembler code for function SSL_get_ex_data_X509_STORE_CTX_idx:\n0x0000000000024710 <SSL_get_ex_data_X509_STORE_CTX_idx+0>:      sub    $0x8,%rsp\n0x0000000000024714 <SSL_get_ex_data_X509_STORE_CTX_idx+4>:      mov   \n1094190(%rip),%eax        # 0x12f948 <ssl_x509_store_ctx_idx.0>\n0x000000000002471a <SSL_get_ex_data_X509_STORE_CTX_idx+10>:     test   %eax,%eax\n0x000000000002471c <SSL_get_ex_data_X509_STORE_CTX_idx+12>:     js     0x24730\n<SSL_get_ex_data_X509_STORE_CTX_idx+32>\n0x000000000002471e <SSL_get_ex_data_X509_STORE_CTX_idx+14>:     mov   \n1094180(%rip),%eax        # 0x12f948 <ssl_x509_store_ctx_idx.0>\n0x0000000000024724 <SSL_get_ex_data_X509_STORE_CTX_idx+20>:     add    $0x8,%rsp\n0x0000000000024728 <SSL_get_ex_data_X509_STORE_CTX_idx+24>:     retq\n0x0000000000024729 <SSL_get_ex_data_X509_STORE_CTX_idx+25>:     data16\n0x000000000002472a <SSL_get_ex_data_X509_STORE_CTX_idx+26>:     data16\n0x000000000002472b <SSL_get_ex_data_X509_STORE_CTX_idx+27>:     data16\n0x000000000002472c <SSL_get_ex_data_X509_STORE_CTX_idx+28>:     nop\n0x000000000002472d <SSL_get_ex_data_X509_STORE_CTX_idx+29>:     data16\n0x000000000002472e <SSL_get_ex_data_X509_STORE_CTX_idx+30>:     data16\n0x000000000002472f <SSL_get_ex_data_X509_STORE_CTX_idx+31>:     nop\n0x0000000000024730 <SSL_get_ex_data_X509_STORE_CTX_idx+32>:     lea   \n20449(%rip),%rdx        # 0x29718 <empty.0+908>\n0x0000000000024737 <SSL_get_ex_data_X509_STORE_CTX_idx+39>:     mov    $0x8d,%ecx\n0x000000000002473c <SSL_get_ex_data_X509_STORE_CTX_idx+44>:     mov    $0xc,%esi\n0x0000000000024741 <SSL_get_ex_data_X509_STORE_CTX_idx+49>:     mov    $0x9,%edi\n0x0000000000024746 <SSL_get_ex_data_X509_STORE_CTX_idx+54>:     callq  0xc268\n0x000000000002474b <SSL_get_ex_data_X509_STORE_CTX_idx+59>:     mov   \n1094135(%rip),%eax        # 0x12f948 <ssl_x509_store_ctx_idx.0>\n0x0000000000024751 <SSL_get_ex_data_X509_STORE_CTX_idx+65>:     test   %eax,%eax\n0x0000000000024753 <SSL_get_ex_data_X509_STORE_CTX_idx+67>:     jns    0x24770\n<SSL_get_ex_data_X509_STORE_CTX_idx+96>\n0x0000000000024755 <SSL_get_ex_data_X509_STORE_CTX_idx+69>:     lea   \n20423(%rip),%rsi        # 0x29723 <empty.0+919>\n0x000000000002475c <SSL_get_ex_data_X509_STORE_CTX_idx+76>:     xor    %r8d,%r8d\n0x000000000002475f <SSL_get_ex_data_X509_STORE_CTX_idx+79>:     xor    %ecx,%ecx\n0x0000000000024761 <SSL_get_ex_data_X509_STORE_CTX_idx+81>:     xor    %edx,%edx\n0x0000000000024763 <SSL_get_ex_data_X509_STORE_CTX_idx+83>:     xor    %edi,%edi\n0x0000000000024765 <SSL_get_ex_data_X509_STORE_CTX_idx+85>:     callq  0xc8a8\n0x000000000002476a <SSL_get_ex_data_X509_STORE_CTX_idx+90>:     mov   \n%eax,1094104(%rip)        # 0x12f948 <ssl_x509_store_ctx_idx.0>\n0x0000000000024770 <SSL_get_ex_data_X509_STORE_CTX_idx+96>:     lea   \n20385(%rip),%rdx        # 0x29718 <empty.0+908>\n0x0000000000024777 <SSL_get_ex_data_X509_STORE_CTX_idx+103>:    mov    $0x95,%ecx\n0x000000000002477c <SSL_get_ex_data_X509_STORE_CTX_idx+108>:    mov    $0xc,%esi\n0x0000000000024781 <SSL_get_ex_data_X509_STORE_CTX_idx+113>:    mov    $0xa,%edi\n0x0000000000024786 <SSL_get_ex_data_X509_STORE_CTX_idx+118>:    callq  0xc268\n0x000000000002478b <SSL_get_ex_data_X509_STORE_CTX_idx+123>:    mov   \n1094071(%rip),%eax        # 0x12f948 <ssl_x509_store_ctx_idx.0>\n0x0000000000024791 <SSL_get_ex_data_X509_STORE_CTX_idx+129>:    add    $0x8,%rsp\n0x0000000000024795 <SSL_get_ex_data_X509_STORE_CTX_idx+133>:    retq\n\nThe call to CRYPTO_w_lock() should ensure that ssl_x509_store_ctx_idx can only\ntake on a value of zero.  The assembler looks correct to me.\n\nIt looks like a thread synchronization problem, but its hard to believe that\nthread synchronization is broken.  Remember that this is an SMP box.  I'm\nthinking that the reason I can't reproduce the problem is because the test\nserver is not as heavily loaded as the live server.\n\nAlso note that this is running the prefork mpm module.\n\n
32529	Mitch Frazier	1102298862000	(In reply to comment #7)\nI was just reading how the prefork module works and it doesn't even have threads\nso now I'm more confused.
32529	Mitch Frazier	1102300367000	(In reply to comment #7)\nAlso note that the only call to X509_STORE_CTX_get_ex_new_index() in apache and\nopenssl is from the function SSL_get_ex_data_X509_STORE_CTX_idx().\n
32529	Mitch Frazier	1102303039000	(In reply to comment #6)\n> Could you try changing the first line of ssl_callback_SSLVerify as follows,\ninstead:\n> \n> -    SSL *ssl            = (SSL *)X509_STORE_CTX_get_app_data(ctx);\n> +    SSL *ssl = X509_STORE_CTX_get_ex_data(ctx,\n> +                                         SSL_get_ex_data_X509_STORE_CTX_idx());\n\nThis is what I was thinking should be the fix should be, which is what I was\ndriving at in my first post:\n\n>> The bug is that a callback function has no way of retrieving\n>> the value returned by SSL_get_ex_data_X509_STORE_CTX_idx(),\n>> in apache's case it uses 0 via the X509_STORE_CTX_get_app_data() macro.\n\nAlthough I was thinking that SSL_get_ex_data_X509_STORE_CTX_idx() wasn't\nexported from the library and therefore was not callable so I got started down\nother paths.\n\nAlthough I can't see where else X509_STORE_CTX_get_ex_new_index() is being\ncalled from, but maybe I'm not seeing the big picture.\n\nI'm attempting to rebuild the apache RPM now...\n
32529	Joe Orton	1102324168000	Good analysis, thanks.\n\nThis could well be one of the insane cases which occurs where libssl.so gets\nloaded and unloaded during startup but libcrypto.so always stays mapped.  Global\nvariables in libcrypto.so hence don't get reset to their initialization state,\nbut those in libssl.so do: \n\nnote that X509_STORE_CTX_get_ex_new_index is probably just incrementing some\nglobal variable behind the scenes, no doubt (haven't verified that): so if \nssl_x509_store_ctx_idx gets reset to -1, but that global variable does not, then\nthe _idx variable will quite likely get set to '1' next time round.\n\nThat might also explain the crash.  You could try some fprintf debugging in both\nlibcrypto and libssl to try and verify this; or LD_DEBUG stuff to see when each\nis getting loaded and unloaded.\n
32529	Mitch Frazier	1102479138000	(In reply to comment #11)\n> This could well be one of the insane cases which occurs where libssl.so gets\n> loaded and unloaded during startup but libcrypto.so always stays mapped.  Global\n> variables in libcrypto.so hence don't get reset to their initialization state,\n> but those in libssl.so do: \n> \nYep, you guessed it.  I put some printfs in libssl and libcrypto:\n\n 1  29336:\n 2    29336  644.580855: in crypto_init, ppid: 29335, count: 1\n 3    29336  644.580921: in ssl_init, ppid: 29335, count: 1\n 4    29336  645.198972: CRYPTO_get_ex_new_index, ix: 0, ppid: 29335, count2: 1\n 5    29336  645.198980: /usr/lib64/libcrypto.so.0.9.7(my_dumper+0x2e)\n[0x2a97aac149]\n 6    29336  645.198985:\n/usr/lib64/libcrypto.so.0.9.7(X509_STORE_CTX_get_ex_new_index+0x2b) [0x2a97aac25b]\n 7    29336  645.198989:\n/usr/lib64/libssl.so.0.9.7(SSL_get_ex_data_X509_STORE_CTX_idx+0x50) [0x2a978ee580]\n 8    29336  645.198993: /usr/lib64/libssl.so.0.9.7(SSL_CTX_new+0x1a) [0x2a978ed69a]\n 9    29336  645.198997: /usr/lib64/apache2-prefork/mod_ssl.so [0x2a977a80fd]\n10    29336  645.202025: in ssl_exit, ppid: 29335, count: 2\n11    29336  645.209564: in ssl_init, ppid: 29335, count: 1\n12    29336  645.608884: in ssl_exit, ppid: 29335, count: 2\n13    29336  645.609069: in crypto_exit, ppid: 29335, count: 2\n14  29337:\n15    29336  644.580855: in crypto_init, ppid: 29335, count: 1\n16    29336  645.198972: CRYPTO_get_ex_new_index, ix: 0, ppid: 29335, count2: 1\n17    29336  645.198980: /usr/lib64/libcrypto.so.0.9.7(my_dumper+0x2e)\n[0x2a97aac149]\n18    29336  645.198985:\n/usr/lib64/libcrypto.so.0.9.7(X509_STORE_CTX_get_ex_new_index+0x2b) [0x2a97aac25b]\n19    29336  645.198989:\n/usr/lib64/libssl.so.0.9.7(SSL_get_ex_data_X509_STORE_CTX_idx+0x50) [0x2a978ee580]\n20    29336  645.198993: /usr/lib64/libssl.so.0.9.7(SSL_CTX_new+0x1a) [0x2a978ed69a]\n21    29336  645.198997: /usr/lib64/apache2-prefork/mod_ssl.so [0x2a977a80fd]\n22    29336  645.209564: in ssl_init, ppid: 29335, count: 1\n23    29337  645.699132: CRYPTO_get_ex_new_index, ix: 1, ppid: 1, count2: 2\n24    29337  645.699147: /usr/lib64/libcrypto.so.0.9.7(my_dumper+0x2e)\n[0x2a97aac149]\n25    29337  645.699152:\n/usr/lib64/libcrypto.so.0.9.7(X509_STORE_CTX_get_ex_new_index+0x2b) [0x2a97aac25b]\n26    29337  645.699156:\n/usr/lib64/libssl.so.0.9.7(SSL_get_ex_data_X509_STORE_CTX_idx+0x50) [0x2a978ee580]\n27    29337  645.699161: /usr/lib64/libssl.so.0.9.7(SSL_CTX_new+0x1a) [0x2a978ed69a]\n28    29337  645.699164: /usr/lib64/apache2-prefork/mod_ssl.so [0x2a977a80fd]\n29    29337  656.534013: in ssl_exit, ppid: 1, count: 2\n30    29337  656.536308: in crypto_exit, ppid: 1, count: 2\n\nThe first column is line numbers, the second is process id, the third\nis time (fractional part is microseconds).\n\nLines 2-13 are from process id 29336:\nLine 2:      libcrypto.so gets loaded and initialized\n             (this output is coming from a __attribute__((constructor))\n             function that I added).\nLine 3:      libssl.so gets loaded and initialized\n             (output also from a __attribute__((constructor)) function)\nLine 4:      CRYPTO_get_new_index gets called and returns 0 (the ix value)\nLines 5-9:   traceback of the call into mod_ssl\nLine 10:     libssl.so gets unloaded\n             (output coming from a __attribute__((destructor)) function)\nLine 11:     libssl.so gets reloaded and reinitialized\nLine 12:     libssl.so gets unloaded\nLine 13:     libcrypto.so gets unloaded\n             (output coming from a __attribute__((destructor)) function)\n\nLines 15-30 are from process id 29337:\nLines 15-22: match lines 2-9 and line 11 in process 29336, so they\n             were forked from the same point after line 11 (22).\n             line 10 isn't matched in 29337 because line 10 was lost\n             when libssl.so was unloaded.\nLine 23:     CRYPTO_get_new_index gets called and returns 1 (the ix value)\n             rather than 0 because libcrypto.so was not unloaded and\n             reinitialized but libssl.so was.\nLine 24-30:  backtrace and libraries getting unloaded\n\nThe patch you suggested fixed the problem.  Here is the patch file:\n\n--------------------------------------------------------------\ndiff -r -u httpd-2.0.48-orig/modules/ssl/ssl_engine_kernel.c\nhttpd-2.0.48/modules/ssl/ssl_engine_kernel.c\n--- httpd-2.0.48-orig/modules/ssl/ssl_engine_kernel.c   2004-12-05\n17:54:42.000000000 -0800\n+++ httpd-2.0.48/modules/ssl/ssl_engine_kernel.c        2004-12-05\n17:58:36.000000000 -0800\n@@ -1205,7 +1205,8 @@\n int ssl_callback_SSLVerify(int ok, X509_STORE_CTX *ctx)\n {\n     /* Get Apache context back through OpenSSL context */\n-    SSL *ssl            = (SSL *)X509_STORE_CTX_get_app_data(ctx);\n+    SSL *ssl            = (SSL *)X509_STORE_CTX_get_ex_data(ctx,\n+                                     SSL_get_ex_data_X509_STORE_CTX_idx());\n     conn_rec *conn      = (conn_rec *)SSL_get_app_data(ssl);\n     server_rec *s       = conn->base_server;\n     request_rec *r      = (request_rec *)SSL_get_app_data2(ssl);\n--------------------------------------------------------------\n\n
32529	Joe Orton	1102500506000	Thanks a lot for your thorough investigation!\n\nI'll apply the patch.  But I'd not be surprised if there are more bugs like this\nlurking, abuse of global state is rife in OpenSSL.  The safest fix is to ensure\nthat httpd itself is always linked against both libssl and libcrypto, so neither\never gets unloaded at runtime.  That actually should be done in all 2.0.x\nreleases, it may be an artefact of the SuSE build process that this breaks.\n
32529	Joe Orton	1102502700000	http://svn.apache.org/viewcvs?view=rev&rev=111241
32529	Joe Orton	1115765223000	*** Bug 34846 has been marked as a duplicate of this bug. ***
32561	Andr?? Malo	1102469700000	Thanks for your care.
32699	ducrot	1103049226000	Created an attachment (id=13752)\nfix ssl flush output\n\nmake sure bio_filter_out_flush() return an error if the connection have been\naborted.
32699	Joe Orton	1103061737000	Good work, thanks for the patch.  It's always annoying that core_output_filter\nhides these EPIPE errors :(
32699	Joe Orton	1105715918000	I committed a different fix, to set outctx->rc = ECONNRESET rather than just\nfail here, so that an error is logged properly.  Thanks again for tracking this\ndown.\n\nhttp://svn.apache.org/viewcvs?view=rev&rev=125166 [viewsvn currently disabled]\n
32699	Jason Brady	1125205327000	Since this specific fix, I occasionally get 104 http error codes in my access\nlog. I have tracked it to aborted SSL connections. The patch for this bug\nreturns an APR_ECONNRESET which resolves to 104 on my linux system (Redhat 9 and\nFedora4). It shouldn't be returning invalid http error codes when trying to log\naborted http connections.
32699	Joe Orton	1125587742000	Jason could you please file a new bug for that issue?  I don't think it's\nmod_ssl specific, mod_ssl appears to be doing the right thing here.
32842	Joe Orton	1113583378000	I've added:\n\nBrowserMatch 'MS FrontPage' redirect-carefully\n\nto the default config which should take care of this.  Thanks for the report.
32848	Joe Orton	1105714959000	Thanks for the submission. A trimmed-down version of this patch has been\ncommitted to the trunk for future httpd 2.1/2.2 releases.\n\nhttp://svn.apache.org/viewcvs?view=rev&rev=125165 [viewcvs currently accessible]\n\nDid you have a docs update for this too, BTW?\n
32848	Tim K. Taylor	1106065916000	I had not done the doc but I can certainly do so. I assume that when I am done,\nthat I should attach here as was done with the code.
32848	Joe Orton	1106066602000	That or just send it to docs@httpd.apache.org; ideally as a diff against the XML\nsource.  If it's hassle then just sending in some unformatted text would be great.
32848	Tim K. Taylor	1107383493000	Created an attachment (id=14160)\ndocumentation patch to mod_ssl.xml\n
32985	Joe Orton	1105723097000	Created an attachment (id=13999)\nproposed fix\n\nThere's an off-by-one in the handling of variables which expand to 128\ncharacters, this is a fix, not sure if it's the *correct* fix...
32985	Joe Orton	1105911267000	Created an attachment (id=14025)\nvariable truncation fix #2\n\nfix for variable truncation issue (now with comment)
32985	Joe Orton	1106577600000	Fix committed for 2.0.53; thanks for the simple repro case!
32985	Anthony DiSante	1106591078000	You're welcome; glad to help.  Thanks for the fix!
33112	Per Jessen	1187056510000	Also present in 2.2.4.
33112	Nick Kew	1187058200000	Fixed in trunk: http://svn.apache.org/viewvc?view=rev&revision=565671
33112	Per Jessen	1187063184000	It's probably irrelevant now, but I've applied and tested the patch in 2.2.4.\nWorks fine.
33112	Nick Kew	1188319409000	Fixed for 2.2.6.
33170	Justin Erenkrantz	1107476362000	Applied in r151248.  Thanks!
33290	Rich Bowen	1107053540000	Thanks. Change made.
33382	Terry Lewis	1107613695000	I have the same problem with trying to proxy 2 Axis webcams
33382	Rudolf Kutina	1108477190000	We can pay for patch!
33382	Nick Kew	1108507752000	Are you in a position to try mod_proxy from httpd-2.1 or current CVS? \nIt would be useful to know whether they have a similar problem. 
33382	Rudolf Kutina	1108562572000	(In reply to comment #3)\n> Are you in a position to try mod_proxy from httpd-2.1 or current CVS? \n> It would be useful to know whether they have a similar problem. \n\nCurrent http (2005-02-16) from 2.0 branch have the same problem.
33382	Rudolf Kutina	1108563728000	Current httpd (2005-02-16) from CVS 2.1 branch tree with last APR have the same \nproblem. System is Gentoo with kernel 2.6.10
33382	Rudolf Kutina	1108566440000	The same problem is on actual httpd for win32. Tested on precompiled version \n2.0.53 on Widnows 2003 server.
33382	Rudolf Kutina	1108568032000	The same problem on httpd 1.3.33. 
33382	Rudolf Kutina	1108568304000	I am using Reverse Proxy configurations like:\n\nProxyRequests Off\n\n<Proxy *>\n\nOrder deny,allow\nAllow from all\n\n</Proxy>\n\nProxyPass /foo http://foo.example.com/bar\nProxyPassReverse /foo http://foo.example.com/bar \n\n
33382	Rudolf Kutina	1108572761000	Hello,\n\nI am the director of the company trying to solve this problem.  Our client has \napproved us to pay $500 to someone that can fix this memoryleak. This problem \nis becoming critical and we really need to solve it.\n\nIf you would like to talk to us directly to expedite a resolution, you can call \nUSA 800-341-0860\n\nThanks\n
33382	Paul Querna	1108684495000	A fix for this has been commited to subversion in r154200:\nhttp://svn.apache.org/viewcvs.cgi?rev=154200&view=rev\n\nI am going to propose a backport to the 2.0.x branch.
33382	Paul Querna	1108686699000	Created an attachment (id=14308)\nBackport of r154200 to 2.0.x branch\n\nProposed backport with this patch to the 2.0.x branch.
33382	Paul Querna	1109412497000	Backported to 2.0.x in r r155391.  The fix will part of 2.0.54.\n\nThanks for using Apache.
33438	Bojan Smojver	1107829911000	Created an attachment (id=14203)\nFix\n
33438	Jeff Trawick	1107974592000	fix committed to 2.1-dev and 2.0.next... thanks!
33466	Joshua Slive	1185883717000	Ok fixed a few years later. Thanks.
33508	Mike Brown	1108173939000	Changed summary to improve searchability
33508	Joshua Slive	1185884276000	Several years later...\n\nI just renamed dir to folder in trunk, since dir is never used. I don't see any\nurgency to backport this, since few people use the small icons and it is easy\nenough to fix in the config.\n\nThanks for the report.
33615	Joe Orton	1109267661000	Thanks a lot!  Your patch was not quite right since it should just break out of\nthe loop on EOF: committed for the next release:\n\nhttp://svn.apache.org/viewcvs.cgi?rev=155209&view=rev
33765	Andr?? Malo	1109580219000	Hmm, I'd guess your APR headers are outdated (i.e. not matching the lib\nversion). Could this be?
33765	Christian Ullrich	1109596105000	(In reply to comment #1)\n> Hmm, I'd guess your APR headers are outdated (i.e. not matching the lib\n> version). Could this be?\n\nI don't think so. One, I installed the whole thing from the FreeBSD ports\ncollection, and the APR headers are in the same package as the server, and two,\nthe bug doesn't have anything to do with a wrong #define. In support/htdigest.c,\neven in HEAD, there is a call to apr_file_open() with -1 as fourth argument. Not\nsomething that's #defined to -1, but a literal -1.\n\nAPR_OS_DEFAULT (what htpasswd uses instead) is 07777, but it's special-cased in\nlibapr to use 00666.
33765	Joe Orton	1109604583000	Good catch! Committed to trunk, will propose for 2.0.x:\n\nhttp://svn.apache.org/viewcvs.cgi?rev=155681&view=rev
33765	Joe Orton	1109674973000	And committed for 2.0.54, revision 155762.  Thanks for the report!
33803	Will Rowe	1198325521000	Committed and backported for the next 2.0.62 and 2.2.7 releases.\n\nThanks for the patch!
34209	David Arcuri	1112130438000	\nFurther investigation reveals this condition is only reached when 'require\ngroup' directive is present:\n\n<Directory '/mysitestuff'>\n    Options FollowSymLinks\n    AllowOverride All\n    AuthAuthoritative Off\n    AuthType Basic\n    AuthName 'my stuff'\n    AuthLDAPEnabled On\n    AuthLDAPURL 'ldap://ldapserver'\n    require group cn=blah,o=foo\n    Order allow,deny\n    Allow from all\n\nChanging the 'require group' to 'require ldap-attribute foo=bar' does not\nproduce the segmentation faults in the cache free or compare code.\n\nI have backported only the 2.1 util_ldap_cache code dealing with this function,\nspecifically the addition of numvals to the node struct and the logic to iterate\nbased on this value.  Crashes still occur with this change.\n
34209	David Arcuri	1112217784000	\nMore stack traces, crashing consistently in the same place now:\n\n\n\n(gdb) where\n#0  util_ldap_search_node_compare (a=0x0, b=0xffbfd328) at util_ldap_cache.c:147\n#1  0x0002f8bc in util_ald_cache_fetch (cache=0xfecd04a0, payload=0xffbfd328)\n    at util_ldap_cache_mgr.c:373\n#2  0x0002d708 in util_ldap_cache_checkuserid (r=0x0, ldc=0xffbfd328,\nurl=0xffbfd411 '&#65533;&#65533;t',\n    basedn=0xffbfd3f0 '(&(objectclass=*)(uid=test4806))', scope=916296,\nattrs=0xc9c00,\n    filter=0xff0d9ae4 '/237&#65533;/200', bindpw=0x1939c8 '/bliss_loan.cgi',\nbinddn=0x0, retvals=0x3d)\n    at util_ldap.c:780\n(gdb) quit\n\n\n[emadea3@unixweb2 apache2]$ sudo pstack core\ncore 'core' of 17258:   /tmp/httpd -f\n/usr/local/apache2/conf/qa.web-mi.mgic.com.conf -k start\n 0002ebc0 util_ldap_search_node_compare (0, ffbfd328, c9e9069, f0000000,\nffbfd410, 0) + 4\n 0002f8b4 util_ald_cache_fetch (fecd04a0, ffbfd328, ffbfd411, ffbfd3f0, dfb48,\nc9c00) + 50\n 0002d700 util_ldap_cache_checkuserid (0, 13a758, 12ae48, 12ae90, 2, 0) + 98\n 00030784 mod_auth_ldap_check_user_id (0, ffffffff, 0, 99800, 99800, ffffdfe8) + 190\n 0008d128 ap_run_check_user_id (18efe0, 0, 1, 1905a0, 190528, 0) + 3c\n 0008da44 ap_process_request_internal (0, b5c00, 18efe0, 10, fecb0020, 1) + 210\n 0005c208 ap_process_request (18efe0, ce800, 4, 18efe0, ceb90, 0) + 9c\n 000576d8 ap_process_http_connection (186888, 1867b0, 1867b0, 4, ceb90, 138698) + f4\n 0008163c ap_run_process_connection (186888, 1867b0, 1867b0, 4, 1847e8, 18af98) + 3c\n 000746c0 child_main (184808, 1, cdc00, cf000, 18af98, 4e2e) + 3b0\n 00074814 make_child (73c00, 4, 3, 2, a, cdc00) + b4\n 00074a90 perform_idle_server_maintenance (da098, ce36c, ffbff8a0, da098, dfa28,\n0) + 150\n 000750d4 ap_mpm_run (cdc00, cdc00, 0, ce800, cdc00, cdc00) + 594\n 0007adbc main     (da098, dfa28, ffbff9cc, cf094, cdc00, cdc00) + 610\n 0002bb2c _start   (0, 0, 0, 0, 0, 0) + 5c\n\n\nThere's some garbage in the arguments, stack getting corrupted?  This does not\nhappen on every request -- I have a script running to continuously pump requests\nwith random ID/password into the server from a pool of 5000 LDAP objects so I\ncan fill the cache.  I can get generally 1 failure in every 100 requests until\nit starts purging the cache, then that number increases to approximately 1 in\n10.  This is not acceptable for production website so I have eliminated the\nissue by using ldap-attribute instead of group for now.\n
34209	Brad Nicholes	1112227377000	I can see where there is the possibility of having a NULL payload in the cache \ndue to a node copy unable to succeed because of memory allocation issues, but \nI am unable to duplicate this problem on either NetWare or SUSE Linux.  Adding \na NULL check in the node free routine couldn't hurt.  \n\nThere are a couple of problems that I see with the example configuration.  \nFirst, are member and/or uniquemember attributes of the group object public?  \nIf not then all of your accesses will probably fail anyway unless you \nconfigure a username and password for util_ldap to use when accessing ldap.  \nAlso, there isn't a base context defined in the ldap url.  Was this just a \ntypo?  Anyway, with or without the mis-configuration, I am still unable to \nduplicate the problem.
34209	David Arcuri	1112228003000	\nyes, sorry, there's a base context in the 'real' LDAP URL ... Everything does\nwork correctly -most- of the time.  The 2nd set of stack dumps (where it dumps\nin util_ldap_search_node_compare) is the most recent set of problems I am\nhaving.  I can replicate the intermittent crash (~ 1 out of 20) every time I use\na 'require group cn=foo,o=bar' and it crashes every time in the same function\n(see above.)  And every time the stack trace via gdb seems to have corruption in\nthe arguments to the util_ldap_cache_checkuserid function.  I have tested this\nwith thousands of requests with random IDs from a pool, to stress both the cache\nfilling and purging.  It seems to not exhibit crashy behavior until after the\nfirst purge.\n\nIf you'd like any additional information, I can replicate this easily, and would\nbe happy to provide any other debugging information you need to examine this\nmore fully.\n\nUsing prefork, by the way, if that matters.  (Was debugging with single thread,\nstill got the crash.)\n
34209	David Arcuri	1114035444000	\nThis is what happens when LDAPSharedCacheSize is too small and the out of memory\ncondition is not handled well.  There's no error or anything returned by the\ncalloc functions.  I suspect it's a problem in Solaris only, if no one can\nreplicate this on any other OS.  From reading past bug reports it seems the\nshared memory code on Solaris is problematic at best, anyway.  Increasing\nLDAPSharedCacheSize to a reasonably high value that will not be exceeded during\nregular webserver activity has made this problem go away.
34209	Paul Querna	1114039399000	I think this error condition should be handled. A Crash is not acceptable to me.
34209	Toshiya_Kobayashi	1114052196000	This Problem is reproducible in Redhat AS 2.1.\n\nIt is a little bit difficult to determine 'a reasonably high value' of \nLDAPSharedCacheSize. But I think the default value of \nLDAPSharedCacheSize '100KB' is too small for the default of \nLDAPCacheEntries '1024'.
34209	David Arcuri	1114099047000	\nMaybe it would be helpful if the default settings in the documentation didn't\nreflect a 200k cache size with 1024 entries?  I have mine set to 1024000 with\n512 entries and 120 second timeouts and have just ran 40,000 test hits against\nthe cache with no failures.\n\n
34209	Joe Orton	1122554607000	Created an attachment (id=15811)\nfix cache corruption with full cache\n\nThis patch fixes the cache corruption at full cache for me.
34209	Ryan Morgan	1122692069000	Joe,\n\nWe have loaded tested with this patch applied and it appears to have fixed the cache corruption problem \nfor us as well.
34209	Joe Orton	1123000494000	Good to hear, Ryan.\n\nThis has been committed to the trunk and submitted for backport to 2.0.x.\n\nhttp://svn.apache.org/viewcvs?rev=225746&view=rev\n\nNote that there is at least one other bug I know if in the current 2.0.x code\nwhich could cause cache corruption; the fact that the mutex protecting the shm\nsegment is not initialized properly (see r105412).  I'll be proposing that for\nbackport too.
34209	Joe Orton	1123157015000	Committed for 2.0.55.
34209	Joe Orton	1123443542000	*** Bug 35695 has been marked as a duplicate of this bug. ***
34266	Mladen Turk	1113039668000	Fixed in the HEAD.\nThe reason was that only the true proxy requests pass the query\nstring. Now we are setting this correctly by using parsed args if\nnot present in r->uri.
34275	Basant Kumar Kukreja	1173701389000	I failed to reproduce the issue. I have seen this issue in past regarding\napr_timeout. But in my recent trials, I failed to reproduce the issue.\n\nI tried to increase the concurrency to 1800 but still fails to reproduce the\nissuse. All of the below worked for me.\n./bin/ab -n 550000 -c 2000 -k http://serverhost:1894/micro-benchmarks/snoop.jsp\n./bin/ab -n 550000 -c 1500 -k http://serverhost:1894/micro-benchmarks/snoop.jsp\n./bin/ab -n 550000 -c 2000 -k http://serverhost:1894/micro-benchmarks/snoop.jsp\n./bin/ab -n 550000 -c 1800 -k http://serverhost:1894/micro-benchmarks/snoop.jsp\n./bin/ab -n 550000 -c 1800 -k -i http://serverhost:1894/micro-benchmarks/snoop.jsp\n./bin/ab -n 550000 -c 1800 -k -i http://serverhost:1894/index.html\n/usr/bin/ab -n 550000 -c 1800 -k -i http://serverhost:1894/index.html\n/usr/bin/ab -c 1800 -k -i http://serverhost:1894/index.html\n/usr/bin/ab -t 60 -c 1800 -k -i http://serverhost:1894/index.html\n/usr/bin/ab -t 60 -c 1000 -k -i http://serverhost:1894/index.html\n/usr/bin/ab -t 60 -c 1000 -k http://serverhost:1894/index.html\n\nRecent build on 2.2.x branch:\n# ./bin/ab -V\nThis is ApacheBench, Version 2.0.40-dev <$Revision: 1.146 $> apache-2.0\nCopyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/\nCopyright 2006 The Apache Software Foundation, http://www.apache.org/\n\nFedora core 5 httpd\n# /usr/bin/ab -V\nThis is ApacheBench, Version 2.0.40-dev <$Revision: 1.146 $> apache-2.0\nCopyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/\nCopyright 1997-2005 The Apache Software Foundation, http://www.apache.org/\n\n
34275	Basant Kumar Kukreja	1173703012000	Bostjan, can you try with recent version of ab to confirm if it reproduces the\nissue?\n\nIs server/client running on same box?\n
34275	Takashi Sato	1191045505000	I successed to reproduce this bug with 2.2.6 (both server and ab).\nI'm not sure this is a issue of ab.
34275	Takashi Sato	1200558277000	Created an attachment (id=21402)\nagainst trunk\n\nset c->length zero when HEAD
34275	Takashi Sato	1200558406000	Content-Length doesn't mean a response body size when a request method is HEAD.
34275	Ruediger Pluem	1200571366000	Thanks for the patch. Committed to trunk as r612954\n(http://svn.apache.org/viewvc?rev=612954&view=rev).
34275	Takashi Sato	1204090481000	How about backporting?\nBenchmark of both HEAD and Keep Alive is not special.
34275	Ruediger Pluem	1204115851000	Proposed for backport as r631712 (http://svn.apache.org/viewvc?rev=631712&view=rev). Thanks for the reminder.
34275	Takashi Sato	1208418972000	backported to 2.2\n<http://svn.apache.org/viewvc?rev=649115&view=rev>
34452	Joe Orton	1113497277000	There have been a couple of reports like this recently.  Do you have a precise\nreproduction case with a specific version of MSIE, which only triggers in those\nparticular httpd versions?  What's logged to the error log for the SSL vhost?\n\nAnyway, the default SSL vhost configuration will disable keepalives for MSIE for\nthe SSL vhost, using the SetEnvIf below; I take it you have disabled this?\n\nSetEnvIf User-Agent '.*MSIE.*' /\n         nokeepalive ssl-unclean-shutdown /\n         downgrade-1.0 force-response-1.0\n
34452	Joe Orton	1113497332000	Please also include the full SSL configuration you're using,
34452	Eirik Gjesteland	1113500007000	Created an attachment (id=14715)\nSSL configuration\n
34452	Eirik Gjesteland	1113500221000	For performance reasons (throughput was halfed without keep-alive) the default \nSetEnvIf has been disabled. As 95% of our users use IE, it is not an option to \nuse this setting.\n\nWe tried to include just SetEnvIf User-Agent '.*MSIE.*' ssl-unclean-shutdown, \nbut it did not fix the problem.\n\nWe have also tried to run without mod_deflate, but that didn't help either.\n\nMy full IE version is 6.0.2800.1106.xpsp2_gdr.040517-1325CO with updates \nQ323308, Q832894, Q837009 and Q867801. We have received error reports from \nusers with different versions, though.\n\nThe full SSL config file is now attached (virtual section included).
34452	Eirik Gjesteland	1113500763000	Nothing is logged in the ssl logs on the server. In fact I don't think the \nrequest reaches the server at all, as Explorer seems to try to use a connection \nthat is in CLOSE_WAIT state. One could argue that this seems like an Explorer \nbug, but as we easily reproduce this problem in 2.0.52/53 and not in 40/47, \nsome unfortunate change seems to have been introduced after 47.
34452	Joe Orton	1113503466000	OK, more things it would be useful to try:\n\n1. MSIE can be sensitive to session caching; try switching to the\nSSLSessionCache shmcb:... line\n\n2. it would be useful to narrow down where the regression occurs; particularly,\nif it works with 2.0.48 and fails with 2.0.49, that's useful; there was a\nsignificant change to the SSL connection closure handling there, but it\nshouldn't take effect if you have ssl-unclean-shutdown configured for *MSIE*.\n\n3. get some useful logs; add to the SSL vhost config:\n\nLogLevel debug\nErrorLog logs/ssl_debug_log\n\nand attach the resultant ssl_debug_log showing the reproduction of the failure\n(or better yet; a before-and-after with a version which works and one which doesn't)
34452	Eirik Gjesteland	1113559253000	Created an attachment (id=14724)\nSSL debug log from 2.0.40 (no error)\n\nPerformed the following steps:\n1. Navigated to https://10.110.64.26/ega/connectiontest/index.html (this page\ncontains a lot of large images so that explorer sets up many connections\n2. Waited until all connetions were in CLOSE_WAIT state (~30 secs)\n3. Navigated to https://10.110.64.26/ega/\n\n10.110.5.11 is the proxy server\n10.110.64.26 is the reverse proxy server\n10.110.64.6 is the web server
34452	Eirik Gjesteland	1113559311000	Created an attachment (id=14725)\nSSL debug log from 2.0.52 (page cannot be displayed)\n\nPerformed the following steps:\n1. Navigated to https://10.110.64.26/ega/connectiontest/index.html (this page\ncontains a lot of large images so that explorer sets up many connections\n2. Waited until all connetions were in CLOSE_WAIT state (~30 secs)\n3. Navigated to https://10.110.64.26/ega/\n\n10.110.5.11 is the proxy server\n10.110.64.26 is the reverse proxy server\n10.110.64.6 is the web server
34452	Eirik Gjesteland	1113559377000	Created an attachment (id=14726)\nSSL debug log from 2.0.52 ssl2 (no error)\n\nPerformed the following steps:\n1. Navigated to https://10.110.64.26/ega/connectiontest/index.html (this page\ncontains a lot of large images so that explorer sets up many connections\n2. Waited until all connetions were in CLOSE_WAIT state (~30 secs)\n3. Navigated to https://10.110.64.26/ega/\n\n10.110.5.11 is the proxy server\n10.110.64.26 is the reverse proxy server\n10.110.64.6 is the web server
34452	Eirik Gjesteland	1113559750000	schmcb caching did not help.\n\nI have uploaded some log files from 2.0.52 and 2.0.40.\n\nIf you still need more info I can try to narrow down where the problem occurs \nin a few days.
34452	Eirik Gjesteland	1113564699000	I have now verified that the error is reproducable in 2.0.49 but not in 2.0.48.\n\n
34452	Eirik Gjesteland	1113832987000	I looked at the code and it seems the problem is that ssl-unclean-shutdown is \nignored.\n\nIf you change the default: behaviour in the switch in ssl_filter_io_shutdown() \nin ssl_engine_io.c to unclean the problem disappears.\n\nI guess sslconn->shutdown_type should be set by ssl_configure_env in \nssl_engine_kernel.c, but it seems like this function is not run at all. I don't \nknow the httpd architecture well enough to find why not.\n\nThe reason it worked in 2.0.48 is that the block\n\nelse if (AP_BUCKET_IS_EOC(bucket)) {\n            /* The special 'EOC' bucket means a shutdown is needed;\n             * - turn off buffering in bio_filter_out_write\n             * - issue the SSL_shutdown\n             */\n            filter_ctx->nobuffer = 1;\n            status = ssl_filter_io_shutdown(filter_ctx, f->c, 0);\n            if (status != APR_SUCCESS) {\n                ap_log_error(APLOG_MARK, APLOG_INFO, status, NULL,\n                             'SSL filter error shutting down I/O');\n            }\n            if ((status = ap_pass_brigade(f->next, bb)) != APR_SUCCESS) {\n                return status;\n            }\n            break;\n        }\n\nwas inserted in ssl_io_filter_output in ssl_engine_io.c.\n\nDoes this make sense?
34452	Joe Orton	1113834190000	That does make perfect sense, I was wondering whether that might be the issue. \nBut we now need to work out why the shutdown_type is not getting set; I'll try\nsome tests here.  Thanks a lot!
34452	Joe Orton	1113835526000	Ugh, yes.  ssl_configure_env is called from mod_ssl's ssl_hook_Translate, but\nthat won't run if, e.g. mod_proxy's translate_name hook is run first and returns\nOK, as happens in the reverse-proxy case.\n\nI have no idea why that section of mod_ssl code needs to be in a translate_name\nhook, it's probably historical.  If it can be moved somewhere more sensible this\nwill work.
34452	Joe Orton	1113836518000	Created an attachment (id=14750)\nproposed mod_ssl fix\n\nHere's a patch which should fix this; it moves the ssl_configure_env call to\nthe post_read_request hook, and runs said hook slightly later to ensure that it\nruns later than the mod_setenvif post_read_request hook (a quick hack for\ntesting purposes, I'll do better when committing this).\n\nPatch should apply against 2.0.5[34]-ish.
34452	Joe Orton	1114217271000	Created an attachment (id=14804)\nequivalent patch for 2.0.x backport proposal\n\nThis patch is to be proposed for backport to 2.0.x and is essentially\nequivalent to the previous patch.
34452	Joe Orton	1114418834000	Fixed on the trunk: http://svn.apache.org/viewcvs?view=rev&rev=161958\nand proposed for backport to 2.0.x.  Thanks again for your help debugging this\nissue!
34452	Richard	1146073412000	Does anybody know whether or not this fix was incorporated in the 2.2 tree?   \n\nWe recently upgraded from 2.0.48 to 2.2.0 and are now seeing a similiar issue \nto what's reported here.   Let me know if you require additional information.  
34452	Ruediger Pluem	1146078876000	This patch is also contained in 2.2.0.
34452	Davi Arnaut	1181374798000	*** Bug 20641 has been marked as a duplicate of this bug. ***
34512	Paul Querna	1117773897000	Fixed in r179704
34520	Per Olausson	1113925286000	Created an attachment (id=14755)\nlibtool patch to enable different (hard-coded) deployment directory \n\nThis patch is not suitable for inclusion to apache, but just shows how/what\ndiffers from the vanilla source.
34520	Per Olausson	1113925352000	We have one patch applied to libtool applied to enable us to use a dedicated\nbuild host which builds in one directory structure\n(/appl/cm/build/<env>/<component>/... while we deploy into an environment which\nexpects things to reside under /appl/active/apache/... I never saw any other way\nof achieving this and as far as I can tell it has no bearing on this defect. The\npatch is listed below.\n\nOtherwise there has been no other changes to the distro version and the\nconfigure options etc are the same as we use for a 2.0.51 build.\n\n
34520	Joe Orton	1113925606000	  SSL_SESSION *d2i_SSL_SESSION(SSL_SESSION **a,const unsigned char * const *pp,\n\t\t\t     long length);\n\nthat's not from any OpenSSL release.  What SSL library are you using?
34520	Per Olausson	1113926097000	We are using OpenSSL v0.9.7g. However this bug is in mod_ssl...\n\nIs apache/modssl incompatible with 0.9.7g?
34520	Per Olausson	1113926771000	Sorry, the signature comes from openssl/include/ssl.h...and I can't see that\nthat has changed recently.
34520	Joe Orton	1113927211000	Cripes, yes, they changed it between .7f and .7g! Very bad :( We'll have to fix\nthis in mod_ssl with a bunch of ifdef fun, yes.\n\n@@ -1268,17 +1268,18 @@\n int    SSL_set_generate_session_id(SSL *, GEN_SESSION_CB);\n int    SSL_has_matching_session_id(const SSL *ssl, const unsigned char *id,\n                                        unsigned int id_len);\n-SSL_SESSION *d2i_SSL_SESSION(SSL_SESSION **a,unsigned char **pp,long length);\n+SSL_SESSION *d2i_SSL_SESSION(SSL_SESSION **a,const unsigned char * const *pp,\n+                            long length);\n
34520	Per Olausson	1113928211000	Okay, so the story is that 0.9.7g isn't supported with current version of apache\n2.0.54!
34520	Joe Orton	1116426322000	If you edit build/config_vars.mk and remove the '-qHALT=E' from whichever CFLAGS\nline it ends up in, it should compile OK with warnings.
34520	Will Rowe	1120696030000	  'Okay, so the story is that 0.9.7g isn't supported with current version \n   of apache 2.0.54!'\n\n<rant>\nPeople quit your bitching!!!  If a library vendor screws with declarations\nin the midst of subversion bumps, you expect us to be psychic?!?  Someone\nshould have mentioned this to the SSL project, but I suppose noone here\nbothers to test OpenSSL cvs HEAD.\n</rant>\n\nIn the coming 2.0/2.1-dev releases this is addressed.  It's now committed\nto cvs HEAD.  Thanks Joe for calling out the specific bump :)
34520	Joe Orton	1120758014000	Ease up, Bill.  Per just made a semi-accurate statement of the current state of\nplay, the fact that someone took the time to report the issue is appreciated. \nYes, the API break has been mentioned to openssl-dev, too.
34542	Andr?? Malo	1114072450000	But that would break nph-scripts, wouldn't it?
34542	Pradeep Kumar S	1114081479000	(In reply to comment #1)\n> But that would break nph-scripts, wouldn't it?\nI have just removed the second 3 lines leaving the first 4 lines intact. I have \ntested that with nph scripts. It works. This ensures that nph scripts get just \nthe filename and the others get the whole path.\n\nSo the code is \n---------------\nconf = ap_get_module_config(r->server->module_config, &cgid_module);\n    is_included = !strcmp(r->protocol, 'INCLUDED');\n\n    if ((argv0 = strrchr(r->filename, '/')) != NULL)\n        argv0++;\n    else\n        argv0 = r->filename;\n\n    nph = !(strncmp(argv0, 'nph-', 4));\n\n-    if ((argv0 = strrchr(r->filename, '/')) != NULL)\n-        argv0++;\n-    else\n        argv0 = r->filename;\n\n    if (!(ap_allow_options(r) & OPT_EXECCGI) && !is_scriptaliased(r))\n        return log_scripterror(r, conf, HTTP_FORBIDDEN, 0,\n                               'Options ExecCGI is off in this directory');\n    if (nph && is_included)\n        return log_scripterror(r, conf, HTTP_FORBIDDEN, 0,\n                               'attempt to include NPH CGI script');\n\n------------------------------------------------\n
34542	Will Rowe	1125353598000	\n  Yes, this behavior was broken between mod_cgi and mod_cgid, because the\n  developer hadn't noted that we -tested- argv0 in mod_cgi, but then passed\n  argv[0] for the creation call, and therefore assumed the short name was\n  the argv[0] argument.\n\n  Fixed in SVN trunk, and proposed for backport.\n\n  
34588	Joe Orton	1114708828000	Good catch!  Thanks for the report.\n\nhttp://svn.apache.org/viewcvs?rev=165151&view=rev
34588	Joe Orton	1118228485000	Merged for 2.0.55.  http://svn.apache.org/viewcvs.cgi?rev=189561&view=rev
34618	Joe Orton	1114709308000	*** Bug 34620 has been marked as a duplicate of this bug. ***
34618	Joe Orton	1114709404000	Brad Nicholes requested that someone test this patch:\n\nhttp://svn.apache.org/viewcvs/httpd/httpd/trunk/modules/ldap/util_ldap.c?rev=164919&r1=164918&r2=164919&view=diff
34618	Vincent MATHIEU	1114724160000	(In reply to comment #2)\n> Brad Nicholes requested that someone test this patch:\n> \n>\nhttp://svn.apache.org/viewcvs/httpd/httpd/trunk/modules/ldap/util_ldap.c?rev=164919&r1=164918&r2=164919&view=diff\n\nI try to execute this patch (with 2.0.54 util_ldap.c).\nI have an error during patch executing :\n\nFile to patch: util_ldap.c\npatching file util_ldap.c\nHunk #1 FAILED at 247.\nHunk #2 succeeded at 321 (offset -9 lines).\nHunk #3 FAILED at 1784.\nHunk #4 FAILED at 1917.\n3 out of 4 hunks FAILED -- saving rejects to file util_ldap.c.rej\n
34618	Joe Orton	1114726301000	Brad, can you provide a patch which applies to 2.0.x which mod_ldap users can test?
34618	Brad Nicholes	1114729601000	Created an attachment (id=14873)\nswitch to connection timout per ldap connection\n\nTest the ldap connection timeout on a per connection basis rather than global
34618	Vincent MATHIEU	1114775627000	(In reply to comment #5)\n> Created an attachment (id=14873) [edit]\n\nGood!\nI compiled apache2.0.54 with your patch.\nI do not have any more segmentation faults\n\nThank's
34618	Brad Nicholes	1114793052000	Created backport proposal in the STATUS file.  Just waiting for the three +1 \nvotes.
34618	Joe Orton	1115215394000	*** Bug 34705 has been marked as a duplicate of this bug. ***
34618	Justo Alonso	1115315263000	I installed the patch and compiled it, and at first it seemed to work. But I do\nsome tests, works, and then if some time passes from the last test and I make a\nnew one, the apache process hangs.\n\nI think that the ldap connection pool has some issues with the connection\ntimeouts and that makes the apache process to be unresponsive,
34618	Brad Nicholes	1116453880000	The patch has been backported to 2.0.55-dev
34618	Joshua	1121140930000	i tried the patch with apache 2.0.54 and recompiled. I still getseg faults in\nthe error log\n\n[Tue Jul 12 11:57:52 2005] [notice] child pid 24029 exit signal Aborted (6)\n[Tue Jul 12 11:57:54 2005] [notice] child pid 23956 exit signal Segmentation\nfault (11)\n\nany ideas
34618	Markus Schuh	1121801282000	I tried the patch on a LDAP enabled apache-2.0.54 on SuSE Enterprise Linux 9 \nbut get more segmentation faults afterwards. This apache was compiled against \nthe builtin openldap 2.2.6 in SLES9.\n\nAfter installation of openldap-2.2.27 and recompilation of apache against this \nversion the segmentation faults are gone.\n\nThis seems to be related to the following patch in openldap 2.2.20\n\nhttp://www.openldap.org/its/index.cgi/Software%20Bugs?\nid=3487;expression=TIMEOUT;casesensitive=1;usearchives=1;statetype=-1\n
34618	Broughan	1122013098000	We also applied the patch to 2.0.54 and the segmentation fault errors appeared \nagain, although less frequent. I see there was a bug fixed in openldap, we use \nmod_ldap and auth_ldap, should we be using openldap?
34618	Brad Nicholes	1122022679000	Yes, you need to update OpenLDAP\n\n(In reply to comment #13)\n> We also applied the patch to 2.0.54 and the segmentation fault errors \nappeared \n> again, although less frequent. I see there was a bug fixed in openldap, we \nuse \n> mod_ldap and auth_ldap, should we be using openldap?\n\n
34618	Broughan	1124251192000	We are having the same problem with Microsoft Active Directory Service (Windows \n2000), we don't use OpenLDAP.\n\nWe did the patch on 2.0.54 but didn't help. So we're looking for a Windows 2000 \nbug now?\n\nIs this bug closed because it works with OpenLDAP server? Can anyone else test \non Windows 2000?\n\n\n(In reply to comment #14)\n> Yes, you need to update OpenLDAP\n> (In reply to comment #13)\n> > We also applied the patch to 2.0.54 and the segmentation fault errors \n> appeared \n> > again, although less frequent. I see there was a bug fixed in openldap, we \n> use \n> > mod_ldap and auth_ldap, should we be using openldap?\n\n
34618	Joe Orton	1124363108000	Broughan, this bug concerns a specific issue with OpenLDAP introduced in 2.0.54\nwhich is now fixed for 2.0.55.\n\nBug 18334 seems to be a generic 'problems with Microsoft LDAP SDK' bug.
34834	Timo Viipuri	1115720638000	Created an attachment (id=14981)\nPatch to modify server/util.c:ap_getword_conf() to accept a trailing backslash\n
34834	Paul Querna	1116962778000	Commited to trunk in revision 178209.\n\nThanks for writing the patch!
35081	Joe Orton	1117811714000	Thanks, Mark.  Committed to the trunk and proposed for backport.\nhttp://svn.apache.org/viewcvs?rev=179781&view=rev\n\nPlease note that bugs which you think may have security implications should be\nreported in the first place to security@apache.org address.
35081	Joe Orton	1118228980000	Merged for 2.0.55.  http://svn.apache.org/viewcvs?rev=189562&view=rev
35178	Paul Querna	1117773671000	Fixed in trunk.
35211	Paul Querna	1118716799000	Fixed in trunk.  Went with modifiying the .headers file format to include a new\n'Vary Headers' format.
35279	Joe Orton	1118311934000	Created an attachment (id=15345)\npossible fix\n\nThanks for the detailed report and analysis.  Can you try this patch?
35279	Joe Orton	1118424115000	This looks obviously correct, so, committed to trunk;\nhttp://svn.apache.org/viewcvs?rev=189971&view=rev\nand proposed for backport for 2.0.x.\n\nThanks again for the report and analysis.
35279	Jean Dagenais	1118759070000	We have tested the fix and confirm that the problem is resolved.\n
35292	Gonzalo Paniagua Javier	1118338948000	Created an attachment (id=15353)\nPatch that fixes the problem.\n\nThis patch fixes the issue and 2 warnings I got with -Wall on apr_shutdown and\napr_recv not being declared.
35292	Paul Querna	1118341246000	apr_shutdown should be part of apr_compat.h.  The submitted patch is against the\n2.0.x branch, not trunk.
35292	Joe Orton	1118420830000	This was mentioned on http-wg a while ago, indeed.\n\nDoes the current behaviour actually cause practical problems?  The change\nintroduces an extra gettimeofday() call into the normal processing of every\nrequest so it needs good justification.
35292	Gonzalo Paniagua Javier	1118426814000	I found this out because I was sending a POST of a few MB to a web service, but\nI got the url wrong and saw that there were 15 small reads when closing before i\ngot the RST when trying to read from the socket.
35292	Joe Orton	1118433126000	OK, there are a few alternatives here:\n\n- take the hit on the uncommon path where the read() doesn't get EOF first time\nthrough, and keep calling read()/apr_time_now() until 30 seconds have *really*\npassed\n\npro: equally as safe as 1.3 code\ncon: more overhead\n\n- bump the tmp buffer size to 8K and lower the read() timeout to 1 second.  this\nway the server could eat 30*8K=245K bytes without additional overhead, giving a\nsignificantly better chance of getting the response to the client than just\n15*512=~7K\n\npro: little more overhead than current 2.0 code\ncon: still less safe than 1.3
35292	Gonzalo Paniagua Javier	1118435543000	If there's anything I can say, I'd go for the first alternative and linger for\nat most ~32s, while not incurring in any additional penalty for the common path.
35292	Jeff Trawick	1118518710000	The reason that such code isn't in there now is to avoid all the syscalls\n(retrieving the time).  Some cleverness may allow an implementation that is\nwilling to wait longer (close to MAX_SECS_TO_LINGER) without retrieving the time\nso much.
35292	Gonzalo Paniagua Javier	1118522233000	Created an attachment (id=15375)\nSecond attempt. Patch against http-2.0.x\n\nHow about this? There are no calls to time() involved. The first read polls for\nup to 30s and subsequent ones only for 0.5s, with a limit on the maximum number\nof reads that doubles the maximum read length existing now.
35292	Gonzalo Paniagua Javier	1118522295000	Oops. Forgot to increment nread_ops in the loop.
35292	Joe Orton	1118584016000	I don't see how that implementation actually fixes the problem.  Or am I missing\nsomething fundamental?\n\nThe *problem* is that the server is not reading enough bytes from the socket to\neat up the TCP window and prevent an RST from allowing the client to see the\nresponse.  Just changing the timeouts makes no difference, the solution needs to\nactually increase the number of read() calls made (and/or increase the buffer\nsize passed to read).\n\nIn the situation which lingering close is helping, the first read call is *not*\ngoing to time out; the TCP receive buffer for this socket on the server will\nalready be non-empty so it will necessarily return data immediately.\n\nChanging that first timeout just introduces a new problem; if the client\ndisappears completely after reading the response, the server will now hang\naround for thirty seconds waiting for a FIN that will never arrive, rather than\njust for two seconds.\n
35292	Joe Orton	1127686605000	Fixed on trunk and back-ported for 2.1.8 and later.\n\nhttp://svn.apache.org/viewcvs?rev=291452&view=rev
35292	Joe Orton	1127687036000	*** Bug 17722 has been marked as a duplicate of this bug. ***
35330	kabe	1118535416000	*** Bug 35329 has been marked as a duplicate of this bug. ***
35330	Sander Temme	1127166471000	We now have a 'regression' severity in Bugzilla. Removed the keyword. 
35330	Joe Orton	1127492986000	Thanks a lot for the patch (attaching it might have avoided the line-wrapping ;).\nThis has been applied for 2.1.8.\n\nhttp://svn.apache.org/viewcvs?rev=291125&view=rev
35343	Will Rowe	1198338126000	Fantastic suggestion, thank you!  Adopted a similar patch for the \nnext 2.0.62/2.2.7 releases, along with quite a bit of additional\nvetting of the results, resolution of a possible segfault, and also\ncaught the possibility of winsock2 linkages not working.
35469	Joe Orton	1122466460000	Created an attachment (id=15793)\npossible fix\n\nLooks like the right solution.\tCan you try this patch?
35469	Nick Grynkewich	1122670061000	Apologies for the delay; I was unable to install your patch, per se. However, I\nmade this change:\n\n$ diff -u modules/ssl/ssl_engine_init.orig modules/ssl/ssl_engine_init.c   \n--- modules/ssl/ssl_engine_init.orig    Fri Jul 29 12:17:39 2005\n+++ modules/ssl/ssl_engine_init.c       Fri Jul 29 12:17:56 2005\n@@ -83,6 +83,7 @@\n \n     SSL_load_error_strings();\n     SSL_library_init();\n+    OpenSSL_add_all_algorithms();\n }\n \n /*\n\nAnd that fixes the problem. So, assuming that my inability to apply the patch is\nstrictly user error (most likely case). Then I would consider this resolved.
35469	Joe Orton	1123250676000	OK thanks, applied on the trunk. 
35550	Roy T. Fielding	1188213262000	Added .ecma to trunk in rev 570206.\n\nThe .es extension is already used by languages (Spanish).\n
36090	Chris Darroch	1123557542000	Created an attachment (id=15973)\nsuggested patch to ap_process_request()\n
36090	Chris Darroch	1133539313000	Created an attachment (id=17122)\nfor 2.2.0\n\nupdated for 2.2.0
36090	Nick Kew	1134133220000	Fixed for 2.2.1 in Revision 355454. 
36166	Joshua Slive	1124124850000	It does actually refer to the URL-Path, although the term 'fully qualified' is\nprobably misleading.  It means that the path must start with a slash, and cannot\nbe relative to the directory containing the .htaccess file.
36166	Ryan Schmidt	1124127033000	Ah, I see... And what of 'URL'? Must it be a full URL with protocol, or can it be a 'fully-qualified URL' (i.e. \nstarting with a slash)? Could it be a relative URL? The examples only show full URLs with protocol, but the \ndocumentation does not seem to specify whether other forms are also permissible.
36166	Joshua Slive	1124133685000	It is best practice to use a full URL starting with a scheme, although I believe\nthat recent versions will also take a URL-path and tag on the current server name.\n\nBut you are right that this all should be clarified.  Something along the lines\n<usage>\n<p>The Redirect directive maps an old URL into a new one by asking the client to\nrefetch the resource at the new location.</p>\n\n<p>The old <em>URL-path</em> is a (%-decoded) path beginning with a slash.  A\nrelative path is not allowed.  The new <em>URL</em> should be an absolute URL\nbeginning with a scheme, but a URL-path beginning with a slash may also be used,\nin which case the scheme and hostname of the current server will be added.</p>\n\n<p>Then any request beginning with <em>URL-Path</em> will return a redirect\nrequest to the client at the location of the target <em>URL</em>.  Additional\npath information beyond the matched <em>URL-Path</em> will be appended to the\ntarget URL.</p>\n\n...
36166	Joshua Slive	1125086102000	Fixed in 2.1.
36410	Colm MacCarthaigh	1125354843000	Not quite on the unixd.c, but there is a more correct way of doing this within\ncgid, working on it now.
36410	Colm MacCarthaigh	1125409058000	This bug has been fixed in trunk, see;\n\nhttp://svn.apache.org/viewcvs?rev=264759&view=rev
36410	Colm MacCarthaigh	1125420894000	A patch for the 2.2.x branch is now available at;\n\nhttp://people.apache.org/~colm/2.2.x-suexec-cgid.patch
36410	Colm MacCarthaigh	1125420989000	Apologies, I meant the 2.0.x branch;\n\nhttp://people.apache.org/~colm/2.0.x-suexec-cgid.patch
36438	Joe Orton	1125583597000	Thanks for the report.  This is fixed on the trunk:\n\nhttp://svn.apache.org/viewcvs.cgi?rev=265702&view=rev
36506	Joshua Slive	1185885280000	Several years later...\nThanks, I've improved the documentation on this point by adding a separate\nsection discussing it.
36507	R??diger Pl??m	1127949453000	Created an attachment (id=16546)\nPatch against trunk\n\nI can confirm this problem.\nThe attached patch should fix this. Can you please give it a try?
36507	Christoph Bachhuber-Haller	1128437278000	Hi Ruediger,\n\n(In reply to comment #1)\n> Created an attachment (id=16546) [edit]\n> Patch against trunk\n> \n> I can confirm this problem.\n> The attached patch should fix this. Can you please give it a try?\n\nI can confirm that this patch fixes my problem. Thank you very much! I wonder\nthough whether the tomcat session id format is any standard or if apache should\nsupport sticky sessions for load balancing in a more generic way. \n\nBye,\nChristoph
36507	Ruediger Pluem	1128509877000	Committed to trunk (r295013)\nhttp://svn.apache.org/viewcvs.cgi/httpd/httpd/trunk/modules/proxy/mod_proxy_balancer.c?rev=295013&r1=279973&r2=295013
36507	Ruediger Pluem	1128640485000	Committed and backported to 2.2.x branch (r306888).
36507	Ruediger Pluem	1128640860000	> though whether the tomcat session id format is any standard or if apache should\n> support sticky sessions for load balancing in a more generic way. \n\nIt does. As you can choose the name of the cookie you can make any application\nwhere you can set a cookie work with that. Just set cookie BLAH=a.route in your\napplication. Of course it is more convenient if the application container is\nable to do this (like Tomcat). BTW: I know no standard for coding such routing\ninformation inside a cookie. But if you know one I would be interested to get it\nknown.
36563	Brad Nicholes	1126223513000	  This has been fixed in Apache 2.1 rev. 156587 but never backported to Apache \n2.0.\n\n*** This bug has been marked as a duplicate of 33901 ***
36563	Ondrej Sury	1126258739000	Will you accept backported patch if I prepare it?\n\nOndrej
36563	Brad Nicholes	1126285318000	  Sure.  It will have to be proposed for backport, reviewed and accepted by a \nvote before it actually makes it into the code.  But it can certainly be done.
36563	Ondrej Sury	1126911882000	Created an attachment (id=16429)\nBackported patch to fix invalid cache content handling\n
36563	Ondrej Sury	1126911978000	Hi,\nI have created backport of fix for correct cache items handling if they include\nNULL values, thus reopening bug and changing severity to wishlist.\n\nOndrej.\nP.S.: If this is not correct way how to propose backport then bang me :-)
36563	Brad Nicholes	1126919185000	Proposed for backport to 2.0.  Waiting for votes.
36563	Ondrej Sury	1127142601000	Changing severity to Major, since this bug is not as harmless as I thought to be.\nThere is memory leak in util_ldap_search_node_free().  Only items before first\nitem with NULL value are freed, and rest of items are left in cache.
36563	Brad Nicholes	1127492867000	Backported to 2.0.55
36883	Noel J. Bergman	1128312417000	If you bring up the same stock configurations described above, you can also \nreproduce the redirect to HTTPS problem by accessing http://tomcat/tomcat-docs.
36883	Noel J. Bergman	1128629141000	I can reproduce the problem with 5.5.12 (and httpd 2.0.8) as well, so since \nfrom the lack of response no one in tomcat-dev appears to care about problems \nwith 5.0.x, I'm modifying the record to show that it effects the current \ndevelopment branch, too.
36883	Noel J. Bergman	1128629394000	(In reply to comment #2)\n> ... httpd 2.0.8 ...\n\nEr, make that 2.1.8, i.e., the latest available code.
36883	william.barker@wilshire.com	1128637347000	(In reply to comment #2)\n> I can reproduce the problem with 5.5.12 (and httpd 2.0.8) as well, so since \n> from the lack of response no one in tomcat-dev appears to care about \nproblems \n> with 5.0.x, I'm modifying the record to show that it effects the current \n> development branch, too.\n\nIt seems that the problem is that mod_proxy_ajp isn't playing nice with \nmod_ssl (so that this is really a Httpd bug).  Even when the connection isn't \nHTTPS, mod_proxy_ajp is sending (empty) SSL attributes like cipher, client-\ncert, session-id.  This causes Tomcat to believe that the request was recieved \non HTTPS, so it redirects accordingly.  Below is a dump of the Request message \nthat Tomcat recieves from Httpd:\n\nFINE: 12 34 00 6b 02 02 00 08 48 54 54 50 2f 31 2e 31  | .4.k....HTTP/1.1\nFINE: 00 00 0c 2f 74 6f 6d 63 61 74 2d 64 6f 63 73 00  | .../tomcat-docs.\nFINE: 00 09 31 32 37 2e 30 2e 30 2e 31 00 ff ff 00 07  | ..127.0.0.1.??..\nFINE: 68 6f 75 73 74 6f 6e 00 22 b8 00 00 02 a0 0b 00  | houston.'?...?..\nFINE: 0c 68 6f 75 73 74 6f 6e 3a 38 38 38 38 00 00 0c  | .houston:8888...\nFINE: 4d 61 78 2d 46 6f 72 77 61 72 64 73 00 00 02 31  | Max-Forwards...1\nFINE: 30 00 07 00 00 00 08 00 00 00 09 00 00 00 ff     | 0.............?\n
36883	Noel J. Bergman	1128648404000	Now that William Barker has assessed the defect locale, try reassigning to \nApache httpd-2.0 product.
36883	Ruediger Pluem	1128698543000	Created an attachment (id=16617)\nPatch against trunk\n\nThanks to all for the analysis data. The attached patch against trunk should\nfix this. Can you please give it a try and give feedback.
36883	Ruediger Pluem	1128701119000	Created an attachment (id=16619)\nPatch against Tomcat 5.5.9\n\nAfter doing some further tests and further analysis I must revert my earlier\nassumption that this is a httpd bug. It rather seems that\norg.apache.ajp.RequestHandler does not honour the isSSL bit inside an ajp\nmessage correctly. Attached is a patch against Tomcat 5.5.9 that should fix\nthis.
36883	Mladen Turk	1128702092000	Hi,\n\nI must dissagree with you.\nThe bug has nothing to do with Tomcat.\nTomcat works pretty well with mod_jk w or w/o SSL.\n\nThe error is obviously in mod_proxy_ajp.
36883	Remy Maucherat	1128702209000	Mladen is insisting that the problem is with mod_proxy_ajp, so he'll veto the\npatch. Unfortunately, he's quite busy right now, so more comments later.\n\nIt also seems to me that it is a mod_proxy_ajp bug if it sends bogus HTTPS\nrelated headers if this isn't actually using HTTPS.
36883	william.barker@wilshire.com	1128703218000	(In reply to comment #7)\n> Created an attachment (id=16619) [edit]\n> Patch against Tomcat 5.5.9\n> After doing some further tests and further analysis I must revert my earlier\n> assumption that this is a httpd bug. It rather seems that\n> org.apache.ajp.RequestHandler does not honour the isSSL bit inside an ajp\n> message correctly. Attached is a patch against Tomcat 5.5.9 that should fix\n> this.\n\nThe first patch of mod_proxy_ajp is sub-optimal, but will work.  It would be \nbetter if mod_proxy_ajp honored the is_ssl flag and didn't bother to check the \nSSL attributes unless it was set.\n\nYour patch of Tomcat isn't even worth vetoing, since the patched class doesn't \nexist in 5.5.x, and is deprecated in 4.1.x.\n
36883	william.barker@wilshire.com	1128704314000	Play watch the bouncing bug ;-).
36883	william.barker@wilshire.com	1128704565000	Created an attachment (id=16620)\nFix for mod_proxy_ajp's SSL attributes\n\nThis fixes mod_proxy_ajp handling of SSL attributes.  Not only does it stop it\nfrom sending garbage to Tomcat, but it doesn't even bother with the lookup\nunless the request came in on SSL.  And, as a bonus feature, it even gets the\nkey-size working again.\n\nSomeday, mod_proxy_ajp may be almost as good as mod_jk ;-).
36883	Ruediger Pluem	1128717500000	Apart from a few minor style issues the patch looks good to me. Thanks. It\nremoves the problem I saw with my first version of the patch which did not fix\nit correctly. What still worries me a little bit is the comment above the\nkey_size block, which says 'added support only in ajp14 mode'. Maybe I am just\nmisreading this comment, but could someone of the AJP gurus confirm that this\nattribute is also valid in AJP13?
36883	william.barker@wilshire.com	1128720459000	(In reply to comment #13)\n> misreading this comment, but could someone of the AJP gurus confirm that this\n> attribute is also valid in AJP13?\n\nAll current release versions of Tomcat support it, and any older ones will \nignore an attribute that they don't recognize.\n\n\n\n
36883	Ruediger Pluem	1128726800000	Committed a style adjusted variant to trunk (r307195)\nhttp://svn.apache.org/viewcvs.cgi/httpd/httpd/trunk/modules/proxy/ajp_header.c?rev=307195&r1=232247&r2=307195\n\nand to 2.2.x branch (r307196)\nhttp://svn.apache.org/viewcvs.cgi/httpd/httpd/branches/2.2.x/modules/proxy/ajp_header.c?rev=307196&r1=234103&r2=307196\n
36883	Ruediger Pluem	1128727063000	(In reply to comment #8)\n> Hi,\n> \n> I must dissagree with you.\n> The bug has nothing to do with Tomcat.\n> Tomcat works pretty well with mod_jk w or w/o SSL.\n> \n> The error is obviously in mod_proxy_ajp.\n\nAgreed, but I am not sure if the AJP connector on Tomcat side should set isSSL\nto true once it finds some of the SSL variables in the AJP message. From my\npoint of view it should also ignore all SSL variables in the message if isSSL is\nset to false in the message.
36906	Ruediger Pluem	1129939628000	Created an attachment (id=16777)\nPatch against trunk\n\nCould you please give the attached patch a try? It should fix your problem.
36906	Heiko Jansen	1130177056000	Nope, only partially:\nThe case of the leading 'T' is no longer changed to lower case, but the trailing\nslash is still appended. The internal application does not handle that. It\nexpects to see '/Test', not '/Test/'.
36906	Ruediger Pluem	1130185910000	This problem is caused by a configuration flaw on your side. Please use the\nfollowing configuration instead:\n\n<Proxy balancer://mycluster>\n    BalancerMember 'http://10.1.2.10:4321' retry=10 loadfactor=1\n    BalancerMember 'http://10.1.2.11:4321' retry=10 loadfactor=1\n</Proxy>\nProxyPass /Test balancer://mycluster/Test lbmethod=byrequests
36906	Heiko Jansen	1130236038000	That does not seem sensible to me - and it also does not work.\nUsing your config my backend servers see only '/' as URL.\n\nAnd if you were right I believe I could not do sth. like this - which would be a\nmajor drawback in my eyes:\n\n<Proxy balancer://mycluster>\n    BalancerMember 'http://10.1.2.10:4321/Test1' retry=10 loadfactor=1\n    BalancerMember 'http://10.1.2.11:4321/Path/to/Test2' retry=10 loadfactor=1\n</Proxy>\nProxyPass /MyTest balancer://mycluster/Test lbmethod=byrequests\n\nCorrect me if I??m wrong...
36906	Heiko Jansen	1130265689000	Have to correct myself: the config you proposed _does_ work. Should??ve been more\naccurate when testing it....\n\nThe second part of my comment, however, still applies: if things work like you\nsay one cannot have different paths on the backend servers. Sometimes this would\ncome in very handy. \nOn the other hand: if things work like you say, the majority of cases should be\ncovered.\n\nPerhaps the docs could be enhanced to better describe the way the configuration\nworks. Adding the path to the BalancerMember parameter seemed quite natural to\nme since the port to be used on the respective backend is given there - so why\nnot the path also?!\n\nAnyway: thanks for your effort and thanks for mod_proxy_balancer: it is a\npowerfull enrichment for the httpd!\n
36906	Ruediger Pluem	1130274934000	Ok, you got me :-). Of course your second comment is completely valid and it\ndoes not seem to be logical why your configuration does not work, but mine does.\nSo I try to explain what happens:\n\nThe right side of a ProxyPass side will be normalized. Your configuration\ncontains the URL balancer://mycluster. This gets normalized to\nbalancer://mycluster/ which is correct, as the URL should consist of\n<scheme>://<host><uri>. If uri is empty it is assumed to be '/'.\nOn the other hand when creating the final proxy URL from a balancer member the\napproach is:\n\n<balancer member><uri of right side of ProxyPass><path after left side of\nProxyPass in request>\n\nIn your case this means e.g.\n\nhttp://10.1.2.11:4321/Test (balancer member) + '/' (uri of right side of\nProxyPass) + '' (path after left side of ProxyPass in request) =\nhttp://10.1.2.11:4321/Test/.\n\nIn general this approach is fine and correct. But it makes the following\nconfigurations impossible in cases where Test1 and Test2 cannot handle the\ntrailing /:\n\n  <Proxy balancer://mycluster>\n    BalancerMember 'http://10.1.2.10:4321/Test1' retry=10 loadfactor=1\n    BalancerMember 'http://10.1.2.11:4321/Test2' retry=10 loadfactor=1\n  </Proxy>\n  ProxyPass /Test balancer://mycluster lbmethod=byrequests\n\nBut after a first glance to the code make this work and keep all other cases\nworking seem to get complicated. So I will\n\n- Mark this bug as fixed close (as your problem is fixed with the patch and the\nadjusted configuration)\n- Try to get the patch in 2.1.9\n- Keep this in mind and have a look when I have time. I will update this PR once\nI find a solution for this.
36906	Ruediger Pluem	1130277997000	Committed to trunk (r328463):\nhttp://svn.apache.org/viewcvs?rev=328463&view=rev\n\nCommitted to 2.2.x branch (r328465):\nhttp://svn.apache.org/viewcvs?rev=328465&view=rev
36917	Jason Lingohr	1130656267000	Does this ring true?  A quick scan over mod_dumpio.c seems to say yes.  If so,\nI'll hack mod_dumpio.xml a bit.
36917	Vincent Bray	1185251302000	Fixed in 2.0, 2.2 & trunk.\n\nhttp://svn.apache.org/viewvc?view=rev&rev=559006\nhttp://svn.apache.org/viewvc?view=rev&rev=559008\nhttp://svn.apache.org/viewvc?view=rev&rev=559009\n\nThanks.
36951	Ruediger Pluem	1128617172000	I guess http://httpd.apache.org/dev/debugging.html#gdb could be useful for you\nto further debug the problem. It would be nice to have stacktrace of the runaway\nprocess to get an idea what goes wrong.
36951	Jeff Trawick	1128621931000	I wonder if this is it?  Streams-based TCP surfacing EOF situation in different\nmanner?\n\nIndex: modules/proxy/mod_proxy_connect.c\n===================================================================\n--- modules/proxy/mod_proxy_connect.c   (revision 292899)\n+++ modules/proxy/mod_proxy_connect.c   (working copy)\n@@ -358,6 +358,7 @@\n                         break;\n                 }\n                 else if ((pollevent & APR_POLLERR) || (pollevent & APR_POLLHUP))\n+                    rv = APR_EOF;\n                     break;\n             }\n             else\n\nThe break in that scenario just gets us out of the loop for checking events\nwhich were notified.  It doesn't get us out of the while (1).\n\nThere are other paths to consider in that loop as well.  This was just a quick\ntheory.
36951	Rocky Seelbach	1128624040000	UnixWare debug stack trace follows.  I'm currently stepping through and \nprinting the stack.  If I get it to loop I'll put the whole trace up.\n\nNew program httpd (process p1) grabbed\nCreated 1 thread(s) for process p1\nHALTED p1.1 [_poll]\n        0xbffc3b3c (_poll+12:)          jb     0x1 <bffc3b3f>\nError: Could not grab /usr/local/apache2/bin/httpd\ndebug> stack\nStack Trace for p1.1, Program httpd\n*[0] _poll(0x81bdac8, 0x2, 0xffffffff)  [0xbffc3b3c]\n [1] apr_pollset_poll(0x81bdab0, 0xffffffff, 0xffffffff, 0x8045558, 0x804555c)  \n[0xbfc7a4a9]\n [2] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@284]\n [3] proxy_run_scheme_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyhost=NULL, proxyport=0)      [mod_proxy.c@1928]\n [4] proxy_handler(r=0x81bc498) [mod_proxy.c@725]\n [5] ap_run_handler(r=0x81bc498)        [config.c@158]\n [6] ap_invoke_handler(r=0x81bc498)     [config.c@371]\n [7] ap_process_request(r=0x81bc498)    [http_request.c@258]\n [8] ap_process_http_connection(c=0x81b6538)    [http_core.c@172]\n [9] ap_run_process_connection(c=0x81b6538)     [connection.c@43]\n [10] ap_process_connection(c=0x81b6538, csd=0x81b6480) [connection.c@178]\n [11] child_main(child_num_arg=5)       [prefork.c@640]\n [12] make_child(s=0x80f3120, slot=5)   [prefork.c@736]\n [13] perform_idle_server_maintenance(p=0x80ed3c0)      [prefork.c@871]\n [14] ap_mpm_run(_pconf=0x80ed3c0, plog=0x81334d8, s=0x80f3120) [prefork.c@1075]\n [15] main(argc=3, argv=0x804790c, 0x804791c)   [main.c@710]\n [16] _start()  [0x8053650]\n
36951	Rocky Seelbach	1128627790000	Here's the loop.\n\n [2] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@284]\n\n*[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@294]\n\n*[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@295]\n\n*[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@297]\n\n*[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@331]\n\n*[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@332]\n\n*[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@333]\n\n*[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@360]\n\n*[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@361]\n\n*[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@366]\n\n*[0] proxy_connect_handler(r=0x81bc498, worker=0x8179258, conf=0x80f5de8, \nurl='content:443', proxyname=NULL, proxyport=0) [mod_proxy_connect.c@284]\n
36951	Ruediger Pluem	1128631758000	Thanks for the data. It is very helpful. The loop seems to confirm Jeffs theory.\nBut I guess the patch should look like\n\nIndex: mod_proxy_connect.c\n===================================================================\n--- mod_proxy_connect.c (Revision 295013)\n+++ mod_proxy_connect.c (Arbeitskopie)\n@@ -357,8 +357,11 @@\n                     else\n                         break;\n                 }\n-                else if ((pollevent & APR_POLLERR) || (pollevent & APR_POLLHUP))\n+                else if ((pollevent & APR_POLLERR)\n+                         || (pollevent & APR_POLLHUP)) {\n+                    rv = APR_EOF;\n                     break;\n+                }\n             }\n             else\n                 break;\n\nbecause I guess we need to set rv to APR_EOF *and* do a break.
36951	Rocky Seelbach	1128634741000	Ruediger, that appears to correct the bug.  With the change you describe \ncompiled in I am no longer able to reproduce the problem.  Ausgezeichnete \nArbeit.
36951	Ruediger Pluem	1128636804000	The credits belong to Jeff who had the correct theory just from the start. I\nonly tweaked his patch.\nJeff I am not quite sure by your comments if you fear bad sideeffects of this\npatch. So I would like to leave the commit decision to you.
36951	Jeff Trawick	1128639900000	Thanks for the follow-up fix, Reudiger!  That was the intended execution but I\nam too old and blind to see properly and too lazy to test for myself.\n\nThanks for the quick feedback, Rocky!\n\nNow committed to 2.2 branch and trunk.
36966	Sander Temme	1128706566000	Sounds like an off-by-one error. 
36966	Watson	1129114565000	The culprit?\n1672        for (i = 0; i < n; i++) {\n1673            const apr_pollfd_t *next_fd = &(pollresults[i]);\n1674            struct connection *c = next_fd->client_data;
36966	Joe Orton	1129122454000	Fixed on trunk, thanks for the report.\n\nhttp://svn.apache.org/viewcvs?rev=314844&view=rev
36966	Watson	1129128142000	Thanks for the speedy response :)
37051	Ruediger Pluem	1129156543000	It would be helpful if you can post your ssl and virtual host configuration here.
37051	Graham Coker	1129207833000	Thanks, here is the ssl.conf file I am using to test the 64bit build, its a \ncopy from our of our 'production' servers which are currently on a 32bit build \nof Apache 2.0.54, I've xxx'ed out part of the pathnames as they appear on the \nproduction server, but apart from that the config file is 'as is'\n\nBuilding the same source tree in 32 bit resolves the warning, but as soon as I \ncompile into 64bit I have the problem. \n\nMy configure is /\n./configure --enable-modules=most --enable-mods-shared=all --enable-so --\nenable-ssl=/usr/local/ssl --enable-ssl=shared --enable-suexec --with-suexec-\ncaller=xxx --with-suexec-docroot=/xxx/xxx --with-suexec-\nlogfile=/var/log/suexec.cgi.log\n\nWhen compiling with GCC, in 64bit, im using CFLAGS=-mcpu=ultrasparc -m64 -O3, \nand with Sun Studio im using CFLAGS=-Xa -xtarget=ultra2 -xarch=v9a -xvis -xO4 -\nxspace -xdepend\n\nBoth compilers successfully build both the 32bit, and 64bit versions, both the \nGCC and Sun CC 32 bit builds have no errors in the error_log, but the GCC and \nSun CC 64bit builds both exhibit the same warnings in the error_log.\n\nAs I reported initialy the server continues to startup after the warning, and \nthe SSL sites are functioning 100%, with the correct certificate attached to \nthe sites as I would expect.\n\nApart from this one warning in the error_log, the 64bit build is performing \nspectacularly well, on identical 500mhz Netra AC200 servers the 32bit build is \npumping out 350 requests per second according to an AB test on a very simple \nstatic html file, the same test on the 64bit build is giving 400 \nrequests/second.\n\nI initially tested the 64bit build using a production httpd.conf with 200 \nvirtual *:80 NameVirtual hosts, but to simplify testing I replaced it with the \ndefault httpd.conf that is installed after the initial make install, so the \nonly 'modified' config file is ssl.conf which I have added below. \n\n\n\n#    CustomLog logs/dummy-host.example.com-access_log common\n\n##\n##  SSL Global Context\n##\n##  All SSL configuration in this context applies both to\n##  the main server and all SSL-enabled virtual hosts.\n##\n\n#\n#   Some MIME-types for downloading Certificates and CRLs\n#\nAddType application/x-x509-ca-cert .crt\nAddType application/x-pkcs7-crl    .crl\n\n#   Pass Phrase Dialog:\n#   Configure the pass phrase gathering process.\n#   The filtering dialog program ("builtin' is a internal\n#   terminal dialog) has to provide the pass phrase on stdout.\nSSLPassPhraseDialog  builtin\n\n#   Inter-Process Session Cache:\n#   Configure the SSL Session Cache: First the mechanism\n#   to use and second the expiring timeout (in seconds).\n#SSLSessionCache        none\n#SSLSessionCache        shmht:logs/ssl_scache(512000)\n#SSLSessionCache        shmcb:logs/ssl_scache(512000)\nSSLSessionCache         dbm:logs/ssl_scache\nSSLSessionCacheTimeout  300\n\n#   Semaphore:\n#   Configure the path to the mutual exclusion semaphore the\n#   SSL engine uses internally for inter-process synchronization.\nSSLMutex  file:logs/ssl_mutex\n\n#   Pseudo Random Number Generator (PRNG):\n#   Configure one or more sources to seed the PRNG of the\n#   SSL library. The seed data should be of good random quality.\n#   WARNING! On some platforms /dev/random blocks if not enough entropy\n#   is available. This means you then cannot use the /dev/random device\n#   because it would lead to very long connection times (as long as\n#   it requires to make more entropy available). But usually those\n#   platforms additionally provide a /dev/urandom device which doesn't\n#   block. So, if available, use this one instead. Read the mod_ssl User\n#   Manual for more details.\nSSLRandomSeed startup builtin\nSSLRandomSeed connect builtin\n#SSLRandomSeed startup file:/dev/random  512\n#SSLRandomSeed startup file:/dev/urandom 512\n#SSLRandomSeed connect file:/dev/random  512\n#SSLRandomSeed connect file:/dev/urandom 512\n\n##\n## SSL Virtual Host Context\n##\n\n#<VirtualHost 212.46.140.6:443>\n\n#  General setup for the virtual host\n#DocumentRoot '/xxx/xxx/wyenetco'\n#ServerName www.wyenet.co.uk\n#ServerAdmin webmaster@wyenet.net\n#ScriptAlias /cgi-bin/ '/xxx/xxx/wyenetco/cgi-bin/'\n#ErrorLog /xxx/xxx/wyenetco/logs/error_log\n#TransferLog /xxx/xxx/wyenetco/logs/access_log\n\n\n#   SSL Engine Switch:\n#   Enable/Disable SSL for this virtual host.\n#SSLEngine on\n\n#   SSL Cipher Suite:\n#   List the ciphers that the client is permitted to negotiate.\n#   See the mod_ssl documentation for a complete list.\n#SSLCipherSuite ALL:!ADH:!\nEXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL\n\n#   Server Certificate:\n#   Point SSLCertificateFile at a PEM encoded certificate.  If\n#   the certificate is encrypted, then you will be prompted for a\n#   pass phrase.  Note that a kill -HUP will prompt again.  Keep\n#   in mind that if you have both an RSA and a DSA certificate you\n#   can configure both in parallel (to also allow the use of DSA\n#   ciphers, etc.)\n#SSLCertificateFile /xxx/xxx/conf/ssl.crt/www.wyenet.co.uk.crt\n#SSLCertificateFile /xxx/xxx/conf/ssl.crt/server-dsa.crt\n\n#   Server Private Key:\n#   If the key is not combined with the certificate, use this\n#   directive to point at the key file.  Keep in mind that if\n#   you've both a RSA and a DSA private key you can configure\n#   both in parallel (to also allow the use of DSA ciphers, etc.)\n#SSLCertificateKeyFile /xxx/xxx/conf/ssl.key/www.wyenet.co.uk.key\n#SSLCertificateKeyFile /xxx/xxx/conf/ssl.key/server-dsa.key\n\n#   Server Certificate Chain:\n#   Point SSLCertificateChainFile at a file containing the\n#   concatenation of PEM encoded CA certificates which form the\n#   certificate chain for the server certificate. Alternatively\n#   the referenced file can be the same as SSLCertificateFile\n#   when the CA certificates are directly appended to the server\n#   certificate for convinience.\n#SSLCertificateChainFile /xxx/xxx/conf/ssl.crt/ca.crt\n\n#   Certificate Authority (CA):\n#   Set the CA certificate verification path where to find CA\n#   certificates for client authentication or alternatively one\n#   huge file containing all of them (file must be PEM encoded)\n#   Note: Inside SSLCACertificatePath you need hash symlinks\n#         to point to the certificate files. Use the provided\n#         Makefile to update the hash symlinks after changes.\n#SSLCACertificatePath /xxx/xxx/conf/ssl.crt\n#SSLCACertificateFile /xxx/xxx/conf/ssl.crt/ca-bundle.crt\n\n#   Certificate Revocation Lists (CRL):\n#   Set the CA revocation path where to find CA CRLs for client\n#   authentication or alternatively one huge file containing all\n#   of them (file must be PEM encoded)\n#   Note: Inside SSLCARevocationPath you need hash symlinks\n#         to point to the certificate files. Use the provided\n#         Makefile to update the hash symlinks after changes.\n#SSLCARevocationPath /xxx/xxx/conf/ssl.crl\n#SSLCARevocationFile /xxx/xxx/conf/ssl.crl/ca-bundle.crl\n\n#   Client Authentication (Type):\n#   Client certificate verification type and depth.  Types are\n#   none, optional, require and optional_no_ca.  Depth is a\n#   number which specifies how deeply to verify the certificate\n#   issuer chain before deciding the certificate is not valid.\n#SSLVerifyClient require\n#SSLVerifyDepth  10\n\n#   Access Control:\n#   With SSLRequire you can do per-directory access control based\n#   on arbitrary complex boolean expressions containing server\n#   variable checks and other lookup directives.  The syntax is a\n#   mixture between C and Perl.  See the mod_ssl documentation\n#   for more details.\n#<Location />\n#SSLRequire (    %{SSL_CIPHER} !~ m/^(EXP|NULL)/ /\n#            and %{SSL_CLIENT_S_DN_O} eq 'Snake Oil, Ltd.' /\n#            and %{SSL_CLIENT_S_DN_OU} in {'Staff', 'CA', 'Dev'} /\n#            and %{TIME_WDAY} >= 1 and %{TIME_WDAY} <= 5 /\n#            and %{TIME_HOUR} >= 8 and %{TIME_HOUR} <= 20       ) /\n#           or %{REMOTE_ADDR} =~ m/^192/.76/.162/.[0-9]+$/\n#</Location>\n\n#   SSL Engine Options:\n#   Set various options for the SSL engine.\n#   o FakeBasicAuth:\n#     Translate the client X.509 into a Basic Authorisation.  This means that\n#     the standard Auth/DBMAuth methods can be used for access control.  The\n#     user name is the "one line' version of the client's X.509 certificate.\n#     Note that no password is obtained from the user. Every entry in the user\n#     file needs this password: "xxj31ZMTZzkVA'.\n#   o ExportCertData:\n#     This exports two additional environment variables: SSL_CLIENT_CERT and\n#     SSL_SERVER_CERT. These contain the PEM-encoded certificates of the\n#     server (always existing) and the client (only existing when client\n#     authentication is used). This can be used to import the certificates\n#     into CGI scripts.\n#   o StdEnvVars:\n#     This exports the standard SSL/TLS related "SSL_*' environment variables.\n#     Per default this exportation is switched off for performance reasons,\n#     because the extraction step is an expensive operation and is usually\n#     useless for serving static content. So one usually enables the\n#     exportation for CGI and SSI requests only.\n#   o CompatEnvVars:\n#     This exports obsolete environment variables for backward compatibility\n#     to Apache-SSL 1.x, mod_ssl 2.0.x, Sioux 1.0 and Stronghold 2.x. Use this\n#     to provide compatibility to existing CGI scripts.\n#   o StrictRequire:\n#     This denies access when 'SSLRequireSSL' or 'SSLRequire' applied even\n#     under a 'Satisfy any' situation, i.e. when it applies access is denied\n#     and no other module can change it.\n#   o OptRenegotiate:\n#     This enables optimized SSL connection renegotiation handling when SSL\n#     directives are used in per-directory context.\n#SSLOptions +FakeBasicAuth +ExportCertData +CompatEnvVars +StrictRequire\n#<Files ~ '/.(cgi|shtml|phtml|php3?)$'>\n#    SSLOptions +StdEnvVars\n#</Files>\n#<Directory '/usr/local/apache2/cgi-bin'>\n#    SSLOptions +StdEnvVars\n#</Directory>\n\n#   SSL Protocol Adjustments:\n#   The safe and default but still SSL/TLS standard compliant shutdown\n#   approach is that mod_ssl sends the close notify alert but doesn't wait for\n#   the close notify alert from client. When you need a different shutdown\n#   approach you can use one of the following variables:\n#   o ssl-unclean-shutdown:\n#     This forces an unclean shutdown when the connection is closed, i.e. no\n#     SSL close notify alert is send or allowed to received.  This violates\n#     the SSL/TLS standard but is needed for some brain-dead browsers. Use\n#     this when you receive I/O errors because of the standard approach where\n#     mod_ssl sends the close notify alert.\n#   o ssl-accurate-shutdown:\n#     This forces an accurate shutdown when the connection is closed, i.e. a\n#     SSL close notify alert is send and mod_ssl waits for the close notify\n#     alert of the client. This is 100% SSL/TLS standard compliant, but in\n#     practice often causes hanging connections with brain-dead browsers. Use\n#     this only for browsers where you know that their SSL implementation\n#     works correctly.\n#   Notice: Most problems of broken clients are also related to the HTTP\n#   keep-alive facility, so you usually additionally want to disable\n#   keep-alive for those clients, too. Use variable 'nokeepalive' for this.\n#   Similarly, one has to force some clients to use HTTP/1.0 to workaround\n#   their broken HTTP/1.1 implementation. Use variables 'downgrade-1.0' and\n#   'force-response-1.0' for this.\n#SetEnvIf User-Agent '.*MSIE.*' /\n#         nokeepalive ssl-unclean-shutdown /\n#         downgrade-1.0 force-response-1.0\n#\n#   Per-Server Logging:\n#   The home of a custom SSL log file. Use this when you want a\n#   compact non-error SSL logfile on a virtual host basis.\n#CustomLog logs/ssl_request_log /\n#          '%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x /'%r/' %b'\n#\n#</VirtualHost>\n\n<VirtualHost 212.46.140.76:443>\nSuexecUserGroup crowsfeet nobody\nServerAdmin webmaster@blackhillcomputersoftware.co.uk\nDocumentRoot /xxx/xxx/crowsfeet/docs-ssl\nScriptAlias /cgi-bin/ '/xxx/xxx/crowsfeet/cgi-bin-ssl/'\n#Alias /images/ '/xxx/xxx/crowsfeet/docs/images/'\nServerName www.crowsfeet.net\nErrorLog /xxx/xxx/crowsfeet/logs/error_log\nCustomLog /xxx/xxx/crowsfeet/logs/access_log combined\nSSLEngine on\nSSLCipherSuite ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL\nSSLCertificateFile /xxx/xxx/conf/ssl.crt/www.crowsfeet.net.crt\nSSLCertificateKeyFile /xxx/xxx/conf/ssl.key/www.crowsfeet.net.key\n<Files ~ '/.(cgi|shtml|phtml|php3?)$'>\n    SSLOptions +StdEnvVars\n</Files>\n<Directory '/xxx/xxx/apache/cgi-bin-ssl'>\n    SSLOptions +StdEnvVars\n</Directory>\nSetEnvIf User-Agent '.*MSIE.*' /\n         nokeepalive ssl-unclean-shutdown /\n         downgrade-1.0 force-response-1.0\nCustomLog /xxx/xxx/crowsfeet/logs/ssl_request_log /\n          '%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x /'%r/' %b'\n</VirtualHost>\n\n<VirtualHost 212.46.140.73:443>\nSuexecUserGroup pmorris nobody\nServerAdmin webmaster@philipmorris.uk.com\nDocumentRoot /xxx/xxx/philipmorris/docs-ssl\nScriptAlias /cgi-bin/ '/xxx/xxx/philipmorris/cgi-bin-ssl/'\nAlias /images/ '/xxx/xxx/philipmorris/docs/images/'\nServerName www.philipmorris.uk.com\nErrorLog /xxx/xxx/philipmorris/logs/error_log\nCustomLog /xxx/xxx/philipmorris/logs/access_log combined\nSSLEngine on\nSSLCipherSuite ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL\nSSLCertificateFile /xxx/xxx/conf/ssl.crt/www.philipmorris.uk.com.crt\nSSLCertificateKeyFile /xxx/xxx/conf/ssl.key/www.philipmorris.uk.com.key\n<Files ~ '/.(cgi|shtml|phtml|php3?)$'>\n    SSLOptions +StdEnvVars\n</Files>\n<Directory '/usr/local/apache/cgi-bin-ssl'>\n    SSLOptions +StdEnvVars\n</Directory>\nSetEnvIf User-Agent '.*MSIE.*' /\n         nokeepalive ssl-unclean-shutdown /\n         downgrade-1.0 force-response-1.0\nCustomLog /wyenet/web/philipmorris/logs/ssl_request_log /\n          '%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x /'%r/' %b'\n</VirtualHost>\n\n<VirtualHost 212.46.140.64:443>\nSuexecUserGroup queenswd nobody\nServerAdmin webmaster@queenswood.co.uk\nDocumentRoot /xxx/xxx/queenswood/\nScriptAlias /cgi-bin/ '/xxx/xxx/queenswood/cgi-bin/'\nServerName www.queenswood.co.uk\nErrorLog /wyenet/web/queenswood/logs/error_log\nCustomLog /xxx/xxx/queenswood/logs/access_log combined\nSSLEngine on\nSSLCipherSuite ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL\nSSLCertificateFile /xxx/xxx/conf/ssl.crt/www.queenswood.co.uk.crt\nSSLCertificateKeyFile /xxx/xxx/conf/ssl.key/www.queenswood.co.uk.key\n<Files ~ '/.(cgi|shtml|phtml|php3?)$'>\n    SSLOptions +StdEnvVars\n</Files>\n<Directory '/usr/local/apache/cgi-bin'>\n    SSLOptions +StdEnvVars\n</Directory>\nSetEnvIf User-Agent '.*MSIE.*' /\n         nokeepalive ssl-unclean-shutdown /\n         downgrade-1.0 force-response-1.0\n#CustomLog /xxx/xxx/queenswood/logs/ssl_request_log /\n#          '%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x /'%r/' %b'\n</VirtualHost>\n\n</IfDefine>\n#
37051	Ruediger Pluem	1129212378000	I think I need some debugging information from you since I do not have a 64 Bit\nsystem at hand. For debugging httpd with gdb please have a look at\n\nhttp://httpd.apache.org/dev/debugging.html\n\nPlease keep in mind to recompile your httpd with gcc and -O2 -g instead of -O3\nin this case.\nYou should set a breakpoint at ssl_engine_init.c:1039 via\nbreak ssl_engine_init.c:1039\nAfter httpd stopped at this point please issue\nprint key\n\nBackground: I think that\n\n        key = apr_psprintf(p, '%pA:%u',\n                           &s->addrs->host_addr, s->addrs->host_port);\n\nin line 1037-1038 of ssl_engine_init.c do not deliver different results for the\ndifferent virtual host, because apr_psprintf might not correctly format 64 Bit\npointers.\nBTW: Some APR guys listening? Could you guys give a hint on that theory?
37051	Joe Orton	1129215101000	Nice! You found the buggy code ;) but the reason why is:\n\n%pA takes a 'struct in_addr *' argument, but that's being passed an\n'apr_sockaddr_t *' argument.\n\n...it should be %pI instead.
37051	Ruediger Pluem	1129216519000	Created an attachment (id=16684)\nPatch against trunk\n\nGraham could you please give this patch a try and see if this removes your\nproblem? It does what Joe proposed.
37051	Joe Orton	1129217381000	That isn't quite right, since %pI prints 'address:port' using the port out of\nthe apr_sockaddr_t structure.   I'm not sure even whether that port will be the\nsame as s->addr->host_port - probably not.  If it is, that's OK; need to test that.\n\nThere's a further problem that %pI is liable to print corrupt strings with\napr_psprintf due to an APR bug (only fixed on the trunk).
37051	Joe Orton	1129218088000	Created an attachment (id=16685)\npatch against 2.0.x \n\nHere's an alternative patch which should be slightly safer.
37051	Graham Coker	1129221214000	Applied Joe's second patch to my 2.0.54 code, and compiled, so far so good, no \nerrors reported in the error_log now.\n\nExcellent, with my normal config file the error_log is now clean, and just \nshows the server starting up. I also ran a test with an invalid SSL \nconfiguration with NameVirtual hosts, and it correctly identified the problem, \nand logged it to error_log.\n\n\n
37051	Ruediger Pluem	1129221633000	Thanks for the update Graham.\nJoe, sorry for the misunderstanding and thanks for the update. As far as I can\nsee the problem is also on the trunk and given the apr problem I think we should\nnot rely on apr_psprintf in this point on the trunk too. Do you commit or should\nI do?
37051	Joe Orton	1129230435000	Thanks for testing the patch out.  Committed to trunk and 2.2.x; this is\nprobably not worth a backport to 2.0.x since it's only a warning.\n\nhttp://svn.apache.org/viewcvs?rev=320796&view=rev
37074	Jason Lingohr	1130305121000	Thanks for your submission on this -- changes committed.\n
37074	Andr?? Malo	1130310281000	Doh! Jason, please don't reassign bugs to yourself.
37074	Andr?? Malo	1130310325000	Assign back to bugs@httpd.apache.org.
37074	Andr?? Malo	1130310347000	And fixed again.
37288	Joe Orton	1130506538000	Created an attachment (id=16828)\nproposed fix for handling of unknown state tokens in mod_dav\n\nThe current behaviour is caused by the fix for bug 16452; attached patch\nimproves handling of unknown state tokens in mod_dav so that they are evaluated\nto false at the right time.
37288	Joe Orton	1130682389000	Fixed on the trunk, thanks for the report.\n\nhttp://svn.apache.org/viewcvs.cgi?view=rev&rev=329562
37347	Ruediger Pluem	1131048077000	Created an attachment (id=16870)\nPatch against 2.0.x branch\n\nThis has been fixed in trunk and 2.2.x a while ago (r220038). Can you please\ngive the attached patch a try? It should fix the problem for mod_disk_cache and\nfor mod_mem_cache
37347	John Stefani	1131054149000	\nThank You,\n\nthe patch you supplied fixed the issue.\n\nAre there any plans to merge it into the 2.0.x code?\n\n
37347	Ruediger Pluem	1131056170000	Thanks for testing. I proposed it for backport to 2.0.x by adding it to the\nSTATUS file:\nhttp://svn.apache.org/viewcvs.cgi/httpd/httpd/branches/2.0.x/STATUS?p2=%2Fhttpd%2Fhttpd%2Fbranches%2F2.0.x%2FSTATUS&p1=httpd%2Fhttpd%2Fbranches%2F2.0.x%2FSTATUS&r1=330635&r2=330634&rev=330635&view=diff&makepatch=1&diff_format=u\n\nI reopen the bug and will close it again once the patch has been backported.
37347	Takashi Sato	1195962874000	fixed as r372047\nhttp://svn.apache.org/viewvc?view=rev&revision=372047
37357	Joe Orton	1133891242000	Thanks for the report.  Fixed on the trunk: \n\nhttp://svn.apache.org/viewcvs?rev=354389&view=rev
37559	Marc Guardiola	1132337728000	Forgot to mention that mod_proxy is not the cause, without mod_deflate it works \nfine (The Vary header is not deleted by mod_proxy):\n\n# cat /usr/local/apache/conf/deflate.conf\n<Virtualhost *>\n  ServerName            backend.test.nl\n  DocumentRoot          /var/www/html\n</VirtualHost>\n\n<Virtualhost *>\n  ServerName            proxynodeflate.test.nl\n  ProxyPass             /       http://backend.test.nl/\n  ProxyPassReverse      /       http://backend.test.nl/\n</VirtualHost>\n\n__________________\n\n# wget --header='Accept-Encoding: compress, gzip' -SO proxynodeflate      \nproxynodeflate.test.nl/cgi-bin/test.cgi 2>&1 | grep Vary\n 4 Vary: Accept\n\nRegards, \n\nMarc
37559	Ruediger Pluem	1132360634000	Created an attachment (id=16995)\nPatch against 2.0.x (merge Vary instead of setting it)\n\nI think you hit the problem that has been fixed on the trunk in r161691\n(http://svn.apache.org/viewcvs.cgi?rev=161691&view=rev). Please try if the\nattached patch fixes your problem.
37559	Marc Guardiola	1132574418000	It works! Vary headers set by applications and/or by mod_headers are merged now.\n\nThanks!\n\nMarc
37559	Ruediger Pluem	1132608252000	Proposed for backport to 2.0.x:\n(http://svn.apache.org/viewcvs.cgi?rev=347969&view=rev)
37566	Ruediger Pluem	1132437010000	Created an attachment (id=16998)\nPatch against 2.0.55\n
37566	Ruediger Pluem	1132437292000	Proposed patch for backport (http://svn.apache.org/viewcvs.cgi?rev=345685&view=rev).
37566	Ruediger Pluem	1141684028000	The patch will be part of 2.0.56.
37753	Kazuhiro Osawa	1133526554000	Created an attachment (id=17119)\npatch to mod_proxe_balancer URL stickysession bug.\n
37753	Kazuhiro Osawa	1133526597000	It doesn't move in stickysession when not Cookie but URL is used when \nstickysession of the ProxyPass directive is specified when mod_proxy_balancer \nis used. \n
37753	Ruediger Pluem	1133645025000	Thanks for submiting the patch. Fixed in trunk as r352010\n(http://svn.apache.org/viewcvs.cgi?rev=352010&view=rev) and proposed for\nbackport in r352011 (http://svn.apache.org/viewcvs.cgi?rev=352010&view=rev).\n
37753	Nick Kew	1134558582000	Backported r356764 
37790	Nick Kew	1133800037000	Created an attachment (id=17151)\nPatch\n\nAttach HTTP input filter before discarding request body.
37790	Nick Kew	1134558477000	Fixed  r356764 
37791	Joe Orton	1133891852000	Thanks for the report, this has been fixed on the trunk:\n\nhttp://svn.apache.org/viewcvs.cgi?rev=354394&view=rev
37791	Ruediger Pluem	1137022088000	Created an attachment (id=17393)\nPatch against 2.0.x\n
37791	Ruediger Pluem	1137022775000	Proposed for backport to 2.2.x as r355720\n(http://svn.apache.org/viewcvs.cgi?rev=355720&view=rev) and proposed for\nbackport to 2.0.x as r368152\n(http://svn.apache.org/viewcvs.cgi?rev=368152&view=rev).\nThere is also a CVEID for this bug: CAN-2005-3357
37791	Marc Stern	1138374898000	Doesn't the same problem also appear at the very beginning of in ssl_hook_Fixup() ?\n\nif (!(sc->enabled && sslconn && (ssl = sslconn->ssl)))\n   should become\nif ( !sc->enabled || !sslconn || (ssl != sslconn->ssl) )\n\nRight ?
37791	Ruediger Pluem	1138411056000	(In reply to comment #4)\n> \n> if (!(sc->enabled && sslconn && (ssl = sslconn->ssl)))\n>    should become\n> if ( !sc->enabled || !sslconn || (ssl != sslconn->ssl) )\n> \n> Right ?\n\nNo.\n\n1. Your version is nearly the same as above because\n\n!(sc->enabled && sslconn && (ssl = sslconn->ssl))  is equal to\n\n!sc->enabled || !sslconn || !(ssl == sslconn->ssl)\n\nkeep in mind that \n\nssl = sslconn->ssl\n\nand\n\nssl == sslconn->ssl\n\nare different things. So the original condition becomes true if sslconn->ssl is\nequal to NULL which is only checked if sslconn is different from NULL.\nBut I need to check on the trunk where the current condition is somewhat\ndifferent and maybe also wrong. So thanks for the pointer.\n
37791	Ruediger Pluem	1138536739000	Meanwhile I checked the slightly different condition on trunk and 2.2.x and they\nare also correct.
37791	Marc Stern	1138613136000	I read too fast, sorry :-(
37798	Andr?? Malo	1133853614000	As stated in the docs, we only add types on request if they are registered at\nIANA but I can't find 'mshelp' here:\n<http://www.iana.org/assignments/media-types/application/>.\n\nThanks anyway.
37798	techie	1144862215000	Done. Now you can add application/vnd.ms-htmlhelp to mime.types\n\nhttp://www.iana.org/assignments/media-types/application/vnd.ms-htmlhelp
37798	Roy T. Fielding	1188213358000	Added\n\n   application/vnd.ms-htmlhelp   chm\n\nto trunk in rev 570206.
37840	Per Olausson	1134052353000	BIO.h is for OpenSSL and not apache, this incompatibility is seen with 0.9.8a\nOpenSSL.
37840	Joe Orton	1134065833000	Thanks for the report and patches.  Have you passed on the bio.h problem to the\nOpenSSL developers?\n\nThe apr_dbd.c thing was already fixed on the trunk, I've committed the sockets.c\nand httpd.h fixes too and proposed the latter for inclusion in the next 2.2.x\nrelease.\n\nhttp://svn.apache.org/viewcvs?rev=355141&view=rev\nhttp://svn.apache.org/viewcvs?rev=355143&view=rev\n
37840	Per Olausson	1134089000000	Yes I emailed in a bug to the openssl guys.\n\nopenssl.org #1252
37874	Mark Cox	1134408282000	Created an attachment (id=17199)\nPatch for apache-1.3 tree (ack fielding, jorton)\n
37874	Mark Cox	1134408314000	Created an attachment (id=17200)\nPatch for apache-2.0 tree (ack fielding, jorton)\n
37874	Mark Cox	1134408393000	VU#299838 JPCERT#94453446 JVN#06045169
37874	Joe Orton	1144762153000	The fixes for this were committed a while back:\n\nhttp://svn.apache.org/viewcvs?rev=357161&view=rev (trunk)\nhttp://svn.apache.org/viewcvs?rev=356291&view=rev (2.2.x)\nhttp://svn.apache.org/viewcvs?rev=356278&view=rev (1.3.x)\nhttp://svn.apache.org/viewcvs?rev=356279&view=rev (2.0.x)\n
37905	Nick Kew	1134576711000	Whatever you saw isn't there now, and the document was last modified well over \na week ago. 
37905	Nick Kew	1134577197000	Beg pardon, I was looking at the first instance of 'background.logo'.  You \nmeant the second!  I've just fixed it in svn, so it should show up soon on the \nsite. 
37911	Joe Orton	1140180287000	Thanks for the report and the patch.  This is checked in to the trunk:\n\nhttp://svn.apache.org/viewcvs.cgi?rev=378487&view=rev
37911	Dale	1181286672000	I'm still getting this with the Apache provided 2.0.59 binary build for win32\nwhen using a wildcard certificate.
37911	Davi Arnaut	1181347277000	The fix has not been been proposed for backport. If you feel this is\nimportant, try bringing it up on dev@httpd.apache.org
37911	Ruediger Pluem	1188702050000	Proposed for backport as r571936 (http://svn.apache.org/viewvc?rev=571936&view=rev).
37911	Ruediger Pluem	1188891758000	Backported to 2.2.x as r572630 (http://svn.apache.org/viewvc?rev=572630&view=rev)
37911	Joe Orton	1190114658000	*** Bug 43278 has been marked as a duplicate of this bug. ***
37968	Nick Kew	1135084230000	'httpd.spec' and 'zlib-devel' come from your distro's package manager, not \nfrom Apache.  \n  \nA build bug in Apache itself would appear totally differently. 
37968	Lo	1135084529000	httpd.spec is included in httpd-2.2.0.tar.gz which I downloaded from apache.org\ntoday. So it is not provided by RedHat.\nWhat was really missing on my system was /usr/include/zlib.h (which is provided\nby zlib-devel on RedHat systems, but exists on other systems).
37968	Nick Kew	1135084640000	Oops, sorry, httpd.spec does appear in the package.  zlib-devel (indeed \nanything-devel) is still a package-manager thing. \n \nWhat did you say fails?  Is it in configure (in which case that's expected \nbehaviour) or in make (in which case it's a bug if your configure was \nsuccessful)? 
37968	Lo	1135085004000	When configure came to mod_deflate, it stopped whit this message\n'error: mod_deflate has been requested but can not be built due to prerequisite\nfailures'\nJust before, the check for zlib.h ('checking for zlib library') had failed.\n\nOn RedHat systems, this file is provided by the RPM zlib-devel. Since httpd.spec\nis provided for building on RPM-friendly systems (whether or not RedHat), it\nshould include a BuildPrereq: on zlib-devel
37968	Paul Querna	1150880401000	Fixed in r415945 in trunk:\nhttp://svn.apache.org/viewvc?view=rev&revision=415945\n\nThanks for reporting the problem!
38017	Ruediger Pluem	1136478198000	Created an attachment (id=17342)\nPatch proposal against trunk\n
38017	Ruediger Pluem	1136478268000	I can confirm that this is a regression. Could you please give the attached\npatch a try and let me know the results?
38017	Ruediger Pluem	1136543666000	Oh I forgot: Thanks for the good analysis of the problem. That eased my search\nfor the cause very much.
38017	Dick Snippe	1136904692000	(In reply to comment #2)\n> I can confirm that this is a regression. Could you please give the attached\n> patch a try and let me know the results?\n\nthe patch works!\nI tested all comninations of mod_mem_cache, mod_disk_cache and mod_proxy_http,\nmod_proxy_ajp and it appears to work in all cases
38017	Ruediger Pluem	1136932706000	Thanks for testing. The patch has been commited to trunk as r367798\n(http://svn.apache.org/viewcvs.cgi?rev=367798&view=rev) and been proposed for\nbackport to 2.2.x as r367800\n(http://svn.apache.org/viewcvs.cgi?rev=367800&view=rev).
38017	Ruediger Pluem	1139092782000	The patch has been backported to 2.2.x as r374931\n(http://svn.apache.org/viewcvs.cgi?rev=374931&view=rev) and will be part of 2.2.1
38017	Alex Georgopoulos	1151541080000	I am still seeing these errors on 2.0.58 & 2.2.2 using mod_proxy for a reverse\nproxy for RPC over HTTP and Exchange.  Downgrading to 2.0.54 fixes the problem,\nmaybe there are still some other occurences besides the ones patched here that\nhave not been fixed?  I also tried this on 2.2.2 and it didn't work either.\n\n[Tue Jun 27 18:08:08 2006] [error] (70014)End of file found: proxy: prefetch\nrequest body failed to 10.2.181.53 from 15.235.153.107 ()\n[Tue Jun 27 19:07:46 2006] [error] (104)Connection reset by peer: proxy:\nprefetch request body failed to 10.2.181.53 from 10.2.181.18 ()
38017	Ruediger Pluem	1151573072000	Sorry, but your problem is completely unrelated to this bug.
38034	Julian Reschke	1172822187000	It seems that If-Match and If-None-Match in general aren't evaluated properly\nwhen the target does not exist.\n\nFor instance:\n\nLOCK /unmapped\nIf-Match: '*'\n\nshould fail with 412, but creates the lock.\n\nOr\n\nLOCK /unmapped\nIf-None-Match: '*'\n\nshould succeed, but fails with 412.\n
38034	Julian Reschke	1172822292000	Created an attachment (id=19658)\ntest cases for LOCK request with if-* headers\n
38034	Werner	1185336540000	Isn't there any programmer somewhere to help fix this bug.\nIt is a *severe* bug in mod_dav and it is open for at least four years, while\nIIS does it right.\n
38034	Werner	1185449439000	Created an attachment (id=20552)\nFixes If-Match: * and If-None-Match: * bug for mod_dav\n\nThe bug is in function ap_meets_conditions() in modules/http/http_protocol.c:\nit always evaluates 'If-Match: *' to TRUE (is FALSE, if resource does not\nexist) and 'If-None-Match: *' to FALSE (is TRUE, if the resource does not\nexist).\nThis function is called by mod_dav, function dav_validate_request(). In this\ncase, ap_meets_conditions() seems not able to get etag reliably (probably a bug\nin mod_dav).\nFix: A new function dav_meets_conditions() is created in\nmodules/dav/main/util.c. It is mostly a copy of ap_meets_conditions(), but\nfixes the mentioned errors. dav_validate_request() calls dav_meets_conditions()\ninstead of ap_meets_conditions().\nToDo: it would be better to fix this in ap_meets_conditions(). But to do this,\nthis functions must know, whether the resource exists, and it must be able to\nreliably get the etag of the resource. But as I am not familiar with\nApache-programming, I can't do this. I even doubt that it is possible without\nchanges in other Apache modules besides mod_dav.\n
38034	Werner	1185450091000	Created an attachment (id=20553)\nTest results for conditional LOCK-requests\n\nHTTP-body and irrelevant headers are removed.\nClients should remove 'W/' from weak Etags. Apache always creates weak Etags,\nwhen a request is sent within less than 1 second after the last modification.\nSo clients that use HEAD to get the Etag immediately after PUT will be fooled\nwhen they use this Etag some seconds later.
38034	Julian Reschke	1185450843000	Why would a client remove the weakness indicator?\n\nIf the server wants to make x and W/x match, it needs to implement Etag matching\nthat way. But clients should treat etags as opaque strings. IMHO.\n
38034	Werner	1185458755000	> Why would a client remove the weakness indicator?\nBecause the weakness indicator sent by Apache is nonsense.\n\nWhen I send a PUT request and immediately thereafter send a HEAD request, I\nalways get a weak Etag from Apache, say W/'19e60b-20-279033c0'. If I do the HEAD\nrequest some seconds later, I get the strong Etag '19e60b-20-279033c0'. Neither\nApache nor somebody else changed the content, it is just what I sent in the PUT\nrequest. And this makes no sense to the client.\n\nThe reason is in modules/http/http_etag.c, ap_make_etag():\n\n     * If the request was made within a second of the last-modified date,\n     * we send a weak tag instead of a strong one, since it could\n     * be modified again later in the second, and the validation\n     * would be incorrect.\n\nWhat should be the sense of this (would be nice if you could explain it to me)?\n\n- changes may happen at any time. Why are young files bad and old ones good?\n\n- are there race conditions within in Apache, so the Etag will not match the\nbody of the response (mtime and etag are evaluated at one time, the\nresponse-body some time later)? In this case a weak Etag is just as wrong as\nstrong one. Why should this race condition occur only within 1 second after the\nfile has been modified? If this realy is the case, it needs debugging.\n\n- when the Etag matches the body of the response, it is completely ok to change\nthe content on the server 0.1 microsecond later (because this will change Etag).\n\nAs long as Apache (or some module) does not distinguish between 'semantically\nsignificant changes' and changing some byte, there is no reason for weak Etags\n(see RFC 2616, 13.3.3 Weak and Strong Validators).\n\nFor any caching WebDAV-client, it is essential to get the Etag of files uploaded\nto the server. If this is impossible, the client has to throw away the local\ncopy and download it from the server again -- but only after waiting at least\none second.\n\nReal world: As long as one uses only standard WebDAV (RFC 4918) with Apache\nmod_dav (I don't know about extension like versioning), or any other\nWebDAV-server, removing the weakness indicator is no problem at all. davfs2 does\nit, and I never heard of any problem that might be related to this.\n\nP.S.: Servers, that don't edit the body of a PUT, should send a strong Etag and\nLast-Modiefied in the PUT-response, allthough the WebDAV Working Group was not\nable to address this problem. It would avoid race conditions.\n
38034	Julian Reschke	1185498558000	(In reply to comment #7)\n> > Why would a client remove the weakness indicator?\n> Because the weakness indicator sent by Apache is nonsense.\n\nBut that doesn't mean that people should apply hacks to their clients.\n\n> When I send a PUT request and immediately thereafter send a HEAD request, I\n> always get a weak Etag from Apache, say W/'19e60b-20-279033c0'. If I do the HEAD\n> request some seconds later, I get the strong Etag '19e60b-20-279033c0'. Neither\n> Apache nor somebody else changed the content, it is just what I sent in the PUT\n> request. And this makes no sense to the client.\n\nIt makes perfect sense for clients that just need a weak etag, such as for\nmaking GET in the browser conditional.\n \n> The reason is in modules/http/http_etag.c, ap_make_etag():\n> \n>      * If the request was made within a second of the last-modified date,\n>      * we send a weak tag instead of a strong one, since it could\n>      * be modified again later in the second, and the validation\n>      * would be incorrect.\n> \n> What should be the sense of this (would be nice if you could explain it to me)?\n> \n> - changes may happen at any time. Why are young files bad and old ones good?\n\nAs long as the timestamp of the file equals the system time, it can't be used to\ncompute a strong etag (because the file can change again in the same interval).\nOnce it's not the same anymore, it can be used to compute a strong etag.\n\n> - are there race conditions within in Apache, so the Etag will not match the\n> body of the response (mtime and etag are evaluated at one time, the\n> response-body some time later)? In this case a weak Etag is just as wrong as\n> strong one. Why should this race condition occur only within 1 second after the\n> file has been modified? If this realy is the case, it needs debugging.\n> \n> - when the Etag matches the body of the response, it is completely ok to change\n> the content on the server 0.1 microsecond later (because this will change Etag).\n\nThat depends on the resolution of the system clock.\n\n> As long as Apache (or some module) does not distinguish between 'semantically\n> significant changes' and changing some byte, there is no reason for weak Etags\n> (see RFC 2616, 13.3.3 Weak and Strong Validators).\n> \n> For any caching WebDAV-client, it is essential to get the Etag of files uploaded\n> to the server. If this is impossible, the client has to throw away the local\n> copy and download it from the server again -- but only after waiting at least\n> one second.\n\nYes, that's a problem. But putting hacks into the clients (removing the weakness\nindicator) is the wrong way to handle this.\n\n> Real world: As long as one uses only standard WebDAV (RFC 4918) with Apache\n> mod_dav (I don't know about extension like versioning), or any other\n> WebDAV-server, removing the weakness indicator is no problem at all. davfs2 does\n> it, and I never heard of any problem that might be related to this.\n\nThat's because nobody has tested with other WebDAV servers that may assign weak\netags for other reasons than the one you see in Apache/moddav.\n\n> P.S.: Servers, that don't edit the body of a PUT, should send a strong Etag and\n> Last-Modiefied in the PUT-response, allthough the WebDAV Working Group was not\n> able to address this problem. It would avoid race conditions.\n\nActually, servers should send the ETag always, no matter whether the body was\nchanged (IMHO). See proposal in\nhttp://greenbytes.de/tech/webdav/draft-reschke-http-etag-on-write-latest.html\n(follow ups with respect to this on the http-wg mailing list, please). \n
38034	Werner	1185514707000	Looks like this is the wrong place for our discussion. So I created a new bug\nreport. (#42987 Weak Etags in Apache are useless and violate RFC 2616, 13.3.3)\nPlease have a look at the test cases for the 'perfect sense' of apache-style\nweak etags in a conditional GET.\n
38034	Simon Perreault	1198067022000	This bug is not specific to WebDAV! If-None-Match is a pure HTTP construct and\nas such fixing this bug should not touch mod_dav.\n\nI'll post a patch shortly.
38034	Simon Perreault	1198067308000	Created an attachment (id=21295)\nClean fix\n\nThis patch comes from mod_dav_acl-0.1.2 and was written by Jari Urpalainen.\n\nPlease consider applying and closing this bug.
38034	Tim Olsen	1198070559000	RFC 2616 says '...or if '*' is given and any current entity exists for that\nresource, then the server MUST NOT perform the requested method.'  Therefore,\nthis patch assumes that the absence of an etag implies the absence of the entity.\n\nIs this an assumption we want to make?
38034	Tim Olsen	1198071117000	\nalso see the discussion at:\n\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200710.mbox/%3c470E9A9F.8020202@pearsoncmg.com%3e\n\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200711.mbox/%3c1b4c87db0711190838v69dd7593l15c0ceb4e4755b01@mail.gmail.com%3e
38034	Simon Perreault	1198129561000	(In reply to comment #12)\n> Is this an assumption we want to make?\n\nI'm not qualified to provide advice on that question. But please note that the\npatch can easily be modified if this assumption turns out not to be valid. So\nthe only thing preventing this bug from being closed is making this decision.
38034	Simon Perreault	1198129739000	(In reply to comment #13)\n>\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200710.mbox/%3c470E9A9F.8020202@pearsoncmg.com%3e\n>\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200711.mbox/%3c1b4c87db0711190838v69dd7593l15c0ceb4e4755b01@mail.gmail.com%3e\n\nI didn't read everything slowly, but isn't all this related to a different bug?\nI mean, the problem in #38034 is fixed in a correct way easily enough, without\nrefactoring.
38034	Tim Olsen	1198140397000	> I'm not qualified to provide advice on that question. But please note that the\n> patch can easily be modified if this assumption turns out not to be valid. So\n> the only thing preventing this bug from being closed is making this decision.\n\nThe main thing preventing this bug from being closed is an actual commit to the source code.  This bug \nhas been opened for almost 2 years (16593 has been open for over 4.5 years!) and has seen 3 or 4 \nproposed patches.\n\nWhen a bug sees this many patches and no action, then there is a scaling problem somewhere in the \ndevelopment process.\n\nAdoption of the litmus webdav test suite would also be good to prevent regressions.  I spoke to Greg \nStein at ApacheCon last month about this bug and he mentioned that he had tested If-Match / If-\nNone-Match behavior when he originally wrote mod_dav.  Unfortunately, mod_dav has regressed in \nthat regard.  An automated test would have caught the regression.
38034	Tim Olsen	1198142004000	(In reply to comment #14) \n> I'm not qualified to provide advice on that question. But please note that the\n> patch can easily be modified if this assumption turns out not to be valid. So\n> the only thing preventing this bug from being closed is making this decision.\n\n(Ok, my last reply was me venting.  Here is my more productive response ;-)\n\nThe patch may be easily modified to any particular state, but deciding on that state is the hard part ;-)  \nIn this case, if the assumption is not valid (which I do not believe it is), then we must decide on how we \nsignify that a resource does not exist (i.e. is null).  The email thread I pointed you to discusses that \nissue somewhat.  Chris Darroch proposed NON_EXTANT_RESOURCE or NO_RESOURCE.  Paritosh had \nalready submitted a patch with 'resource-exists' but then later agreed with Chris on using \nNO_RESOURCE (a trivial change to the patch).   Then in the next month, after discussing this bug with \nPaul Querna at ApacheCon, Paritosh attempted to revive the thread and proposed another possible \napproach endorsed by Paul.  No one replied to Paritosh's email.\n\nAt that point, Paritosh and I decided not to invest more time in creating and testing yet another patch \nwhich may not make it into Apache.   We're not opposed to doing so in the future, but we'd like to get \nour own automated testing infrastructure setup specifically for our patches to Apache (there are more \nto come).  Testing that mod_dav_fs still works by hand for every patch (and every time a patch needs to \nbe changed) is time consuming.  \n\nRight now, we are under increasing pressure to tend more to our non-open-source-community tasks \nat our company.  We hope to devote more time to pushing fixes for bugs such as this one in the near \nfuture.  Hopefully, your and our efforts will not be in vain.\n\nbtw, please vote for this bug if you haven't done so already.\n\n
38034	Werner	1198239351000	The patch proposed by Simon Perreault only treats the bug in 'If-None-Match: *',\nbut the same bug is in 'If-Match: *' and must be fixed too.\n\n>> Is this an assumption we want to make?\n>I'm not qualified to provide advice on that question. But please note that the\n>patch can easily be modified if this assumption turns out not to be valid. So\n>the only thing preventing this bug from being closed is making this decision.\n\nEvaluation of 'If-Match: *' and 'If-None-Match: *' depends on whether the\nresources does *exist*. I do not know, whether checking for the existence of an\nEtag is equivalent to checking for the existence of the resource. But if you\nwant to do it this way, you must *know*. I am worrying about the idea of making\na decision about making an *assumption*.\n\n>This bug is not specific to WebDAV! If-None-Match is a pure HTTP construct and\n>as such fixing this bug should not touch mod_dav.\n\nThis is true, and it is wrong. Most applications seem not to use 'If-None-Match:\n*' and 'If-Match: *' and will therefore not be affected by this bug. But these\nconditionals are essential for WebDAV. So\n- it would be *nice* to have a clean and general solution\n- it is *necessary* to fix that bug for WebDAV.\n\nAs it is, a WebDAV-client can either work reliable or work with Apache. These\ntwo options are exclusive.\n\nCheers\nWerner\n
38034	Werner	1198288320000	Additional remark an equivalence of 'check for existence' and 'check for Etag':\n\nI am not familiar with apache programming, so this is based on one assumption.\n- Apache modules can register their own, specialised ap_make_etag-function,\noverriding apaches generic ap_make_etag-function.\n\nIf this assumption is true, it would be perfectly reasonable for a module, to\nreturn an etag only if the resource is cacheable, and to return NULL if the\nresource is not cacheable. So checking for the existance of an etag can not\nreplace the check for existance of the resource.\n\nI think a clean, general solution should be in the line of the patch provided by\nParitosh Shah. There must also be a clean solution for the potential problems\nconsiderd by Paritosh Shah and Chris Darroch.\n\nAs I understand, a clean solution might possibly change some internal interface\nand possibly affect other modules. I fully understand that this needs serious\nconsideration and might take some time.\n\nIf it is therefore not possible to fix this bug in a clean, general way for the\nnext release, I suggest that the next release should fix the bug for mod_dav\nonly (so it will not affect other modules). You might use that ugly, code\ndublicating monster from me. As soon as a better solution is found, this\nmod_dav-only patch can be removed without side effects.\n\nWerner\n
38034	Ruediger Pluem	1199415355000	Created an attachment (id=21343)\nFix against 2.2.x\n\nWerner, can you please confirm that the attached patch against 2.2.x solves\nyour problem? This is the version of the patch that should be backported.
38034	Werner	1199447388000	Referring to comment #20:\nI applied the patch to the Debian/Etch-version of Apache 2.2.3 and only\nexchanged mod_dav.so in the installed binary version.\n\nAll my tests succeeded (no errors).\n\nThe tests included (with response code):\n\nLOCK If-None-Match: *, file does not exist\n200 OK\n\nPUT If-None-Match: *, file does not exist\n201 Created\n\nPUT If-None-Match: *, file does exist\n412 Precondition Failed\n\nPUT If-Match: *, file does exist\n204 No Content\n\nPUT If-Match: 'af508-2c-69e15c40', etag matches existing file\n204 No Content\n\nPUT If-Match: 'quatsch', etag seems to not exactly match existing file\n412 Precondition Failed\n\nThanks\nWerner\n
38034	Ruediger Pluem	1199450524000	Just to be crystal clear: Everything is now as you expect, right?
38034	Werner	1199454339000	Yes!\n\nYour patch fixes bug 38034.\n\nWerner\n
38034	Ruediger Pluem	1199455403000	Thanks for confirmation. I am sorry to say that it is likely that the patch\nmissed the boat for 2.2.7, but it is highly likely that it will be part of 2.2.8\nas it already has two votes for backport and only misses one:\n\nhttp://svn.apache.org/viewvc?view=rev&revision=609024\nhttp://svn.apache.org/viewvc/httpd/httpd/branches/2.2.x/STATUS?view=markup&pathrev=609024\n\nBut at least a accepted patch that is already in trunk is now available.\nThanks for being persistent.
38034	Michael Clark	1199487190000	Just a question related to this issue - not sure if I'm 100% correct in my\nthinking yet...\n\nDid ap_meet_condition fail because the ETag for the non-existant file is\nconstantly changing (mtime only ETag from http_etag.c) as there is no finfo\n(as a by product of it not existing)?\n\nlocks on non-existent files create a .DAV/.locknull so a resource does actually\nexist (a lock-null resource)? is this correct?\n\nI'm happy with the present work-around but if what i'm thinking is the case\nthen a cleaner fix in the future could be having mod_dav always\nproviding its ETags (overriding http_etag for DAV directories) and as it knows\nabout lock-null resources it could use the .locknull file for a constant\ninode-size-mtime Etag instead of just mtime, making ap_meets_condition happy?\n\nThat's if my assumptions are correct.
38034	Werner	1199499132000	In reply to comment #25:\n\nLock-null resources do *not* exist. Only the name is locked to prevent other\nclients from creating a resource with that name.\n\nLock-null resources have no etag and no mtime associated.\n\nGET requests on lock-null resources will fail with 404 NOT FOUND.\n\nAn LOCK If-None-Match: * must fail with '423 LOCKED' (not 412 PRECONDITION FAILED).\n\nFinally:\nLocked-null resources are deprecated by RFC 4918 in favour of locked-empty\nresources, which do exist. They will probably disappear in an overhaul of mod_dav.\n\nEtags in mod_dav and mod_dav_fs should be handled separately from the Apache\ncore. This is an open issue which cannot be solved that easy. Please see\nBug report #42987 as well as the discussion thread starting at\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200710.mbox/%3c470E9A9F.8020202@pearsoncmg.com%3e\n\nWerner\n
38034	Werner	1199522486000	Sorry, it's me again.\n\nThere seems to be a related bug in the way apache/mod_dav handles conditional\nPUT with header If-Unmodified-Since. It will always fail because\nap_meets_conditions does not know the mtime of the resource. This bug will not\nshow up most of the time as etag is checked first. I only noticed it, because a\nbug in davfs2 caused a PUT-request without If-Match-header and with\nIf-Unmodified-Since-header.\n\nAs the interface documentation of ap_meets_conditions in include/http_protocal.h\nsays, ap_meets_conditions is only ment for GET requests. It can't work with PUT.\nSo a future revision should either change ap_meets_conditions, as proposed by\nParitosh, or mod_dav should handle conditionals all of it's own (taking into\naccount that the requirements of WebDAV are quite different in this respect).\n\nWerner\n
38034	Julian Reschke	1199550896000	> So a future revision should either change ap_meets_conditions, as proposed by\n> Paritosh, or mod_dav should handle conditionals all of it's own (taking into\n> account that the requirements of WebDAV are quite different in this respect).\n\nThe requirements fot WebDAV are exactly the same as for plain HTTP, except for\nthe addition of the 'If' header.\n\nOr am I missing something?\n
38034	Werner	1199589795000	In reply to comment #28:\n\nYes, you missed the point.\n\nApache core does not handle PUT-requests and ap_meets_conditions is designed for\nGET/HEAD-requests only (this is documented behaviour). This is perfectly OK for\nthe vast majority of Web-servers (they don't need and don't want PUT). WebDAV is\nabout authoring and PUT is essential.\n\nWhy ap_meets_conditions cannot work with PUT:\nap_meets_conditions compares the validators from the request with the validators\nfrom the response. This is OK for GET.\nWith PUT-requests, the validators from the request have to be compared to the\nvalidators associated with the stored entity before the PUT-body is stored. The\nvalidators in the response will be different.\n\nIt is up to the decision by Apache developers, whether they want to\n- change ap_meets_conditions (this will change the interface), or\n- leave it to modules like mod_dav to check the conditions according to their needs.\n\nWerner\n
38034	Julian Reschke	1199597105000	What you're describing are the differences between Apache httpd and moddav, not\nbetween RFC2616 and RFC4918.\n\nPUT is part of RFC2616, so are all conditional headers (except 'If'). Maybe an\nHTTP server implementation that does not support PUT can get away with a simpler\n*implementation*, but that doesn't really change the required semantics.\n
38034	Werner	1199605018000	Hello Julian,\n\nthe header ot this page says 'ASF Bugzilla'. I assume 'A' stands for Apache, not\nfor Anything.\n\nWerner\n
38034	Tim Olsen	1199633082000	(In reply to comment #29)\n> the vast majority of Web-servers (they don't need and don't want PUT). WebDAV is\n\nIf Apache just wants to keep the status quo, then yes.  But PUT is showing up in REST-style applications \n(although disguised as a POST) and in XForms.  Core Apache may eventually want to care about PUT \n\n
38034	Ruediger Pluem	1200743289000	Fixed in 2.2.8.
38070	Masanari Iida	1137309247000	I have posted this symptom to apache users mailing list.\nNick Kew reply to the question.\n\nFrom: Nick Kew <>\tMailed-By: httpd.apache.org\nReply-To: users httpd apache org\nTo: users@httpd apache org\nDate: Jan 15, 2006 4:26 AM\nSubject: Re: [users@httpd] Bug or feature?\n\nOn Saturday 14 January 2006 18:04, Masanari Iida wrote:\n> Hi,\n>\n> I would like to ask the list members if following are\n> bug or feature of apache.\n>\n> Use following sample script,\n> Apache version: ANY  (1.3, 2.0 and 2.2)\n>\n> #!/bin/sh\n> cat <<EOT\n> Status: 200 OK\n> Last-Modified: Tue, 15 Feb 2005 15:00:00 GMT\n> Content-Type: text/html\n>\n> Hello world\n> EOT\n\nInteresting.  I can confirm that your CGI script with an If-Modified-Since\nheader later than the Last-Modified date supplied by the script does\nindeed return 200 with no body.  That's broken, but is it Apache or\nthe script that's at fault[1]?\n\nRFC2616 says of If-Modified-Since:\n\n     c) If the variant has not been modified since a valid If-^M\n        Modified-Since date, the server SHOULD return a 304 (Not^M\n        Modified) response.^M\n\nThat makes sense: the script is stupid but technically within its rights\nto send the 200 unconditionally.  So Apache should presumably\naccommodate it by ignoring the If-Modified-Since header and\nreturning 200 with the full body.\n\nIf that's not already in bugzilla, you might consider entering it there.\n\n[1] It's both, of course.\n\n--\nNick Kew
38070	Nick Kew	1137724682000	Fixed in trunk:  r370692 
38070	Dave Sparks	1138914368000	Are you sure you don't want to convert a CGI-generated 200 to a 304 when the\nHTTP conditions fail?  ap_scan_script_header_err is also called by mod_asis .  I\nuse mod_asis extensively, with files which include Last-Modified: and ETag:\nheaders, and it would be disastrous to return 200 when 304 would be appropriate.\n\nAdmittedly, I've had to patch both mod_asis.c and util_script.c to get the right\nresults, but my server seems to return the responses I expect.
38070	Nick Kew	1138930785000	(In reply to comment #3) \n> Are you sure you don't want to convert a CGI-generated 200 to a 304 when the \n> HTTP conditions fail? \n \nThere are two cases.  If the CGI *explicitly* generates a Status: header, we \nshould honour it.  If not, then we just need to generate whatever is \nappropriate - usually 200, or 302 if the CGI emitted a Location header. \n \n>   ap_scan_script_header_err is also called by mod_asis .  I \n \nThe crucial difference thare is that mod_asis isn't documented as having a \nStatus header (though I guess it might, if it goes through the same parsing as \nCGI). \n \n> use mod_asis extensively, with files which include Last-Modified: and ETag: \n> headers, and it would be disastrous to return 200 when 304 would be \nappropriate. \n \nYour asis doesn't say 'Status: foo'?  Then the patch won't affect it. \n>  \n> Admittedly, I've had to patch both mod_asis.c and util_script.c to get the \nright \n> results, but my server seems to return the responses I expect. \n \nIf you're saying we've got something wrong in the patch, please explain. 
38070	Nick Kew	1139079009000	Fixed in:  \n trunk: http://svn.apache.org/viewcvs?rev=370692&view=rev  \n 2.0:   http://svn.apache.org/viewcvs?rev=374894&view=rev \n 2.2:   http://svn.apache.org/viewcvs?rev=374895&view=rev 
38070	Masanari Iida	1140518983000	I have opened Red Hat's bugzilla case and ask RH to back\nport your patch into RH's.  \nhttps://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=176663\n\nThen RH's engineer wrote in comment #5.\n\n>Comment #5 From Joe Orton (jorton@redhat.com)  \t on 2006-02-20 10:49 EST  \n[reply]  \t   \t \n>\n>The fix committed upstream prevents handling of conditional requests with a CGI\n>script which outputs an explicit (albeit redundant) 'Status: 200' header.  This\n>would count as a regression so we would not include that patch as-is in a RHEL\n>update.\n>\n>I've prepared a (simpler) alternative patch, which fixes the real issue and will\n>make packages available for testing.\n>\n\n--- httpd-2.0.52/server/util_script.c.cgistatus\n+++ httpd-2.0.52/server/util_script.c\n@@ -462,6 +462,13 @@\n\n            if ((cgi_status == HTTP_OK) && (r->method_number == M_GET)) {\n                cond_status = ap_meets_conditions(r);\n+\n+                /* In case an explicit Status: header had set\n+                 * r->status_line, then unset it here, so that the\n+                 * actual handler return value will be honoured. */\n+                if (cond_status != OK) {\n+                    r->status_line = NULL;\n+                }\n            }\n            apr_table_overlap(r->err_headers_out, merge,\n                APR_OVERLAP_TABLES_MERGE);\n\nWith Red Hat's fix, apache with sample cgi return 200,304,304,304.\nWith Nick's fix, apache with sample cgi return 200,200,200,200.\nBoth cases, no more white (empty) display.\nBut,which one is better solution?\n
38070	Nick Kew	1140540968000	The CGI spec. is quite explicit on this: \n \n7.2.1.3. Status   \n The 'Status' header field is used to indicate to the server what status code  \nthe server MUST use in the response message. \n \nso a patch that causes it to change that breaks CGI. \n \nHaving said that, for the particular example reported in this bug, Joe's fix \nis better in practical terms.  That's because the CGI script itself misused \n'status'.  See todays thread on dev@httpd. 
38070	Dave Sparks	1140554364000	Notwithstanding a semantically flawed sentence in a draft which expired over six\nyears ago, a CGI script which includes cache validation headers in its response\ncannot rely on a status code of 200 being returned to the client.  An HTTP/1.1\nproxy may return a 304 response without troubling the server; or if it has to\ntransmit the request via an HTTP/1.0 proxy it may convert a conditional GET to a\nHEAD whose 200 response may be converted to a 304 if the conditions are\nsatisfied.  Insisting that a 200 response with cache validation headers be\ntransmitted unchanged is futile.\n\nThe draft supposedly encodes current CGI practice, but I suspect that in the\narea of cache validation headers in CGI-generated responses there is no current\npractice to encode.\n\nThe documentation for mod_asis says 'A Status: header is also required', where\n'required' implies that it can never be omitted.  Since the header handling is\ncommon with mod_cgi the documentation is plainly wrong.  I have removed the\nStatus line from my 802 .asis files with no ill effects.\n\nWhatever the outcome of the argument about 'Status: 200' with a 'Last-Modified:'\nwhich satisfies a conditional request, I'm going to have to continue to patch\nap_scan_script_header_err to include my 'ETag:' headers in the check.
38070	Nick Kew	1140560977000	(In response to Dave Sparks) \n \n1. What a proxy can do with a response is totally independent of CGI rules.  \nThey operate at different levels, and affect different agents. \n \n2. Thanks for the headsup re: mod_asis documentation.  I've just fixed \nthe .xml source, so that should propagate through to the live docs in due \ncourse. \n \n3. You keep telling us you had to patch a problem, but I still can't see a \nproblem description.  If we had one, maybe we could fix it, as we have done \nthe bug that was clearly and accurately described in this bug report. 
38084	Nick Kew	1136141606000	Fixed in the documentation source (SVN r360505).  Will percolate through to \nthe online HTML docs in due course. 
38084	Otmar Lendl	1171679158000	(In reply to comment #1)\n> Fixed in the documentation source (SVN r360505).  Will percolate through to \n> the online HTML docs in due course. \n\nAdditional comment regarding this case:\n\nWhile that documentation fix was definitly correct for the postgresql case, it\ncost me more than an hour of debugging as I simply changed the driver from psql\nto mysql and expected the params line to have the same syntax.\n\nYes, that is documented somewhere else, but it would be nice to add a remark to\nthe mod_authn_dbd page noting that other drivers need 'pass=' and not 'password='. \n\nThat subtile difference is otherwise easily overlooked.
38084	Tony Stevenson	1184333510000	Otmar,\n\nI'm not sure that adding arbitrary comments to one modules documentation will\nhelp someone looking for help with a different module.\n\nHowever I will add a disclaimer to the docs, that states that 'pass' or\n'password' are usually reserved words in rdbms'\n\n--\nTony\n
38108	Joe Orton	1136323138000	Do you have LANG set?  Google says this can happen because of an AIX bug with\nLANG set.
38108	Scott Fletcher	1136323461000	*** Bug 38111 has been marked as a duplicate of this bug. ***
38108	Scott Fletcher	1136323483000	*** Bug 38112 has been marked as a duplicate of this bug. ***
38108	Ruediger Pluem	1136325932000	*** Bug 38110 has been marked as a duplicate of this bug. ***
38108	Scott Fletcher	1136326864000	That's interesting.  I don't get it on why does the LANGUAGE have to do with this.\n\nI did 'echo $LANG' and got the 'en_US' response so I did this, 'export LANG='''\nand did the 'echo $LANG' and got the blank response.\n\nSo, tried running this command manually, '/usr/local/apache2/build/instdso.sh\nSH_LIBTOOL='/usr/local/apache2/build/libtool' libphp5.la\n/usr/local/apache2/modules' and still get this sed error message.  The same\nthing for 'make install' in the /usr/local/src/php5.1.1 directory.  I did the\nmake clean  and double check to make sure.
38108	Scott Fletcher	1136328256000	The output of the cat command of the libphp5.la in the\n/usr/local/apache/modules/libphp5.la result in ..\n\n--snip--\n# libphp5.la - a libtool library file\n# Generated by ltmain.sh - GNU libtool 1.5.18 (1.1220.2.245 2005/05/16 08:55:27)\n#\n# Please DO NOT delete this file!\n# It is necessary for linking the library.\n\n# The name that we can dlopen(3).\ndlname='libphp5.so'\n\n# Names of this library.\nlibrary_names='libphp5.a libphp5.a'\n\n# The name of the static archive.\nold_library=''\n\n# Libraries that this one depends upon.\ndependency_libs=' -lssl -lcrypto -lssl -lcrypto -lssl -lcrypto\n-L/usr/local/ssl/lib -L/usr/local/lib -lssl -lcrypto -lssl -lcrypto -lm\n/usr/local/lib/libcurl.la -lssl -lcrypto -lssl -lcrypto\n/usr/local/lib/libodbc.la -ldl -liconv -lthread'\n\n# Version information for libphp5.\ncurrent=0\nage=0\nrevision=0\n\n# Is this an already installed library?\ninstalled=yes\n\n# Should we warn about portability when linking against -modules?\nshouldnotlink=yes\n\n# Files to dlopen/dlpreopen\ndlopen=''\ndlpreopen=''\n\n# Directory that this library needs to be installed in:\nlibdir='/usr/local/src/php-5.1.1/libs'\n--snip--\n\nif that can be of a further help here..
38108	Joe Orton	1136902569000	Can you try adding at the top of build/instdso.sh:\n\nLANG=C\nLC_ALL=C\nLANGUAGE=C\nexport LANG LC_ALL LANGUAGE\n\n(and then 'make install' from httpd, then try installing PHP again)
38108	Scott Fletcher	1136918644000	Still get the same error but it look a little better...  The old error was \n\n--snip--\nsed: 0602-404 Function /^dlname=/{s/.*='/([^']*/)'//1/;p} cannot be parsed.\nsed: 0602-404 Function /^library_names/{s/library_names='/([^']*/)'//1/;p}\ncannot be parsed.\nWarning!  dlname not found in /usr/local/apache2/modules/libphp5.la.\nAssuming installing a .so rather than a libtool archive.\n--snip--\n\nwhile the new error is\n\n--snip--\nsed: Function /^dlname=/{s/.*='/([^']*/)'//1/;p} cannot be parsed.\nsed: Function /^library_names/{s/library_names='/([^']*/)'//1/;p} cannot be parsed.\nWarning!  dlname not found in /usr/local/apache2/modules/libphp5.la.\nAssuming installing a .so rather than a libtool archive.\n--snip--\n\nNoticed that the '0602-404' is no longer there in the new error message.  I'm\nnot sure if the AIX's native sed is that compatible with that sed script or not.
38108	Masaoki Kobayashi	1141295782000	Created an attachment (id=17816)\nPatch file to avoid sed errors on installing apache 2.2\n
38108	Masaoki Kobayashi	1141296330000	I believe the patch file I attached will eliminate sed error.\nIt has been affected to all environments so that the ${prefix}/modules \ndirectory contains '.a' and '.la' files because of this error.
38108	Scott Fletcher	1141319570000	>LANG=C\n>LC_ALL=C\n>LANGUAGE=C\n>export LANG LC_ALL LANGUAGE\n\nThe sed error you were referring to, I found out it only apply to AIX 4.3, not\nAIX 5.2.\n\nTrying your patch that eliminate the sed error and it seem to work pretty well\nwith no sed error but I get further compile error.  Here's what I got...\n\n--snip--\nInstalling PHP SAPI module:       apache2handler\n/usr/local/apache2/build/instdso.sh\nSH_LIBTOOL='/usr/local/apache2/build/libtool' libphp5.la /usr/local/apache2/modules\nrm -f /usr/local/apache2/modules/libphp5.so\n/usr/local/apache2/build/libtool --mode=install cp libphp5.la\n/usr/local/apache2/modules/\ncp .libs/libphp5.a /usr/local/apache2/modules/libphp5.a\ncp .libs/libphp5.lai /usr/local/apache2/modules/libphp5.la\nlibtool: install: warning: remember to run "libtool --finish\n/usr/local/src/php-5.1.2/libs'\nchmod 755 /usr/local/apache2/modules/libphp5.so\nchmod: /usr/local/apache2/modules/libphp5.so: A file or directory in the path\nname does not exist.\napxs:Error: Command failed with rc=65536\n--snip--\n\nSo, I check the /usr/local/apache2/module directory and found there is no\nlibphp5.so file.  So, with further studying and tracing to the instdso.sh script\nI noticed that \n\n--snip--\nrm -f /usr/local/apache2/modules/libphp5.so\n--snip-- \n\nis removed first as to remove the older or obselote file.  Then the next part\nget executed..\n\n--snip--\n/usr/local/apache2/build/libtool --mode=install cp libphp5.la\n/usr/local/apache2/modules/\n--snip--\n\nwhich does in fact copy both files, libphp5.a and libphp5.la files, not the\nlibphp5.so file.  So, hte next few part of the script which use sed.  With some\ntracing and execution of a shell script.  I get\n\n--snip--\nlibphp5.so\n\n\nlibphp5.a libphp5.a\n\n\nlibphp5.a libphp5.a\n--snip--\n\nand no sed error.  So, we the patch is working as it fix this bug.  Then further\nbelow in the script is a 'rm -f ....' script that remove those libphp5.a files\nso it explained why there's no libphp5.* files in that directory.  Which lead us\nto the next part of the script that caused the \n\n--snip--\nWarning!  dlname not found in /usr/local/apache2/modules/libphp5.la.\n--snip--\n\nto appear.  Then the next part of the script here\n\n--snip--\nif test '$DLNAME' != '$TARGET_NAME'\nthen\n    mv $TARGETDIR/$DLNAME $TARGETDIR/$TARGET_NAME\nfi\n--snip--\n\nwhere the 'if test' script produced a result..\n\n--snip--\nif test 'libphp5.so' != 'libphp5.so'\nthen \n    mv /usr/local/apache2/modules/libphp5.so /usr/local/apache2/modules/\nfi\n--snip--\n\nSo, this part of the script is correct and there's still no libphp5.so in that\ndirectory at all.  The next part of the script just removed everything.  So, no\nwonder why I get the apxs errors and chmod error.  The libphp5.so is never\ncopied over in the first place.\n\nI'm looking forward to a further patch fix that would allow the libphp5.so to be\nput into the /usr/local/apache2/module directory...  It is just a bad script.\n\nSo, go ahead and check in that patch fix as it fix this AIX sed problem....
38108	Joe Orton	1141387908000	Nice work Masaoki, was that patch to fix the issue with the AIX sed too?  We've\nhad a report of a similar error on Solaris too (bug 38696) so I've asked whether\nthis fix works there too.
38108	Joe Orton	1141387995000	this time, adding CC:\n\nNice work Masaoki, was that patch to fix the issue with the AIX sed too?  We've\nhad a report of a similar error on Solaris too (bug 38696) so I've asked whether\nthis fix works there too.
38108	Scott Fletcher	1141399315000	> was that patch to fix the issue with the AIX sed too?\nYea, for the AIX sed?
38108	Masaoki Kobayashi	1141615898000	Actually I don't have AIX environment.  This was not the right place to post the\npatch.  However, I guess, this should be common problem as just sed script\nstring was wrong.  I confirmed my pacth works on RedHat 7.3 x86 and Solaris 10 x86.
38108	Joe Orton	1141639047000	*** Bug 38696 has been marked as a duplicate of this bug. ***
38108	Scott Fletcher	1141657212000	I meant to say this patch fix for AIX's sed now work without a problem.  So, \nit's a good thing you posted here.  Since you mentioned Red Hat too.  (Along \nwith Sun)\n\nOS --> All\n\nLet us know the patch had been check into the branch.\n\nThe newer problem I have is not a sed bug (with the patch fix) so I'll file a \nnew bug later (cleaner bug report) on this week or next week as soon as I \nfinish rebuilting AIX from scratch.  (Well PHP folks said I need GNU Linker \nwhich doesn't solve the problem.  Also later learned that GNU Linker doesn't \nwork too well with AIX as it's incompactible with AIX and IBM's web site said \nwe only need to use the AIX's native sed instead of the GNU linker.  A sign of \nfurther messed up.)
38108	Masaoki Kobayashi	1141716860000	The original sed script works fine on GNU sed 4.1.2, while it does not on GNU \nsed 3.1 or Solaris sed.\nThe patched script works fine on all of above.
38108	Scott Fletcher	1143232607000	Filed bug #39099 for the php module that doesn't work in Apache 2.2.0.  Any\nchance of anyone testing this patch any further or checking it in to the branch\nwithout breaking it before the next Apache release?  I thought I did see\nsomewhere in the Apache file that specify the minimum GNU Sed version somewhere\nbut I couldn't find it.\n\nIs the reason for this bug being unchanged due to not assigning the bug to\nbugs@httpd.apache.org instead of leaving it as new?  This bugzilla is a little\nconfusing as I'm so used to the Mozilla's bugzilla.  Sorry for the spam if I\nmisunderstood.
38108	Joe Orton	1143645238000	No, just lazy engineers lacking round tuits.  This is now committed to the\ntrunk, and proposed for inclusion in 2.2.x.\n\nhttp://svn.apache.org/viewcvs?rev=389797&view=rev\n\nThanks again for the patch, Masaoki.
38123	Ruediger Pluem	1136411066000	This is because httpd is waiting for more header data. Please lower the value of\nTimeOut (default 300 seconds) to mitigate this problem. In general this can\nhappen with lots of other incompletely sent header situations.
38123	Joshua Slive	1137081647000	Not a security bug because the request does timeout.  But not a proper response\nto the request either.  httpd should give an immediate error rather than waiting.
38123	Ruediger Pluem	1137604103000	A patch was checked into trunk as r370172\n(http://svn.apache.org/viewcvs.cgi?rev=370172&view=rev).\nPatch:\nhttp://svn.apache.org/viewcvs.cgi/httpd/httpd/trunk/server/protocol.c?p2=%2Fhttpd%2Fhttpd%2Ftrunk%2Fserver%2Fprotocol.c&p1=httpd%2Fhttpd%2Ftrunk%2Fserver%2Fprotocol.c&r1=370172&r2=370171&rev=370172&view=diff&makepatch=1&diff_format=u
38123	Ruediger Pluem	1137889997000	Created an attachment (id=17481)\nImproved patch against 2.2.x\n
38123	Ruediger Pluem	1143844500000	Backported to 2.2.1 as r390503\n(http://svn.apache.org/viewcvs?rev=390503&view=rev).
38177	Garrett Rooney	1136957122000	Committed to the 1.3.x branch in r367914.  Thanks for the reminder!
38227	Ruediger Pluem	1137018379000	In order to make it reconnect please add retry=1 to your ProxyPass directive\n(see also parameter retry at\nhttp://httpd.apache.org/docs/2.2/mod/mod_proxy.html#proxypass)\nHave you checked for the Tomcat logs? The first error seems to indicate that\nTomcat is not responding any longer\n
38227	Malcolm Amir Hussain-Gambles	1140541053000	I have experienced the same bug, the problem also seem to cause the tomcat\nserver (5.0.28) to run out of threads, I assume the problem is also causing the\najp threads not to be closed, so I assume using a retry will not help.\nYet to confirm whether using prefork instead of worker fixes the problem, but\nI'll try this and add this to the bug report.\n\najp_read_header: ajp_ilink_receive failed\n(120006)APR does not understand this error code: proxy: read response failed\nfrom (null) (<ip_addr_here>)\nThen later \nproxy: AJP: failed to make connection to backend: <ip_addr_here>\n(110)Connection timed out: proxy: AJP: attempt to connect to <ip_addr_here>:8009\n(<ip_addr_here>) failed\n\nIt looks like tomcat can recover if it is under light load and the threads\ntimeout, but when the load increases tomcat dies as all the threads get used up\n\n
38227	Ruediger Pluem	1140561369000	Maybe PR#36495 is a similar bug. Could you please provide your proxy config?
38227	Brad Boyer	1140569266000	The config in bug 36495 is very similar to my original situation. Apache httpd\n2.2 and tomcat runnnig together on a single Linux box with the config on httpd\nusing ProxyPass to redirect to 127.0.0.1:8009. The messages once the poster\nmoved to 2.2 are basically the same.\n\nHere's the proxy config I have (with some URL segments changed to xxx):\n\n    ProxyRequests off\n    <Proxy *>\n        Order allow,deny\n        Deny from all\n    </Proxy>\n    <Proxy ajp://127.0.0.1:8009/*>\n        Order deny,allow\n        Allow from all\n    </Proxy>\n    ProxyPass /xxx ajp://127.0.0.1:8009/xxx
38227	Malcolm Amir Hussain-Gambles	1141045226000	After further testing this appears to be a problem with a misconfigured tomcat,\nthe ajp connector behaves differently in worker mode than prefork and requires a\nlarger number of tomcat ajp threads. Tested this under extreemly heavy load and\nall seems to work ok with no problems.\nThis is all documented in the connector docs, I guess I should have picked this\nup earlier.
38227	Ruediger Pluem	1141048158000	Thanks for feedback. Could you please add the link to the connector docs where\nyou found the information that solved your problem?
38227	Malcolm Amir Hussain-Gambles	1141211517000	Fixing the tomcat configuration did help, but it still appears that we are\nhaving the same problem where tomcat will run out of threads using ajp mod_proxy\nin worker mode.\nWe cannot reproduce this problem in testing, only on the live systems.\nNo real errors from apache except this, by which point tomcat has run out of\nthreads, which I assume why this error appears.\n[error] (70007)The timeout specified has expired: ajp_ilink_receive() can't\nreceive header\n\nWe also get this error in prefork mode, but it does not seem to cause tomcat to die
38227	Tino Schwarze	1143132704000	I'm seeing similar errors. \n\nThe setup is Apache 2.2.0 with mod_proxy_ajp and Tomcat 5.0.27. I tried\nRewriteRules with [P] first, then switched to ProxyPass - same result.\n\nThis is the log of the virtual host: (Servernames replaced by $MYSERVER, IPs\nreplaced by $LOCALIP)\n==> httpd_error_log <==\n[Thu Mar 23 16:23:09 2006] [error] ajp_read_header: ajp_ilink_receive failed\n[Thu Mar 23 16:23:09 2006] [error] (120006)APR does not understand this error\ncode: proxy: read response failed from (null) (localhost)\n                                                                               \n                                                                               \n                    \nThis is the global apache log:\n==> /opt/httpd/logs/error_log <==\n[Thu Mar 23 16:23:09 2006] [error] [client $LOCALIP] proxy: error reading status\nline from remote server $MYSERVER referer: $REFERER\n[Thu Mar 23 16:23:09 2006] [error] [client $LOCALIP] proxy: Error reading from\nremote server returned by $URL, referer: $REFERER\n[Thu Mar 23 16:23:09 2006] [error] (70007)The timeout specified has expired:\najp_ilink_receive() can't receive header\n\n\nNothing fancy shows up in catalina.out or Tomcat logs, just a lot of\n\nMar 23, 2006 4:24:40 PM org.apache.jk.common.ChannelSocket processConnection\nINFO: connection timeout reached\n\nbut they seem normal and occur all the time.\n\nI do _not_ see this behaviour under heavy load, I see it almost instantly.\n\nThings get worse: Connections from Apache to Tomcat stay open:\n\n[root@server root]# netstat -tn|sed -n -e '1,2p;/8059/p'\nActive Internet connections (w/o servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State\ntcp        1      0 127.0.0.1:46802         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46814         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46790         127.0.0.1:8059          CLOSE_WAIT\ntcp        0      0 127.0.0.1:46826         127.0.0.1:8059          ESTABLISHED\ntcp        1      0 127.0.0.1:46729         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46777         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46753         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46765         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46697         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46604         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46636         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46544         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46551         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46518         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46505         127.0.0.1:8059          CLOSE_WAIT\ntcp        1      0 127.0.0.1:46414         127.0.0.1:8059          CLOSE_WAIT\ntcp      794      0 127.0.0.1:8059          127.0.0.1:46328         CLOSE_WAIT\ntcp        0      0 127.0.0.1:8059          127.0.0.1:46826         ESTABLISHED\n\nThere are times when no ESTABLISHED connection is available - it seems to take\nquite long for tomcat to recover. Not that the Recv-Q has data in it!\n\nserver.xml snippet:\n\n    <Connector protocol='AJP/1.3'\n               address='127.0.0.1'\n               port='8059'\n               minProcessors='10'\n               maxProcessors='250'\n               maxPostSize='0'\n               enableLookups='false'\n               useBodyEncodingForURI='true'\n               acceptCount='25'\n               debug='0'\n               redirectPort=''\n               connectionTimeout='60000'\n    />\n\n(Yes, there are probably some superfluous settings there).\n\nI do not see an increase in thread count or apache child count (using prefork MPM).
38227	James A. Robinson	1144303406000	Created an attachment (id=18031)\nDebugging output patch referenced in my comment.\n\nI believe I'm seeing the same problem with my build of Apache 2.2.0\nconnecting to an instance of Tomcat 5.5.10.\n\nTHE SETUP\n\nI'm running this on a dual cpu (Intel(R) Xeon(TM) CPU 2.80GHz) machine\nrunning Linux 2.4.21-15.ELsmp.\tApache server-info reveals:\n\n  -D APACHE_MPM_DIR='server/mpm/worker'\n  -D APR_HAS_SENDFILE -D APR_HAS_MMAP\n  -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)\n  -D APR_USE_SYSVSEM_SERIALIZE\n  -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT\n  -D APR_HAS_OTHER_CHILD\n  -D AP_HAVE_RELIABLE_PIPED_LOGS\n  -D HTTPD_ROOT='/usr/local/apache/2.2.0'\n  -D SUEXEC_BIN='/usr/local/apache/2.2.0/bin/suexec'\n  -D DEFAULT_ERRORLOG='logs/error_log'\n  -D AP_TYPES_CONFIG_FILE='conf/mime.types'\n  -D SERVER_CONFIG_FILE='conf/httpd.conf'\n\nI'm using mod_proxy to balance incoming requests to an Apache\nVirtualHost to a mounted Tomcat service via AJP.  I think I've\nincluded the important Apache configuration below:\n\n  <Proxy balancer://tomcat>\n    BalancerMember ajp://server.mydomain.org:8009 route=server.mydomain.org\n  </Proxy>\n\n  <VirtualHost vhost.mydomain.org:80>\n    RewriteEngine on\n    RewriteCond %{ENV:HTTPD_BASE}/logs/myapp.pause -f\n    RewriteRule .* - [forbidden,last]\n    RewriteRule ^(/+test(?:/.*)?)$ /myapp$1 [env=internal:yes]\n    RewriteCond %{ENV:internal} =yes\n    RewriteRule ^(/+myapp/.*) $1 [passthrough,last]\n    RewriteRule ^/+myapp/(.*) /$1 [redirect=permanent,last]\n\n    ProxyPass /myapp balancer://tomcat/myapp stickysession=JSESSIONID\nnofailover=on\n    ProxyPassReverse / http://vhost.mydomain.org/myapp/\n    ProxyPassReverseCookiePath /myapp/ /\n  </VirtualHost>\n\nMy Tomcat Connector in server.xml is straightforward:\n\n    <Connector\n\t     protocol='AJP/1.3'\n\t      address='${catalina.hostname}'\n\t\t port='8009'\n\tenableLookups='false'\t\t     />\n\nSo a user connects to\n\n  http://vhost.mydomain.org/test\n\nand then mod_proxy will forward the request via AJP to\n\n  http://server.mydomain.org:8009/myapp/test\n\nThe 'test' servlet is a simple one.  It computes a random number been\n0 and 1000, and sleeps for that many milliseconds, before printing a\none line response to the client.\n\n\nTHE PROBLEM\n\nUsing this stripped down configuration, what I see when I use ab(1) to\nload test the service, is that Tomcat is forced to keep creating new\nthreads to service incoming connections, and it leaves them in the\nKeepalive state after ab(1) has finished.  Tomcat also indicates it is\n*using* those threads (perhaps polling on them?)\n\nEvery time I make a new request via mod_proxy, a new Thread is started\nin Tomcat.  However, when I query Tomcat directly, I see a thread get\ncreated, the request gets serviced, and the thread is switch to the\nReady steady, indicating it is now able to to accept new requests.\n\nIf I run\n\n  netstat -t | egrep '^tcp.*:8009'\n\non the server, I see a constantly growing number of connections\nbetween Apache and Tomcat.  When I query Tomcat directly, I do not see\nthis growing pool of connections.\n\nThis lead me to believe the problem was mod_proxy keeping connections\nopen (perhaps the backend pooling code), but failing to either reuse\nthem, or perhaps failing to properly close them on cleanup.\n\n\nTHE DEBUGGING\n\n\nFirst, I added some debugging to proxy_util.c.\tI've attached it to\nthis comment.  Basically all I did was print out a stupid log message\nwhen it first initializes, and then each time a connections is\nacquired.\n\nNow, starting up Apache I see this in the log:\n\n[Wed Apr 05 21:09:35 2006] [error] 0: worker->hmax: 25, worker->cp->res: not\nnull\n[Wed Apr 05 21:09:35 2006] [debug] proxy_util.c(1666): proxy: initialized\nworker 0 in child 16610 for (server.mydomain.org) min=0 max=25 smax=25\n[Wed Apr 05 21:09:35 2006] [error] 0: worker->hmax: 25, worker->cp->res: not\nnull\n[Wed Apr 05 21:09:35 2006] [debug] proxy_util.c(1666): proxy: initialized\nworker 2 in child 16610 for (*) min=0 max=25 smax=25\n\nFor my test I first see if any connections exist to Tomcat (there\nshould not be any):\n\n ; netstat -t | egrep '^tcp.*:8009' | tr -s ' '\n\nAs I expect, no connections exist.  Next, on a different machine, I\nmake a single request to my virtual host:\n\n  ab -n 1  http://vhost.mydomain.org/test\n\nIt completes, and tells me it was successful.  I see a bunch of\ndebugging in the log indicating mod_proxy is working.  In the chatter,\nI see my own debugging lines:\n\n[Wed Apr 05 21:09:43 2006] [error] 1: worker->hmax: 0, worker->cp->res: not\nnull\n[Wed Apr 05 21:09:43 2006] [error] 2: called connection_constructor\n\nThis surprises me for two reasons.  First of all, I was expecting\nworker->hmax to be 25, not 0.  The second reason is that I expected to\nsee that worker->cp->res have a value, not to be null.\n\n[As an aside, subsequent testing showed that if I added 'max=25' to\nthe BalanceMember configuration directive, worker->hmax would be 25 in\nrequests; the null value for worker->cp->res did not change.]\n\nNow, I check on my server to see if any connections exist (I expect a\nconnection, due to the connection pooling):\n\n; netstat -t | egrep '^tcp.*:8009' | tr -s ' '\ntcp 0 0 server.mydomain.org:8009 server.mydomain.org:39642 ESTABLISHED\ntcp 0 0 server.mydomain.org:39642 server.mydomain.org:8009 ESTABLISHED\n\n\nNow, if I run a second request, I would have expected mod_proxy_ajp to\nreuse the existing connection.\tBut look what happens after I ran my\nab command a second time:\n\n[Wed Apr 05 21:09:46 2006] [error] 1: worker->hmax: 0, worker->cp->res: null\n[Wed Apr 05 21:09:46 2006] [error] 2: called connection_constructor\n\nAnd netstat shows two *new* connections, for a total of four:\n\n  ; netstat -t | egrep '^tcp.*:8009' | tr -s ' '\n  tcp 0 0 server.mydomain.org:8009 server.mydomain.org:39753 ESTABLISHED\n  tcp 0 0 server.mydomain.org:8009 server.mydomain.org:39642 ESTABLISHED\n  tcp 0 0 server.mydomain.org:39753 server.mydomain.org:8009 ESTABLISHED\n  tcp 0 0 server.mydomain.org:39642 server.mydomain.org:8009 ESTABLISHED\n\nI tried making a number of connections, and watched the connections\ngrow until it filled all available threads on my Tomcat container\n(which was set to the default maxThreads of 200).  First, I reset\neverything:\n\n  ; apachectl stop\n  ; catalina.sh stop\n\n  ; apachectl start\n  ; catalina.sh start\n\n  ; netstat -t | egrep '^tcp.*:8009' | tr -s ' '|wc -l\n\t0\n\nAnd then on my test client I make 200 connections:\n\n   ab -n 200 http://vhost.mydomain.org/test\n\nand then my server shows over 400 established connections:\n\n  ; netstat -t | egrep '^tcp.*:8009' | tr -s ' '|grep -c ESTABLISHED\n  466\n\nAck!\n\nIf I tweak the proxy code, setting one of these the 'close'\nflags to true:\n\n  conn->close_on_recycle = 1;\n  conn->close = 1;\n\nThen Apache cleans itself up, and Tomcat does not get overwhelmed.\n\nWhat I'm unable to determine so far is if this is a problem with\nmod_proxy(_(balance|ajp))?.c, a problem with Tomcat + Apache, a\nproblem with the APR utilities, etc.  :(\n\nAny insights from folks would be much appreciated!\n\nApologies for the long post...\n\n\nJim\n
38227	Ruediger Pluem	1144309623000	Thank you very much for your detailed post. I suspect a thing that has been\nfixed meanwhile. Could you please give\nhttp://httpd.apache.org/dev/dist/httpd-2.2.1.tar.gz a try? Keep in mind that\nthis is NO official release of httpd-2.2.1, but one that the developers are\ncurrently deciding on whether to release it or not. It is known that this\ntarball currently contains a bug that prevents using SSL backends with the\nproxy, but this does not harm your current problem. It would be very nice if you\ncould give it a try and let me know the results.\n\nAnother thing regarding your astonishments regarding the reusing of connections.\nKeep in mind that the pool limit is PER httpd process. So the maximum number of\nconnections is not what you set via max, but <max> * <maximum number of httpd\nprocesses>. You have not posted your MPM settings here, so if you allow httpd to\ncreate 8 processes, 200 connections to the backend are ok.\n\n> And netstat shows two *new* connections, for a total of four:\n> \n>  ; netstat -t | egrep '^tcp.*:8009' | tr -s ' '\n>  tcp 0 0 server.mydomain.org:8009 server.mydomain.org:39753 ESTABLISHED\n>  tcp 0 0 server.mydomain.org:8009 server.mydomain.org:39642 ESTABLISHED\n>  tcp 0 0 server.mydomain.org:39753 server.mydomain.org:8009 ESTABLISHED\n>  tcp 0 0 server.mydomain.org:39642 server.mydomain.org:8009 ESTABLISHED\n\nActually there is only *one* more connection, but as httpd and Tomcat are\nrunning on the same server you see *both* ends of the tcp connection in netstat.\nIf you are running httpd and tomcat on the same server you have to divide your\nnetstat results by 2.
38227	James A. Robinson	1144311320000	(In reply to comment #10)\n> Thank you very much for your detailed post. I suspect a thing that has been\n> fixed meanwhile. Could you please give\n> http://httpd.apache.org/dev/dist/httpd-2.2.1.tar.gz a try?\n\nI certainly would be happy to!  I was about to post that I had added\nsome more debugging and discovered that mod_proxy was emitting\ninfo that it had initialized worker->id 0 and worked->id 2, but not\nworker->id 1, and that mod_proxy_ajp was being handed worker->id 1. Dunno\nif that was the problem being resolved in the fix. \n\nI will try 2.2.1 right now.  It'll take me a few minutes to compile and\ntest, but I'll post back here within the hour.\n\n> Actually there is only *one* more connection, but as httpd and Tomcat are\n> running on the same server you see *both* ends of the tcp connection in\n\nSorry, reading my original post shows I put too much stress on the high\nnumber of connections.  I was in fact realizing the two lines were from\nthe same connection, I was just surprised that new sockets kept getting\nadded instead of old ones being reused.
38227	James A. Robinson	1144313655000	(In reply to comment #10)\n> I suspect a thing that has been fixed meanwhile. Could you please give\n> http://httpd.apache.org/dev/dist/httpd-2.2.1.tar.gz a try? Keep in mind that\n> this is NO official release of httpd-2.2.1, but one that the developers are\n> currently deciding on whether to release it or not. It is known that this\n> tarball currently contains a bug that prevents using SSL backends with the\n> proxy, but this does not harm your current problem. It would be very nice if \n> you could give it a try and let me know the results.\n\nHi,\n\nI tried out 2.2.1, and I'm now seeing the kind of connection growth I\nexpected.\n\nI slowly increased the concurrent requests (from the original *1* thread\nI was using in the tests I originally posted about), to tens of threads,\nwithout seeing an undue increase in the number of used connections.\n\nI note that Tomcat does still eventually reach 200 active threads when\nI hit it Apache with many requests, but it appears as though Apache is\nnow reusing existing connections.\n\nFrom this first pass, it looks to me like 2.2.1 fixes the problem I was\nhaving. Thank you very much for your help!\n
38227	Ruediger Pluem	1144327250000	(In reply to comment #12)\n\n> \n> I note that Tomcat does still eventually reach 200 active threads when\n> I hit it Apache with many requests, but it appears as though Apache is\n\nAs mentioned, this possibly works as designed. This depends on your MPM settings.\n\n> \n> From this first pass, it looks to me like 2.2.1 fixes the problem I was\n\nSounds good. Please let me know the results if you do more intense tests.\n\n
38227	James A. Robinson	1144716023000	Created an attachment (id=18055)\nmake mod_proxy_balancer init_balancer_member call ap_proxy_initialize_worker\n\n(In reply to comment #13)\n>\n> As mentioned, this possibly works as designed. This depends on your MPM\nsettings.\n> \n> > \n> > From this first pass, it looks to me like 2.2.1 fixes the problem I was\n> \n> Sounds good. Please let me know the results if you do more intense tests.\n\nHi,\n\nI've done some more testing, and I *think* I may have found a bug with\nthe load balancer.  I am running httpd 2.2.1, with server/thread\nlimits of\n\n  StartServers 8\n  ServerLimit 16\n  ThreadsPerChild 64\n\nI allowed for 1024 threads on the Tomcat side.\tThe proxy setup is the\nsame as I mention in comment #9.\n\nWhen I was initially load testing the 2.2.1 server, I happened to be\nsetting the max attributes on the balancer:\n\n  <Proxy balancer://tomcat>\n    BalancerMember ajp://server.mydomain.org:8009 route=server.mydomain.org\nmax=64\n  </Proxy>\n\nThis seemed rock solid, I threw batches of 500+ concurrent requests\nfrom our Sun Fire T2000 to this linux server, and it dealt with the\nload.\n\nHowever, I then tried removing the 'max' attribute, and ran into some\nproblem.  I found that, without the hard-coded the max attribute, I\ncould reliably lock the system up when throwing 500 concurrent\nrequests at it.\n\nMy understanding from previous comments and the notes is that, if one\ndoes not specify additional attributes, the defaults should be to use\nthe ThreadsPerChild to set s/max:\n\n  smin=0  smax=64 max=64\n\nSetting LogLevel to debug I saw that mod_proxy code says\n\n[debug] proxy_util.c(1690): proxy: initialized worker 0 in child 15926 for\n(argo02.highwire.org) min=0 max=64 smax=64\n[debug] proxy_util.c(1690): proxy: initialized worker 2 in child 15926 for (*)\nmin=0 max=64 smax=64\n\nBut that it never said it had initialized worker 1.  Adding my own\ndebugging, I can see that 'worker 1' is the one which is being used by\nthe balancer, and that the 'worker 1' hmax was always 0 *if I did not\nset the 'max=64' attribute.*  In other words, it was never inheriting\nthe 'default' hmax.\n\nDelving into the mod_balancer code, I found that\n\n  mod_proxy_balancer.c:77\n  init_balancer_member(proxy_server_conf *, server_rec *, proxy_balancer *)\n\nwas running\n\n  ap_proxy_initialize_worker_share(conf, workers, s);\n\nbut was not running, as far as I could tell, anything which might\ninitialize all the other fields for the worker.  Is this a bug?\n\nI noted that mod_proxy.c:1867 and mod_proxy.c:1868 performs a two-step\ninitialization, where it calls ap_proxy_initialize_worker_share and\nthen it calls\n\n ap_proxy_initialize_worker(workers, s);\n\nNow, I don't know if this lack of a two-step initialization in\nmod_proxy_balancer is a problem (or if it just a lack of understanding\nof the code on my part), but I am finding that adding the second\ninitialization call to init_balancer_member seemed to fix the problem\nfor me (the default, ThreadsPerChild based, hmax was picked up for\nworker 1).\n\nAny thoughts?\n\nThank you for your time,\n\nJim\n
38227	James A. Robinson	1144943670000	Folks,\n\nI don't know if my previous followup on this bug was read or not, or\nif people are already looking at it.  Without feedback, I can't tell\nif I should keep pursuing this, follow up with more details, etc.\n\nI can understand somebody telling me 'No, we know this isn't the\nproblem' but I'm not hearing anything.  Without feedback I'm stuck not\nknowing if this is a bug or a fatal misunderstanding on my part.\n\nGiven httpd 2.2.1 and the following settings:\n\n  Server Version: Apache/2.2.1 (Unix) DAV/2 mod_ssl/2.2.1 OpenSSL/0.9.7a\n  Server Built: Apr 6 2006 00:22:26\n  Module Magic Number: 20051115:1\n  Hostname/port: server.mydomain.org:80\n  Timeouts: connection: 300    keep-alive: 300\n  MPM Name: Worker\n  MPM Information: Max Daemons: 2 Threaded: yes Forked: yes\n  Server Architecture: 32-bit\n  Server Root: /highwire/server/apache\n  Config File: -c/-C directives\n  Server Built With:\n    -D APACHE_MPM_DIR='server/mpm/worker'\n    -D APR_HAS_SENDFILE\n    -D APR_HAS_MMAP\n    -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)\n    -D APR_USE_SYSVSEM_SERIALIZE\n    -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT\n    -D APR_HAS_OTHER_CHILD\n    -D AP_HAVE_RELIABLE_PIPED_LOGS\n    -D HTTPD_ROOT='/usr/local/apache/2.2.1'\n    -D SUEXEC_BIN='/usr/local/apache/2.2.1/bin/suexec'\n    -D DEFAULT_ERRORLOG='logs/error_log'\n    -D AP_TYPES_CONFIG_FILE='conf/mime.types'\n    -D SERVER_CONFIG_FILE='conf/httpd.conf'\n\nIt appears as though the mod_proxy pool of connections is not being\nconsistently reused when the balancer is used.  Given the\nconfiguration:\n\n  ServerLimit 2\n  ThreadsPerChild 10\n\n  <Proxy balancer://tomcat>\n    BalancerMember ajp://server.mydomain.org:8009 route=server.mydomain.org\n  </Proxy>\n\n  <VirtualHost  vhost.mydomain.org:80>\n    ServerName  vhost.mydomain.org\n\n    RewriteEngine on\n\n    RewriteCond %{ENV:HTTPD_BASE}/logs/myapp.pause -f\n    RewriteRule .* - [forbidden,last]\n\n    DocumentRoot vhosts/myapp/htdocs\n\n    RewriteRule ^(/+test(?:/.*)?)$ /myapp$1 [env=internal:yes]\n\n    RewriteCond %{ENV:internal} =yes\n    RewriteRule ^(/+myapp/.*)  $1 [passthrough,last]\n    RewriteRule ^/+myapp/(.*) /$1 [redirect=permanent,last]\n\n    ProxyPass /myapp balancer://tomcat/myapp stickysession=JSESSIONID nofailover=on\n    ProxyPassReverse / http://vhost.mydomain.org/myapp/\n    ProxyPassReverseCookiePath /myapp/ /\n  </VirtualHost>\n\nMy understanding of the documentation\n\n  http://httpd.apache.org/docs/2.2/mod/mod_proxy.html#proxypass\n\nis that, with the above ServerLimit and ThreadPerChild limit, we\nshould never see more than 20 connections form between Apache and any\none BalancerMember target (2 servers x 10 threads = 20 total threads).\n\nOn startup, we see zero connections between Apache and Tomcat:\n\n  ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'\n  ;\n\nI make one request, and see one connection form:\n\n  ; ab -n 1 http://vhost.mydomain.org/test\n  ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'\n  tcp 0 0 server.mydomain.org:59165 server.mydomain.org:8009 ESTABLISHED\n\nNow what happens if I make 20 concurrent requests? What I would expect to\nsee is up to 20 connections established, and no more.\n\n  ; ab -c 20 -n 20 http://vhost.mydomain.org/test\n  ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'|wc -l\n       21\n\nIf I make another 20 connections, I see the connections more than\ndouble:\n\n  ; ab -c 20 -n 20 http://vhost.mydomain.org/test\n  ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'|wc -l\n       44\n\nNow look what happens when I plug in min/smax/max settings into the\nBalancerMember directive.  These are settings which I think the\ndocumentation indicates are the defaults, given my configuration\nabove:\n\n  <Proxy balancer://tomcat>\n    BalancerMember ajp://server.mydomain.org:8009 route=server.mydomain.org\nmin=0 smax=10 max=10\n  </Proxy>\n\nAfter an apache restart, we have no connections, I make a bunch of\nrequests, and see 20 connections, and never more than that.  Even when\nI make 50 concurrent requests, Apache simply queues and processes as\nit should:\n\n  ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'|wc -l\n        0\n\n  ; ab -c 20 -n 20 http://vhost.mydomain.org/test\n  ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'|wc -l\n       20\n\n  ; ab -c 50 -n 50 http://vhost.mydomain.org/test\n  ; netstat -t | tr -s ' ' | egrep '^tcp.*:8009 ESTABLISHED'|wc -l\n       20\n\nIf we activate the balancer, and the balancer has only one Tomcat\ntarget as in this case, shouldn't it should still be obeying the same\nlimits as defined in the configuration.  Otherwise we have a situation\nwhere the number of proxy connections is unbounded, right?\n\nSay Apache is configured to serve no more than 1024 requests at any\none moment in time, and we wanted to balance load between two Tomcat\nservers.  What we'd probably do is set up two Tomcat servers which are\neach configured to accept 1024 requests, but we would expect to see\napache balancer send ~512 requests to each Tomcat server.  What we\nwould *not* expect to see is Apache opening more connections to a\nTomcat server than Apache itself is configured to serve at any one\ntime.\n\nIn summary, it appears to be a bug to have to declare min/smax/max\nvalues which are the same as the defaults per the documentation,\nwithout which the number of connections opened appears to be\nunbounded.\n\nMy examination of the code led me to believe that the source of the\nproblem is that the BalancerMember worker is not getting its hmax\nvalue properly initialized, and that it is therefore bypassing the\npool of reusable connections when it is acquiring connections\n(proxy_util.c:1758, in ap_proxy_acquire_connection).\n\nIf I add the patch I submitted in comment #14 and remove the\nmin/smax/max directives, I see the behavior I am expecting -- Apache\nnever opens more than 20 connections in all to its Tomcat server.\n\nLooking at svn.apache.org, I see that initialization was actually\nremoved in a previous version, though the comments do not explain why\nit is not appropriate to initialize the balancer worker:\n\n \nhttp://svn.apache.org/viewcvs.cgi/httpd/httpd/trunk/modules/proxy/proxy_balancer.c?rev=105347&r1=105320&r2=105347\n\nThe only reason I can think of to have the current behavior is that\nsomehow the dynamic of balancing between multiple backend servers is\nexpected to be able to handle more connections -- but it just doesn't\nmake sense to me that it would ever be normal for Apache to open more\nconnections to any one backend server than Apache can serve itself.\n\nIf this isn't considered a bug, I'd very much appreciate it if someone\nwould point out the reason.\n\nThank you for your time,\n\n\nJim\n
38227	Ruediger Pluem	1145015034000	You are correct this is a bug. I checked your patch and it looks fine. I have\nnot committed it yet, because I want to find out the reason, why we are making a\ncopy of each worker we add to a balancer (see\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200604.mbox/%3c443F81D8.3030401@apache.org%3e).\nIf we would not make a copy of each worker there would be no need for additional\ninitialization.
38227	James A. Robinson	1145028913000	Thank you for the details. My impression has been that the additional\nworker copies are somehow meant to be virtual, and the intent was to\nhave them resolve to the actual workers.  I wasn't actually seeing\nwhere that occured in the code though.\n\nI'll watch the email thread you refer to with interest! Please let me\nknow if you need any further debugging/testing done.\n
38227	Ruediger Pluem	1145178994000	If it turns out that copying the worker is not really the correct thing to do it\nwould require several changes to the code to do this differently. These changes\nwill take some time. As your patch does not run in a wrong direction and we\nactually have the bug now I committed your patch to the trunk as r394446\n(http://svn.apache.org/viewcvs?rev=394446&view=rev).
38227	Ruediger Pluem	1145270621000	Proposed for backport to 2.2.x as r394653\n(http://svn.apache.org/viewcvs?rev=394653&view=rev).
38227	Ruediger Pluem	1145719595000	Backported to 2.2.x as r396050 (http://svn.apache.org/viewcvs?rev=396050&view=rev).
38227	Ruediger Pluem	1145719647000	*** Bug 39267 has been marked as a duplicate of this bug. ***
38277	Lee Thompson	1137280351000	Created an attachment (id=17423)\npkg-config for openssl\n\nThink this fixes the issue
38277	Joe Orton	1137412142000	That's not correct; what needs to be done to fix this is to set the\nPKG_CONFIG_PATH environment variable at the same time that CPPFLAGS is set when\nan  argument is passed to --with-ssl
38277	Joe Orton	1140174744000	Fixed on the trunk:\n\nhttp://svn.apache.org/viewcvs.cgi?rev=378473&view=rev\n\nThanks for the report.
38277	Lee Thompson	1140388692000	I like your patch better than mine.  Yours is compliant with the documentation\nof pkgconfig.
38301	Alex Hudson	1137502301000	Created an attachment (id=17443)\nProposed patch to add the necessary mime types.\n
38301	Alex Hudson	1149153300000	Just to update this bug, the MIME types mentioned have now been registered with\nIANA; see vnd.oasis.opendocument.*\n\nIt would be good to see future versions of Apache deliver these files correctly\nout-of-the-box.
38301	Lars Nood	1149166495000	The full list can be found at IANA:\n   http://www.iana.org/assignments/media-types/application/
38301	Roy T. Fielding	1188473369000	Committed to trunk in rev 571267.\n
38340	Aleksey Pesternikov	1137806626000	Created an attachment (id=17470)\nPatch against 2.2\n
38340	Aleksey Pesternikov	1137806881000	Created an attachment (id=17471)\nPatch against trunk\n\nThe trunk version is got ahead so patch is different
38340	Ruediger Pluem	1137809034000	Thanks for the patch. From the first glance it seems to do the correct thing.\nCould you please attach a testcase (e.g. a jsp) such that I can doublecheck the\npatch?
38340	Ruediger Pluem	1137844240000	Forget about the example. I was not able to reproduce the problem, because I\nused Tomcat 5 to test which does not sent the headers back as integers any\nlonger but as strings.\nBTW: Your trunk version of the patch is wrong as we need to peek at this\nposition of the code. Nevertheless the 2.2.x version looks good and I will take\ncare of it.
38340	Ruediger Pluem	1137847790000	Committed to trunk as r371013 \n(http://svn.apache.org/viewcvs.cgi?rev=371013&view=rev) and proposed for \nbackport as r371014 (http://svn.apache.org/viewcvs.cgi?rev=&view=rev). 
38340	Aleksey Pesternikov	1138042971000	(In reply to comment #5) \n> Committed to trunk as r371013  \n> (http://svn.apache.org/viewcvs.cgi?rev=371013&view=rev) and proposed for  \n> backport as r371014 (http://svn.apache.org/viewcvs.cgi?rev=&view=rev).  \n \nThank you, Ruediger! \n \nI have a small comment on reproducing the problem. \ndefault connector in Tomcat 4.1 is org.apache.coyote.tomcat4.CoyoteConnector \nwhich works ok. \nTo reproduce the problem you have to use \norg.apache.ajp.tomcat4.Ajp13Connector. \nThis is a part of server.xml as of jakarta-tomcat-4.1.31-src.tar.gz: \n \n    <!-- Define a Coyote/JK2 AJP 1.3 Connector on port 8009 --> \n    <Connector className='org.apache.coyote.tomcat4.CoyoteConnector' \n               port='8009' minProcessors='5' maxProcessors='75' \n               enableLookups='true' redirectPort='8443' \n               acceptCount='10' debug='0' connectionTimeout='0' \n               useURIValidationHack='false' \n               \nprotocolHandlerClassName='org.apache.jk.server.JkCoyoteHandler'/> \n \n    <!-- Define an AJP 1.3 Connector on port 8009 --> \n    <!-- \n    <Connector className='org.apache.ajp.tomcat4.Ajp13Connector' \n               port='8009' minProcessors='5' maxProcessors='75' \n               acceptCount='10' debug='0'/> \n    --> \n \nSo you need to comment out the first connector and uncomment the second one. \nAfter that any access (even 404) will cause the problem. \n 
38340	Ruediger Pluem	1138051547000	(In reply to comment #6)\n\n> To reproduce the problem you have to use \n> org.apache.ajp.tomcat4.Ajp13Connector.\n\nThis is the one that had been marked deprecated some time ago :-).\n
38340	Aleksey Pesternikov	1138054854000	(In reply to comment #7) \n> > To reproduce the problem you have to use  \n> > org.apache.ajp.tomcat4.Ajp13Connector. \n>  \n> This is the one that had been marked deprecated some time ago :-). \n \nNot a good reason to break own specs \nhttp://httpd.apache.org/docs/2.2/mod/mod_proxy_ajp.html.en#resppacketstruct \n 
38403	matthias	1138303800000	> This bug is probably related to #36951, however the offered solution was for\n> 2.1.8 and not merged into 2.2.0.\nsorry wrong guess, ' rv=APR_EOF; ' is in 2.2.0, it's probably a similar thing on\nanother line 
38403	matthias	1138304545000	(In reply to comment #1)\n> sorry wrong guess, ' rv=APR_EOF; ' is in 2.2.0, it's probably a similar thing on\n> another line \nYES, about 35 lines above is the same situation as in #36951 only for the\nanother socket (i guess the one to the remote server). (this makes sense, as I\nhad a 'buggy' backend server, while the other bug hat 'buggy' client.\n\nI'm trying the patched version and get the info back here.\n\nIf this sounds like a good thing, can someone provide a patch and get this into\nCVS ? Sorry I'm not that good with this
38403	Ruediger Pluem	1138313828000	Could you please let me know where in the code (filename, line) you suppose the\nerror?\nPR #36951 is about mod_proxy_connect. I doubt that it is used in your reverse\nproxy configuration.\nRegarding the problem getting a backtrace:\nYou called gdb with the LWP id:\n\ngdb httpd 1928\n\nTry to call it with the PID of the LWP. That would be\n\ngdb httpd -p 1839\n\nHope that helps.\nFurther debugging tips can be found at:\nhttp://httpd.apache.org/dev/debugging.html
38403	Ruediger Pluem	1138313906000	Forgot one thing: Debugging can be problematic if you compiled your httpd with\n--enable-pie on Linux.
38403	matthias	1138365409000	its build without pie, however i tried to build everything static .\n\nthx for the gdb hint, heres the output\n\n(gdb) info threads\n  3 Thread -1884591184 (LWP 8768)  0xb7e7f308 in allocator_free () from\n/home/apache22/lib/libapr-1.so.0\n  2 Thread -2052428880 (LWP 8785)  0x0807b039 in ap_core_input_filter ()\n  1 Thread -1209833792 (LWP 8702)  0xb7f89402 in ?? ()\n(gdb) thread 3\n[Switching to thread 3 (Thread -1884591184 (LWP 8768))]#0  0xb7e7f308 in\nallocator_free () from /home/apache22/lib/libapr-1.so.0\n(gdb) bt\n#0  0xb7e7f308 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n#1  0xb7e7f224 in apr_allocator_free () from /home/apache22/lib/libapr-1.so.0\n#2  0xb7f6a81f in apr_bucket_free () from /home/apache22/lib/libaprutil-1.so.0\n#3  0xb7f6b146 in heap_bucket_destroy () from /home/apache22/lib/libaprutil-1.so.0\n#4  0xb7f6b35c in apr_brigade_cleanup () from /home/apache22/lib/libaprutil-1.so.0\n#5  0xb7f6b3b1 in apr_brigade_destroy () from /home/apache22/lib/libaprutil-1.so.0\n#6  0x0806e810 in ap_getline ()\n#7  0x0809b7a0 in ap_proxy_http_process_response ()\n#8  0x0809c878 in proxy_http_handler ()\n#9  0x08095249 in proxy_run_scheme_handler ()\n#10 0x08092ab1 in proxy_handler ()\n#11 0x0807ce41 in ap_run_handler ()\n#12 0x0807d581 in ap_invoke_handler ()\n#13 0x080b4a66 in ap_process_request ()\n#14 0x080b1f7c in ap_process_http_connection ()\n#15 0x080842d8 in ap_run_process_connection ()\n#16 0x08084707 in ap_process_connection ()\n#17 0x080c2ecb in process_socket ()\n#18 0x080c36d4 in worker_thread ()\n#19 0xb7e8b868 in dummy_worker () from /home/apache22/lib/libapr-1.so.0\n#20 0x00bfb341 in start_thread () from /lib/tls/libpthread.so.0\n#21 0x00b136fe in clone () from /lib/tls/libc.so.6\n(gdb) thread 2\n[Switching to thread 2 (Thread -2052428880 (LWP 8785))]#0  0x0807b039 in\nap_core_input_filter ()\n(gdb) bt\n#0  0x0807b039 in ap_core_input_filter ()\n#1  0x08087957 in ap_get_brigade ()\n#2  0x0806e3c8 in ap_rgetline_core ()\n#3  0x0806e7ff in ap_getline ()\n#4  0x0809b4f9 in ap_proxy_read_headers ()\n#5  0x0809ba00 in ap_proxy_http_process_response ()\n#6  0x0809c878 in proxy_http_handler ()\n#7  0x08095249 in proxy_run_scheme_handler ()\n#8  0x08092ab1 in proxy_handler ()\n#9  0x0807ce41 in ap_run_handler ()\n#10 0x0807d581 in ap_invoke_handler ()\n#11 0x080b4a66 in ap_process_request ()\n#12 0x080b1f7c in ap_process_http_connection ()\n#13 0x080842d8 in ap_run_process_connection ()\n#14 0x08084707 in ap_process_connection ()\n#15 0x080c2ecb in process_socket ()\n#16 0x080c36d4 in worker_thread ()\n#17 0xb7e8b868 in dummy_worker () from /home/apache22/lib/libapr-1.so.0\n#18 0x00bfb341 in start_thread () from /lib/tls/libpthread.so.0\n#19 0x00b136fe in clone () from /lib/tls/libc.so.6\n(gdb) thread 1\n[Switching to thread 1 (Thread -1209833792 (LWP 8702))]#0  0xb7f89402 in ?? ()\n(gdb) bt\n#0  0xb7f89402 in ?? ()\n#1  0x00bfc06d in pthread_join () from /lib/tls/libpthread.so.0\n#2  0xb7e8ba3b in apr_thread_join () from /home/apache22/lib/libapr-1.so.0\n#3  0x080c3c89 in join_workers ()\n#4  0x080c4090 in child_main ()\n#5  0x080c419d in make_child ()\n#6  0x080c46c3 in perform_idle_server_maintenance ()\n#7  0x080c48e4 in server_main_loop ()\n#8  0x080c4bb8 in ap_mpm_run ()\n#9  0x080683aa in main ()\n\n\nI reattached the process a few times, the threads seem to do not leave their\nfunctions.\n\nstepi circles around this:\n\n0xb7e7f277 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f27a in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f27c in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f27f in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f282 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f285 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f288 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f28c in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2a6 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2aa in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2ac in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2af in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2b2 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2b5 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2b9 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2bb in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2bd in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2cd in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2d0 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2d3 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2d6 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2da in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2dd in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2e0 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f2e2 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f300 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f303 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f306 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f308 in allocator_free () from /home/apache22/lib/libapr-1.so.0\n0xb7e7f30a in allocator_free () from /home/apache22/lib/libapr-1.so.0
38403	matthias	1138368788000	This was the proposed patch, but i guess you're right and this is not used in my\nsetup.\n\n\n*** mod_proxy_connect.c.myversion 2006-01-26 18:32:12.000000000 +0000\n--- mod_proxy_connect.c.orig    2006-01-27 11:32:08.000000000 +0000\n*************** static int proxy_connect_handler(request\n*** 325,334 ****\n                      else\n                          break;\n                  }\n!                 else if ((pollevent & APR_POLLERR) || (pollevent & APR_POLLHUP)) {\n!                   rv = APR_EOF;\n                      break;\n-               }\n              }\n              else if (cur->desc.s == client_socket) {\n                  pollevent = cur->rtnevents;\n--- 325,332 ----\n                      else\n                          break;\n                  }\n!                 else if ((pollevent & APR_POLLERR) || (pollevent & APR_POLLHUP))\n                      break;\n              }\n              else if (cur->desc.s == client_socket) {\n                  pollevent = cur->rtnevents;\n\n\n\n\nAnother interesting point:  \nI configured the server to use a pool for to the backend server:\n\n\nit limits the maximal connections to the backend server. this works normal, but\nif i have this amok threads it stops working. could be related to the behaviour\nof a graceful restart ..\n
38403	matthias	1138369024000	> it limits the maximal connections to the backend server. this works normal, but\n> if i have this amok threads it stops working. could be related to the behaviour\n> of a graceful restart ..\n> \n\nto clarify this is the pool:\nProxyPass           / http://127.0.0.1:8081/ min=1 smax=10 max=14 ttl=120\nacquire=10000 timeout=5 retry=2\n\nwenn starting multiple clients against a sleep.php there are no more than 14\nconenctions on the backend. with a amok-thread + possibly after a graceful\nrestart. there's no limit on the connections to the backend anymore. \n\nthis could be intended behaviour of graceful restart or it is related to the\nloop above which prevents apache from counting. \n\nI know that the limit is per process, so i double checked that there's only one\nprocess with 250 threads running in apache2.\n
38403	Ruediger Pluem	1138409135000	Please do not change the assignments of bugs.
38403	matthias	1138454717000	(In reply to comment #8)\n> Please do not change the assignments of bugs.\nI'm sorry, this info on the status link encouraged me:\n'Once you provide this information, please reassign thebug back to the person\nthat placed it in the NEEDINFO status.'\nhttp://issues.apache.org/bugzilla/page.cgi?id=fields.html#status
38403	Ruediger Pluem	1138538662000	To be sure that the thread is really looping in allocator_free, could you please\nrun ltrace against the process to see which library calls it does?
38403	matthias	1139054563000	we were unable to ltrace the processes (ltrace returns without error, and\nsometimes kills the amok process). we found out from looking at /proc, that it\nis not the allocator_free thread which consumes the cpu, but the\ncore_input_filter thread (telling from the SleepAVG in /proc/PID/status).\n\nwe recompiled with -ggdb and obtained more infos at the next occurence of the\nphenomenon. \n\n(gdb) info threads\n  3 Thread -2063254608 (LWP 9309)  allocator_free (allocator=0x195737d0,\nnode=0xa52eec0) at memory/unix/apr_pools.c:332\n  2 Thread 1801628592 (LWP 9350)  0x0807af5b in ap_core_input_filter\n(f=0x195740b8, b=0x9feddc8, mode=AP_MODE_GETLINE, block=APR_BLOCK_READ, readbytes=0)\n    at core_filters.c:141\n  1 Thread -1210169664 (LWP 9228)  0xb7f09402 in __kernel_vsyscall ()\n\nI attach a complete backtrace to this bug. Bottom line is, that we are stuck on\nthis line: \n\nap_core_input_filter (f=0x195740b8, b=0x9feddc8, mode=AP_MODE_GETLINE,\n    block=APR_BLOCK_READ, readbytes=0) at core_filters.c:141\n141         BRIGADE_NORMALIZE(ctx->b);\n\n\ncode says this:\n\n    /* ### This is bad. */\n    BRIGADE_NORMALIZE(ctx->b);\n\n\nbut I'm not sure whether 'this is bad' refers to a possible bug or just a\nperformance issue. \n\nIs there a simple way to inspect the BRIGADE in gdb ? I guess there's a special\nsituation with the brigade or its buckets, that arives from the fact that we run\nthe http-backend on localhost (probably caused by unusual/local tcp behaviour ?)
38403	matthias	1139054669000	Created an attachment (id=17584)\nfull gdb backtrace, (copied from shell)\n
38403	Ruediger Pluem	1139057056000	(In reply to comment #11)\nThanks for the update.\n\n> \n> ap_core_input_filter (f=0x195740b8, b=0x9feddc8, mode=AP_MODE_GETLINE,\n>     block=APR_BLOCK_READ, readbytes=0) at core_filters.c:141\n> 141         BRIGADE_NORMALIZE(ctx->b);\n> \n> \n> code says this:\n> \n>     /* ### This is bad. */\n>     BRIGADE_NORMALIZE(ctx->b);\n> \n> \n> but I'm not sure whether 'this is bad' refers to a possible bug or just a\n> performance issue. \n> \n> Is there a simple way to inspect the BRIGADE in gdb ? I guess there's a special\n\nYes, there is a helpful macro to inspect a brigade in gdb (dump_brigade). Please\nhave a look at the end of the section of\nhttp://httpd.apache.org/dev/debugging.html#gdb\n\nBRIGADE_NORMALIZE is a macro that does a loop. May it would be helpful to replace\n\nBRIGADE_NORMALIZE(ctx->b);\n\nwith the expanded macro to see if the loop is never left.\n\ndo { \n    apr_bucket *e = APR_BRIGADE_FIRST(ctx->b); \n    do {  \n        if (e->length == 0 && !APR_BUCKET_IS_METADATA(e)) { \n            apr_bucket *d; \n            d = APR_BUCKET_NEXT(e); \n            apr_bucket_delete(e); \n            e = d; \n        } \n        else { \n            e = APR_BUCKET_NEXT(e); \n        } \n    } while (!APR_BRIGADE_EMPTY(ctx->b) && (e != APR_BRIGADE_SENTINEL(ctx->b))); \n} while (0)\n\nFurthermore it would be better to use step / next instead of stepi to check\nwhere the code circles. stepi only executes one assembler instruction, whereas\nstep executes one line of C code.\n\nIn your initial comment to this bug you mentioned that a thread is looping with\nclose(-1). Would it be possible to get a backtrace of this thread?\n\nSo I would recommend the following next steps:\n\n1. Expand the BRIGADE_NORMALIZE macro and recompile.\n2. If the error occurs again do a dump_brigade ctx->b and attach the output\n3. Check with if the BRIGADE_NORMALIZE loop is left. For this set a breakpoint\nafter the loop and cont. If you reach it the loop is left if not we circle in\nthe loop.\n4. Try to get a backtrace of the thread that loops with close(-1)
38403	matthias	1139166036000	short update: I'm still trying to hunt it down. here's a short summary:\n\nCurrently not reproducable at will, but steadily recurring about once a day. \n\nAs long as I did close looks at it, there are always 2 threads with similar\nstack trace ( ap_proxy_http_process_response, one ap_proxy_read_headers, the\nother just ap_getline ). While one is cleaning up, the other is probably stuck\nin BRIGADE_NORMALIZE (which also does some cleanup). Sounds like a race\ncondition where 2 threads are cleaning up the same brigade. (I will try to get\nsome info on the brigade that the other thread tries to cleanup, next time). \n\nstep/next did not return the last time, so the MACRO line was never left. \n\nthe strace close(-1) threads does only show up 1 in 10 times. Either its a\ndifferent bug or it is about the repeated cleanup/normalization of a\nsocket-bucket. Most of the times the threads produce no system/library calls, so\nI guess they are caught in a very small loop.
38403	matthias	1139253562000	We probably found the root of evil:\n\na graceful restart does destroy but not reinitialize the resource list that\nkeeps the pooled connections. this is due to a early return in\nap_proxy_initialize_worker (proxy_util.c) when called again. Our patch is not\nnice, but worked for us. (restart instead of graceful did it also as workaround)\n\n\n--- proxy_util.c        2006-02-06 13:59:35.000000000 +0000\n+++ proxy_util.c.orig   2006-02-06 17:48:39.000000000 +0000\n@@ -1629,7 +1630,7 @@\n     int mpm_threads;\n #endif\n\n-    if (worker->s->status & PROXY_WORKER_INITIALIZED && worker->cp->res) {\n+    if (worker->s->status & PROXY_WORKER_INITIALIZED) {\n         /* The worker is already initialized */\n         return APR_SUCCESS;\n     }\n\n\nWe noticed this when we tried to force the 99% cpu threads by stressing the\nwebserver with ab ( -k -c 20 ). after a graceful restart the server was likely\nto coredump at \n\nproxy_util.c:1758 (*conn)->worker = worker;\n\nbecause conn was null. it seems that conn is deleted be another thread.\nconditional breakpoints above proxy_util.c:1745 (rv = APR_SUCCESS;) never\nspotted a conn = 0.\n\nbefore the graceful we run through this condition (no problems) but after\ngracefull res is null.\n\n    if (worker->hmax && worker->cp->res) {\n        rv = apr_reslist_acquire(worker->cp->res, (void **)conn);\n    }\n\nthis change in flow introduces the concurrency problems. is the else branch\nwithout the pool threadsafe or only intended for prefork ? \n\nSome facts that would speek for the graceful theory:\na) 99% threads only appeared on servers in the farm that used graceful and not\nrestart\nb) they only appeared after a graceful, never directly after startup\nc) after a graceful, there was no limit on the number of backend connections\n\n\non the setup: We use Dual Xeons with Hyperthreading (so there might be higher\nconcurrency) and we compiled with --enable-nonportable-atomics
38403	Ruediger Pluem	1139346988000	Thanks for the update and the in depth analysis. From my first brief into this I\nagree that the resource list needs to be initialized in these cases.\nBut it seems also that your patch as you assumed isn't complete. From a first\nbrief view I think more fixes are required.\nAs I am still wondering whether the problem that is fixed by your patch is\nreally the root cause of the problem you reported I would like you to keep me\nupdated if the problem is gone with your patched httpd's.\nAnyway: Good work.
38403	matthias	1139682118000	Feedback: we are running almost a week now with the patched version. So far this\nserver remains free of problems, except for 2 seg faults in 5 days. (so there's\nmore to do as you said)\n\nOn the other servers in the farm I got one 99% percent process in the last 5\ndays and a whole bunch of segfaults. \n\nThey are all running non-patched non-debug httpds and are running on same\nhardware, kernel, config etc. except that they do a restart instead of graceful,\nwhich has helped so far (i thought). So if 'restart' always runs the if-branch\nthat creates the pool, than you're right and it was not the root of OUR evil).\n\nI also have to modify my statement that 99er only appear on graceful restarting\napaches, they are just more likely to be seen there and to survive long enough\nto be analyzed.\n\nWe will do more testing with patched versions next week and see if we can get\nmore insight. I'll keep you updated.
38403	Ruediger Pluem	1143882386000	Meanwhile patches have been created on trunk that are proposed for backport:\n\nhttp://svn.apache.org/viewcvs?rev=377738&view=rev\nhttp://svn.apache.org/viewcvs?rev=377780&view=rev\n
38403	Ruediger Pluem	1143929758000	Backported to 2.2.1.
38448	Stijn Hoop	1138638515000	Created an attachment (id=17536)\npatch to reserve ~ character in mod_proxy\n\nHere is the trivial patch.
38448	Stijn Hoop	1155031265000	well.. guess nobody's interested either way?
38448	Nick Kew	1155041300000	(In reply to comment #2)\n> well.. guess nobody's interested either way?\n\n~ may or may not be a reserved character according to which edition of the RFC \nyou read.  Encoding it as %7E is a safe option.\n\nI don't see any strong reason to apply your patch (but feel free to try and \nconvince me).  Neither do I see any reason to close this report - it's marked \nas PatchAvailable for the benefit of anyone who wants it.
38448	Nick Kew	1155079998000	I changed my mind since my previous comment, and I've committed this \nto /trunk/.  Thanks:-)
38448	Stijn Hoop	1155193255000	Many thanks! That's one less customized package to maintain!
38448	Nick Kew	1188541710000	Fixed in 2.2 branch (r571456).  Closing.
38449	Ruediger Pluem	1138658679000	Thanks for the fix. Committed as r373585\n(http://svn.apache.org/viewcvs.cgi?rev=373585&view=rev) to the trunk and as\nr373588 (http://svn.apache.org/viewcvs.cgi?rev=373588&view=rev) to 2.2.x
38521	Nick Kew	1139171569000	Actually a 301 redirect, which then returns 404. \n \nNow fixed in svn, so that'll percolate through to the site soon - thanks. 
38524	Ruediger Pluem	1139347812000	Created an attachment (id=17619)\nPatch against trunk\n\nI had a look in this issue and have an idea why this happens. I still need some\ndiscussion for this patch on the dev list, but I would like to know if it fixes\nyour problem. So could you please try the attached patch and check if it solves\nthe problem?
38524	matthias	1139362396000	thanks for the quick patch, it works for me. However you also need to get rid of\nline 616 which already clears the connection header from the headers_in.
38524	Ruediger Pluem	1139433072000	(In reply to comment #2)\n> thanks for the quick patch, it works for me. However you also need to get rid of\n> line 616 which already clears the connection header from the headers_in.\n\nThanks for the quick test. I think you mean line 620, don't you?\nAlas! Stupid copy and paste error. Thanks for pointing it out.\nI will discuss the patch on the dev list and keep you in the loop.\n\n
38524	Ruediger Pluem	1139433160000	Next stupid thing of mine: Of course its 616 in the patched version, but 620 in\nthe unpatched one :-).
38524	matthias	1139444285000	I really should RTFM of patch and diff, so line numbers and order of fileargs \nwouldn't be a problem ...\n\n2 things I'm wondering as code novice about: does the copied table get freed and\nwouldn't it be better to just save the removed headers ? (P.S: patch isnt't in\nproductive environment yet, so we don't know of possible side-effects)
38524	Ruediger Pluem	1139495163000	(In reply to comment #5)\n> I really should RTFM of patch and diff, so line numbers and order of fileargs \n> wouldn't be a problem ...\n\nI should have looked at the patched version :-).\n\n> \n> 2 things I'm wondering as code novice about: does the copied table get freed and\n\nYes, because the space is allocated from a memory pool and this pool is cleaned\nafter the end of the request.\n\n> wouldn't it be better to just save the removed headers ? (P.S: patch isnt't in\n> productive environment yet, so we don't know of possible side-effects)\n\nIn principle yes, especially if the other headers are large. I have to take a\nlook into it whether the extra effort of doing so is justified, because several\nheaders are removed by ap_proxy_clear_connection and it adds some work to save\nthem and merge them back in. The full copy approach has a simpler logic and if\npossible I like to keep things simple :-)
38524	Ruediger Pluem	1139528549000	(In reply to comment #6)\n\n> \n> > wouldn't it be better to just save the removed headers ? (P.S: patch isnt't in\n> > productive environment yet, so we don't know of possible side-effects)\n\nMeanwhile I had a closer look into this and as apr_table_copy only copies the\npointers to the key / value pairs of the headers I guess we neither gain much\nspeed (actually I think we will loose speed for a small number of headers) nor\nsave a reasonable amount of memory (also guess that we waste memory for a low\nnumber of headers) by only saving the removed headers and merg??ng them back in\nlater on.\nI keep you updated.\n\n
38524	Ruediger Pluem	1139696413000	I committed two patches to the trunk (r377053 and r377057,\nhttp://svn.apache.org/viewcvs.cgi?rev=377053&view=rev,\nhttp://svn.apache.org/viewcvs.cgi?rev=377057&view=rev). r377053 fixes the\nproblem with the missing keepalive headers in the response, wheras r377055\nprevents the closing of the backend connection if the client send Connection: close.
38524	Ruediger Pluem	1139875594000	http://svn.apache.org/viewcvs.cgi?rev=377053&view=rev introduced a pool memory\nproblem since I used the wrong pool for apr_table_copy.\nhttp://svn.apache.org/viewcvs.cgi?rev=377525&view=rev should fix this, but I am\nwaiting for confirmation by other developers. I keep you updated.\n\n
38524	Ruediger Pluem	1140311058000	It has been confirmed that http://svn.apache.org/viewcvs.cgi?rev=377525&view=rev\nfixes the pool memory problem. So could you please test with both patches\napplied and let me know the results? Many thanks.
38524	matthias	1140740466000	we are running the patches productive, keepalive headers are correctly exchanged\nbetween browser and frontend apache (mod_proxy). Backend Connections remain open\nas far as the backends keep alive settings permits it. No memory problems\nnoticed. Good work. Thanks.
38524	Philip Brusten	1148377256000	We were experiencing the same problem for our reverse proxy (v2.0) and therefore\nupdated to version 2.2.2 that included this patch.\nFor testing and debugging purposes we used HTTP connections to our backend (a\nwebdispatcher).\nClient <--https--> Apache2.2.2 as Reverse Proxy <--http--> Dispatcher <--http-->\nApp Server\n\nFor production we need a HTTPS connection to this webdispatcher.\nClient <--https--> Apache2.2.2 as Reverse Proxy <--httpS--> Dispatcher\n<--http--> App Server\n\nWhen using this setup (mod_proxy + mod_ssl), we're experiencing a lot more\nconnections in contrast to the setup without mod_ssl.\nSince I cannot sniff on these HTTPS connections, I cannot provide you with any logs.\n\nHas anyone experienced the same problem? Any suggestions? 
38524	James	1148377580000	From mod_proxy_http.c Apache 2.2.2\n\n  /*\n     * TODO: Currently we cannot handle persistent SSL backend connections,\n     * because we recreate backend->connection for each request and thus\n     * try to initialize an already existing SSL connection. This does\n     * not work.\n     */\n    if (is_ssl)\n        backend->close_on_recycle = 1;\n\n(In reply to comment #12)\n> We were experiencing the same problem for our reverse proxy (v2.0) and therefore\n> updated to version 2.2.2 that included this patch.\n> For testing and debugging purposes we used HTTP connections to our backend (a\n> webdispatcher).\n> Client <--https--> Apache2.2.2 as Reverse Proxy <--http--> Dispatcher <--http-->\n> App Server\n> \n> For production we need a HTTPS connection to this webdispatcher.\n> Client <--https--> Apache2.2.2 as Reverse Proxy <--httpS--> Dispatcher\n> <--http--> App Server\n> \n> When using this setup (mod_proxy + mod_ssl), we're experiencing a lot more\n> connections in contrast to the setup without mod_ssl.\n> Since I cannot sniff on these HTTPS connections, I cannot provide you with any\nlogs.\n> \n> Has anyone experienced the same problem? Any suggestions? \n\n(In reply to comment #12)\n> We were experiencing the same problem for our reverse proxy (v2.0) and therefore\n> updated to version 2.2.2 that included this patch.\n> For testing and debugging purposes we used HTTP connections to our backend (a\n> webdispatcher).\n> Client <--https--> Apache2.2.2 as Reverse Proxy <--http--> Dispatcher <--http-->\n> App Server\n> \n> For production we need a HTTPS connection to this webdispatcher.\n> Client <--https--> Apache2.2.2 as Reverse Proxy <--httpS--> Dispatcher\n> <--http--> App Server\n> \n> When using this setup (mod_proxy + mod_ssl), we're experiencing a lot more\n> connections in contrast to the setup without mod_ssl.\n> Since I cannot sniff on these HTTPS connections, I cannot provide you with any\nlogs.\n> \n> Has anyone experienced the same problem? Any suggestions? \n\n(In reply to comment #12)\n> We were experiencing the same problem for our reverse proxy (v2.0) and therefore\n> updated to version 2.2.2 that included this patch.\n> For testing and debugging purposes we used HTTP connections to our backend (a\n> webdispatcher).\n> Client <--https--> Apache2.2.2 as Reverse Proxy <--http--> Dispatcher <--http-->\n> App Server\n> \n> For production we need a HTTPS connection to this webdispatcher.\n> Client <--https--> Apache2.2.2 as Reverse Proxy <--httpS--> Dispatcher\n> <--http--> App Server\n> \n> When using this setup (mod_proxy + mod_ssl), we're experiencing a lot more\n> connections in contrast to the setup without mod_ssl.\n> Since I cannot sniff on these HTTPS connections, I cannot provide you with any\nlogs.\n> \n> Has anyone experienced the same problem? Any suggestions? \n\n
38602	Doug Dixon	1139719216000	In HTTP/1.1 the _default_ behaviour is to use persistent connections. To quote\nthe spec:\n\n'A significant difference between HTTP/1.1 and earlier versions of HTTP is that\npersistent connections are the default behavior of any HTTP connection. That is,\nunless otherwise indicated, the client SHOULD assume that the server will\nmaintain a persistent connection, even after error responses from the server.'\n\nSo in this case IE is sending a Keep-Alive header to try to get persistent\nconnections even if it's talking to an HTTP/1.0 server that supports them. It's\nnot needed for HTTP/1.1 servers.\n\nAnyway, it looks to me like you probably are getting persistent connections\nbetween Apache and JBoss, which I infer from the HTTP/1.1 in the request and\nresponse headers and more specifically from the lack of a 'Connection: close'\nheader from JBoss. ('Connection: close' is how an HTTP/1.1 server says it wants\nto close the TCP connection)\n\nThis is not conclusive, though. The Ultimate Test, of course - and what I\nrecommend - is to look at the TCP conversation between your hosts (e.g. with\nEthereal or Tethereal) to see whether TCP connections really are being closed\nafter each request.
38602	Jean Dagenais	1139858149000	I did a trace with Ethereal, and the socket connection between IE and Apache \nis kept open, but a new socket is used between Apache and JBoss for each \nexchange.\n\nIE Is running on 198.252.177.123\nApache is running on 198.252.177.38\nJBOss is running on 198.252.177.19\n\nNo.     Time        Source                Destination           Protocol Info\n     16 0.250856    198.252.177.123       198.252.177.38        HTTP     \nGET /jmsproxy/company/jmsproxy/u.jsp?diagnum=221\n     17 0.000203    198.252.177.38        198.252.177.19        TCP      11970 \n> 8080 [SYN] Seq=0 Ack=0 Win=5840 Len=0 MSS=1460 TSV=8098330 TSER=0 WS=9\n     18 0.000053    198.252.177.19        198.252.177.38        TCP      8080 \n> 11970 [SYN, ACK] Seq=0 Ack=1 Win=5792 Len=0 MSS=1460 TSV=30418315 \nTSER=8098330 WS=9\n     19 0.000022    198.252.177.38        198.252.177.19        TCP      11970 \n> 8080 [ACK] Seq=1 Ack=1 Win=6144 Len=0 TSV=8098330 TSER=30418315\n     20 0.000066    198.252.177.38        198.252.177.19        HTTP     \nGET /jmsproxy/company/jmsproxy/u.jsp?diagnum=221\n     21 0.000156    198.252.177.19        198.252.177.38        TCP      8080 \n> 11970 [ACK] Seq=1 Ack=858 Win=7680 Len=0 TSV=30418316 TSER=8098330\n     22 0.102066    198.252.177.19        198.252.177.38        HTTP     \nHTTP/1.1 200 OK\n     23 0.000011    198.252.177.38        198.252.177.19        TCP      11970 \n> 8080 [ACK] Seq=858 Ack=257 Win=7168 Len=0 TSV=8098432 TSER=30418418\n     24 0.000086    198.252.177.38        198.252.177.19        TCP      11970 \n> 8080 [FIN, ACK] Seq=858 Ack=257 Win=7168 Len=0 TSV=8098432 TSER=30418418\n     25 0.000041    198.252.177.38        198.252.177.123       HTTP     \nHTTP/1.1 200 OK\n     26 0.000114    198.252.177.19        198.252.177.38        TCP      8080 \n> 11970 [FIN, ACK] Seq=257 Ack=859 Win=7680 Len=0 TSV=30418418 TSER=8098432\n     27 0.000010    198.252.177.38        198.252.177.19        TCP      11970 \n> 8080 [ACK] Seq=859 Ack=258 Win=7168 Len=0 TSV=8098432 TSER=30418418\n     28 0.217864    198.252.177.123       198.252.177.38        TCP      1578 \n> http [ACK] Seq=1493 Ack=512 Win=16656 Len=0\n\n\n     29 0.091197    198.252.177.123       198.252.177.38        HTTP     \nGET /jmsproxy/company/jmsproxy/u.jsp?diagnum=222\n     30 0.000145    198.252.177.38        198.252.177.19        TCP      11971 \n> 8080 [SYN] Seq=0 Ack=0 Win=5840 Len=0 MSS=1460 TSV=8098741 TSER=0 WS=9\n     31 0.000107    198.252.177.19        198.252.177.38        TCP      8080 \n> 11971 [SYN, ACK] Seq=0 Ack=1 Win=5792 Len=0 MSS=1460 TSV=30418727 \nTSER=8098741 WS=9\n     32 0.000014    198.252.177.38        198.252.177.19        TCP      11971 \n> 8080 [ACK] Seq=1 Ack=1 Win=6144 Len=0 TSV=8098742 TSER=30418727\n     33 0.000064    198.252.177.38        198.252.177.19        HTTP     \nGET /jmsproxy/company/jmsproxy/u.jsp?diagnum=222\n     34 0.000170    198.252.177.19        198.252.177.38        TCP      8080 \n> 11971 [ACK] Seq=1 Ack=857 Win=7680 Len=0 TSV=30418728 TSER=8098742\n     35 0.102191    198.252.177.19        198.252.177.38        HTTP     \nHTTP/1.1 200 OK\n     36 0.000009    198.252.177.38        198.252.177.19        TCP      11971 \n> 8080 [ACK] Seq=857 Ack=257 Win=7168 Len=0 TSV=8098844 TSER=30418830\n     37 0.000079    198.252.177.38        198.252.177.19        TCP      11971 \n> 8080 [FIN, ACK] Seq=857 Ack=257 Win=7168 Len=0 TSV=8098844 TSER=30418830\n     38 0.000041    198.252.177.38        198.252.177.123       HTTP     \nHTTP/1.1 200 OK\n     39 0.000122    198.252.177.19        198.252.177.38        TCP      8080 \n> 11971 [FIN, ACK] Seq=257 Ack=858 Win=7680 Len=0 TSV=30418830 TSER=8098844\n     40 0.000009    198.252.177.38        198.252.177.19        TCP      11971 \n> 8080 [ACK] Seq=858 Ack=258 Win=7168 Len=0 TSV=8098844 TSER=30418830\n\n\nI am also trying to used pooled connection to the backend, \n\ne.g. ProxyPass /example http://backend.example.com min=20 max=50 \n\nand I was wondering why I do not see these 20 connections created when I start \nthe Apache server? Does it require a Proxy message do be received before \ncreating these connections?
38602	Ruediger Pluem	1140039372000	A patch against trunk has been created (r378032,\nhttp://svn.apache.org/viewcvs?rev=378032&view=rev). Could you please give it a try?\nPlease keep in mind that there is a further keepalive bug with mod_proxy on the\nclient side of the connection (#38524).
38602	Jean Dagenais	1141743477000	I verified the patch, and it solve the issues with Keep Alive connections.\n\nThe connections are kept open, and the Keep-Alive header is passed to the \nJBoss server.\n\nThanks a lot!
38602	Ruediger Pluem	1141763753000	Proposed for backport as r383321 (http://svn.apache.org/viewcvs?rev=383321&view=rev)
38602	Ruediger Pluem	1144700285000	*** Bug 39258 has been marked as a duplicate of this bug. ***
38602	Ruediger Pluem	1144793693000	*** Bug 39258 has been marked as a duplicate of this bug. ***
38602	Axel-Stephane Smorgrav	1199837330000	*** Bug 43238 has been marked as a duplicate of this bug. ***
38699	Christophe JAILLET	1140215559000	Created an attachment (id=17732)\nPatch for the proposed clean-up\n
38699	Christophe JAILLET	1175349495000	Created an attachment (id=19852)\nUpdated patch\n\nThe patch has been updated to be synchronized with the current SVN HEAD.
38699	Nick Kew	1184870611000	http://svn.apache.org/viewvc?view=rev&revision=557837\n
38701	Christophe JAILLET	1140216162000	Created an attachment (id=17733)\nproposed patch for the clean up\n
38701	Jeff Trawick	1142538021000	Thanks for the patch!  It has now been committed to trunk.
38737	Chris Darroch	1140542872000	Created an attachment (id=17761)\nsignals worker threads after closing their sockets\n
38737	Chris Darroch	1140542900000	Created an attachment (id=17762)\nsame again for event MPM\n
38737	Chris Darroch	1140631672000	(From update of attachment 17762)\nActually, this isn't needed because of the asynchronous polling on Keep-Alives.\n
38737	Chris Darroch	1148668547000	Committed to 2.3 HEAD:\n\nhttp://svn.apache.org/viewvc?view=rev&revision=409715
38737	Chris Darroch	1148674651000	Created an attachment (id=18355)\npatch for current 2.2.x branch\n
38793	matthias	1141499910000	I did some more debugging and found a strange behaviour in ap_proxy_connect_backend\n\n#0  ap_proxy_connect_backend (proxy_function=0x80d5ff9 'HTTP', conn=0x9d0cfd8,\nworker=0x9c95db0, s=0x9d154c8) at proxy_util.c:2045\n        rv = 164679640\n        connected = 1\n        loglevel = 164190680\n        backend_addr = (apr_sockaddr_t *) 0x9d60a00\n        newsock = (apr_socket_t *) 0x9d8fa28\n#1  0x0809c748 in proxy_http_handler (r=0x9d99af8, worker=0x9c95db0,\nconf=0x9c959d8, url=0x9d91268 '/test/output.php?delay=0', proxyname=0x0,\nproxyport=0)\n    at mod_proxy_http.c:1691\n\nI put a breakpoint on the return statement in case that conn->sock is null,\nhowever the function will return true, because its internal newsock is valid and\nits connected counter is 1. (see stacktrace above). conn looks magically empty:\n\n(gdb) inspect conn->hostname\n$4 = 0x0\n(gdb) inspect conn->port\n$5 = 0\n(gdb) inspect conn->pool\n$6 = (apr_pool_t *) 0x9d60768\n(gdb) inspect conn->is_ssl\n$7 = 0\n(gdb) inspect conn->sock\n$8 = (apr_socket_t *) 0x0\n(gdb) inspect conn->addr\n$9 = (apr_sockaddr_t *) 0x0\n(gdb) inspect conn->flags\n$10 = 0\n(gdb) inspect conn->close\n$11 = 0\n(gdb) inspect conn->close_on_recycle\n$12 = 0\n(gdb) inspect conn->worker\n$13 = (proxy_worker *) 0x9c95db0\n\nconnected is only set right after conn->sock = newsock , both vars are never\ntouched until return then. How does conn become so empty ? I also do not have\nany of the error messages from ap_proxy_connect_backend in the error_log, so I\nassume the bad boy might be another thread.\n\nI get the following error messages from other threads and they are already int\nthe logfile when the above breakpoint is hit, so chances are that things get\nmessed up here.\n\n[Sat Mar 04 18:12:48 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Sat Mar 04 18:12:48 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n\nabove this errormessage is \nap_proxy_http_cleanup(NULL, r, backend);\nwhich i think is redundant as proxy_http_handler runs cleanup: anyway. removing\ndid not fix the problem. \n\nLet me know if this looks like something to go into deeper.\n(PS. We are running mod_worker)\n
38793	Ruediger Pluem	1141568003000	Created an attachment (id=17836)\nTemporary debug patch to narrow down the problem.\n\nCould you please apply the attached patch temporarily and set the LogLevel to\ndebug? A conn data structure should be only leased to one thread at the same\ntime from the connection pool. So in theory different threads should not have\naccess to the same data structure at the same time. The patch logs the aquire\nand release operations and hopefully helps to see if this is not the case.
38793	matthias	1141676199000	switch loglevel to debug eliminates problem ( probably because of a change in\ntiming because of the additional overhead).\n\nI changed the patch to log as ERROR. I grepped the logfile for the segfaulting\nbackend and all non 'backend' messages:\n\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Aquired backend 0x987bff8 for\nrequest 0xa9e20540, connection 0xaa01ab08, pid 13549, tid 0xb4184bb0\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Released backend 0x987bff8 for\nrequest 0xa9e20540, connection 0xaa01ab08, pid 13549, tid 0xb4184bb0\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Released backend 0x987bff8 for\nrequest 0xa9e20540, connection 0xaa01ab08, pid 13549, tid 0xb4184bb0\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Aquired backend 0x987bff8 for\nrequest 0xaa034be8, connection 0xaa030d90, pid 13549, tid 0xadd7abb0\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Aquired backend 0x987bff8 for\nrequest 0xa9e2a568, connection 0xaa018a90, pid 13549, tid 0xaf17cbb0\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Released backend 0x987bff8 for\nrequest 0xa9e2a568, connection 0xaa018a90, pid 13549, tid 0xaf17cbb0\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Released backend 0x987bff8 for\nrequest 0xa9e2a568, connection 0xaa018a90, pid 13549, tid 0xaf17cbb0\n\nThe backend gets released, 'error reading status line' gets logged, and the same\nbackend gets released again. Afterwards it gets acquired by 2 different threads. \nOne thread fails with same error (0xaf17cbb0) releasing the backend, the other\nthread gets the segfault (0xadd7abb0) while in ap_proxy_connection_create. (gdb bt).\n\nI suspect   ap_proxy_http_cleanup(NULL, r, backend)   in line 1220 ( and 1246,\nnumbers my vary because of your patch ) of mod_proxy_http.c to be the problem,\nas mentioned in previous comment, it gets called there and again in line 1741,\nafter the cleanup:-goto.  I don't know what the proxy_function argument means in\nline 1741, because the other cleanups are called with NULL ?\n\n\n\nRemoving line 1220 eliminates the Segfaults. But I get these lines after some\ntime running ab:\n\n(99)Cannot assign requested address: proxy: HTTP: attempt to connect to\n127.0.0.1:8081 (127.0.0.1) failed\n\nI guess this could be related to a temporary shortage of tcp-ip source ports\n(I'm running ab from the same machine and it never happens for the first 20000\nrequests)
38793	matthias	1141677324000	BTW: this also fixes the ' remote server (null) ' thing of the error line.\nsee also: http://issues.apache.org/bugzilla/show_bug.cgi?id=37770#c2\n\n
38793	Ruediger Pluem	1141686261000	Many thanks for the update. It was very helpful. The problem seems to be caused\nby the fact that apr_reslist_release does not notice 'double releases' (see also\nhttp://marc.theaimsgroup.com/?l=apr-dev&m=114168465029319&w=2).\nI am checking now if this is a bug inside apr-util or inside the proxy code.\nIf it is a bug inside the proxy code, I need to implement additional measures to\nprevent such 'double releases' (apart from removing the unnecessary double calls\nto ap_proxy_http_cleanup which you already mentioned). These additional measures\nshould help track down such issues faster in the future and prevent the server\nfrom segfaulting in such situations. I'll keep you updated.
38793	Ruediger Pluem	1142122372000	Created an attachment (id=17874)\nPatch against trunk to fix double return of connections to pool\n\nI created a patch that removes the double calls to ap_proxy_http_cleanup and\nadds a check if a connection has been already returned to the connection pool\nbefore. Could you please give the patch a try and let me know if this fixes\nyour problem and if you do not see any error messages of 'proxy: Pooled\nconnection 0x%pp for worker %s has been already returned to the connection\npool.'. Thanks.\n
38793	matthias	1143548033000	We applied the patch about 10 days ago, no double-free warnings so far. Crash is\nno longer reproducable with ab in test environment. \n\nHowever we are still seeing segfaults in our logfiles in production use. I have\nthe suspect it might be related to mod_ssl, but I did not have time to look into\nthis so far. \n\nSo this patch is probably ready to roll, although there's more to do ...
38793	Ruediger Pluem	1145020856000	Committed patch to trunk as r394088\n(http://svn.apache.org/viewcvs?rev=394088&view=rev).
38793	Ruediger Pluem	1145270624000	Proposed for backport to 2.2.x as r394653\n(http://svn.apache.org/viewcvs?rev=394653&view=rev).
38793	Ruediger Pluem	1145719710000	Backported to 2.2.x as r396049 ( http://svn.apache.org/viewcvs?rev=396049&view=rev).
38819	Bob Ionescu	1141228195000	Created an attachment (id=17814)\nproposed patch\n
38819	Joshua Slive	1185885619000	I just removed the compatibility line entirely, since we don't track whether\n2.2+ is compatible with 1.3.
38819	Takashi Sato	1204103157000	Please backport\n\nhttp://httpd.apache.org/docs/2.0/en/mod/mod_headers.html\nhttp://httpd.apache.org/docs/2.2/en/mod/mod_headers.html
38838	Joe Orton	1141391098000	Created an attachment (id=17823)\nshmcb inline-beats-alignment-workaround fix\n\nGosh, haven't had to fix one of these for ages.  Are you using gcc?  If so,\nwhat version?\n\nCan you try the attached patch?\n
38838	Alex Deiter	1141391924000	# /usr/local/bin/gcc -v\nUsing built-in specs.\nTarget: sparc64-sun-solaris2.9\nConfigured with: ../configure --prefix=/usr/local --libexecdir=/usr/local/lib\n--enable-threads=solaris --enable-languages=c,c++ --enable-shared=libstdc++\n--disable-multilib --disable-nls --disable-libstdcxx-pch sparc64-sun-solaris2.9\nThread model: solaris\ngcc version 4.0.2\n
38838	Alex Deiter	1141393543000	> Can you try the attached patch?\n\nPatch work fine for me. Thanks for a fast reply!\n\nThanks a lot!
38838	Joe Orton	1143648566000	Fixed on trunk and proposed for inclusion in 2.2.x: thanks for the report.\n\nhttp://svn.apache.org/viewcvs?rev=382799&view=rev
38848	Sander Temme	1141458713000	FWIW I'm seeing the same thing on Darwin on my Powerbook. \n\nControl-C (which I think sends a SIGINT) also doesn't give me a reaction. It's as if we go through the \ntrouble of ignoring the signals (default for most signals is to terminate the program), but don't register \nhandlers when in -X mode. \n\nInterestingly, httpd reacts to ^C when run under -X. Maybe gdb plants its own handler? \n\nTrunk is also affected. \n\nSome notes on checking out the development trunk at http://httpd.apache.org/dev/devnotes.html . \n\nIn short, you get the latest and greatest as follows: \n\n$ svn co http://svn.apache.org/repos/asf/httpd/httpd/trunk httpd-trunk \n$ cd httpd-trunk/srclib/apr\n$ svn co http://svn.apache.org/repos/asf/apr/apr/trunk apr\n$ svn co http://svn.apache.org/repos/asf/apr/apr-util/trunk apr-util
38848	Garrett Rooney	1141530686000	I was playing around with this, and I can 'fix' the problem with the following\nchange:\n\nIndex: server/mpm/prefork/prefork.c\n===================================================================\n--- server/mpm/prefork/prefork.c        (revision 383230)\n+++ server/mpm/prefork/prefork.c        (working copy)\n@@ -536,7 +536,7 @@\n\n     bucket_alloc = apr_bucket_alloc_create(pchild);\n\n-    while (!die_now) {\n+    while (!die_now && !shutdown_pending) {\n         conn_rec *current_conn;\n         void *csd;\n\n\nI'm not sure if this is correct though, and I'm not sure when this problem\nstarted.  svn blame and poking around areas of the code related to die_now and\nshutdown_pending didn't show any particularly promising changes, mostly stuff\nfrom way the hell back in the day.\n\nDidn't try to fix the problem on non-prefork MPMs, but I do recall noticing it\nwith worker a while back.
38848	becarre@free.fr	1186389035000	I tried your patch and it did allow me to terminate httpd with Ctrl-C. However\nsemaphores don't get released (the real problem IMHO), thus I still have to run\nipcrm every once in a while.\n\nBtw, you can kill httpd without patching by hitting Ctrl-/ (SIGQUIT).
38848	Joe Orton	1192085840000	This was committed as: http://svn.apache.org/viewvc?view=rev&rev=552029
38910	Robby Griffin	1141922962000	Created an attachment (id=17857)\nadds proper html escaping\n\nOk, fine, so I can add an attachment after first creating the bug report.
38910	Will Rowe	1141931965000	Thank you for your patch; it appears this affects 2.0 and 1.3 httpd as well?\n\nWe very rarely patch httpd 1.3, but this looks like one of those rare examples\nof a very clean change affecting all versions.
38910	Robby Griffin	1141932513000	(In reply to comment #2)\n> Thank you for your patch; it appears this affects 2.0 and 1.3 httpd as well?\n\nYes, that's correct.
38910	Joe Orton	1147876818000	Thanks a lot for the patch.  Committed to trunk:\n\n  http://svn.apache.org/viewcvs.cgi?rev=407265&view=rev\n\nand proposed for 2.2.x.
38966	Joshua Slive	1151691476000	Thanks.  This was in trunk but not 2.2.  It should get in the next release.
39133	Nick Kew	1143578735000	Fixed in trunk and in the 2.0 and 2.2 branches.  Should percolate through to \nthe online documentation in the next couple of days, as well as future \nreleases. 
39203	Ruediger Pluem	1144185434000	\n\n> ProxyPass /KenwoodAccess/ http://172.20.111.33:80/KenwoodAccess/\n\nand\n\n> ProxyPass /KenwoodAccess/ balancer://KWA_cluster lbmethod=byrequests\n\nare different cases. In the first case you have a trailing slash at both ends in\nthe second case you do not have this.\n\n\n> This will generate an error message in Apache logs:\n> \n> [Mon Apr 03 17:04:55 2006] [warn] proxy: No protocol handler was valid for the\n> URL /site/images/buts/forgotpassword.gif. If you are using a DSO version of\n> mod_proxy, make sure the proxy submodules are included in the configuration\n> using LoadModule.\n\nPlease specify the request that leads to this error message.\n\nPlease set also the LogLevel to debug and attach the output of your error_log file.
39203	Ruediger Pluem	1144188713000	*** Bug 39206 has been marked as a duplicate of this bug. ***
39203	Noah Schoenholtz	1147990337000	I had the same issue, and this does not necessarily mean that is not a bug but I\nhave at least discovered a workaround.\n\nIn my case, within a certain Virtual Host I pass all requests to the Load\nBalancer. This received the same errors when configured as follows:\n\nProxyPass / balancer://cluster nofailover=On\nProxyPassReverse / balancer://cluster\n<Proxy balancer://cluster>\n  BalancerMember ajp://10.0.1.102:8009\n  BalancerMember ajp://10.0.1.103:8009\n</Proxy>\n\nBut works if the configuration is changed to this:\n\nProxyPass / balancer://cluster/ nofailover=On\nProxyPassReverse / balancer://cluster/\n<Proxy balancer://cluster/>\n  BalancerMember ajp://10.0.1.102:8009/\n  BalancerMember ajp://10.0.1.103:8009/\n</Proxy>\n
39203	Ruediger Pluem	1148560245000	I agree that the error message is misleading, but this problem is not limited to\nmod_proxy_balancer and the balancer scheme but also occurs with\n\nProxyPass / http://www.somewhere.com\n\n(it must be ProxyPass / http://www.somewhere.com/)\n\nSo the problem is really a misconfiguration on the user side that I mark as a\nWONTFIX.
39203	Bob Ionescu	1148561634000	(In reply to comment #4)\n> ProxyPass / http://www.somewhere.com\n> \n> (it must be ProxyPass / http://www.somewhere.com/)\n> \n> So the problem is really a misconfiguration on the user side that I mark as a\n> WONTFIX.\n\nMay be the manual should be updated, too, because three or four examples\nprovided under the ProxyPass directive are using such invalid syntax.
39203	Ruediger Pluem	1148563397000	(In reply to comment #5)\n> \n> May be the manual should be updated, too, because three or four examples\n> provided under the ProxyPass directive are using such invalid syntax.\n\nOk, agreed, but strictly speaking only the balancer example is wrong. \n\nProxyPass /example http://backend.example.com\n\nis correct again. The basic rule for this is:\n\nIf the left side of ProxyPass ends with a / the right side must also end with a\n/. If the right side of ProxyPass ends with a / but the left side does not this\nwill cause // in the URL send to the backend which usually does not harm, but to\nplay safe both sides really should end in the same manner. Maybe an idea for a\nsanity check that issues a warning to the error log during the configuration\nparsing of the ProxyPass directives if this is not the case.
39203	Ruediger Pluem	1148588151000	I have added a note to the documentation regarding trailing slashes: r409455\n(http://svn.apache.org/viewvc?rev=409455&view=rev)
39245	Jeff Tharp	1144442439000	Created an attachment (id=18043)\nBart's proposed patch\n\nHere are some comments made on this patch on the httpd-dev list by Ruediger\nPluem along with Bart's replies:\nPl&#65533;m wrote:\n> \n>> -----Urspr&#65533;ngliche Nachricht-----\n>> Von: Bart van der Schans\n>>\n>> Hi,\n>>\n>> The 'ProxyErrorOverride On' setting is correctly catching the errors\n>> from the (reverse) proxied server. Only, it overrides too much IMHO.\n>> Right now it overrides anything that's not in the 2xx range, \n>> but I think\n>> it should allow also the 3xx range for redirects etc.\n> \n> I had a quick look into this and noticed the following:\n> \n> 1. It may make sense to add ap_is_HTTP_INFO to this also.\nYes, that shounds like a good idea.\n\n> 2. ProxyErrorOverride is currently only honoured by mod_proxy_http,\n>    mod_proxy_ajp ignores it. Is this intended?\nI don't have much experience with ajp, but being able to set a custom\nerror is a good idea I think.\n\n> 3. This is a change in behaviour for people who use customized redirect\n>    pages for browsers that do not support redirects (are there any?)\nWouldn't that change from currently broken to working?\n\n> 4. 304 not modified responses from the backend are currently not supported\n>    without this patch.\nI didn't actually tested that.\n\nRegards,\nBart
39245	Ruediger Pluem	1145950960000	Have you tried to set a custom error document?\nCan you check if\n\nErrorDocument 301 /dummy.html\nErrorDocument 302 /dummy.html\nErrorDocument 303 /dummy.html\n\nfixes your problem? Of course dummy.html must be a file in your document root.
39245	Jeff Tharp	1161609127000	Finally able to work on this bug again.  Tested this behavior using version\n2.2.3 and it looks like the issue is now resolved.  Cookies are correctly set on\n302 redirect requests with ProxyErrorOverride On.  I suspect changes elsewhere\ncleaned up this issue since the bug was first reported.
39245	jonah benton	1167388112000	NOT FIXED in vanilla 2.2.3. \n\nI'm using mod_proxy_http to reverse proxy a resin application server. Cookies\nand most headers set by resin in a 302 response are dropped by 2.2.3 when\nproxyerroroverride is on. \n\nWhat follows are transcripts with our internal 2.2.3 server; the first\ntranscript is with proxyerroroverride on in the specified virtual host config;\nthe second with proxyerroroverride off. \n\nTranscript #1, proxyerroroverride on\n\n[user@HOST ~]$ telnet HOST 80\nTrying 172.20.17.48...\nConnected to HOST (172.20.17.48).\nEscape character is '^]'.\nPOST /ec/login.htm HTTP/1.1\nHost: HOST\nCookie: JSESSIONID=A6534nqtHTaUTMwp-q\nContent-Type: application/x-www-form-urlencoded\nContent-Length: 33\n\nuserName=z10000&password=password\nHTTP/1.1 302 Found\nDate: Fri, 29 Dec 2006 17:56:23 GMT\nLocation: http://HOST/ec/postLogin.htm\nContent-Length: 234\nContent-Type: text/html; charset=iso-8859-1\n\n<!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'>\n<html><head>\n<title>302 Found</title>\n</head><body>\n<h1>Found</h1>\n<p>The document has moved <a href='http://HOST/ec/postLogin.htm'>here</a>.</p>\n</body></html>\nConnection closed by foreign host.\n\n\n\nTranscript #2, proxyerroroverride off\n\n[user@HOST ~]$ telnet HOST 80\nTrying 172.20.17.48...\nConnected to HOST (172.20.17.48).\nEscape character is '^]'.\nPOST /ec/login.htm HTTP/1.1\nHost: HOST\nCookie: JSESSIONID=A6534nqtHTaUTMwp-q\nContent-Type: application/x-www-form-urlencoded\nContent-Length: 33\n\nuserName=z10000&password=password\nHTTP/1.1 302 Found\nDate: Fri, 29 Dec 2006 17:57:44 GMT\nServer: Resin/3.0.14\nPragma: No-cache\nExpires: Thu, 01 Jan 1970 00:00:00 GMT\nCache-Control: no-cache\nCache-Control: no-store\nContent-Language: en-US\nLocation: http://HOST/ec/postLogin.htm\nContent-Length: 88\nSet-Cookie: userInfo=VARIOUSSTUFF; domain=HOST; path=/\nSet-Cookie: XXXX=w0NIFrSTDuo250TP4oXq13pk9C1Rlt9Q; domain=HOST; path=/\nContent-Type: text/html; charset=UTF-8\n\nThe URL has moved <a href='http://HOST/ec/postLogin.htm'>here</a>\n\nConnection closed by foreign host.\n\n
39245	jonah benton	1167747783000	Update: we applied Bart's proposed patch, with line numbers modified to suit\n2.2.3, and it solved the problem for us. \n\nSo with proxyerroroverride On and patched 2.2.3, we are able to pass cookies\nback from a resin app server serving 302 responses over http.\n\nVery good! 
39245	Stuart Children	1171352819000	*** Bug 41601 has been marked as a duplicate of this bug. ***
39245	Jeff Tharp	1171475204000	I can confirm this is indeed NOT FIXED in httpd 2.2.4.  I had thought it was\nbased on some tests I did earlier, but today we had application who displayed\nthe exact same symptoms as others have reported...when issuing a 302 redirect\nwith ProxyErrorOverride On, the Set-Cookie header was lost.  I used the patch\nfrom Bug ID 41601 submitted by Stuart Children as this was updated for 2.2.4.  I\ncan confirm that applying this patch fixed my problem...could this patch please\nbe applied to both trunk and/or 2.2?
39245	Nick Kew	1171503240000	I don't think this can reasonably be described as a bug: rather it's documented\nbehaviour of ProxyErrorOverride.  We can't apply the suggested patch, because it\nbreaks that.  *You* can of course apply the patch yourself, since it's the\nbehaviour you want.\n\nHowever, it's a reasonable enhancement request, to provide an option to preserve\n*headers* from the backend while substituting a local response *body*.\n\nSimple solution: if you want your cookies from the backend, don't override them.\n
39245	Stuart Children	1171503596000	(In reply to comment #8)\n> I don't think this can reasonably be described as a bug: rather it's\n> documented behaviour of ProxyErrorOverride.\n\nHuh? http://httpd.apache.org/docs/2.2/mod/mod_proxy.html#proxyerroroverride\n\n[quote]\nThis directive is useful for reverse-proxy setups, where you want to have a\ncommon look and feel on the error pages seen by the end user. This also allows\nfor included files (via mod_include's SSI) to get the error code and act\naccordingly (default behavior would display the error page of the proxied\nserver, turning this on shows the SSI Error message).\n[/quote]\n\nSince when are redirects considered errors?\n\nThis bug is a *regression* in behaviour from 2.0.x.\n\n> However, it's a reasonable enhancement request, to provide an option to\n> preserve *headers* from the backend while substituting a local response\n> *body*.\n\nWe (well, I) don't want that. We want the entire proxied request to be left\nalone, because there's nothing wrong with it! Don't replace the body with the\nErrorDocument, don't remove the headers.\n\n> Simple solution: if you want your cookies from the backend, don't override\n> them.\n\nI'm not...
39245	Joe Orton	1171516628000	Clearly the documentation is not explicit enough here to define how the\nimplementation should act; I'd certainly agree that not treating 3xx response as\n'errors' for the purposes of ProxyErrorOverride would be the obvious default.\n\nAre you sure this is a regression since vanilla 2.0.x Stuart?  AFAICT the 2.0.x\ncode will override errors for any non-2xx response too.
39245	Stuart Children	1171536059000	(In reply to comment #10)\n> Clearly the documentation is not explicit enough here to define how the\n> implementation should act; I'd certainly agree that not treating 3xx response\n> as 'errors' for the purposes of ProxyErrorOverride would be the obvious\n> default.\n\nYes, granted it does give a definition of 'error pages' - but as you seem to\nagree, most people would not take that to include redirects (or 304 responses\ncome to that).\n\n> Are you sure this is a regression since vanilla 2.0.x Stuart?  AFAICT the\n> 2.0.x code will override errors for any non-2xx response too.\n\nGranted we do apply patches and our own modules to the server I saw this on\n(when just upgrading the httpd version and looking for broken things), but I'm\npretty sure none of those would affect this area of behaviour. However, I have\nconfirmed that (see below).\n\nThe 2.0.x code is actually pretty confused, and potentially broken in other\nways. Within ap_proxy_http_process_response  we see:\n\n    * if we are overriding the errors, we can't put the content\n    * of the page into the brigade\n    */\n    if ( (conf->error_override ==0) || r->status < 400 ) {\n\nWhich would be correct in my book (though better expressed using the macros).\nBut then later:\n\n    if ( conf->error_override ) {\n        /* the code above this checks for 'OK' which is what the hook expects */\n        if ( r->status == HTTP_OK )\n            return OK;\n        else  {\n            int status = r->status;\n            r->status = HTTP_OK;\n            /* Discard body, if one is expected */\n            if ((status > 199) && /* not any 1xx response */\n                (status != HTTP_NO_CONTENT) && /* not 204 */\n                (status != HTTP_RESET_CONTENT) && /* not 205 */\n                (status != HTTP_NOT_MODIFIED)) { /* not 304 */\n               ap_discard_request_body(rp);\n           }\n            return status;\n        }\n    } else \n        return OK;\n\nwhich would seem to indicate that only 200 would ever be considered a non-error\nresponse (even more wrong I hope you'll agree)!\n\nHowever, there is something more going on - which I've not had time to follow\nthrough/debug as yet. Proof is in what an actual vanilla server does, so here goes:\n\nBuilt Apache (2.2.4 and 2.0.58) with:\n./configure --prefix=/tmp/httpd-X.X.X --with-mpm=prefork --enable-so\n--enable-mods-shared='rewrite expires info deflate speling headers unique-id\nproxy asis'\n\nwith: gcc (GCC) 4.1.1 20070105 (Red Hat 4.1.1-51)\non: Linux gnl05024.int.gnl 2.6.19-1.2895.fc6 #1 SMP Wed Jan 10 19:28:18 EST 2007\ni686 i686 i386 GNU/Linux\n\nOn one server (I guess being fair you'd put this somewhere independent - but I\ntried it both way rounds), create a CGI which does this:\n\n$ curl --get --verbose http://localhost:2058/cgi-bin/redirect\n* About to connect() to localhost port 2058\n*   Trying 127.0.0.1... connected\n* Connected to localhost (127.0.0.1) port 2058\n> GET /cgi-bin/redirect HTTP/1.1\n> User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b\nzlib/1.2.3 libidn/0.6.5\n> Host: localhost:2058\n> Accept: */*\n> \n< HTTP/1.1 302 Found\n< Date: Thu, 15 Feb 2007 18:07:36 GMT\n< Server: Apache/2.0.58 (Unix)\n< X-My-Secret-Header: moo\n< Location: http://httpd.apache.org/\n< Content-Length: 283\n< Content-Type: text/html; charset=iso-8859-1\n<!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'>\n<html><head>\n<title>302 Found</title>\n</head><body>\n<h1>Found</h1>\n<p>The document has moved <a href='http://httpd.apache.org/'>here</a>.</p>\n<hr>\n<address>Apache/2.0.58 (Unix) Server at localhost Port 2058</address>\n</body></html>\n* Connection #0 to host localhost left intact\n* Closing connection #0\n\nOK, so we've got a 302 response, with a custom header in there.\n\nNow take both our 2.2 and 2.0 servers with respective vanilla configs and add:\n\nProxyPass /rproxy http://localhost:2058/cgi-bin\nProxyPassReverse /rproxy http://localhost:2058/cgi-bin\nProxyErrorOverride On\n\nand restart. Now we can make the request to the CGI above but going through each\nreverse proxy. Firstly, on the 2.0.58 server:\n\n$ curl --get --verbose http://localhost:2058/rproxy/redirect\n* About to connect() to localhost port 2058\n*   Trying 127.0.0.1... connected\n* Connected to localhost (127.0.0.1) port 2058\n> GET /rproxy/redirect HTTP/1.1\n> User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b\nzlib/1.2.3 libidn/0.6.5\n> Host: localhost:2058\n> Accept: */*\n> \n< HTTP/1.1 302 Found\n< Date: Thu, 15 Feb 2007 18:16:54 GMT\n< Server: Apache/2.2.4 (Unix)\n< X-My-Secret-Header: moo\n< Location: http://httpd.apache.org/\n< Content-Length: 208\n< Content-Type: text/html; charset=iso-8859-1\n<!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'>\n<html><head>\n<title>302 Found</title>\n</head><body>\n<h1>Found</h1>\n<p>The document has moved <a href='http://httpd.apache.org/'>here</a>.</p>\n</body></html>\n* Connection #0 to host localhost left intact\n* Closing connection #0\n\nCorrect HTTP status and custom header is present. Now on the 2.2.4 server:\n\n$ curl --get --verbose http://localhost:2204/rproxy/redirect\n* About to connect() to localhost port 2204\n*   Trying 127.0.0.1... connected\n* Connected to localhost (127.0.0.1) port 2204\n> GET /rproxy/redirect HTTP/1.1\n> User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b\nzlib/1.2.3 libidn/0.6.5\n> Host: localhost:2204\n> Accept: */*\n> \n< HTTP/1.1 302 Found\n< Date: Thu, 15 Feb 2007 18:17:40 GMT\n< Location: http://httpd.apache.org/\n< Content-Length: 208\n< Content-Type: text/html; charset=iso-8859-1\n<!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'>\n<html><head>\n<title>302 Found</title>\n</head><body>\n<h1>Found</h1>\n<p>The document has moved <a href='http://httpd.apache.org/'>here</a>.</p>\n</body></html>\n* Connection #0 to host localhost left intact\n* Closing connection #0\n\nWe've lost the headers. QED.\n\n\nInterestingly, making HEAD requests we see behaviour the other way around:\n\n$ curl --head --verbose http://localhost:2058/rproxy/redirect\n* About to connect() to localhost port 2058\n*   Trying 127.0.0.1... connected\n* Connected to localhost (127.0.0.1) port 2058\n> HEAD /rproxy/redirect HTTP/1.1\n> User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b\nzlib/1.2.3 libidn/0.6.5\n> Host: localhost:2058\n> Accept: */*\n> \n< HTTP/1.1 302 Found\nHTTP/1.1 302 Found\n< Date: Thu, 15 Feb 2007 18:18:11 GMT\nDate: Thu, 15 Feb 2007 18:18:11 GMT\n< Location: http://httpd.apache.org/\nLocation: http://httpd.apache.org/\n< Content-Type: text/html; charset=iso-8859-1\nContent-Type: text/html; charset=iso-8859-1\n\n* Connection #0 to host localhost left intact\n* Closing connection #0\n\n$ curl --head --verbose http://localhost:2204/rproxy/redirect\n* About to connect() to localhost port 2204\n*   Trying 127.0.0.1... connected\n* Connected to localhost (127.0.0.1) port 2204\n> HEAD /rproxy/redirect HTTP/1.1\n> User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b\nzlib/1.2.3 libidn/0.6.5\n> Host: localhost:2204\n> Accept: */*\n> \n< HTTP/1.1 302 Found\nHTTP/1.1 302 Found\n< Date: Thu, 15 Feb 2007 18:18:52 GMT\nDate: Thu, 15 Feb 2007 18:18:52 GMT\n< Server: Apache/2.2.4 (Unix)\nServer: Apache/2.2.4 (Unix)\n< X-My-Secret-Header: moo\nX-My-Secret-Header: moo\n< Location: http://httpd.apache.org/\nLocation: http://httpd.apache.org/\n< Content-Type: text/html; charset=iso-8859-1\nContent-Type: text/html; charset=iso-8859-1\n\n* Connection #0 to host localhost left intact\n* Closing connection #0\n\nAlso note that *both* servers 'pause' for ~5s between receiving the request and\nresponding. I think that this is caused by the backend server trying to stream\nits body out, and the frontend server not consuming it - possibly a seperate\nissue. Why the custom header comes through in 2.2.4 and not in 2.0.5 I haven't\nlooked into - but the fact that GET and HEAD give you different headers would\nseem to be a bug with each version yes?\n\nAnyway, applying my patch to 2.2.4:\n\n$ curl --get --verbose http://localhost:2204/rproxy/redirect\n* About to connect() to localhost port 2204\n*   Trying 127.0.0.1... connected\n* Connected to localhost (127.0.0.1) port 2204\n> GET /rproxy/redirect HTTP/1.1\n> User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b\nzlib/1.2.3 libidn/0.6.5\n> Host: localhost:2204\n> Accept: */*\n> \n< HTTP/1.1 302 Found\n< Date: Thu, 15 Feb 2007 18:30:59 GMT\n< Server: Apache/2.2.4 (Unix)\n< X-My-Secret-Header: moo\n< Location: http://httpd.apache.org/\n< Content-Length: 208\n< Content-Type: text/html; charset=iso-8859-1\n<!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'>\n<html><head>\n<title>302 Found</title>\n</head><body>\n<h1>Found</h1>\n<p>The document has moved <a href='http://httpd.apache.org/'>here</a>.</p>\n</body></html>\n* Connection #0 to host localhost left intact\n* Closing connection #0\n\nSo it now passes the header through correctly. Also, the HEAD is now the same:\n\n$ curl --head --verbose http://localhost:2204/rproxy/redirect\n* About to connect() to localhost port 2204\n*   Trying 127.0.0.1... connected\n* Connected to localhost (127.0.0.1) port 2204\n> HEAD /rproxy/redirect HTTP/1.1\n> User-Agent: curl/7.15.5 (i686-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b\nzlib/1.2.3 libidn/0.6.5\n> Host: localhost:2204\n> Accept: */*\n> \n< HTTP/1.1 302 Found\nHTTP/1.1 302 Found\n< Date: Thu, 15 Feb 2007 18:31:37 GMT\nDate: Thu, 15 Feb 2007 18:31:37 GMT\n< Server: Apache/2.2.4 (Unix)\nServer: Apache/2.2.4 (Unix)\n< X-My-Secret-Header: moo\nX-My-Secret-Header: moo\n< Location: http://httpd.apache.org/\nLocation: http://httpd.apache.org/\n< Content-Type: text/html; charset=iso-8859-1\nContent-Type: text/html; charset=iso-8859-1\n\n* Connection #0 to host localhost left intact\n* Closing connection #0\n\nAnd the 'pause' has gone - hence my theory.\n\nI think the above all indicates:\n\n1) 2.2.x has different behaviour from 2.0.x (as myself - and others it would\nseem - were expecting/relying on that, I call it a regression) in how they treat\n3xx response when erroroveride is on.\n2) Both branches may have a bug with HEAD not being the same as GET.\n3) There's a potential issue left with bodies not being consumed (?) \n\nI'll look further into 2) and 3) tomorrow, if time allows. Have been stuck in\nmeetings most of this afternoon, it's past home time, and I've looked at this\nenough already for one day. :)
39245	Stuart Children	1171536316000	(In reply to comment #11)\n> Yes, granted it does give a definition of 'error pages' - but as you seem to\n> agree, most people would not take that to include redirects (or 304 responses\n> come to that).\n\nSigh, see what happens when you're tired. That should obviously read:\n\nit does *not* give a definition of 'error pages'
39245	Stuart Children	1171621553000	(In reply to comment #11)\n> 2) Both branches may have a bug with HEAD not being the same as GET.\n\nThis one is slightly complex. See bug #41646\n\n> 3) There's a potential issue left with bodies not being consumed (?) \n\nRelatively straight-forward. See bug #41644\n\nI think these are all independent issues (well, they are related in the block of\ncode the affect which makes for confusion testing when you start discovering\nthem, but they can be resolved on their own).
39245	Eric Covener	1175695875000	Created an attachment (id=19915)\nextend directive based on Nick's comments\n\nsee\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200704.mbox/%3c20070404163031.71e4da7b@grimnir%3e
39245	Jeff Trawick	1176365922000	simple fix to skip override processing for 1xx and 3xx (in addition to 2xx)\nresponses committed to trunk and proposed for backport to 2.2.x
39245	Joe Orton	1179130758000	For posterity; references to the fixes committed:\n\ntrunk: http://svn.apache.org/viewvc?view=rev&rev=527969\n2.2.x: http://svn.apache.org/viewvc?view=rev&rev=534068\n
39253	Ruediger Pluem	1144526288000	Created an attachment (id=18045)\nPatch against trunk\n\nCould you please give the attached patch a try and have a look if it fixes your\nproblem?
39253	Bjorn Stabell	1144528969000	Yes, great!  With the patch applied I can no longer reproduce the problem.\n\nThanks a bunch!  What great service, on a Saturday! :)
39253	Ruediger Pluem	1144582200000	Patch committed to trunk as r392613\n(http://svn.apache.org/viewcvs?rev=392613&view=rev) and proposed for backport\n2.2.x as r392700 (http://svn.apache.org/viewcvs?rev=392700&view=rev)
39253	Ruediger Pluem	1145719951000	Backported to 2.2.x as r393047 (http://svn.apache.org/viewcvs?rev=393047&view=rev).
39253	Nick Kew	1149849360000	*** Bug 39763 has been marked as a duplicate of this bug. ***
39266	Ruediger Pluem	1145025948000	Created an attachment (id=18097)\nPatch against trunk\n
39266	Ruediger Pluem	1145025991000	I can confirm this bug. Can you please check if the attached patch fixes your\nproblem?
39266	James Pfaff	1145031149000	(In reply to comment #2)\n> I can confirm this bug. Can you please check if the attached patch fixes your\n> problem?\n\nI would like to, but if I am correct I can't just add that to the module \nseeing as it is already pre-compiled and I am on a Windows system. I \nappologize, but I don't have much proficiency with C/C++ programming. If you \ncould give me the mod_mem_cache.so module for Windows with that patch applied \nI would be happy to give it a try.
39266	James Pfaff	1145032339000	Ok, scratch that. I downloaded the source and applied the patch to the proper \nsection of the file, now the only problem is how exactly do I go about \ncompiling the updated file?
39266	Ruediger Pluem	1145053154000	You need to recompile the whole server, but you do not need to exchange anything\nmore then the mod_mem_cache file within your installed server with the one that\ncame out of your compilation. I am not a Windows guy so I cannot provide any\nhelp about how to compile httpd on Windows, but I guess the following links will\nprovide valuable help:\n\nhttp://httpd.apache.org/docs/trunk/platform/win_compiling.html\nhttp://httpd.apache.org/docs/trunk/platform/windows.html
39266	Dick Snippe	1146664119000	Hmmm... I just found this bug report. I'm going to give the attached patch a try\nand let you know what happens.
39266	Dick Snippe	1146666008000	(In reply to comment #6)\n> Hmmm... I just found this bug report. I'm going to give the attached patch a try\n> and let you know what happens.\n\nAfter some limited testing this patch appears to fix the problem (applied it to\napache-2.2.0)
39266	Dick Snippe	1146667295000	(In reply to comment #7)\n> After some limited testing this patch appears to fix the problem (applied it to\n> apache-2.2.0)\n\nAlso applied it to apache-2.2.2 and it appears to fix the problem in 2.2.2 as well.\n
39266	Ruediger Pluem	1146685011000	Thanks for test. Committed to trunk as r399388\n(http://svn.apache.org/viewcvs?rev=399388&view=rev).
39266	Ruediger Pluem	1146685066000	*** Bug 39124 has been marked as a duplicate of this bug. ***
39266	Ruediger Pluem	1146775152000	Proposed for backport to 2.2.x as r399856\n(http://svn.apache.org/viewcvs?rev=399856&view=rev).
39266	Ruediger Pluem	1147233852000	*** Bug 39539 has been marked as a duplicate of this bug. ***
39266	Ruediger Pluem	1149192906000	Backported to 2.2.x as r410932 (http://svn.apache.org/viewvc?rev=410932&view=rev).
39282	Davi Arnaut	1144852919000	Created an attachment (id=18083)\ninitialize last_char with zero\n
39282	Ruediger Pluem	1145017319000	Committed to trunk as r394070 (http://svn.apache.org/viewcvs?rev=394070&view=rev).\nThanks.
39282	Ruediger Pluem	1145270619000	Proposed for backport to 2.2.x as r394653\n(http://svn.apache.org/viewcvs?rev=394653&view=rev).
39282	Ruediger Pluem	1145271274000	Created an attachment (id=18112)\n2.0.x version of the patch\n
39282	Ruediger Pluem	1145271383000	Proposed for backport to 2.0.x as r394654\n(http://svn.apache.org/viewcvs?rev=394654&view=rev).\n
39282	Ruediger Pluem	1145719815000	Backported to 2.2.x as r395985 (http://svn.apache.org/viewcvs?rev=395985&view=rev).
39317	Nick Kew	1145078674000	Your URL points to a draft that claims to expire in 2005.  Google fails to \nfind any reference to the type being registered, or even in process of \nregistration, at IANA.  Please clarify. 
39317	Roy T. Fielding	1188213172000	Added to trunk in rev 570206\n
39321	Nick Kew	1145141563000	Fixed in trunk: http://svn.apache.org/viewcvs?rev=394390&view=rev \nBackport to 2.2 proposed. \n 
39321	Nick Kew	1145221415000	Fixed - http://svn.apache.org/viewcvs?rev=394557&view=rev 
39386	Nick Kew	1155074036000	Fixed in 2.2.3
39420	Philip Gladstone	1151284647000	It seems that the code path that handles the 'resp=' case (around line 640) in\n2.2.2 does not invoke ap_str_tolower(str). If you add this line, then things\nstart to work a lot better. However, I am not sure whether this should be added\nfor all cases, or only for the resp= case. Hence I am not proposing a patch.
39420	Alan Hicks	1163411823000	The documentation (mod/mod_filter.html) gives the following example\n\nFilterDeclare SSI\nFilterProvider SSI INCLUDES resp=Content-Type $text/html\nFilterChain SSI\n\nas despatch is currently case sensitive and needs to be lower case to work,\nchanging the documentation to the following could help\n\nFilterDeclare SSI\nFilterProvider SSI INCLUDES resp=content-type $text/html\nFilterChain SSI
39420	Nick Kew	1166189706000	Fixed in /trunk/ and 2.2.4.  Thanks for the report.\n
39487	Joe Orton	1153225863000	This is an unnecessarily confusing error message, it means simply that\nrotatelogs could not open the log file - perhaps an SELinux error, check for\naudit errors in dmesg.
39487	Joe Orton	1164167373000	Fixed on trunk, http://svn.apache.org/viewvc?view=rev&revision=478135
39518	Christophe JAILLET	1147120917000	Created an attachment (id=18247)\nPatch for the proposed clean-up\n
39518	Nick Kew	1184870655000	http://svn.apache.org/viewvc?view=rev&revision=557837\n
39529	Brad Nicholes	1149286687000	Fixed in trunk and proposed for backport
39529	Damien Lachuer	1150371886000	Bug observed as well on Sun Solaris 5.8.\nApparently, LDAP_INSUFFICIENT_RIGHTS isn't defined neither in Sun sdk.\nLDAP_INSUFFICIENT_ACCESS may be used instead.
39529	Graham Leggett	1150889748000	The abstraction of this error message in APR-util in apr_ldap_init.h \n needs to be fixed, mod_authnz_ldap shouldn't be including toolkit specific\n#defines anywhere.
39529	Brad Nicholes	1151092602000	The abstraction has been added to apr-util.  It is called \nAPU_LDAP_INSUFFICIENT_ACCESS.  But we can't use it in mod_authnz_ldap.c until \na suitable libaprutil has been released.  So for now, mod_authnz_ldap.c has to \ninclude #defines.
39529	Ruediger Pluem	1153923883000	Backported to 2.2.x as r425731 (http://svn.apache.org/viewvc?rev=425731&view=rev).
39593	Ruediger Pluem	1147821038000	This bug is somewhat similar to #38017. I can confirm it. Could you please give\nthe attached patch a try? It is against trunk, but also works against httpd 2.2.2.
39593	Ruediger Pluem	1147821075000	Created an attachment (id=18296)\nPatch against trunk\n
39593	Michael Han	1147821804000	I saw that bug and even tried backing out the patch from the 2.2.2 code. But the\npatch you provided seems to work fine. Thanks!
39593	Ruediger Pluem	1147893469000	Commited to trunk as r407357\n(http://svn.apache.org/viewcvs?rev=407268&view=rev). Thanks for testing.
39593	Ruediger Pluem	1148582607000	Proposed for backport to 2.2.x as r409425\n(http://svn.apache.org/viewcvs?rev=409425&view=rev).
39593	Ruediger Pluem	1153749688000	Backported to 2.2.x as r425035 (http://svn.apache.org/viewvc?rev=425035&view=rev).
39613	Joshua Slive	1189690119000	Fixed in trunk. Thanks.
39647	Ruediger Pluem	1148418740000	Please post your cache and proxy configuration here. Furthermore please set the\nloglevel to debug on the proxy server and post the error_log of two subsequent\nrequests where the first one is served directly and the second one is served by\nthe cache with the wrong content-type.
39647	Christopher Shumway	1148419633000	Thank you for the follow up.  Here's some more information:\n\n--- httpd.conf ---\nServerRoot '/usr/local'\nListen 80\n\nLoadModule authn_file_module libexec/apache22/mod_authn_file.so\nLoadModule authn_dbm_module libexec/apache22/mod_authn_dbm.so\nLoadModule authn_anon_module libexec/apache22/mod_authn_anon.so\nLoadModule authn_default_module libexec/apache22/mod_authn_default.so\nLoadModule authz_host_module libexec/apache22/mod_authz_host.so\nLoadModule authz_groupfile_module libexec/apache22/mod_authz_groupfile.so\nLoadModule authz_user_module libexec/apache22/mod_authz_user.so\nLoadModule authz_dbm_module libexec/apache22/mod_authz_dbm.so\nLoadModule authz_owner_module libexec/apache22/mod_authz_owner.so\nLoadModule authz_default_module libexec/apache22/mod_authz_default.so\nLoadModule auth_basic_module libexec/apache22/mod_auth_basic.so\nLoadModule auth_digest_module libexec/apache22/mod_auth_digest.so\nLoadModule file_cache_module libexec/apache22/mod_file_cache.so\nLoadModule cache_module libexec/apache22/mod_cache.so\nLoadModule disk_cache_module libexec/apache22/mod_disk_cache.so\nLoadModule mem_cache_module libexec/apache22/mod_mem_cache.so\nLoadModule include_module libexec/apache22/mod_include.so\nLoadModule filter_module libexec/apache22/mod_filter.so\nLoadModule charset_lite_module libexec/apache22/mod_charset_lite.so\nLoadModule deflate_module libexec/apache22/mod_deflate.so\nLoadModule log_config_module libexec/apache22/mod_log_config.so\nLoadModule logio_module libexec/apache22/mod_logio.so\nLoadModule env_module libexec/apache22/mod_env.so\nLoadModule mime_magic_module libexec/apache22/mod_mime_magic.so\nLoadModule cern_meta_module libexec/apache22/mod_cern_meta.so\nLoadModule expires_module libexec/apache22/mod_expires.so\nLoadModule headers_module libexec/apache22/mod_headers.so\nLoadModule usertrack_module libexec/apache22/mod_usertrack.so\nLoadModule unique_id_module libexec/apache22/mod_unique_id.so\nLoadModule setenvif_module libexec/apache22/mod_setenvif.so\nLoadModule version_module libexec/apache22/mod_version.so\nLoadModule proxy_module libexec/apache22/mod_proxy.so\nLoadModule proxy_connect_module libexec/apache22/mod_proxy_connect.so\nLoadModule proxy_ftp_module libexec/apache22/mod_proxy_ftp.so\nLoadModule proxy_http_module libexec/apache22/mod_proxy_http.so\nLoadModule proxy_ajp_module libexec/apache22/mod_proxy_ajp.so\nLoadModule proxy_balancer_module libexec/apache22/mod_proxy_balancer.so\nLoadModule ssl_module libexec/apache22/mod_ssl.so\nLoadModule mime_module libexec/apache22/mod_mime.so\nLoadModule dav_module libexec/apache22/mod_dav.so\nLoadModule status_module libexec/apache22/mod_status.so\nLoadModule autoindex_module libexec/apache22/mod_autoindex.so\nLoadModule asis_module libexec/apache22/mod_asis.so\nLoadModule info_module libexec/apache22/mod_info.so\nLoadModule cgi_module libexec/apache22/mod_cgi.so\nLoadModule dav_fs_module libexec/apache22/mod_dav_fs.so\nLoadModule vhost_alias_module libexec/apache22/mod_vhost_alias.so\nLoadModule negotiation_module libexec/apache22/mod_negotiation.so\nLoadModule dir_module libexec/apache22/mod_dir.so\nLoadModule imagemap_module libexec/apache22/mod_imagemap.so\nLoadModule actions_module libexec/apache22/mod_actions.so\nLoadModule speling_module libexec/apache22/mod_speling.so\nLoadModule userdir_module libexec/apache22/mod_userdir.so\nLoadModule alias_module libexec/apache22/mod_alias.so\nLoadModule rewrite_module libexec/apache22/mod_rewrite.so\n\nUser www\nGroup www\n\nServerAdmin sysadmin@greatschools.net\n\n<Directory />\n  AllowOverride None\n  Order deny,allow\n  Deny from all\n</Directory>\n\nTypesConfig /usr/local/etc/apache22/mime.types\n\nErrorLog /var/log/httpd-error.log\nLogLevel debug\n\n# simulated proxy log\nLogFormat '%h %u %X %t /'%r/' %s %b /'%{Referer}i/' /'%{User-Agent}i/'\n/'%{Cookie}i/'' proxylog\ncustomlog /var/log/apache/proxy.log proxylog\n\n# proxy-level rewrites\nRewriteEngine on\n\n# return 403 forbidden if no user-agent specified\n# but don't block our load balancers since they don't specify a user-agent\nRewriteCond %{HTTP_USER_AGENT} =''\nReWriteCond %{REMOTE_ADDR} !207.33.22.13[34]\nReWriteRule ^/* / [L,F]\n\n# cache\nMCacheRemovalAlgorithm GDSF \nMCacheSize 786432\nMCacheMaxObjectSize  256000\nMCacheMaxObjectCount 65535\nCacheDefaultExpire 14400\nCacheEnable mem /\n\n# proxy\nProxyRequests Off\nProxyPreserveHost on\nProxyPass / http://dev.greatschools.net/\n\n<Proxy *>\n  Order deny,allow\n  Allow from all\n</Proxy>\n\n# mod_deflate\n<Location />\n  SetOutputFilter DEFLATE\n  SetEnvIfNoCase Request_URI /.(?:gif|jpe?g|png)$ no-gzip dont-vary\n  Header append Vary User-Agent env=!dont-vary\n</Location>\n\n---\nHere's the relevent log for the working request:\n\n\n[Tue May 23 14:23:20 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /res/img/content/liferaft.jpg\n[Tue May 23 14:23:20 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /res/img/content/liferaft.jpg\n[Tue May 23 14:23:20 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/res/img/content/liferaft.jpg\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(1378): [client 198.144.205.133]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/res/img/content/liferaft.jpg\n[Tue May 23 14:23:20 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Tue May 23 14:23:20 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/res/img/content/liferaft.jpg\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/res/img/content/liferaft.jpg to dev.greatschools.net:80\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(1951): proxy: connected\n/res/img/content/liferaft.jpg to dev.greatschools.net:80\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(2045): proxy: HTTP: fam 2 socket\ncreated to connect to dev.greatschools.net\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Tue May 23 14:23:20 2006] [debug] mod_proxy_http.c(1448): proxy: start body send\n[Tue May 23 14:23:20 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Tue May 23 14:23:20 2006] [debug] mod_cache.c(602): cache: Caching url:\n/res/img/content/liferaft.jpg\n[Tue May 23 14:23:20 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Tue May 23 14:23:20 2006] [info] mem_cache: Cached url:\nhttp://nuked.greatschools.net:80/res/img/content/liferaft.jpg?\n[Tue May 23 14:23:20 2006] [debug] mod_proxy_http.c(1537): proxy: end body send\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net)\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 0 in child 63574 for worker http://dev.greatschools.net/\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(1644): proxy: worker\nhttp://dev.greatschools.net/ already initialized\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 0 in child 63574 for (dev.greatschools.net)\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 1 in child 63574 for worker proxy:reverse\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(1644): proxy: worker\nproxy:reverse already initialized\n[Tue May 23 14:23:20 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 1 in child 63574 for (*)\n\nHere's the relevent log for the non-working request:\n\n[Tue May 23 14:23:24 2006] [debug] cache_storage.c(261): Cached response for\n/res/img/content/liferaft.jpg isn't fresh.  Adding/replacing conditional request\nheaders.\n[Tue May 23 14:23:24 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /res/img/content/liferaft.jpg\n[Tue May 23 14:23:24 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /res/img/content/liferaft.jpg\n[Tue May 23 14:23:24 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/res/img/content/liferaft.jpg\n[Tue May 23 14:23:24 2006] [debug] proxy_util.c(1378): [client 198.144.205.133]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/res/img/content/liferaft.jpg\n[Tue May 23 14:23:24 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Tue May 23 14:23:24 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/res/img/content/liferaft.jpg\n[Tue May 23 14:23:24 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Tue May 23 14:23:24 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/res/img/content/liferaft.jpg to dev.greatschools.net:80\n[Tue May 23 14:23:24 2006] [debug] proxy_util.c(1951): proxy: connected\n/res/img/content/liferaft.jpg to dev.greatschools.net:80\n[Tue May 23 14:23:24 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Tue May 23 14:23:24 2006] [debug] mod_proxy_http.c(1541): proxy: header only\n[Tue May 23 14:23:24 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Tue May 23 14:23:24 2006] [debug] mod_cache.c(602): cache: Caching url:\n/res/img/content/liferaft.jpg\n[Tue May 23 14:23:24 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Tue May 23 14:23:24 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net)\n[Tue May 23 14:23:24 2006] [debug] cache_storage.c(261): Cached response for\n/res/img/content/liferaft.jpg isn't fresh.  Adding/replacing conditional request\nheaders.\n[Tue May 23 14:23:24 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /res/img/content/liferaft.jpg\n[Tue May 23 14:23:24 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /res/img/content/liferaft.jpg\n[Tue May 23 14:23:24 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/res/img/content/liferaft.jpg\n[Tue May 23 14:23:24 2006] [debug] proxy_util.c(1378): [client 198.144.205.133]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/res/img/content/liferaft.jpg\n[Tue May 23 14:23:24 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Tue May 23 14:23:24 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/res/img/content/liferaft.jpg\n[Tue May 23 14:23:24 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Tue May 23 14:23:24 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/res/img/content/liferaft.jpg to dev.greatschools.net:80\n[Tue May 23 14:23:24 2006] [debug] proxy_util.c(1951): proxy: connected\n/res/img/content/liferaft.jpg to dev.greatschools.net:80\n[Tue May 23 14:23:24 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Tue May 23 14:23:24 2006] [debug] mod_proxy_http.c(1541): proxy: header only\n[Tue May 23 14:23:24 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Tue May 23 14:23:24 2006] [debug] mod_cache.c(602): cache: Caching url:\n/res/img/content/liferaft.jpg\n[Tue May 23 14:23:24 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Tue May 23 14:23:24 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net) \n
39647	Christopher Shumway	1148422978000	Heres some data from the log when fetching a stand-alone image, one not served\nvia mod_jk.  Interestingly I noticed when mem_cache cached the content, it added\na '?' at the end of the URI.  I added a '?' to the end of\n/res/img/content/liferaft.jpg and it looks like it sent the headers correctly\nevery time.\n\n\n[Tue May 23 15:15:20 2006] [info] mod_unique_id: using ip addr 198.144.205.144\n[Tue May 23 15:15:21 2006] [info] Init: Seeding PRNG with 0 bytes of entropy\n[Tue May 23 15:15:21 2006] [info] Init: Generating temporary RSA private keys\n(512/1024 bits)\n[Tue May 23 15:15:21 2006] [info] Init: Generating temporary DH parameters\n(512/1024 bits)\n[Tue May 23 15:15:21 2006] [warn] Init: Session Cache is not configured [hint:\nSSLSessionCache]\n[Tue May 23 15:15:21 2006] [info] Init: Initializing (virtual) servers for SSL\n[Tue May 23 15:15:21 2006] [info] Server: Apache/2.2.2, Interface:\nmod_ssl/2.2.2, Library: OpenSSL/0.9.7e-p1\n[Tue May 23 15:15:21 2006] [info] mod_unique_id: using ip addr 198.144.205.144\n[Tue May 23 15:15:22 2006] [info] Init: Seeding PRNG with 0 bytes of entropy\n[Tue May 23 15:15:22 2006] [info] Init: Generating temporary RSA private keys\n(512/1024 bits)\n[Tue May 23 15:15:23 2006] [info] Init: Generating temporary DH parameters\n(512/1024 bits)\n[Tue May 23 15:15:23 2006] [info] Init: Initializing (virtual) servers for SSL\n[Tue May 23 15:15:23 2006] [info] Server: Apache/2.2.2, Interface:\nmod_ssl/2.2.2, Library: OpenSSL/0.9.7e-p1\n[Tue May 23 15:15:23 2006] [notice] Digest: generating secret for digest\nauthentication ...\n[Tue May 23 15:15:23 2006] [notice] Digest: done\n[Tue May 23 15:15:23 2006] [notice] Apache/2.2.2 (FreeBSD) mod_ssl/2.2.2\nOpenSSL/0.9.7e-p1 DAV/2 configured -- resuming normal operations\n[Tue May 23 15:15:23 2006] [info] Server built: May 23 2006 12:40:34\n[Tue May 23 15:15:23 2006] [debug] prefork.c(991): AcceptMutex: flock (default:\nflock)\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 0 in child 63711 for worker http://dev.greatschools.net/\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 0 in child 63711 for (dev.greatschools.net)\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 1 in child 63711 for worker proxy:reverse\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 1 in child 63711 for (*)\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 0 in child 63712 for worker http://dev.greatschools.net/\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker\nhttp://dev.greatschools.net/ already initialized\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 0 in child 63712 for (dev.greatschools.net)\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 1 in child 63712 for worker proxy:reverse\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker\nproxy:reverse already initialized\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 1 in child 63712 for (*)\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 0 in child 63715 for worker http://dev.greatschools.net/\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker\nhttp://dev.greatschools.net/ already initialized\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 0 in child 63715 for (dev.greatschools.net)\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 1 in child 63715 for worker proxy:reverse\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker\nproxy:reverse already initialized\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 1 in child 63715 for (*)\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 0 in child 63713 for worker http://dev.greatschools.net/\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker\nhttp://dev.greatschools.net/ already initialized\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 0 in child 63713 for (dev.greatschools.net)\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 1 in child 63713 for worker proxy:reverse\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker\nproxy:reverse already initialized\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 1 in child 63713 for (*)\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 0 in child 63714 for worker http://dev.greatschools.net/\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker\nhttp://dev.greatschools.net/ already initialized\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 0 in child 63714 for (dev.greatschools.net)\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 1 in child 63714 for worker proxy:reverse\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1644): proxy: worker\nproxy:reverse already initialized\n[Tue May 23 15:15:23 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 1 in child 63714 for (*)\n[Tue May 23 15:16:25 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /images/reportcard.jpg\n[Tue May 23 15:16:25 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /images/reportcard.jpg\n[Tue May 23 15:16:25 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/images/reportcard.jpg\n[Tue May 23 15:16:25 2006] [debug] proxy_util.c(1378): [client 198.144.205.133]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/images/reportcard.jpg\n[Tue May 23 15:16:25 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Tue May 23 15:16:25 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/images/reportcard.jpg\n[Tue May 23 15:16:25 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Tue May 23 15:16:25 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80\n[Tue May 23 15:16:25 2006] [debug] proxy_util.c(1951): proxy: connected\n/images/reportcard.jpg to dev.greatschools.net:80\n[Tue May 23 15:16:25 2006] [debug] proxy_util.c(2045): proxy: HTTP: fam 2 socket\ncreated to connect to dev.greatschools.net\n[Tue May 23 15:16:25 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Tue May 23 15:16:25 2006] [debug] mod_proxy_http.c(1448): proxy: start body send\n[Tue May 23 15:16:25 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Tue May 23 15:16:25 2006] [debug] mod_cache.c(602): cache: Caching url:\n/images/reportcard.jpg\n[Tue May 23 15:16:25 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Tue May 23 15:16:25 2006] [info] mem_cache: Cached url:\nhttp://nuked.greatschools.net:80/images/reportcard.jpg?\n[Tue May 23 15:16:25 2006] [debug] mod_proxy_http.c(1537): proxy: end body send\n[Tue May 23 15:16:25 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net)\n[Tue May 23 15:16:26 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 0 in child 63719 for worker http://dev.greatschools.net/\n[Tue May 23 15:16:26 2006] [debug] proxy_util.c(1644): proxy: worker\nhttp://dev.greatschools.net/ already initialized\n[Tue May 23 15:16:26 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 0 in child 63719 for (dev.greatschools.net)\n[Tue May 23 15:16:26 2006] [debug] proxy_util.c(1625): proxy: grabbed scoreboard\nslot 1 in child 63719 for worker proxy:reverse\n[Tue May 23 15:16:26 2006] [debug] proxy_util.c(1644): proxy: worker\nproxy:reverse already initialized\n[Tue May 23 15:16:26 2006] [debug] proxy_util.c(1724): proxy: initialized single\nconnection worker 1 in child 63719 for (*)\n[Tue May 23 15:16:41 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /images/reportcard.jpg\n[Tue May 23 15:16:41 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /images/reportcard.jpg\n[Tue May 23 15:16:41 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/images/reportcard.jpg\n[Tue May 23 15:16:41 2006] [debug] proxy_util.c(1378): [client 198.144.205.133]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/images/reportcard.jpg\n[Tue May 23 15:16:41 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Tue May 23 15:16:41 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/images/reportcard.jpg\n[Tue May 23 15:16:41 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Tue May 23 15:16:41 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80\n[Tue May 23 15:16:41 2006] [debug] proxy_util.c(1951): proxy: connected\n/images/reportcard.jpg to dev.greatschools.net:80\n[Tue May 23 15:16:41 2006] [debug] proxy_util.c(2045): proxy: HTTP: fam 2 socket\ncreated to connect to dev.greatschools.net\n[Tue May 23 15:16:41 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Tue May 23 15:16:41 2006] [debug] mod_proxy_http.c(1448): proxy: start body send\n[Tue May 23 15:16:41 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Tue May 23 15:16:41 2006] [debug] mod_cache.c(602): cache: Caching url:\n/images/reportcard.jpg\n[Tue May 23 15:16:41 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Tue May 23 15:16:41 2006] [info] mem_cache: Cached url:\nhttp://nuked.greatschools.net:80/images/reportcard.jpg?\n[Tue May 23 15:16:41 2006] [debug] mod_proxy_http.c(1537): proxy: end body send\n[Tue May 23 15:16:41 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net)\n\n
39647	Christopher Shumway	1148433433000	Here's an interesting data point.  I was tinkering with this issue a bit more\ntoday and discovered that I could hit the cached image that was origionally\nserved via mod_jk using wget all I want, and it would always return image/jpeg\nas the content-type.  Once I loaded up firefox and hit ctrl+F5 (force refresh)\nmod_cache started to return text/html as the content type.  So for some reason,\nthe act of force refreshing in firefox seems to be a trigger.\n
39647	Ruediger Pluem	1148557027000	You are correct that this has something to do with doing a refresh in Firefox.\nRequesting a refresh in Firefox requires the cache to revalidate the cached\nentity on the back end server. Something seems to go wrong during this process.\nCurrently I cannot decide if this is because something is wrong in the cache\ncode or because the backend delivers a bad response. So it would be most helpful\nif you could sniff the network traffic between your proxy httpd and your backend\nhttpd, do a non working refresh request with Firefox and attach the results of\nyour sniffing to this report.
39647	Christopher Shumway	1148595963000	Thank you for the followup.  Here's some investigation with tcpdump and ethereal\nfrom the proxy server.\n\nThe client is 198.144.205.133, the reverse proxy server is 198.144.205.144 and\nthe backend web server is 198.144.205.152.\n\nHere is the client making the inital request for /res/img/content/liferaft.jpg.\n13:39:20.748596 IP 198.144.205.133.3180 > 198.144.205.144.80: S\n3335533019:3335533019(0) win 65535 <mss 1460,nop,nop,sackOK>\n\n13:39:20.748697 IP 198.144.205.144.80 > 198.144.205.133.3180: S\n876667792:876667792(0) ack 3335533020 win 65535 <mss 1460,sackOK,eol>\n\n13:39:20.748824 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 1 win 65535\n\n13:39:20.749129 IP 198.144.205.133.3180 > 198.144.205.144.80: P 1:834(833) ack 1\nwin 65535\n\n\nHere are the headers the client sent to the proxy server.\n\nGET /res/img/content/liferaft.jpg HTTP/1.1\nHost: nuked.greatschools.net\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3)\nGecko/20060426 Firefox/1.5.0.3\nAccept:\ntext/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\nAccept-Language: en-us,en;q=0.5\nAccept-Encoding: gzip,deflate\nAccept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7\nKeep-Alive: 300\nConnection: keep-alive\nCookie: T3CK=TANT%3D1%7CTANO%3D0; fcP=C=133&T=1137020088512&V=1137020102487;\ns_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; RMID=c690cd854329f1d0;\nRMFD=011Fiz3b;\nNXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF;\nTRNO=1127250133.198.144.205.133\n\nNext, the proxy server makes a connection to the backend web server to fufill\nthe request:\n\n13:39:20.751945 IP 198.144.205.144.55524 > 198.144.205.152.80: S\n1402262641:1402262641(0) win 65535 <mss 1460,nop,wscale 1,nop,nop,timestamp\n4082124725 0,sackOK,eol>\n13:39:20.752099 IP 198.144.205.152.80 > 198.144.205.144.55524: S\n2054288495:2054288495(0) ack 1402262642 win 57344 <mss 1460,nop,wscale\n0,nop,nop,timestamp 1733763502 4082124725>\n13:39:20.752170 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 1 win 33304\n<nop,nop,timestamp 4082124725 1733763502>\n13:39:20.752735 IP 198.144.205.144.55524 > 198.144.205.152.80: P 1:956(955) ack\n1 win 33304 <nop,nop,timestamp 4082124726 1733763502>\n13:39:20.757824 IP 198.144.205.152.80 > 198.144.205.144.55524: . 1:1449(1448)\nack 956 win 57920 <nop,nop,timestamp 1733763503 4082124726>\n13:39:20.757934 IP 198.144.205.152.80 > 198.144.205.144.55524: . 1449:2897(1448)\nack 956 win 57920 <nop,nop,timestamp 1733763503 4082124726>\n13:39:20.757977 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 2897 win\n32580 <nop,nop,timestamp 4082124731 1733763503>\n13:39:20.758057 IP 198.144.205.152.80 > 198.144.205.144.55524: . 2897:4345(1448)\nack 956 win 57920 <nop,nop,timestamp 1733763503 4082124726>\n13:39:20.758179 IP 198.144.205.152.80 > 198.144.205.144.55524: . 4345:5793(1448)\nack 956 win 57920 <nop,nop,timestamp 1733763503 4082124726>\n13:39:20.758211 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 5793 win\n31132 <nop,nop,timestamp 4082124731 1733763503>\n13:39:20.758313 IP 198.144.205.152.80 > 198.144.205.144.55524: . 5793:7241(1448)\nack 956 win 57920 <nop,nop,timestamp 1733763503 4082124726>\n13:39:20.758426 IP 198.144.205.152.80 > 198.144.205.144.55524: . 7241:8689(1448)\nack 956 win 57920 <nop,nop,timestamp 1733763503 4082124731>\n13:39:20.758462 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 8689 win\n29684 <nop,nop,timestamp 4082124732 1733763503>\n13:39:20.758549 IP 198.144.205.152.80 > 198.144.205.144.55524: .\n8689:10137(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124731>\n13:39:20.758675 IP 198.144.205.152.80 > 198.144.205.144.55524: .\n10137:11585(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124731>\n13:39:20.758715 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 11585 win\n28236 <nop,nop,timestamp 4082124732 1733763503>\n13:39:20.758796 IP 198.144.205.152.80 > 198.144.205.144.55524: .\n11585:13033(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124731>\n13:39:20.758918 IP 198.144.205.152.80 > 198.144.205.144.55524: .\n13033:14481(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124731>\n13:39:20.758953 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 14481 win\n26788 <nop,nop,timestamp 4082124732 1733763503>\n13:39:20.759041 IP 198.144.205.152.80 > 198.144.205.144.55524: .\n14481:15929(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124731>\n13:39:20.759168 IP 198.144.205.152.80 > 198.144.205.144.55524: .\n15929:17377(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732>\n13:39:20.759211 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 17377 win\n25340 <nop,nop,timestamp 4082124732 1733763503>\n13:39:20.759288 IP 198.144.205.152.80 > 198.144.205.144.55524: .\n17377:18825(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732>\n13:39:20.759411 IP 198.144.205.152.80 > 198.144.205.144.55524: .\n18825:20273(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732>\n13:39:20.759448 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 20273 win\n23892 <nop,nop,timestamp 4082124733 1733763503>\n13:39:20.759536 IP 198.144.205.152.80 > 198.144.205.144.55524: .\n20273:21721(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732>\n13:39:20.759656 IP 198.144.205.152.80 > 198.144.205.144.55524: .\n21721:23169(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732>\n13:39:20.759697 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 23169 win\n22444 <nop,nop,timestamp 4082124733 1733763503>\n13:39:20.759780 IP 198.144.205.152.80 > 198.144.205.144.55524: .\n23169:24617(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732>\n13:39:20.759903 IP 198.144.205.152.80 > 198.144.205.144.55524: .\n24617:26065(1448) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732>\n13:39:20.759940 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 26065 win\n20996 <nop,nop,timestamp 4082124733 1733763503>\n13:39:20.759994 IP 198.144.205.152.80 > 198.144.205.144.55524: P\n26065:27126(1061) ack 956 win 57920 <nop,nop,timestamp 1733763503 4082124732>\n13:39:20.760244 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 27126 win\n24465 <nop,nop,timestamp 4082124733 1733763503>\n13:39:20.761346 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 27126 win\n28465 <nop,nop,timestamp 4082124735 1733763503>\n13:39:20.762105 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 27126 win\n32465 <nop,nop,timestamp 4082124735 1733763503>\n13:39:37.395766 IP 198.144.205.152.80 > 198.144.205.144.55524: F 27126:27126(0)\nack 956 win 57920 <nop,nop,timestamp 1733765167 4082124735>\n13:39:37.395864 IP 198.144.205.144.55524 > 198.144.205.152.80: . ack 27127 win\n33304 <nop,nop,timestamp 4082141370 1733765167>\n13:40:46.519437 IP 198.144.205.144.55524 > 198.144.205.152.80: F 956:956(0) ack\n27127 win 33304 <nop,nop,timestamp 4082210495 1733765167>\n13:40:46.519586 IP 198.144.205.152.80 > 198.144.205.144.55524: . ack 957 win\n57920 <nop,nop,timestamp 1733772078 4082210495>\n\nHere are the headers that the proxy server sends to the backend for the request:\n\nGET /res/img/content/liferaft.jpg HTTP/1.1\nHost: nuked.greatschools.net\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3)\nGecko/20060426 Firefox/1.5.0.3\nAccept:\ntext/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\nAccept-Language: en-us,en;q=0.5\nAccept-Encoding: gzip,deflate\nAccept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7\nCookie: T3CK=TANT%3D1%7CTANO%3D0; fcP=C=133&T=1137020088512&V=1137020102487;\ns_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; RMID=c690cd854329f1d0;\nRMFD=011Fiz3b;\nNXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF;\nTRNO=1127250133.198.144.205.133\nMax-Forwards: 10\nX-Forwarded-For: 198.144.205.133\nX-Forwarded-Host: nuked.greatschools.net\nX-Forwarded-Server: nuked.greatschools.net.\nConnection: Keep-Alive\n\nHere are the headers the backend responds with:\n\nHTTP/1.1 200 OK\nDate: Thu, 25 May 2006 20:39:20 GMT\nServer: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d\nmod_jk/1.2.15\nETag: W/'26797-1148506126000'\nLast-Modified: Wed, 24 May 2006 21:28:46 GMT\nContent-Length: 26797\nKeep-Alive: timeout=15, max=1000\nConnection: Keep-Alive\nContent-Type: image/jpeg\n\n\nThen the proxy server responds to the client's request:\n\n13:39:20.760358 IP 198.144.205.144.80 > 198.144.205.133.3180: . 1:1461(1460) ack\n834 win 65535\n13:39:20.760894 IP 198.144.205.144.80 > 198.144.205.133.3180: . 1461:2921(1460)\nack 834 win 65535\n13:39:20.760919 IP 198.144.205.144.80 > 198.144.205.133.3180: . 2921:4381(1460)\nack 834 win 65535\n13:39:20.760932 IP 198.144.205.144.80 > 198.144.205.133.3180: . 4381:5841(1460)\nack 834 win 65535\n13:39:20.761507 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 2921 win 65535\n13:39:20.761607 IP 198.144.205.144.80 > 198.144.205.133.3180: . 5841:7301(1460)\nack 834 win 65535\n13:39:20.761621 IP 198.144.205.144.80 > 198.144.205.133.3180: . 7301:8761(1460)\nack 834 win 65535\n13:39:20.761635 IP 198.144.205.144.80 > 198.144.205.133.3180: . 8761:10221(1460)\nack 834 win 65535\n13:39:20.761719 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 5841 win 65535\n13:39:20.761748 IP 198.144.205.144.80 > 198.144.205.133.3180: .\n10221:11681(1460) ack 834 win 65535\n13:39:20.761763 IP 198.144.205.144.80 > 198.144.205.133.3180: .\n11681:13141(1460) ack 834 win 65535\n13:39:20.761778 IP 198.144.205.144.80 > 198.144.205.133.3180: .\n13141:14601(1460) ack 834 win 65535\n13:39:20.763225 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 8761 win 65535\n13:39:20.763468 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 11681 win 65535\n13:39:20.763526 IP 198.144.205.144.80 > 198.144.205.133.3180: .\n14601:16061(1460) ack 834 win 65535\n13:39:20.763544 IP 198.144.205.144.80 > 198.144.205.133.3180: .\n16061:17521(1460) ack 834 win 65535\n13:39:20.763712 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 14601 win 65535\n13:39:20.763735 IP 198.144.205.144.80 > 198.144.205.133.3180: .\n17521:18981(1460) ack 834 win 65535\n13:39:20.763748 IP 198.144.205.144.80 > 198.144.205.133.3180: .\n18981:20441(1460) ack 834 win 65535\n13:39:20.764661 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 17521 win 65535\n13:39:20.764691 IP 198.144.205.144.80 > 198.144.205.133.3180: .\n20441:21901(1460) ack 834 win 65535\n13:39:20.764703 IP 198.144.205.144.80 > 198.144.205.133.3180: .\n21901:23361(1460) ack 834 win 65535\n13:39:20.764904 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 20441 win 65535\n13:39:20.764924 IP 198.144.205.144.80 > 198.144.205.133.3180: .\n23361:24821(1460) ack 834 win 65535\n13:39:20.764937 IP 198.144.205.144.80 > 198.144.205.133.3180: .\n24821:26281(1460) ack 834 win 65535\n13:39:20.765177 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 23361 win 65535\n13:39:20.765197 IP 198.144.205.144.80 > 198.144.205.133.3180: P 26281:27164(883)\nack 834 win 65535\n13:39:20.765423 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 26281 win 65535\n13:39:20.941506 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 27164 win 64652\n13:39:25.763406 IP 198.144.205.144.80 > 198.144.205.133.3180: F 27164:27164(0)\nack 834 win 65535\n13:39:25.763601 IP 198.144.205.133.3180 > 198.144.205.144.80: . ack 27165 win 64652\n13:39:27.958133 IP 198.144.205.133.3180 > 198.144.205.144.80: F 834:834(0) ack\n27165 win 64652\n13:39:27.958237 IP 198.144.205.144.80 > 198.144.205.133.3180: . ack 835 win 65534\n\nHere are the headers the proxy responds with:\n\nHTTP/1.1 200 OK\nDate: Thu, 25 May 2006 20:39:20 GMT\nServer: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d\nmod_jk/1.2.15\nETag: W/'26797-1148506126000'\nLast-Modified: Wed, 24 May 2006 21:28:46 GMT\nContent-Length: 26797\nContent-Type: image/jpeg\nExpires: Thu, 25 May 2006 22:58:23 GMT\nKeep-Alive: timeout=5, max=100\nConnection: Keep-Alive\n\nThat transaction worked okay.  Here's one that didn't work:\n\n13:41:01.094260 IP 198.144.205.133.3187 > 198.144.205.144.80: S\n1953506917:1953506917(0) win 65535 <mss 1460,nop,nop,sackOK>\n13:41:01.094354 IP 198.144.205.144.80 > 198.144.205.133.3187: S\n1632330321:1632330321(0) ack 1953506918 win 65535 <mss 1460,sackOK,eol>\n13:41:01.094490 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 1 win 65535\n13:41:01.094805 IP 198.144.205.133.3187 > 198.144.205.144.80: P 1:877(876) ack 1\nwin 65535\n13:41:01.102707 IP 198.144.205.144.80 > 198.144.205.133.3187: . 1:1461(1460) ack\n877 win 65535\n13:41:01.102733 IP 198.144.205.144.80 > 198.144.205.133.3187: . 1461:2921(1460)\nack 877 win 65535\n13:41:01.103237 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 2921 win 65535\n13:41:01.103328 IP 198.144.205.144.80 > 198.144.205.133.3187: . 2921:4381(1460)\nack 877 win 65535\n13:41:01.103340 IP 198.144.205.144.80 > 198.144.205.133.3187: . 4381:5841(1460)\nack 877 win 65535\n13:41:01.103354 IP 198.144.205.144.80 > 198.144.205.133.3187: . 5841:7301(1460)\nack 877 win 65535\n13:41:01.103824 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 5841 win 65535\n13:41:01.103847 IP 198.144.205.144.80 > 198.144.205.133.3187: . 7301:8761(1460)\nack 877 win 65535\n13:41:01.103858 IP 198.144.205.144.80 > 198.144.205.133.3187: . 8761:10221(1460)\nack 877 win 65535\n13:41:01.103870 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n10221:11681(1460) ack 877 win 65535\n13:41:01.104210 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 8761 win 65535\n13:41:01.104234 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n11681:13141(1460) ack 877 win 65535\n13:41:01.104246 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n13141:14601(1460) ack 877 win 65535\n13:41:01.104258 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n14601:16061(1460) ack 877 win 65535\n13:41:01.104457 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 11681 win 65535\n13:41:01.104481 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n16061:17521(1460) ack 877 win 65535\n13:41:01.104495 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n17521:18981(1460) ack 877 win 65535\n13:41:01.104507 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n18981:20441(1460) ack 877 win 65535\n13:41:01.104724 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 14601 win 65535\n13:41:01.104745 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n20441:21901(1460) ack 877 win 65535\n13:41:01.104758 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n21901:23361(1460) ack 877 win 65535\n13:41:01.104771 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n23361:24821(1460) ack 877 win 65535\n13:41:01.104966 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 17521 win 65535\n13:41:01.104985 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n24821:26281(1460) ack 877 win 65535\n13:41:01.105004 IP 198.144.205.144.80 > 198.144.205.133.3187: P 26281:27164(883)\nack 877 win 65535\n13:41:01.105213 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 20441 win 65535\n13:41:01.105461 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 23361 win 65535\n13:41:01.105706 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 26281 win 65535\n13:41:01.237467 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 27164 win 64652\n13:41:05.312399 IP 198.144.205.133.3187 > 198.144.205.144.80: P 877:1753(876)\nack 27164 win 64652\n13:41:05.316143 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n27164:28624(1460) ack 1753 win 65535\n13:41:05.316167 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n28624:30084(1460) ack 1753 win 65535\n13:41:05.316187 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n30084:31544(1460) ack 1753 win 65535\n13:41:05.316197 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n31544:33004(1460) ack 1753 win 65535\n13:41:05.316217 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n33004:34464(1460) ack 1753 win 65535\n13:41:05.316233 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n34464:35924(1460) ack 1753 win 65535\n13:41:05.316242 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n35924:37384(1460) ack 1753 win 65535\n13:41:05.316261 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n37384:38844(1460) ack 1753 win 65535\n13:41:05.316278 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n38844:40304(1460) ack 1753 win 65535\n13:41:05.316293 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n40304:41764(1460) ack 1753 win 65535\n13:41:05.316302 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n41764:43224(1460) ack 1753 win 65535\n13:41:05.316323 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n43224:44684(1460) ack 1753 win 65535\n13:41:05.316679 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 30084 win 65535\n13:41:05.316774 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n44684:46144(1460) ack 1753 win 65535\n13:41:05.316785 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n46144:47604(1460) ack 1753 win 65535\n13:41:05.316795 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n47604:49064(1460) ack 1753 win 65535\n13:41:05.316874 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 33004 win 65535\n13:41:05.316897 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n49064:50524(1460) ack 1753 win 65535\n13:41:05.316910 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n50524:51984(1460) ack 1753 win 65535\n13:41:05.316922 IP 198.144.205.144.80 > 198.144.205.133.3187: .\n51984:53444(1460) ack 1753 win 65535\n13:41:05.317132 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 35924 win 65535\n13:41:05.317153 IP 198.144.205.144.80 > 198.144.205.133.3187: P 53444:54325(881)\nack 1753 win 65535\n13:41:05.317382 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 38844 win 65535\n13:41:05.317626 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 41764 win 65535\n13:41:05.317868 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 44684 win 65535\n13:41:05.318118 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 47604 win 65535\n13:41:05.318363 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 50524 win 65535\n13:41:05.318610 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 53444 win 65535\n13:41:05.503052 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 54325 win 64654\n13:41:05.629138 IP 198.144.205.133.3187 > 198.144.205.144.80: P 1753:2489(736)\nack 54325 win 64654\n13:41:05.633724 IP 198.144.205.144.80 > 198.144.205.133.3187: P 54325:54883(558)\nack 2489 win 65535\n13:41:05.831178 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 54883 win 64096\n13:41:10.634808 IP 198.144.205.144.80 > 198.144.205.133.3187: F 54883:54883(0)\nack 2489 win 65535\n13:41:10.634969 IP 198.144.205.133.3187 > 198.144.205.144.80: . ack 54884 win 64096\n13:41:24.506079 IP 198.144.205.133.3187 > 198.144.205.144.80: F 2489:2489(0) ack\n54884 win 64096\n13:41:24.506191 IP 198.144.205.144.80 > 198.144.205.133.3187: . ack 2490 win 65534\n\nThis is actually two requests over a single tcp connection.  I assume firefox is\nrecycling a still connected keep alive session if the user hits ctrl+F5 fast enough.\n\nThe client / server headers:\n\nGET /res/img/content/liferaft.jpg HTTP/1.1\nHost: nuked.greatschools.net\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3)\nGecko/20060426 Firefox/1.5.0.3\nAccept:\ntext/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\nAccept-Language: en-us,en;q=0.5\nAccept-Encoding: gzip,deflate\nAccept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7\nKeep-Alive: 300\nConnection: keep-alive\nCookie: T3CK=TANT%3D1%7CTANO%3D0; fcP=C=133&T=1137020088512&V=1137020102487;\ns_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; RMID=c690cd854329f1d0;\nRMFD=011Fiz3b;\nNXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF;\nTRNO=1127250133.198.144.205.133\nPragma: no-cache\nCache-Control: no-cache\n\nHTTP/1.1 200 OK\nDate: Thu, 25 May 2006 20:41:01 GMT\nServer: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d\nmod_jk/1.2.15\nETag: W/'26797-1148506126000'\nContent-Length: 26797\nExpires: Fri, 26 May 2006 00:41:01 GMT\nContent-Type: image/jpeg\nLast-Modified: Wed, 24 May 2006 21:28:46 GMT\nKeep-Alive: timeout=5, max=100\nConnection: Keep-Alive\n\nGET /res/img/content/liferaft.jpg HTTP/1.1\nHost: nuked.greatschools.net\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3)\nGecko/20060426 Firefox/1.5.0.3\nAccept:\ntext/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\nAccept-Language: en-us,en;q=0.5\nAccept-Encoding: gzip,deflate\nAccept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7\nKeep-Alive: 300\nConnection: keep-alive\nCookie: T3CK=TANT%3D1%7CTANO%3D0; fcP=C=133&T=1137020088512&V=1137020102487;\ns_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; RMID=c690cd854329f1d0;\nRMFD=011Fiz3b;\nNXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF;\nTRNO=1127250133.198.144.205.133\nPragma: no-cache\nCache-Control: no-cache\n\nHTTP/1.1 200 OK\nDate: Thu, 25 May 2006 20:41:05 GMT\nServer: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d\nmod_jk/1.2.15\nETag: W/'26797-1148506126000'\nContent-Length: 26797\nExpires: Fri, 26 May 2006 00:41:05 GMT\nContent-Type: text/html\nLast-Modified: Wed, 24 May 2006 21:28:46 GMT\nKeep-Alive: timeout=5, max=99\nConnection: Keep-Alive\n\n\nThe first request worked, but the second one was returned as text/html.\n\nMeanwhile, the proxy server is making requests to the backend to handle the\nclient's request.\n\n13:40:46.519646 IP 198.144.205.144.64919 > 198.144.205.152.80: S\n755704577:755704577(0) win 65535 <mss 1460,nop,wscale 1,nop,nop,timestamp\n4082210496 0,sackOK,eol>\n13:40:46.519763 IP 198.144.205.152.80 > 198.144.205.144.64919: S\n2886095240:2886095240(0) ack 755704578 win 57344 <mss 1460,nop,wscale\n0,nop,nop,timestamp 1733772078 4082210496>\n13:40:46.519805 IP 198.144.205.144.64919 > 198.144.205.152.80: . ack 1 win 33304\n<nop,nop,timestamp 4082210496 1733772078>\n13:40:46.520087 IP 198.144.205.144.64919 > 198.144.205.152.80: P 1:1089(1088)\nack 1 win 33304 <nop,nop,timestamp 4082210496 1733772078>\n13:40:46.524652 IP 198.144.205.152.80 > 198.144.205.144.64919: P 1:257(256) ack\n1089 win 57920 <nop,nop,timestamp 1733772079 4082210496>\n13:40:46.624500 IP 198.144.205.144.64919 > 198.144.205.152.80: . ack 257 win\n33304 <nop,nop,timestamp 4082210601 1733772079>\n13:41:01.097038 IP 198.144.205.144.63148 > 198.144.205.152.80: F 999:999(0) ack\n27127 win 33304 <nop,nop,timestamp 4082225073 1733765874>\n13:41:01.097158 IP 198.144.205.152.80 > 198.144.205.144.63148: . ack 1000 win\n57920 <nop,nop,timestamp 1733773536 4082225073>\n13:41:01.097278 IP 198.144.205.144.55877 > 198.144.205.152.80: S\n3660931143:3660931143(0) win 65535 <mss 1460,nop,wscale 1,nop,nop,timestamp\n4082225074 0,sackOK,eol>\n13:41:01.097392 IP 198.144.205.152.80 > 198.144.205.144.55877: S\n1545466721:1545466721(0) ack 3660931144 win 57344 <mss 1460,nop,wscale\n0,nop,nop,timestamp 1733773536 4082225074>\n13:41:01.097431 IP 198.144.205.144.55877 > 198.144.205.152.80: . ack 1 win 33304\n<nop,nop,timestamp 4082225074 1733773536>\n13:41:01.097709 IP 198.144.205.144.55877 > 198.144.205.152.80: P 1:1089(1088)\nack 1 win 33304 <nop,nop,timestamp 4082225074 1733773536>\n13:41:01.102080 IP 198.144.205.152.80 > 198.144.205.144.55877: P 1:257(256) ack\n1089 win 57920 <nop,nop,timestamp 1733773536 4082225074>\n13:41:01.202018 IP 198.144.205.144.55877 > 198.144.205.152.80: . ack 257 win\n33304 <nop,nop,timestamp 4082225179 1733773536>\n13:41:03.254784 IP 198.144.205.152.80 > 198.144.205.144.64919: F 257:257(0) ack\n1089 win 57920 <nop,nop,timestamp 1733773752 4082210601>\n13:41:03.254877 IP 198.144.205.144.64919 > 198.144.205.152.80: . ack 258 win\n33304 <nop,nop,timestamp 4082227231 1733773752>\n13:41:05.313389 IP 198.144.205.144.55877 > 198.144.205.152.80: P 1089:2177(1088)\nack 257 win 33304 <nop,nop,timestamp 4082229290 1733773536>\n13:41:05.315555 IP 198.144.205.152.80 > 198.144.205.144.55877: P 257:512(255)\nack 2177 win 57920 <nop,nop,timestamp 1733773958 4082229290>\n13:41:05.414874 IP 198.144.205.144.55877 > 198.144.205.152.80: . ack 512 win\n33304 <nop,nop,timestamp 4082229392 1733773958>\n13:41:05.629992 IP 198.144.205.144.55877 > 198.144.205.152.80: P 2177:3035(858)\nack 512 win 33304 <nop,nop,timestamp 4082229607 1733773958>\n13:41:05.631281 IP 198.144.205.152.80 > 198.144.205.144.55877: P 512:1753(1241)\nack 3035 win 57920 <nop,nop,timestamp 1733773989 4082229607>\n13:41:05.730896 IP 198.144.205.144.55877 > 198.144.205.152.80: . ack 1753 win\n33304 <nop,nop,timestamp 4082229708 1733773989>\n13:41:22.446789 IP 198.144.205.152.80 > 198.144.205.144.55877: F 1753:1753(0)\nack 3035 win 57920 <nop,nop,timestamp 1733775671 4082229708>\n13:41:22.446885 IP 198.144.205.144.55877 > 198.144.205.152.80: . ack 1754 win\n33304 <nop,nop,timestamp 4082246424 1733775671>\n\nHere are the headers from the proxy -> backend conversation.\n\nGET /res/img/content/liferaft.jpg HTTP/1.1\nHost: nuked.greatschools.net\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3)\nGecko/20060426 Firefox/1.5.0.3\nAccept:\ntext/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\nAccept-Language: en-us,en;q=0.5\nAccept-Encoding: gzip,deflate\nAccept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7\nCookie: T3CK=TANT%3D1%7CTANO%3D0; fcP=C=133&T=1137020088512&V=1137020102487;\ns_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; RMID=c690cd854329f1d0;\nRMFD=011Fiz3b;\nNXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF;\nTRNO=1127250133.198.144.205.133\nPragma: no-cache\nCache-Control: no-cache\nIf-None-Match: W/'26797-1148506126000'\nIf-Modified-Since: Wed, 24 May 2006 21:28:46 GMT\nMax-Forwards: 10\nX-Forwarded-For: 198.144.205.133\nX-Forwarded-Host: nuked.greatschools.net\nX-Forwarded-Server: nuked.greatschools.net.\nConnection: Keep-Alive\n\nHTTP/1.1 304 Not Modified\nDate: Thu, 25 May 2006 20:41:01 GMT\nServer: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d\nmod_jk/1.2.15\nContent-Length: 0\nKeep-Alive: timeout=15, max=1000\nConnection: Keep-Alive\nContent-Type: text/html\n\nIt looks like the backend is responding with http status code 304.  I'm\nwondering if the text/html content-type from the 304 code is being erroniously\ncached in this case?\n\nI have the tcpdump capture file here.  If I can provide any more information or\nperhaps put the capture file somewhere for download please don't hesitate to ask.\n
39647	Christopher Shumway	1148602050000	I just ran some tcpdump sniffing while pulling an image served directly by httpd\non the backend, not going through mod_jk.  It does not set the conent-type\nheader when it returns a 304 http status code.  Here are the headers from the\nproxy -> backend conversation:\n\nGET /images/reportcard.jpg HTTP/1.1\nHost: nuked.greatschools.net\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.0.3)\nGecko/20060426 Firefox/1.5.0.3\nAccept:\ntext/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\nAccept-Language: en-us,en;q=0.5\nAccept-Encoding: gzip,deflate\nAccept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7\nCookie: TRNO=1127250133.198.144.205.133;\nNXCLICK2=011FHWHwNX_mailing/gn/2006_02/ca/8951!y!01!4qcu!52qf!02!4qcv!52qhNX_mailing/gn/2006_02_21/ca/8427!y!01!4r4q!53Uk!02!4r4r!53UqNX_mailing/mss/2006_03/ca/8438.76346803398!y!02!4rJ8!53pF;\nRMFD=011Fiz3b; NumAd=-1; RMID=c690cd854329f1d0;\ns_vi=[CS]v1|43F0FFA7000062EC-A160B0300000792[CE]; T3CK=TANT%3D1%7CTANO%3D0;\nfcP=C=133&T=1137020088512&V=1137020102487\nPragma: no-cache\nCache-Control: no-cache\nIf-None-Match: '1fae43-4487-3f4e92c4'\nIf-Modified-Since: Thu, 28 Aug 2003 23:39:48 GMT\nMax-Forwards: 10\nX-Forwarded-For: 198.144.205.133\nX-Forwarded-Host: nuked.greatschools.net\nX-Forwarded-Server: nuked.greatschools.net.\nConnection: Keep-Alive\n\n\nHTTP/1.1 304 Not Modified\nDate: Thu, 25 May 2006 23:56:23 GMT\nServer: Apache/1.3.33 (Unix) mod_perl/1.29 mod_ssl/2.8.22 OpenSSL/0.9.7d\nmod_jk/1.2.15\nConnection: Keep-Alive, Keep-Alive\nKeep-Alive: timeout=15, max=998\nETag: '1fae43-4487-3f4e92c4'\nExpires: Fri, 26 May 2006 05:56:23 GMT\nCache-Control: max-age=21600\n\n
39647	Ruediger Pluem	1148633652000	Created an attachment (id=18353)\nPatch for additional Debug messages against 2.2.x\n\nThanks for the update. I think we are getting closer. Can you please apply the\nattached patch, run a non working request and post the according error log?\nThe patch is only temporary and does not fix anything, but it should help me to\nunderstand the problem better.
39647	Christopher Shumway	1148667505000	Here you go.  I applied the patch, and also the patch found in bug 39266.  Here\nis a snipit from the debug log.\n\n[Fri May 26 11:15:05 2006] [debug] cache_storage.c(261): Cached response for\n/res/img/content/liferaft.jpg isn't fresh.  Adding/replacing conditional request\nheaders.\n[Fri May 26 11:15:05 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /res/img/content/liferaft.jpg\n[Fri May 26 11:15:05 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /res/img/content/liferaft.jpg\n[Fri May 26 11:15:05 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/res/img/content/liferaft.jpg\n[Fri May 26 11:15:05 2006] [debug] proxy_util.c(1378): [client 64.85.232.3]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/res/img/content/liferaft.jpg\n[Fri May 26 11:15:05 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Fri May 26 11:15:05 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/res/img/content/liferaft.jpg\n[Fri May 26 11:15:05 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Fri May 26 11:15:05 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/res/img/content/liferaft.jpg to dev.greatschools.net:80\n[Fri May 26 11:15:05 2006] [debug] proxy_util.c(1951): proxy: connected\n/res/img/content/liferaft.jpg to dev.greatschools.net:80\n[Fri May 26 11:15:05 2006] [debug] proxy_util.c(2045): proxy: HTTP: fam 2 socket\ncreated to connect to dev.greatschools.net\n[Fri May 26 11:15:05 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Fri May 26 11:15:05 2006] [debug] mod_proxy_http.c(1541): proxy: header only\n[Fri May 26 11:15:05 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Fri May 26 11:15:05 2006] [debug] mod_cache.c(602): cache: Caching url:\n/res/img/content/liferaft.jpg\n[Fri May 26 11:15:05 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Fri May 26 11:15:05 2006] [debug] mod_cache.c(726): cache: Content-Type\ntext/html text/html\n[Fri May 26 11:15:05 2006] [debug] mod_cache.c(738): cache: Content-Type\ntext/html image/jpeg\n[Fri May 26 11:15:05 2006] [debug] http_filters.c(990): http_filter:\nContent-Type text/html image/jpeg\n[Fri May 26 11:15:05 2006] [debug] http_filters.c(995): http_filter:\nContent-Type image/jpeg image/jpeg\n[Fri May 26 11:15:05 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net)\n[Fri May 26 11:15:06 2006] [debug] cache_storage.c(261): Cached response for\n/res/img/content/liferaft.jpg isn't fresh.  Adding/replacing conditional request\nheaders.\n[Fri May 26 11:15:06 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /res/img/content/liferaft.jpg\n[Fri May 26 11:15:06 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /res/img/content/liferaft.jpg\n[Fri May 26 11:15:06 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/res/img/content/liferaft.jpg\n[Fri May 26 11:15:06 2006] [debug] proxy_util.c(1378): [client 64.85.232.3]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/res/img/content/liferaft.jpg\n[Fri May 26 11:15:06 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Fri May 26 11:15:06 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/res/img/content/liferaft.jpg\n[Fri May 26 11:15:06 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Fri May 26 11:15:06 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/res/img/content/liferaft.jpg to dev.greatschools.net:80\n[Fri May 26 11:15:06 2006] [debug] proxy_util.c(1951): proxy: connected\n/res/img/content/liferaft.jpg to dev.greatschools.net:80\n[Fri May 26 11:15:06 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Fri May 26 11:15:06 2006] [debug] mod_proxy_http.c(1541): proxy: header only\n[Fri May 26 11:15:06 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Fri May 26 11:15:06 2006] [debug] mod_cache.c(602): cache: Caching url:\n/res/img/content/liferaft.jpg\n[Fri May 26 11:15:06 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Fri May 26 11:15:06 2006] [debug] mod_cache.c(726): cache: Content-Type\ntext/html text/html\n[Fri May 26 11:15:06 2006] [debug] mod_cache.c(738): cache: Content-Type\ntext/html text/html\n[Fri May 26 11:15:06 2006] [debug] http_filters.c(990): http_filter:\nContent-Type text/html text/html\n[Fri May 26 11:15:06 2006] [debug] http_filters.c(995): http_filter:\nContent-Type text/html text/html\n[Fri May 26 11:15:06 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net)\n\nThis is two requests over the same tcp keepalive connection from firefox.  The\nfirst request seemed to work, the second one firefix tried to render the jpeg as\nif it was html.\n
39647	Christopher Shumway	1148667796000	Just for comparison's sake, here is some debug log output while force-refreshing\nan image being served directly by the backend httpd server, not through mod_jk.\n\n[Fri May 26 11:20:28 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /images/reportcard.jpg\n[Fri May 26 11:20:28 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /images/reportcard.jpg\n[Fri May 26 11:20:28 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:28 2006] [debug] proxy_util.c(1378): [client 64.85.232.3]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:28 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Fri May 26 11:20:28 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:28 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Fri May 26 11:20:28 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80\n[Fri May 26 11:20:28 2006] [debug] proxy_util.c(1951): proxy: connected\n/images/reportcard.jpg to dev.greatschools.net:80\n[Fri May 26 11:20:28 2006] [debug] proxy_util.c(2045): proxy: HTTP: fam 2 socket\ncreated to connect to dev.greatschools.net\n[Fri May 26 11:20:28 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Fri May 26 11:20:29 2006] [debug] mod_proxy_http.c(1448): proxy: start body send\n[Fri May 26 11:20:29 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Fri May 26 11:20:29 2006] [debug] mod_cache.c(602): cache: Caching url:\n/images/reportcard.jpg\n[Fri May 26 11:20:29 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Fri May 26 11:20:29 2006] [debug] http_filters.c(990): http_filter:\nContent-Type image/jpeg image/jpeg\n[Fri May 26 11:20:29 2006] [debug] http_filters.c(995): http_filter:\nContent-Type image/jpeg image/jpeg\n[Fri May 26 11:20:29 2006] [info] mem_cache: Cached url:\nhttp://nuked.greatschools.net:80/images/reportcard.jpg?\n[Fri May 26 11:20:29 2006] [debug] mod_proxy_http.c(1537): proxy: end body send\n[Fri May 26 11:20:29 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net)\n[Fri May 26 11:20:38 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /images/reportcard.jpg\n[Fri May 26 11:20:38 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /images/reportcard.jpg\n[Fri May 26 11:20:38 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:38 2006] [debug] proxy_util.c(1378): [client 64.85.232.3]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:38 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Fri May 26 11:20:38 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:38 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Fri May 26 11:20:38 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80\n[Fri May 26 11:20:38 2006] [debug] proxy_util.c(1951): proxy: connected\n/images/reportcard.jpg to dev.greatschools.net:80\n[Fri May 26 11:20:38 2006] [debug] proxy_util.c(2045): proxy: HTTP: fam 2 socket\ncreated to connect to dev.greatschools.net\n[Fri May 26 11:20:38 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Fri May 26 11:20:38 2006] [debug] mod_proxy_http.c(1448): proxy: start body send\n[Fri May 26 11:20:38 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Fri May 26 11:20:38 2006] [debug] mod_cache.c(602): cache: Caching url:\n/images/reportcard.jpg\n[Fri May 26 11:20:38 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Fri May 26 11:20:38 2006] [debug] http_filters.c(990): http_filter:\nContent-Type image/jpeg image/jpeg\n[Fri May 26 11:20:38 2006] [debug] http_filters.c(995): http_filter:\nContent-Type image/jpeg image/jpeg\n[Fri May 26 11:20:38 2006] [info] mem_cache: Cached url:\nhttp://nuked.greatschools.net:80/images/reportcard.jpg?\n[Fri May 26 11:20:38 2006] [debug] mod_proxy_http.c(1537): proxy: end body send\n[Fri May 26 11:20:38 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net)\n[Fri May 26 11:20:39 2006] [debug] cache_storage.c(261): Cached response for\n/images/reportcard.jpg isn't fresh.  Adding/replacing conditional request headers.\n[Fri May 26 11:20:39 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /images/reportcard.jpg\n[Fri May 26 11:20:39 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /images/reportcard.jpg\n[Fri May 26 11:20:39 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:39 2006] [debug] proxy_util.c(1378): [client 64.85.232.3]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:39 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Fri May 26 11:20:39 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:39 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Fri May 26 11:20:39 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80\n[Fri May 26 11:20:39 2006] [debug] proxy_util.c(1951): proxy: connected\n/images/reportcard.jpg to dev.greatschools.net:80\n[Fri May 26 11:20:39 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Fri May 26 11:20:39 2006] [debug] mod_proxy_http.c(1541): proxy: header only\n[Fri May 26 11:20:39 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Fri May 26 11:20:39 2006] [debug] mod_cache.c(602): cache: Caching url:\n/images/reportcard.jpg\n[Fri May 26 11:20:39 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Fri May 26 11:20:39 2006] [debug] mod_cache.c(726): cache: Content-Type (null)\nimage/jpeg\n[Fri May 26 11:20:39 2006] [debug] mod_cache.c(738): cache: Content-Type (null)\nimage/jpeg\n[Fri May 26 11:20:39 2006] [debug] http_filters.c(990): http_filter:\nContent-Type (null) image/jpeg\n[Fri May 26 11:20:39 2006] [debug] http_filters.c(995): http_filter:\nContent-Type image/jpeg image/jpeg\n[Fri May 26 11:20:39 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net)\n[Fri May 26 11:20:40 2006] [debug] cache_storage.c(261): Cached response for\n/images/reportcard.jpg isn't fresh.  Adding/replacing conditional request headers.\n[Fri May 26 11:20:40 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /images/reportcard.jpg\n[Fri May 26 11:20:40 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /images/reportcard.jpg\n[Fri May 26 11:20:40 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:40 2006] [debug] proxy_util.c(1378): [client 64.85.232.3]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:40 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Fri May 26 11:20:40 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:40 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Fri May 26 11:20:40 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80\n[Fri May 26 11:20:40 2006] [debug] proxy_util.c(1951): proxy: connected\n/images/reportcard.jpg to dev.greatschools.net:80\n[Fri May 26 11:20:40 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Fri May 26 11:20:40 2006] [debug] mod_proxy_http.c(1541): proxy: header only\n[Fri May 26 11:20:40 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Fri May 26 11:20:40 2006] [debug] mod_cache.c(602): cache: Caching url:\n/images/reportcard.jpg\n[Fri May 26 11:20:40 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Fri May 26 11:20:40 2006] [debug] mod_cache.c(726): cache: Content-Type (null)\nimage/jpeg\n[Fri May 26 11:20:40 2006] [debug] mod_cache.c(738): cache: Content-Type (null)\nimage/jpeg\n[Fri May 26 11:20:40 2006] [debug] http_filters.c(990): http_filter:\nContent-Type (null) image/jpeg\n[Fri May 26 11:20:40 2006] [debug] http_filters.c(995): http_filter:\nContent-Type image/jpeg image/jpeg\n[Fri May 26 11:20:40 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net)\n[Fri May 26 11:20:41 2006] [debug] cache_storage.c(261): Cached response for\n/images/reportcard.jpg isn't fresh.  Adding/replacing conditional request headers.\n[Fri May 26 11:20:41 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /images/reportcard.jpg\n[Fri May 26 11:20:41 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /images/reportcard.jpg\n[Fri May 26 11:20:41 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:41 2006] [debug] proxy_util.c(1378): [client 64.85.232.3]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:41 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Fri May 26 11:20:41 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:41 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Fri May 26 11:20:41 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80\n[Fri May 26 11:20:41 2006] [debug] proxy_util.c(1951): proxy: connected\n/images/reportcard.jpg to dev.greatschools.net:80\n[Fri May 26 11:20:41 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Fri May 26 11:20:41 2006] [debug] mod_proxy_http.c(1541): proxy: header only\n[Fri May 26 11:20:41 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Fri May 26 11:20:41 2006] [debug] mod_cache.c(602): cache: Caching url:\n/images/reportcard.jpg\n[Fri May 26 11:20:41 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Fri May 26 11:20:41 2006] [debug] mod_cache.c(726): cache: Content-Type (null)\nimage/jpeg\n[Fri May 26 11:20:41 2006] [debug] mod_cache.c(738): cache: Content-Type (null)\nimage/jpeg\n[Fri May 26 11:20:41 2006] [debug] http_filters.c(990): http_filter:\nContent-Type (null) image/jpeg\n[Fri May 26 11:20:41 2006] [debug] http_filters.c(995): http_filter:\nContent-Type image/jpeg image/jpeg\n[Fri May 26 11:20:41 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net)\n[Fri May 26 11:20:41 2006] [debug] cache_storage.c(261): Cached response for\n/images/reportcard.jpg isn't fresh.  Adding/replacing conditional request headers.\n[Fri May 26 11:20:41 2006] [debug] mod_cache.c(129): Adding CACHE_SAVE filter\nfor /images/reportcard.jpg\n[Fri May 26 11:20:41 2006] [debug] mod_cache.c(136): Adding CACHE_REMOVE_URL\nfilter for /images/reportcard.jpg\n[Fri May 26 11:20:41 2006] [debug] mod_proxy_http.c(54): proxy: HTTP:\ncanonicalising URL //dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:41 2006] [debug] proxy_util.c(1378): [client 64.85.232.3]\nproxy: http: found worker http://dev.greatschools.net/ for\nhttp://dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:41 2006] [debug] mod_proxy.c(756): Running scheme http handler\n(attempt 0)\n[Fri May 26 11:20:41 2006] [debug] mod_proxy_http.c(1662): proxy: HTTP: serving\nURL http://dev.greatschools.net/images/reportcard.jpg\n[Fri May 26 11:20:41 2006] [debug] proxy_util.c(1798): proxy: HTTP: has acquired\nconnection for (dev.greatschools.net)\n[Fri May 26 11:20:41 2006] [debug] proxy_util.c(1858): proxy: connecting\nhttp://dev.greatschools.net/images/reportcard.jpg to dev.greatschools.net:80\n[Fri May 26 11:20:41 2006] [debug] proxy_util.c(1951): proxy: connected\n/images/reportcard.jpg to dev.greatschools.net:80\n[Fri May 26 11:20:41 2006] [debug] proxy_util.c(2141): proxy: HTTP: connection\ncomplete to 198.144.205.152:80 (dev.greatschools.net)\n[Fri May 26 11:20:41 2006] [debug] mod_proxy_http.c(1541): proxy: header only\n[Fri May 26 11:20:41 2006] [debug] mod_headers.c(612): headers:\nap_headers_output_filter()\n[Fri May 26 11:20:41 2006] [debug] mod_cache.c(602): cache: Caching url:\n/images/reportcard.jpg\n[Fri May 26 11:20:41 2006] [debug] mod_cache.c(608): cache: Removing\nCACHE_REMOVE_URL filter.\n[Fri May 26 11:20:41 2006] [debug] mod_cache.c(726): cache: Content-Type (null)\nimage/jpeg\n[Fri May 26 11:20:41 2006] [debug] mod_cache.c(738): cache: Content-Type (null)\nimage/jpeg\n[Fri May 26 11:20:41 2006] [debug] http_filters.c(990): http_filter:\nContent-Type (null) image/jpeg\n[Fri May 26 11:20:41 2006] [debug] http_filters.c(995): http_filter:\nContent-Type image/jpeg image/jpeg\n[Fri May 26 11:20:41 2006] [debug] proxy_util.c(1816): proxy: HTTP: has released\nconnection for (dev.greatschools.net)\n
39647	Ruediger Pluem	1148683777000	Created an attachment (id=18357)\nPatch against trunk\n\nI think I got it know. The attached patch should fix your problem. So could you\nplease do the following:\n\n1. Start with clean sources (at least without the debug patch I sent earlier)\n2. Apply the patch for 39266\n3. Apply the attached patch\n4. Compile\n5. Test\n6. Let me know the results :-).
39647	Ruediger Pluem	1148684372000	Created an attachment (id=18358)\nPatch against mod_jk.c (1.3 Version) of mod_jk 1.2.15\n\nApart from the patch against 2.2.x I am pretty much sure that the behaviour of\nthe backend (sending Content-Length and Content-Type for a 304 response) is not\ncompliant with RFC 2616. \n\n10.3.5 in RFC 2616 states:\n\nThe 304 response MUST NOT contain a message-body, and thus is always terminated\nby the first empty line after the header fields.\n\nI read this as Content-Length and Content-Type header MUST NOT be sent with 304\nresponses and the behaviour of httpd 2.2.x and the http connector of Tomcat not\ndoing this seem to support this view.\nFrom my limited point of view on httpd 1.3 this should be fixed inside mod_jk.\nI  think that the attached patch, which is untested due to my lack of an\navailable httpd 1.3, does this without breaking other things.\nSo, if you like you can give the attached patch a try to make your backend RFC\n2616 compliant again :-).
39647	Christopher Shumway	1149012757000	Hi there.  Thanks for your help on this issue.  The patch\nmodules/cache/cache_storage.c seems to do the trick!\n\nI'll try out the patch to mod_jk too.  I agree, it seems like mod_jk is breaking\nRFC 2616, I'll try out the patch on the backend web server and make sure it\ndoesn't break anything else.\n\n
39647	Ruediger Pluem	1149022153000	Committed to trunk as r410370 (http://svn.apache.org/viewvc?rev=410370&view=rev).
39647	Christopher Shumway	1150246738000	FYI I've been running the patch against mod_jk.c for about two weeks now with no\nill effects.\n
39647	Ruediger Pluem	1153919591000	Backported to 2.2.x as r425725 (http://svn.apache.org/viewvc?rev=425725&view=rev).
39647	Mark Nottingham	1171034257000	The resolution to this bug breaks a MUST-level requirement of RFC2616. From <http://www.w3.org/\nProtocols/rfc2616/rfc2616-sec13.html#sec13.5.3>;\n\n[[[\nThe end-to-end headers stored in the cache entry are used for the constructed response, except that\n[...]\n      - any end-to-end headers provided in the 304 or 206 response MUST\n        replace the corresponding headers from the cache entry.\nUnless the cache decides to remove the cache entry, it MUST also replace the end-to-end headers \nstored with the cache entry with corresponding headers received in the incoming response, except for \nWarning headers as described immediately above. If a header field- name in the incoming response \nmatches more than one header in the cache entry, all such old headers MUST be replaced.\n\nIn other words, the set of end-to-end headers received in the incoming response overrides all \ncorresponding end-to-end headers stored with the cache entry (except for stored Warning headers with \nwarn-code 1xx, which are deleted even if not overridden).\n]]]\n\nThe correct resolution was to fix mod_jk, which the reporter said worked for them.\n\nPlease back this patch out.
39647	Ruediger Pluem	1171036521000	I respectfully disagree here. According to 10.3.5 the response must not / should\nnot contain any entity headers (depending on the validator type). Furthermore\n10.3.5 states that this should prevent inconsistencies between the cached entity\nbody and the updated header. Content-type is an entity header and changing the\nContent-type clearly would create inconsistencies between the cached entity body\nand the updated header. So we are generous in what we acccept.\nIf you still disagree please continue this discussion on the\ndev@httpd.apache.org list.
39647	Mark Nottingham	1171056978000	10.3.5 says:\n \n[[[\nIf the conditional GET used a strong cache validator (see section 13.3.3), the response SHOULD NOT \ninclude other entity-headers. Otherwise (i.e., the conditional GET used a weak validator), the response \nMUST NOT include other entity-headers; this prevents inconsistencies between cached entity-bodies \nand updated headers.\n]]]\n\nThat applies to the responses; it doesn't specify the behaviour of the cache when it receives such \nresponses.\n\n10.3.5 goes on to say \n\n[[[\nIf a cache uses a received 304 response to update a cache entry, the cache MUST update the entry to \nreflect any new field values given in the response.\n]]]\n\nHowever, your reading does make sense. Rather than try and second-guess an apparent inconsistency \nin the spec, I'll follow up with the HTTP-WG list.\n
39672	Nick Kew	1148903672000	Fixed in trunk and proposed for backport\nhttp://svn.apache.org/viewvc?view=rev&revision=410079
39710	Paul Querna	1149288757000	Looks like this is caused by the changes in r231167:\nhttp://svn.apache.org/viewvc?view=rev&revision=231167\n\nmod_cgid was not modified to be kept in sync with mod_cgi.  They both have\nnearly the same code path after the ap_scan_script_header_err...
39710	Vincent Jong	1165574843000	*** Bug 37938 has been marked as a duplicate of this bug. ***
39710	Sven Strickroth	1169270014000	this bug is still in 2.2.4, if you have mod_deflate enabled, you get the\ngz-output instead of a text-file
39710	Paul Querna	1170624609000	Created an attachment (id=19513)\ndon't truncate error replies\n
39710	Paul Querna	1170624659000	Attached patch has been running in production since this bug was opened.  If you\nrun into this problem, can you try patching your mod_cgi.c?
39710	Vincent Jong	1170627938000	I can confirm the patch works on Apache2.2.4 with mod_deflate configured as \nwell.
39710	Bob Kline	1176721722000	Anything I can do to help get this bug fixed?  Is testing the patch all that\nstands in the way of getting it folded into the trunk?
39710	Bob Kline	1177572086000	(In reply to comment #7)\n> Anything I can do to help get this bug fixed?  Is testing the patch all that\n> stands in the way of getting it folded into the trunk?\n\nHello?  Anybody home?  What's next?
39710	Nick Kew	1180179066000	*** Bug 42525 has been marked as a duplicate of this bug. ***
39710	Robert Siemer	1180183420000	Why should bug 42525 be a duplicate of this one?\n\nMy setup runs with the Worker MPM, that means with mod_cgid.c. But the patch\nhere touches only mod_cgi.c and so can't possibly change anything in 'my' bug.\n\nNick, could you explain that to me?
39710	Nick Kew	1180187469000	Please don't add other people to an error report!\n\n(In reply to comment #10)\n> Why should bug 42525 be a duplicate of this one?\n\nIt certainly looks like it.  Is your CGI script\n  (a) crashing,\n  (b) generating an error response, or\n  (c) generating a malformed response?\n\n> My setup runs with the Worker MPM, that means with mod_cgid.c. But the patch\n> here touches only mod_cgi.c and so can't possibly change anything in 'my' bug.\n\nwhat does 'httpd -M' tell you?
39710	Robert Siemer	1180189121000	(In reply to comment #11)\n> Please don't add other people to an error report!\n\nI obviously wanted to make sure you get my comment. I assume now that you get\nthese comments otherwise, too. Do you know a smart way how to find that out? -\nWho added me to this bug here?\n\n> (In reply to comment #10)\n> > Why should bug 42525 be a duplicate of this one?\n> \n> It certainly looks like it.  Is your CGI script\n>   (a) crashing,\n>   (b) generating an error response, or\n>   (c) generating a malformed response?\n\nIf you refer to the script I mention in 'my' bug, it prints a 'hello' and exits.\nI think that is what you refer to with (c). - But what is (a) exactly?\n\nI first noticed the problem with a script that should generated a conforming 200\nOK response, but it didn't because of errors in it. You could say it 'crashed',\nbut doing so, it generated a malformed response...\n\n> > My setup runs with the Worker MPM, that means with mod_cgid.c. But the patch\n> > here touches only mod_cgi.c and so can't possibly change anything in 'my' bug.\n> \n> what does 'httpd -M' tell you?\n\nsiemer@polar:~$ /usr/sbin/apache2 -M\nLoaded Modules:\n core_module (static)\n log_config_module (static)\n logio_module (static)\n mpm_worker_module (static)\n http_module (static)\n so_module (static)\n actions_module (shared)\n alias_module (shared)\n auth_basic_module (shared)\n authn_file_module (shared)\n authz_default_module (shared)\n authz_groupfile_module (shared)\n authz_host_module (shared)\n authz_user_module (shared)\n autoindex_module (shared)\n cache_module (shared)\n cgi_module (shared)\n cgid_module (shared)\n dir_module (shared)\n disk_cache_module (shared)\n env_module (shared)\n include_module (shared)\n info_module (shared)\n mime_module (shared)\n negotiation_module (shared)\n rewrite_module (shared)\n setenvif_module (shared)\n speling_module (shared)\n status_module (shared)\n suexec_module (shared)\n userdir_module (shared)\nSyntax OK\n\n\nThe documentation at http://httpd.apache.org/docs/2.2/mod/mod_cgid.html says\nthat a threaded MPM uses mod_cgid. And the server-info handler on my site\nreports the Worker MPM with 'threaded: yes'. - Are there setups that use both!??\n\nRegards
39710	Nick Kew	1180194407000	(In reply to comment #12)\n\n>  cgi_module (shared)\n\nRemove mod_cgi, and I expect your bug will go away.
39710	Robert Siemer	1180198925000	(In reply to comment #13)\n> (In reply to comment #12)\n> \n> >  cgi_module (shared)\n> \n> Remove mod_cgi, and I expect your bug will go away.\n\nI removed the mod_cgi and the bug went away. Thank you, Nick.\n\nThat makes now the link between the mpm and the two cgi(d) modules unclear to\nme. And if loading both modules makes no sense, it could raise an error or\nwarning...\n\nRegards, R
39710	Ruediger Pluem	1180200519000	(In reply to comment #14)\n\n> \n> That makes now the link between the mpm and the two cgi(d) modules unclear to\n\nSee the second paragraph of the summary of \n\nhttp://httpd.apache.org/docs/2.2/en/mod/mod_cgid.html\n\nfor why mod_cgid exists. If forks of multi threaded processes are not expensive\non your OS you can use mod_cgi with a threaded MPM as well (you can even do so\nif they are expensive but then you may pay a huge performance penalty).
39710	Robert Siemer	1180204272000	(In reply to comment #15)\n> ... \n> If forks of multi threaded processes are not expensive\n> on your OS you can use mod_cgi with a threaded MPM as well (you can even do so\n> if they are expensive but then you may pay a huge performance penalty).\n\nWhat I draw out of that:\nyou can use mod_cgid or mod_cgi with whatever MPM. And the one you load first\ngets used.\n\nThat opens a new question: Why says the doc '[mod_cgid] is used by default\ninstead of mod_cgi whenever a multi-threaded MPM is selected' when there is no\nsuch default?\n
39722	Will Rowe	1149549983000	Just a footnote that we need to determine if the fault occurs in apr, or as\na result of a bad call to apr.
39722	Adrian Buckley	1193478177000	I have traced this to line 1176 in server/core.c:\n\n    arg = ap_server_root_relative(cmd->pool, arg);\n\nwhich returns a NULL if a directory does not exist.\n\nWhen line 1178 in server/core.c is reached, this NULL is passed to\nap_is_directory as a parameter:\n\n    if (apr_filepath_merge((char**)&conf->ap_document_root, NULL, arg,\n                           APR_FILEPATH_TRUENAME, cmd->pool) != APR_SUCCESS\n        || !ap_is_directory(cmd->pool, arg)) {\n\nwhich causes the crash.
39722	Nick Kew	1193485913000	Looks convincing to me.  Committing an additional check - r589177.  Thanks for\nthe diagnosis.fix possible crash at startup in case of nonexistent DocumentRoot.
39722	Nick Kew	1193638921000	Fixed in r589618
39726	Jason Lingohr	1149575264000	(In reply to comment #0)\n> In the first paragraph of 'A Brief Guide to Conditional Requests' appears\n> 'Aoache' instead of 'Apache'.\n\nThanks for this, change has been committed.\n
39727	Nick Kew	1149554613000	Created an attachment (id=18407)\npatch that'll cause mod_filter to unset the etag - see util_filter.h\n\nThis needs more discussion before committing this or any other patch.
39727	Henrik Nordstrom	1149583882000	Some references\n\nMy ETag notes:  http://devel.squid-cache.org/\n\nOld dev discussions:\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200311.mbox/%3C3FB2E075.5010705@modperlcookbook.org%3E\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200311.mbox/%3C3FB2C0CB.30401@sun.com%3E\nhttp://mail-archives.apache.org/mod_mbox/httpd-dev/200206.mbox/%3C00b801c20daf$736dd190$c000000a@KOJ%3E
39727	Ruediger Pluem	1149626959000	(In reply to comment #1)\n> Created an attachment (id=18407) [edit]\n> patch that'll cause mod_filter to unset the etag - see util_filter.h\n> \n> This needs more discussion before committing this or any other patch.\n\nSorry for my confusion, but this will only work if mod_deflate is used via\nmod_filter, right?\nIt will not work if mod_deflate is used without mod_filter. I guess for this\ncase it is needed to unset the ETag header inside mod_deflate. So something like\nthe following:\n\nIndex: mod_deflate.c\n===================================================================\n--- mod_deflate.c       (Revision 411469)\n+++ mod_deflate.c       (Arbeitskopie)\n@@ -389,6 +389,7 @@\n             apr_table_mergen(r->headers_out, 'Content-Encoding', 'gzip');\n         }\n         apr_table_unset(r->headers_out, 'Content-Length');\n+        apr_table_unset(r->headers_out, 'ETag');\n\n         /* initialize deflate output buffer */\n         ctx->stream.next_out = ctx->buffer;
39727	Nick Kew	1149630029000	(In reply to comment #3)\n\n> Sorry for my confusion, but this will only work if mod_deflate is used via\n> mod_filter, right?\n\nYes.  I mentioned that to the reporter in IRC, but not here,\n\n>          apr_table_unset(r->headers_out, 'Content-Length');\n> +        apr_table_unset(r->headers_out, 'ETag');\n\nUgh.  That way every filter has to reinvent protocol handling.  A fertile \nbreeding ground for bugs (and we have a history to prove it).  mod_filter is \ndesigned to centralise that, so we only need to get the protocol right once.
39727	Ruediger Pluem	1149631331000	(In reply to comment #4)\n> >          apr_table_unset(r->headers_out, 'Content-Length');\n> > +        apr_table_unset(r->headers_out, 'ETag');\n> \n> Ugh.  That way every filter has to reinvent protocol handling.  A fertile \n> breeding ground for bugs (and we have a history to prove it).  mod_filter is\n\nYes, and I am pretty sure we have this history :-), BUT mod_filter is not\nmandatory to use.\n \n> designed to centralise that, so we only need to get the protocol right once.\n\nAgreed, but then we must make the use of mod_filter (or at least the usage of\nthese parts) mandatory or must incorporate them into the core filter routines.
39727	Henrik Nordstrom	1149652673000	From a protocol perspective removing the ETag is sufficient to make you\ncompliant. If conditionals (If-xxx) anyway doesn't work right on transformed\nresponses there is not much benefit of sending an ETag out.\n\nBut if you can it's better if you send an ETag. As I said initially you don't\nneed  to compute a new etag, just adding some extra detail to the tag is fine.\n\nI.e. '638f3e-6-1b6d6340-gzip' or similar for a gzip:ed entity where the base\nentity had the etag '638f3e-6-1b6d6340'.  To HTTP the etag is just a string with\nthe only requirement that it must be unique for each entity variants of the same\nURL.\n\nActually I think adding details to the ETag may simplify many things for you as\nthe core routines then can make quick asssssments of conditionals if it's\npossible to infer information about how the object had been processed from\nlooking at the entity tag.
39727	Henrik Nordstrom	1163985079000	Any progress on getting this patch (or another reasonable alternative) into the\nmod_deflate tree?
39727	Nick Kew	1163985799000	(In reply to comment #7)\n> Any progress on getting this patch (or another reasonable alternative) into the\n> mod_deflate tree?\n\nIt needs raising on dev@ so we can reach a consensus solution.  Bugzilla has only proved that we have \nmore than one competing solution.
39727	Roy T. Fielding	1165422613000	This needs to be fixed by mod_deflate producing a new etag.  How we do that\nis going to take some investigation, since it doesn't do any good to produce\nthe etag unless we can also check it on conditional requests.\n
39727	Henrik Nordstrom	1165501156000	My suggestion is to simply extend the existing etag with a gzip marker, for\nexample adding ;gzip at the end or something like that.\n\nI.e. if the original reply had\n\nETag: '6bf1f7-6-1b6d6340'\n\nThen make mod-gzip translate this to\n\nETag: '6bf1f7-6-1b6d6340;gzip'\n\nThis should allows for easy bidirectional mapping, simplifying most conditionals\nas no transformation of the entity body is needed to find the etag, and the\nsimple format makes it easier to trace should any misunderstandings occur.
39727	Henrik Nordstrom	1188192352000	Pinging dev@ one more time..
39727	Nick Kew	1191300742000	Just committed a fix to make any ETag weak if we transform the entity. \nHopefully this should fix protocol compliance (and our users) without being\ncontroversial.\n
39727	Henrik Nordstrom	1191324650000	Not sufficient. The two versions is not semantically equivalen as one can not be\nexchanged for the other without breaking the protocol. In the context of\nIf-None-Match the weak comparator is used in HTTP and there a strong ETag is\nequal to a weak ETag.
39727	Ruediger Pluem	1191325912000	Can you elaborate in more detail why you think that the two versions are not\nsemantically equivalent? I read 13.3.3 in a way that they are.
39727	Henrik Nordstrom	1191327736000	Because you can not exchange the gzip:ed variant with the identity encoded\nvariant wihout causing breakage. The two do not mean the same thing to a\nrecipient who do not know how to handle gzip.\n\nThe two is only semantically equivalent for a recipient capable of handling\ngzip, but not to HTTP in general as HTTP do not guarantee clients can handle gzip.\n\nIf they were semantically equivalent then there would be no need for conditional\nmod_gzip compression, or the use of Vary, at least not other than to reduce the\nload on the server under peak load...
39727	Henrik Nordstrom	1191328237000	What you can do is to either\n\na) Drop the ETag completely. This is not opimal but works..\n\nb) Or modify the ETag value in some manner. For example adding a constant string\ninfront or after the original ETag.\n\nIn 'b', if the compression is not deterministic and always resulting in the same\nencoding then the ETag should additionally be made weak, to make sure no one\nattemtps merging partial responses down the line..\n\n\n\nThe main downside of 'a' is that ETag aware caches will then cache multiple\ncopies of the same object, one per each slight varance of Vary indicated\nheaders. For Apache itself it's not so big difference until conditional requests\nworks proper in precense of filters like mod_deflate (i.e. If-None-Match).
39727	Nick Kew	1191329698000	(In reply to comment #15)\n> Because you can not exchange the gzip:ed variant with the identity encoded\n> variant wihout causing breakage. The two do not mean the same thing to a\n> recipient who do not know how to handle gzip.\n\nBugzilla is the wrong place for this discussion.  Should be on dev@httpd.\n\nOnly a recipient that can handle gzip will be served the gzipped version.\n\n> The two is only semantically equivalent for a recipient capable of handling\n> gzip, but not to HTTP in general as HTTP do not guarantee clients can handle gzip.\n\nHTTP provides a separate mechanism for negotiating that.\n\n> \n> If they were semantically equivalent then there would be no need for conditional\n> mod_gzip compression, or the use of Vary, at least not other than to reduce the\n> load on the server under peak load...\n\nHuh?  Those exist precisely because we need to cater for different clients.
39727	Henrik Nordstrom	1191337837000	(In reply to comment #17)\n\n> Only a recipient that can handle gzip will be served the gzipped version.\n\nWhich isn't true due to this bug. If there is a ETag aware cache between the\nclient and Apache the client will be given whatever the previous client could\nhandle.\n\n> Huh?  Those exist precisely because we need to cater for different clients.\n\nExactly.
39727	Nick Kew	1191388730000	(In reply to comment #18)\n> (In reply to comment #17)\n> \n> > Only a recipient that can handle gzip will be served the gzipped version.\n> \n> Which isn't true due to this bug. If there is a ETag aware cache between the\n> client and Apache the client will be given whatever the previous client could\n> handle.\n\nThe intermediate got a weak ETag.  So the intermediate has been told that the\nentity is equivalent but not byte-by-byte identical, and may be subject to\nnegotiated transformation.  Therefore the intermediate is responsible for\ndealing with content-negotiated properties.\n\nDo you have a particular intermediate in mind, when you propose something that\ntreats a weak ETag as strong?
39727	Takashi Sato	1200734959000	2.2 r608849\nhttp://svn.apache.org/viewvc?view=rev&revision=608849
39727	Takashi Sato	1204087752000	http://svn.apache.org/viewvc?view=rev&revision=581198\nhttp://svn.apache.org/viewvc?view=rev&revision=607219
39761	Nick Kew	1149851771000	Good catch!  It's all working to spec, but just giving you a misleading error \nmessage when you've forgotten to configure DBDriver.\n\nJust fixed: http://svn.apache.org/viewvc?view=rev&revision=413015
39806	Brian	1150234399000	Created an attachment (id=18457)\npatch\n\nquick patch to add env vars to mod_proxy_balancer
39806	Jeff Trawick	1150289481000	Nice tool.\n\nIf you want to log this, use %{BALANCER_foo}e in the access log.  I don't see\nthe need for the debug-level error log messages.  Other opinions from the crowd?
39806	Brian	1150312462000	Created an attachment (id=18467)\nmod_proxy_balancer-trunk.patch\n\nCleaned up patch, added patch to docs, against trunk.
39806	Brian	1150312603000	Created an attachment (id=18468)\nmod_proxy_balancer-trunk.patch\n\nLet's try that again w/o the tab characters ;)
39806	Brian	1150312774000	ok, removed the debug stuff (not needed).  I also went against trunk and added a\npatch to the docs as well.
39806	Ruediger Pluem	1151341746000	Committed to trunk as r417238\n(http://svn.apache.org/viewvc?rev=417238&view=rev). Thanks.
39843	Brian	1150818624000	heh, and before I get corrected on this, I meant to type:\n  RewriteRule ^baz/(.*) bar/$1 [R,L]\nnot \n  RewriteRule ^baz/(.*) /bar/$1 [R,L]\n\nso that it redirects from /foo/baz to /foo/bar.  But, that does not really\nmatter for the issue at hand.
39843	Joshua Slive	1150835875000	Where do you see docs implying the prefix will be stripped?\n\nIn general, using mod_rewrite directives inside <Location> is almost never\nnecessary and can produce unpredictable results.  It should probably just be\ndocumented as unsupported.
39843	Brian	1150837248000	I agree, not that useful really.  But it *is* documented to work in mod_rewrite\ndocs.\n\nhttp://httpd.apache.org/docs/2.2/mod/mod_rewrite.html#rewriterule\n\nAlong with many examples at the end of RewriteRule section, there is also a note\nstating:\n\n'Note: Pattern matching in per-directory context\n\nNever forget that Pattern is applied to a complete URL in per-server\nconfiguration files. However, in per-directory configuration files, the\nper-directory prefix (which always is the same for a specific directory) is\nautomatically removed for the pattern matching and automatically added after the\nsubstitution has been done. This feature is essential for many sorts of\nrewriting - without this, you would always have to match the parent directory,\nwhich is not always possible.\n\nThere is one exception: If a substitution string starts with ""http://'', then\nthe directory prefix will not be added ,and an external redirect (or proxy\nthroughput, if using flag P) is forced!'\n\n\n
39843	Brian	1150837405000	Aslo note that that note states *one* exception, but the examples show that it\nis only added back if there is no leading '/'.  So, the exception is actually\nthe rule in most cases.
39843	Joshua Slive	1150898336000	There's your confusion: When the docs refer to per-directory configuration, they\nmean <Directory> sections and .htaccess files, not <Location> sections.\n\nUnless someone can see a good reason for using RewriteRule in <Location>, I'll\nchange this to a doc bug and suggest just noting that it is unsupported.
39843	Joshua Slive	1151694314000	I've now clarified this somewhat in the docs.
39854	Nick Kew	1150931799000	Fixed in trunk: revision 416165
39854	Ruediger Pluem	1156765889000	Proposed a patch for backport as r437674\n(http://svn.apache.org/viewvc?rev=437674&view=rev).
39854	Ruediger Pluem	1166536038000	Backported to 2.2.x as r488817 (http://svn.apache.org/viewvc?rev=488817&view=rev).
39915	Andrew Pimlott	1151471547000	Oh, server.cert is just a dummy self-signed cert plus key.  For ease of\nreproducing, here it is:\n\n-----BEGIN RSA PRIVATE KEY-----\nMIICXwIBAAKBgQCsxmVAUyU3wCtyCE75p2imqRkv2t43Nw6jTe+me2sCAUYoE+ls\nn39/WnUGk299Yg30W1DQDixD1Q15Kv9qlvL+2FylQqH3teS21MDjWYWi2zwS/u53\nShhrUkKJ98Oj1Cqo26wijLCA3+eEpQO+ydj0uk+m2We4HkNnWXAyOq+OGQIDAQAB\nAoGBAIUOeRVzstrfhNXZ7jA3q9GFsp73GGE/Zmd/csssivlNT+E3jHGZ18+VM0Cw\nNJFD/WktFexUreRDZI/m/DLzMwip4Cq3ySkzIXsOAaMOtz9KGET/K9LcRpYh1byO\nFCV+z+43L7Q+Uh8TeKe/Hj+Sh9kA79JamYPtcMKUfUeBbWB9AkEA3hYrwBUf5/xP\npWwc17YtChAox1e/hCE07rAiW5CxtJNI4z2QEFysISGBtFzHSaiIFQEhrJnOI+9p\nMYLtyP/ACwJBAMcoh8NdFUIDNsC7o8QBonS48UPqRwcKPH0bKj4HmcvFTb7P2aIw\nknAqY71Lx65UOfr8z3NRqtLojEDAQF4VTOsCQQDZ4nSP4enIpsDZMaVmeMPdUJdB\nY7RwhEezOTisDtxZpfpnf1mcw97YLlBbTH70pBTGTrLj7I3SsarJuYNipI+bAkEA\nvSnaCc3X6yNyVg3jtsB2tbcUMhXL8PvgCFRNAy3k/o8hESQK6uqHrNIWei4IM6T8\njVCjGj1vq3QGA1qXyMUikQJBAMn5Yj6xh2piPSEvfFifLlerpqNbrKrhMov1oTWN\nboMMQpjW3tnXiqd04nTXjQCxN+4CWNcIdCfuO4OqCfQ5Lrs=\n-----END RSA PRIVATE KEY-----\n-----BEGIN CERTIFICATE-----\nMIICJTCCAY4CCQDEZpgxQTJ07DANBgkqhkiG9w0BAQUFADBXMQswCQYDVQQGEwJV\nUzETMBEGA1UECBMKQ2FsaWZvcm5pYTERMA8GA1UEBxMITW9udGVyZXkxDzANBgNV\nBAoTBkFuZHJldzEPMA0GA1UEAxMGQW5kcmV3MB4XDTA2MDYyODA0NDUxMFoXDTA2\nMDcyODA0NDUxMFowVzELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWEx\nETAPBgNVBAcTCE1vbnRlcmV5MQ8wDQYDVQQKEwZBbmRyZXcxDzANBgNVBAMTBkFu\nZHJldzCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEArMZlQFMlN8ArcghO+ado\npqkZL9reNzcOo03vpntrAgFGKBPpbJ9/f1p1BpNvfWIN9FtQ0A4sQ9UNeSr/apby\n/thcpUKh97XkttTA41mFots8Ev7ud0oYa1JCiffDo9QqqNusIoywgN/nhKUDvsnY\n9LpPptlnuB5DZ1lwMjqvjhkCAwEAATANBgkqhkiG9w0BAQUFAAOBgQCKe9Mjaeut\nlA6cM6vxhfOsbtc1L1Lz2fA3arXM9dv15jAQGpCDAPzC81ortnQpfohJv1wymIN4\nVSDjmbsZi4R6AqK5Pjh/JoCKppdtHmBUaA2EFAkld9CDJAa02vfQAQfupqurN9zf\nA+kd+smwWefqu0Ea/I6WAX6wad7omNiKBQ==\n-----END CERTIFICATE-----\n\nYou should be able to run my config (from the initial report) with something like\n\napache2 -X -d $PWD -f httpd.conf\n\nif you put the config in httpd.conf and the cert in server.cert in the same\ndirectory.  You'll have to create a few other files, but you're smart, you'll\nfigure it out.
39915	Joe Orton	1151480103000	Can you get a backtrace?\n\ngdb /path/to/httpd\n...\n(gdb) run -X\n...\n(gdb) bt\n
39915	Andrew Pimlott	1151512751000	Hmm, I didn't realize I'd get a reasonable backtrace without recompiling\neverything with debugging.  Here it is:\n\n#0  0xa7e19c61 in CRYPTO_add_lock () from /usr/lib/i686/cmov/libcrypto.so.0.9.8\n#1  0xa7e9dcae in X509_INFO_free () from /usr/lib/i686/cmov/libcrypto.so.0.9.8\n#2  0xa7e83660 in sk_pop_free () from /usr/lib/i686/cmov/libcrypto.so.0.9.8\n#3  0xa7989008 in ssl_init_ModuleKill () from /home/andrew/u/modules/mod_ssl.so\n#4  0xa7c7ee4d in apr_pool_tag () from /usr/lib/libapr-0.so.0\n#5  0xa7c7fd27 in apr_pool_clear () from /usr/lib/libapr-0.so.0\n#6  0x0807e64d in main ()
39915	Joe Orton	1151574644000	That doesn't ring any bells.  What version of OpenSSL, what distribution? Is\nthis reproducible with 2.2.2?  What is the error_log output with 'LogLevel debug'?
39915	Joe Orton	1151575016000	Never mind, I can reproduce this.
39915	Joe Orton	1151577246000	Fixed on the trunk:\n\n  http://svn.apache.org/viewvc?view=rev&revision=417988\n\nand will propose for 2.2.x.  Thanks for the report.\n
39915	Andrew Pimlott	1151611398000	Thanks so much for figuring this out.  Sorry for forgetting all my version\ndetails; somehow the mind just goes when filing bug reports.
39939	Nick Kew	1151682508000	Fixed in svn - should appear on site soon - thanks.
39992	Darryl Miles	1152350016000	Created an attachment (id=18576)\nTrivial patch\n
39992	Ruediger Pluem	1152462363000	Apart from the fact that you attached the reverse patch :-), I committed it to\nthe  trunk as r420307 (http://svn.apache.org/viewvc?rev=420307&view=rev).
40004	PFudd	1152574882000	These rules are inside a <Directory /var/www/html/db> section, if that helps.
40004	Andr?? Malo	1152596641000	Yes. That was obvious from the description and the rewrite log. ;-)\n\nThe [L] flag works as expected (finishing the Ruleset). What you probably didn't\nexpect was that the internal redirect finds the whole ruleset again and again.\nThat's a different issue and a side effect of RewriteRules in the directory context.\n\n-> invalid.
40004	PFudd	1152633851000	Well, as my teacher used to say, it's either a bug in the program or a bug in\nthe documentation.  This behaviour isn't documented; who do I send requests like\nthis to?\n\nThanks!
40004	PFudd	1152639009000	If someone updates the RewriteEngine documentation, some of the points from\nhttp://www.sitepoint.com/print/mod_rewrite-no-endless-loops would be good to\ninclude.
40004	Andr?? Malo	1152689998000	It's kinda documented, but too implicit and so quite bad. The place for such\nrequests is here ;)\nYou can also place patches here or enter the docs list\n(http://httpd.apache.org/docs-project/) :-)
40004	Penelope Fudd	1152690456000	I'd love to supply a patch, but I don't know enough about what's going on to\nwrite one for this.  I'd be supplying some 'G' for the GIGO process.
40004	Rich Bowen	1152701263000	The new rewrite flags documentation (httpd.apache.org/docs/rewrite/flags.html)\nwill be providing more detail on things like this. I'll be certain to cover this\nparticular annoyance there. Thanks for the reminder.
40004	PFudd	1152723454000	The more I think about it, the more I think this is a misfeature.  If '[L]'\ndoesn't stop further rewriting (in directory rules), then it doesn't serve a\npurpose (in directory rules).  Is there a workaround?
40004	Bob Ionescu	1152787291000	(In reply to comment #8)\n> The more I think about it, the more I think this is a misfeature.  If '[L]'\n> doesn't stop further rewriting (in directory rules), then it doesn't serve a\n> purpose (in directory rules).\n\nWell, as  Andr?? said, it stops processing in that round of processing. The\ninternal redirect is nearly a new request (well, not everything is being\nre-processed). The L-Flag is usefull in per-dir context, just think about 20\nrules and the first did match. With out the L-flag everything below would be\ntested in that round of processing, too. That saves processing. I don't think\nthat writing something like 'don't apply rewrite rules any more' into\nrequest_rec is a solution, think about the situation rewriting /a to /b while\nthere are rewriteRules in palce fpr <directory /var/www/b>.\n\n> Is there a workaround?\n\nEither use THE_REQUEST or ENV:REDIRECT_STATUS\n\n    RewriteBase /db/\n    RewriteRule ^experiment-1 experiment-2 [L]\n    RewriteCond %{ENV:REDIRECT_STATUS} =''\n    RewriteRule ^experiment-2 experiment-3\n\nor\n\n    RewriteBase /db/\n    RewriteRule ^experiment-1 experiment-2 [L]\n    RewriteCond %{THE_REQUEST} experiment-2\n    RewriteRule ^experiment-2 experiment-3\n\n> The new rewrite flags documentation (httpd.apache.org/docs/rewrite/flags.html)\n\nThere is a small mistake:\nRewriteRule %{REQUEST_URI} /.(png|gif|jpg) - [E=image:1]\n\nshould be\n\nRewriteRule /.(png|gif|jpg) - [E=image:1]
40004	Rich Bowen	1185352777000	(In reply to comment #9)\n\n> There is a small mistake:\n> RewriteRule %{REQUEST_URI} /.(png|gif|jpg) - [E=image:1]\n> \n> should be\n> \n> RewriteRule /.(png|gif|jpg) - [E=image:1]\n\nThanks. Fixed in r559494 in trunk. Will fix in 2.2 also.
40004	Joshua Slive	1185968978000	Fixed on trunk to note the reinjection possibility in the docs for the L flag.
40030	Joshua Slive	1153540684000	As the <Limit> directive doc says, HEAD is implied by GET.\n\nI'm neutral about POST.  Being more restrictive in the examples is usually\nbetter than less restrictive.
40030	Darryl Miles	1153562318000	If I may clarify my thoughts.\n\nSomeone adding DAV to their website wants to restricts the additional DAV\noperations but retain the existing web-application operations, so their\nweb-application continues to work like it did before.\n\nIf they wanted to restrict the POST operation they would already have configured\na rule for that outside of the additional configuration required for DAV.\n\n\nAre you saying that DAV utilizes the POST method for any operation and in doing\nso that optation may modify data or expose extra data to an anonymous website\nuser; that the anonymous website user wouldn't be able to have done otherwise.\n\nSo summarize that question 'Can a privilege escalation via the POST method occur\nfor an anonymous website user ?'\n\nWhen I audited the example configuration changes myself by researching into the\ncommands I was adding this exact concern immediatly came to mind.  After 5 mins\nlooking over the code for what DAV does via the POST method I could not see any\nactive component.\n\nI'm trying to spare someone else less technical than me this headache that the\nsuggestion of <LimitExcept GET OPTIONS> implies, in that DAV maybe unsafe for\nany website utilizing the POST method for its everyday operations so we dont\nrecommend <LimitExcept GET OPTIONS POST>.\n\n\nPoint taken on the HEAD issue but again <LimitExcept GET HEAD OPTIONS POST> is\nmuch clearer to understand than <LimitExcept GET OPTIONS POST>, it means I dont\nhave the headache of finding out why HEAD wasn't included.  If they are equal\nand one way is clearer than the other, use the clearer way in the documentation.\n\nIs your neurtal stance due to being unsure of the effects of DAV+POST ?  Maybe a\nDAV guru will notice this and contribute their wizdom.  I'm now thinking if\nthere are side effects these should be documented.  Either way I'm just trying\nto remove the concern that a potential user may get after reading the current\ndocumentation.\n
40030	Joshua Slive	1153679958000	I don't have any objection to adding POST.  In general, people should only open\nup the methods they use, which frequently will not include POST.  But I agree\nwith you that in the context of DAV, it may make sense to address the methods\nthat are not affected by 'Dav On'.\n\nI would certainly object to adding HEAD.  It would lead to people thinking they\ncould restrict HEAD and GET independently, resulting in more confusion, not\nless.   In fact, the server should probably issue a warning if HEAD is present\nin a <Limit(except)>. 
40030	Darryl Miles	1153746617000	Understood your objections noted.\n\nHow abouts adding a comment line above the LimitExcept clause:\n\n...\n# HEAD not required explicitly, GET implies HEAD\n<LimitExcept GET OPTIONS POST>\n...\n\nThat would make things very clear and keep us both happy.
40030	Joshua Slive	1156266364000	I've added POST to the trunk version of the docs.  It is unlikely to get\nbackported, so it won't be seen in a release for a while.  Thanks for your\nsuggestion.
40046	Bob Ionescu	1152918021000	And how does your RewriteRule with the corresponding RewriteLog with loglevel 5\nlook like?
40046	Ian Abel	1153123914000	This is not determined from any rewrite rule that i can post but from this code \nsnippet from the latest release of apache 2.2.2. \nhttpd-2.2.2/modules/mappers/mod_rewrite.c , line 3939 and following\n            if (p->flags & RULEFLAG_PASSTHROUGH) {\n                rewritelog((r, 2, perdir, 'forcing '%s' to get passed through '\n                           'to next API URI-to-filename handler', r->filename));\n                r->filename = apr_pstrcat(r->pool, 'passthrough:',\n                                         r->filename, NULL);\n                changed = ACTION_NORMAL;\n                break;\n            }\n\nThe break statement causes the loop over rewrite rules to be exited from. A \nrewrite rule that exhibits this behaviour is for example:\n\nRewriteCond %{QUERY_STRING}  !moose=1\nRewriteRule /(.*) /$1?moose=0 [PT,QSA]\n\nRewriteRule /(.*) /$1 [E=TEST:1]\n\nWhich doesn't result in TEST being set if moose=1 is not present in the query \nstring. This is non-documented non-obvious behaviour. (Yes there are many other \nways of rewriting the rules to avoid this, if you consider this behaviour to be \ncorrect / to spec, please document it).
40046	Ruediger Pluem	1153131552000	I think the behaviour is correct, but of course this should be documented. So I\nchange the component to Documentation.
40046	Samuli K	1166674039000	This behavior bit me, too. Working around it resulted in a somewhat ugly\nsolution. Perhaps add an option that disables the current [L]-like behavior. And\nobviously, this needs to be documented.
40046	Joshua Slive	1185885903000	The fact that PT implies L has been documented on trunk.
40051	Jess Holle	1152918345000	By the way, this bug has been reproduced on both Windows and Linux, though we\ndidn't manage to capture the stack on Windows.
40051	Justin Erenkrantz	1153376198000	Isn't the problem that you have the provider alias being aliased to itself?\n\nYou can't do that: pick another name for the first alias besides 'ldap'.  The\ncode may technically permit it, but I expect that's the root cause as they share\nthe same provider namespace and if you get into a recursive definition, funny\nthings may happen.
40051	Andy Wang	1153433927000	Ahh.\nI guess the documentation for mod_auth_alias wasn't very clear as to what the\nbaseProvider and aliasName were referring to.\n\nThis makes sense.  Seems rather ugly that such a misconfiguration could cause\napache to go into an endless loop.\n\nBut, at least now we know how to make this do the right thing.\nThanks.
40051	Brad Nicholes	1153780742000	Created an attachment (id=18636)\nAdd a check to make sure that the base provider and the alias names are\ndifferent and also that the alias has not been registered before\n\nThis patch as been checked into trunk and proposed for backport
40051	Ruediger Pluem	1153923985000	Backported to 2.2.x as r425740 (http://svn.apache.org/viewvc?rev=425740&view=rev).
40064	Joe Orton	1153233717000	Changing etag_ulong_to_hex() to use an apr_uint64_t and dropping the casts would\nbe a better fix, I think.
40064	Paul Querna	1153328934000	Either way, I've ran into this myself before.  Don't suppose anyone wants to\nwrite a patch :) ?
40064	Joe Orton	1153760434000	Created an attachment (id=18635)\npatch to use apr_uint64_t for etags\n\nHere's a quick patch to always use 64-bit integers in etag generation.\tTested\nonly to compile and produce etags on x86_64, not tried a 32-bit platform or\nanything more thorough.
40064	Joe Orton	1164959773000	*** Bug 41095 has been marked as a duplicate of this bug. ***
40064	Joe Orton	1173687352000	Committed: http://svn.apache.org/viewvc?view=rev&rev=517238 - thanks for the report.\n\nI'm not sure whether it would be a good idea to merge this into 2.2.x; it could\nbreak working 32-bit-only shops by having different 2.2.x releases generate\ndifferent etags across a server farm.
40064	Joe Orton	1188536168000	Note that the patch attached here was incomplete; the subsequent fix is also needed:\n\nhttp://svn.apache.org/viewvc?view=rev&rev=517654
40064	Ruediger Pluem	1197104525000	Backported to 2.2.x as r602503 (http://svn.apache.org/viewvc?rev=602503&view=rev).
40137	Will Rowe	1198273894000	shortcuts can be trivially deleted, and when you give someone the option\nto 'exit' the taskbar app, they need a way to get back in.
40137	Olaf van der Spek	1198292791000	> they need a way to get back in.\n\nYes, but there's no reason for that shortcut to be in the startup group.\nA regular shortcut would work fine for that.
40137	Will Rowe	1198321700000	Now we're talking, you suggest promoting into the regular Apache shortcut group,\ninstead of nesting in the control subgroup, right?\n\nI'll tweak that for 2.2.7, thanks for the suggestion.  Actually I had trouble\nfinding it burried in there when I fixed it (the shortcut had been broken for\na release or two).
40137	Olaf van der Spek	1198323143000	No, I mean the Instance Manager, that sits in the tray. A shortcut for it used\nto be installed in the Startup dir of the start menu, such that it got started\nautomatically after each login. However, I just did a fresh install of 2.2.6 and\ncan't find any shortcut to the instance manager.
40137	Will Rowe	1198326979000	'I just did a fresh install of 2.2.6 and can't find any shortcut to the instance\nmanager.'\n\nThose are called taskbar icon applications, and the shortcut to it was\nbroken in 2.2.6 and sometime earlier (I mentioned it was broken).\n\nI've restored it, and placed it under the Apache HTTP Server 2.2.7 shortcut\ngroup instead of burring it under Apache HTTP Server 2.2.7 -> Control Services.\n
40137	Olaf van der Spek	1198327119000	> Those are called taskbar icon applications,\n\nAFAIK the icons are in the (system) tray.\n\n> I've restored it, and placed it under the Apache HTTP Server 2.2.7 shortcut\ngroup instead of burring it under Apache HTTP Server 2.2.7 -> Control Services.\n\nDoes that mean it doesn't start automatically anymore?
40137	Will Rowe	1198328062000	Ok - so to clarify, all the shortcuts were broken, you would see the\napachemonitor upon installation, and never after.\n\nI totally agree that such can be annoying.  This is why the startup group \nis chosen over the HKxx/Software/Microsoft/Windows/CurrentVersion/Run,\nwhich is much more insidious.\n\nIt will again create these shortcuts.  However, it is not a 'key' resource.\nIf you remove this shortcut, the installer should not believe the package\nhas been broken.  Since this is certainly not a common request, but a very\nminority opinion, we'll leave things be.\n
40137	Will Rowe	1198338747000	Decided you are right in that the ApacheMonitor is a seperate element of the\npackage...\n\ncustom install will let you optionally omit this in 2.2.7 - entirely (none\nof the shortcuts that bothered you, and no ApacheMonitor.exe either).
40137	Olaf van der Spek	1198338944000	Thanks. Still wondering though, what's the advantage of Apache Monitor compared\nto the standard Windows Services interface?
40137	Will Rowe	1198404096000	Very little difference if you are conversant with the SCM (service control\nmanager), although it lets you watch multiple machines at once.  Because\nsome users are 'starting out', it's a handy tool (I use it often to manage\nsome 15 test installations of various flavors of httpd in development.)\n\nI sort of disagree with it's 'coloring scheme' (I think one dead 'automatic'\nservice is too many, while a dead 'manual' service is never bad), and it's\njust a little slow on the uptake about reporting services in transition (it\nwon't tell you as clearly about starting/stopping).\n\nIn full-view mode it provides some extra context about problems starting the\nservice, which is handy.\n\nI should finally point out that with this change, it's actually possible to\ninstall /only/ the ApacheMonitor (although why someone needs to do this is\nsort of beyond me ;-)
40299	Dave Hodder	1156278035000	Created an attachment (id=18743)\nmime.types patch\n
40299	Sierk Bornemann	1171304459000	When does this bug get fixed in Apache?\nPlease let make the patch proposed above into the trunk as soon as possible.\nAll major browser vendors (except Microsoft) did do their homework and did\nadjust the new MIMEType for JavaScript/ECMAScript.
40299	Roy T. Fielding	1188472282000	The extension .es conflicts with existing language extension for Spanish.\nWe will use .ecma instead.
40299	Sierk Bornemann	1199528107000	(In reply to comment #3)\n> The extension .es conflicts with existing language extension for Spanish.\n> We will use .ecma instead.\n\nThe extension .pl for perl files also conflicts with existing file extension for\npolish, .pl. Other existing conflicts may exist. We deal with such conflicts\nsince years...\n\nMy question is: why does this conflict seem to be a problem *now*, but the other\nexisting conflicts (e.g. .pl file extension vs. polish language extension)\ndon't? Why using .ecma instead of the RFC-proposed .es and leave the other\nconflicts untouched?\n\nIs there a possibility to let check apache, if the last file extension is one\nfor content negotiation or the 'normal' file extension? If such a possibility\ntheoretically exists or could exist, I propose, it should be implemented into\napache to avoid such conflict situations in the future. What's your opinion\nabout that issue?\n\n
40299	Sierk Bornemann	1201592601000	Reopened this bug to get an answer to comment #4.
40299	Joshua Slive	1201599787000	You ask why new conflicts are problems but not existing ones.\n\nThe other conflicts are problems too. But when you have a conflict you need to\nmake a decision about which type wins. Absent a very compelling argument\notherwise, it is clear that an existing type/language should win out over a new\none to prevent breaking sites that rely on the existing extension.\n\nA very compelling argument would be, for example, concrete evidence showing that\n.es is very-widely used for your type and almost never used for the language.
40310	Ian Abel	1156436269000	Created an attachment (id=18750)\nPatch that attempts to fix the bug\n\nThis patch _should_, if my understanding of the bug is correct , fix it.\n
40310	Ruediger Pluem	1156449169000	Well spotted! Committed to trunk as r434483\n(http://svn.apache.org/viewvc?view=rev&revision=434483). Thanks for the patch.
40310	Ruediger Pluem	1156449511000	Proposed for backport to 2.2.x as r434488\nhttp://svn.apache.org/viewvc?view=rev&revision=434488).
40310	Russell Hatfield	1167907954000	I'd like to add that in our shop we witnessed this exact same problem with\nApache 2.2.3 and mod_jk 1.2.19, not mod_proxy_ajp.  Will the fix being applied\ncure this problem when using mod_jk or is a seperate patch going to be applied\nto that module as well?\n\nThanks.
40310	Ruediger Pluem	1167910834000	No this will not cure mod_jk. Bugs for mod_jk should not be further handled in\nthis report. Please open a new report with Product: Tomcat 5 and Component:\nNative:JK.\nBTW: The fix for the original bug will be part of 2.2.4 as it has been backported.
40310	jfclere	1174131898000	The problem is still not fixed correctly in 2.2.4 (the worker is marked errored\nand connection retried but that is wrong):\n+++\nFri Mar 16 08:27:06 2007] [error] [client 71.140.198.6] proxy: error processing\nbody, referer: https://xxx.yyy.zzz/site/checkout/ship_method.html\n[Fri Mar 16 08:27:06 2007] [error] proxy: got bad response (5) from\n64.85.80.16:8009 (app4)\n[Fri Mar 16 08:27:06 2007] [error] proxy: BALANCER: (balancer://appservers). All\nworkers are in error state for route (app4-engine1)\n+++\nI have fixed it in trunk.
40310	jfclere	1174556489000	Created an attachment (id=19772)\npatch for 2.2.x\n\nI will commit it in the 2.2.x branch if noone complains.
40310	Ruediger Pluem	1187356078000	Fix backported to 2.2.x as r553593\n(http://svn.apache.org/viewvc?view=rev&revision=553593)
40323	Jeff Trawick	1156525431000	ahh, mod_ext_filter isn't aware that the core server will normalize the case by\nchanging it to lower case; mod_ext_filter has already added the filtername to a\nhash table using your mixed case and later tries to do a lookup using the\nnormalized name\n\nPlease try this patch and report back.\n\nIndex: modules/filters/mod_ext_filter.c\n===================================================================\n--- modules/filters/mod_ext_filter.c\t(revision 431472)\n+++ modules/filters/mod_ext_filter.c\t(working copy)\n@@ -203,6 +203,7 @@\n                                              &ext_filter_module);\n     const char *token;\n     const char *name;\n+    char *normalized_name;\n     ef_filter_t *filter;\n \n     name = ap_getword_white(cmd->pool, &args);\n@@ -210,7 +211,16 @@\n         return 'Filter name not found';\n     }\n \n-    if (apr_hash_get(conf->h, name, APR_HASH_KEY_STRING)) {\n+    /* During request processing, we find information about the filter\n+     * by looking up the filter name provided by core server in our\n+     * hash table.  But the core server has normalized the filter\n+     * name by converting it to lower case.  Thus, when adding the\n+     * filter to our hash table we have to use lower case as well.\n+     */\n+    normalized_name = apr_pstrdup(cmd->pool, name);\n+    ap_str_tolower(normalized_name);\n+\n+    if (apr_hash_get(conf->h, normalized_name, APR_HASH_KEY_STRING)) {\n         return apr_psprintf(cmd->pool, 'ExtFilter %s is already defined',\n                             name);\n     }\n@@ -219,7 +229,7 @@\n     filter->name = name;\n     filter->mode = OUTPUT_FILTER;\n     filter->ftype = AP_FTYPE_RESOURCE;\n-    apr_hash_set(conf->h, name, APR_HASH_KEY_STRING, filter);\n+    apr_hash_set(conf->h, normalized_name, APR_HASH_KEY_STRING, filter);\n \n     while (*args) {\n         while (apr_isspace(*args)) {\n
40323	Richard Crawford	1157365580000	Hi Jeff.  Have re-built 2.0.55 with the provided mod_ext_filter patch and can\nconfirm it fixes the problem.\n\nMany thanks for your help.
40323	Jeff Trawick	1157368248000	Thanks for your testing.\n\nThe fix is now in trunk and proposed for backport to 2.2.x branch.  If approved\nfor 2.2.x branch I'll propose it for backport to 2.0.x branch as well.\n
40379	Roy T. Fielding	1188472050000	We only use the .mpkg suffix.  Using generic extension names causes\nexisting sites to change.  Apple should always use .mpkg at this point.\nCommitted to trunk.\n\nIs there a registered type for disk images (.dmg)?\n
40400	Tomokazu Harada	1157258525000	Created an attachment (id=18810)\na patch for mod_proxy_balancer\n
40400	Ruediger Pluem	1157286081000	Your patch would break session stickyness for other backends (e.g. java\nbackends) which encode the session id differently into the URL like\nwww.someplace.com/somewhere/;jsessionid=gggfgdufdfoef.server?parameter=value.\nPlease give the attached patch a try. It accepts ? and & as separators.
40400	Ruediger Pluem	1157286143000	Created an attachment (id=18812)\npatch to filter out sticky session from url given as parameter\n
40400	Tomokazu Harada	1157383001000	I tried the above patch. It's OK.\nWill the patch be merged to 2.2.x line?\n
40400	Ruediger Pluem	1157399452000	Thanks for testing. First of all I need to commit the patch to the trunk. I just\ndid that as r440160 (http://svn.apache.org/viewvc?view=rev&rev=440160). If there\nare no further comments by other developers I will propose this patch for\nbackport to 2.2.x.
40400	Ruediger Pluem	1157527819000	Proposed for backport to 2.2.x as r440643\n(http://svn.apache.org/viewvc?view=rev&rev=440643).
40400	Jim Jagielski	1162979063000	in 2.2.4-dev and trunk
40432	Joe Orton	1157630450000	For both this and bug 40431 the problem is basically the same: the locale is a\nprocess-global setting which cannot be changed per-request, and changing it to\nmatch an Accept-Language/Charset-supplied values would probably be a nightmare\nanyway.\n\nI think the right fix for this is to simply remove the date from the error\npages.  It's not particularly useful and this complaint is not unreasonable.\n\n[in glibc there are locale-specific interfaces which can use non-global locale\ncontext but being able to use these in httpd would be nearly impossible without\ndesigning a set of essentially glibc-specific interfaces]
40432	Joe Orton	1157630459000	*** Bug 40431 has been marked as a duplicate of this bug. ***
40432	Egmont Koblinger	1157631490000	Well, instead of removing the date, you could perhaps format it using numbers \nonly (e.g. 2006/09/07 14:15 +0200) or format in English using a built-in table \nof English month and weekday names (hence not using libc's localized names).\n\nI know about this newlocale()/uselocale()/*_l() stuff, but that's really glibc-\nspecific and requires a quite recent glibc, too. So it'd really be a bad \napproach for apache. I didn't realize when submitting the bug that apache is a \nmulti-thread app so using setlocale() around strftime() isn't safe.\n
40432	Joshua Slive	1185886162000	The date has been removed from the error pages.
40447	Jason Lingohr	1181420550000	Thanks for this, change committed (submitted by Tony Stevenson).\n
40454	Tony Stevenson	1185459648000	Patch applied, page updated: http://svn.apache.org/viewvc?view=rev&rev=559984\nShould be visible within a few hours.\n\nCheers,\nTony
40470	Will Rowe	1157999907000	I believe you will find this solved in the dev branch, and I've prepared the\nbackport in source and binary form for you to test against 2.0 or 2.2.\n\nPlease grab http://people.apache.org/~wrowe/mod_isapi-416293.zip - replace\nyour mod_isapi.so (or the sources of mod_isapi.c/.h if you compile your own\napache server) and report back.\n
40470	Taniya Pirapokin	1158004717000	The new mod_isapi-416293 still have problem with ServerSupportFunction at least\non HSE_REQ_SEND_RESPONSE_HEADER\n\nFor HSE_REQ_SEND_RESPONSE_HEADER, after send_response_header call, no handling\nof ate == headlen. \n\n        if (ate < 0) {\n            apr_set_os_error(APR_FROM_OS_ERROR(ERROR_INVALID_PARAMETER));\n            return 0;\n        }\n        else if ((apr_size_t)ate < headlen) {\n            apr_bucket_brigade *bb;\n            apr_bucket *b;\n            bb = apr_brigade_create(cid->r->pool, c->bucket_alloc);\n            b = apr_bucket_transient_create((char*) data_type + ate,\n                                           headlen - ate, c->bucket_alloc);\n            APR_BRIGADE_INSERT_TAIL(bb, b);\n            b = apr_bucket_flush_create(c->bucket_alloc);\n            APR_BRIGADE_INSERT_TAIL(bb, b);\n            rv = ap_pass_brigade(cid->r->output_filters, bb);\n            cid->response_sent = 1;\n            return (rv == APR_SUCCESS);\n        }\n    }\n\nFrom looking at the code for case HSE_REQ_SEND_RESPONSE_HEADER_EX, the return\n'return (rv == APR_SUCCESS);', rv may not be initialized.\n\nIn my test with Apache 2.2.3, now I get status log as 1 on the access log, and\nget real Internal Error from apache. I test with HSE_REQ_SEND_RESPONSE_HEADER\ncase and get ate == headlen (Is that suppose to be the normal correct case?)\n\nThanks,\nTP
40470	Will Rowe	1158008536000	Good catch, thank you.\n\nWhen there is a new update, I'll point you at it, or feel free to offer the\npatch you believe will fix it.
40470	Will Rowe	1164036854000	Created an attachment (id=19151)\nDon't fail when sent is the length of the headers\n\nHere's a suggested patch that retains the ability to incrementally add headers,\n\nand won't send them until some of the body is ready.\n\nFeedback please, I plan to commit in the next day if possible.
40470	Taniya Pirapokin	1164101918000	From your last change:\n- server response with correct status code (200 OK)\n- apache log response code as 1 on the isapi handled request (shouldn't it be 200)\n- PROBLEM - The response has \n<!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'>\n<html><head>\n<title>200 OK</title>\n</head><body>\n<h1>OK</h1>\n<p>The server encountered an internal error or\nmisconfiguration and was unable to complete\nyour request.</p>\n<p>Please contact the server administrator,\n root@localhost and inform them of the time the error occurred,\nand anything you might have done that may have\ncaused the error.</p>\n<p>More information about this error may be available\nin the server error log.</p>\n</body></html>\n\nappend to the end of it.\n\nI change the code from the last patch mod_isapi-416293 you direct to me.\n\nThanks\n\n\n(In reply to comment #4)\n> Created an attachment (id=19151) [edit]\n> Don't fail when sent is the length of the headers\n> \n> Here's a suggested patch that retains the ability to incrementally add headers,\n> \n> and won't send them until some of the body is ready.\n> \n> Feedback please, I plan to commit in the next day if possible.
40470	Matt Eaton	1166013305000	Created an attachment (id=19256)\n2.0 isapi workaround\n\nThe problem in the last comment is caused with persistent connections. Apply\nthis patch to work around this problem (reverting to old behavior for this\nreturn code).\n
40470	Will Rowe	1166015729000	Created an attachment (id=19257)\nPatch to record non-APR_SUCCESS results (do not apply with the hack)\n\nObviously if ap_pass_brigade fails, we should -not- return OK.\n\nWhat rv are we seeing here?  Are we getting (invalid) http\nresult codes from ap_pass_brigade?  or another error?\n\nIt seems an error emit would be appropriate here.  See patch.
40470	Matt Eaton	1166090215000	Well the problem is that (rv == APR_SUCCESS) is 1. OK is 0.\n\nSo I am not sure if the right solution is:\n\nreturn ((rv == APR_SUCCESS) ? OK : HTTP_INTERNAL_SERVER_ERROR);\n
40470	Will Rowe	1167836580000	http://svn.apache.org/viewvc?view=rev&revision=492333\n\nPatch committed, thanks to all who provided feedback, and to Matt for the pointer\nto OK results from the handler.
40470	Will Rowe	1167837063000	*** Bug 40698 has been marked as a duplicate of this bug. ***
40470	Will Rowe	1167837178000	*** Bug 40549 has been marked as a duplicate of this bug. ***
40470	Will Rowe	1167854712000	An unreleased build of this module including the last several patches is now \navailable for testing against httpd-2.0 and 2.2 from \n\n  http://people.apache.org/~wrowe/mod_isapi-r492341-win32.zip\n\nIt's not a release; if you test, report back 1) here, at 2) dev@httpd.a.o, or\nat users@httpd.a.o.  Thank you.
40476	Amichai	1158014306000	Oops... this happens in version 2.2.3, which is missing from the dropdown\nmenu... dunno if it's in 2.3 HEAD as well.
40476	Tom Donovan	1158686892000	Created an attachment (id=18888)\nap_open_logs does not store new stderr - \n\nap_open_logs in server/log.c does not store the new stderr in the static\nvariable stderr_log.  The old handle is closed, or might even be re-used for a\ndifferent file (which is probably what happened to this guy).
40476	Joe Orton	1159876317000	I don't really follow that patch: stderr_log is a global variable which is\ninitialized once at startup.  It doesn't really matter *which* apr_file_t * that\ndup2 happens against; fd 2 ends up the same anyway. \n\nDo you have a repro case for this, Tom?
40476	Ruediger Pluem	1159886987000	Is it possible that stderr is not fd 2 on Windows? During my investigations for\nPR40651 I saw a comment in the APR documentation about this\n(http://apr.apache.org/docs/apr/group__apr__file__io.html#ga10). So this maybe a\nWindows specific problem. For Unix systems I agree with your analysis.
40476	Amichai	1159888478000	as u probably discerened from my original post, this indeed occured on a Windows\n(XP) system. If there's some test u'd like me to run to recreate/diagnose this,\nI'd be glad to help.\n
40476	Will Rowe	1159888998000	There is no 'fd' vis-a-vis unix.  Handles are arbitrarilly assigned.\n\nIt absolutely must be applied for non-pure-posix portability.\nThis looks like a good solution but I don't have a platform to apply\nto at this instant.
40476	Tom Donovan	1159934968000	Yes, the problem happens on Windows.  The stderr filehandle is not 2, as in\nUnix, and a dup() of stderr produces a new (arbitrary) filehandle value.\n\nFor a quick repro: If you start Apache 2.2.3 on Windows with a pre-existing\nhttpd.pid - no 'Unclean shutdown' message appears in the error log (the write is\nattempted to a closed filehandle).  If you repeat this after applying the patch,\nthe message correctly appears in the error log.\n\nI cannot repro the case where the message appears in the wrong file.  It is just\nconjecture that a previously closed stderr handle got re-used for an access log\nin Amichai's installation.
40476	Joe Orton	1161674275000	Well it seems like an obviously-correct cleanup anyway, so be it:\n\nhttp://svn.apache.org/viewvc?view=rev&rev=467338
40476	Will Rowe	1188256981000	Note this was surplanted by a new two-pool approach, maintaining the old\nstderr log pool during the creation of the new stderr log pool, then on\nsuccess tearing down the old one.\n\nThat solution required significant refactoring in apr, lest Tom's issue\npop up, all over again.
40573	Matt Eaton	1158863893000	Created an attachment (id=18896)\nPatch against 2.0.59\n\nTrivial fix
40573	Will Rowe	1167836974000	I concur...\nhttp://svn.apache.org/viewvc?view=rev&revision=492341\n\nThanks for the submission!
40576	Xuekun Hu	1162157179000	(In reply to comment #0)\nHi, All\n\nI knew you are all very busy and probaly are busying working on \nmod_disk_cache :-)\n\nI really hope someone could give me some comments since I'm a newbie on \nlearning/reading Apache source code. \n\nThx, Xuekun
40576	Ruediger Pluem	1162215752000	From a first glance 2) seems to be more reasonable to me as I currently cannot\nsee a reason to cache objects of size 0 :-). Regarding your check of the value\nset by MCacheMinObjectSize you should return an error is the value is invalid.
40576	Xuekun Hu	1162232591000	(In reply to comment #2)\n> From a first glance 2) seems to be more reasonable to me as I currently cannot\n> see a reason to cache objects of size 0 :-). Regarding your check of the value\n> set by MCacheMinObjectSize you should return an error is the value is invalid.\n\nThanks for comments. I also think 2) is more reasonable :-)\nBased on your comments, I added the error return value. \n\ndiff -ru httpd-2.2.2/modules/cache/mod_mem_cache.c httpd-\n2.2.2.new/modules/cache/mod_mem_cache.c\n--- httpd-2.2.2/modules/cache/mod_mem_cache.c   2006-04-22 09:53:06.000000000 \n+0800\n+++ httpd-2.2.2.new/modules/cache/mod_mem_cache.c       2006-09-01 \n13:49:08.233344008 +0800\n@@ -98,7 +98,7 @@\n static mem_cache_conf *sconf;\n\n #define DEFAULT_MAX_CACHE_SIZE 100*1024\n-#define DEFAULT_MIN_CACHE_OBJECT_SIZE 0\n+#define DEFAULT_MIN_CACHE_OBJECT_SIZE 1\n #define DEFAULT_MAX_CACHE_OBJECT_SIZE 10000\n #define DEFAULT_MAX_OBJECT_CNT 1009\n #define DEFAULT_MAX_STREAMING_BUFFER_SIZE 100000\n@@ -964,7 +964,8 @@\n     if (sscanf(arg, '%' APR_SIZE_T_FMT, &val) != 1) {\n         return 'MCacheMinObjectSize value must be an integer (bytes)';\n     }\n-    sconf->min_cache_object_size = val;\n+    if (val > 0)\n+       sconf->min_cache_object_size = val;\n+    else\n+       return  'MCacheMinObjectSize value must be an positive integer (bytes)';\n     return NULL;\n }\n static const char\n
40576	Ruediger Pluem	1162357488000	Committed to trunk as r469895\n(http://svn.apache.org/viewvc?view=rev&rev=469895). Thanks.
40576	Ruediger Pluem	1169217508000	*** Bug 41417 has been marked as a duplicate of this bug. ***
40576	Ruediger Pluem	1188702047000	Proposed for backport as r571936 (http://svn.apache.org/viewvc?rev=571936&view=rev).
40576	Ruediger Pluem	1188891717000	Backported to 2.2.x as r572628 (http://svn.apache.org/viewvc?rev=572628&view=rev).
40640	Will Rowe	1159547292000	That's correct, it's a historical curiosity that should be purged from the docs.\n\nIf engine support is installed from OpenSSL, we can use it unconditionally without\nany build time defines.
40640	Rich Bowen	1165493610000	Resolved in r483641
40651	Ruediger Pluem	1159710608000	(In reply to comment #0)\n> I use Apache 2.2.3 on Solaris. All Logfiles are configured to use rotatelogs.\n> Whenever I restart Apache either with 'restart' or with 'graceful' The first\n> piped logger, which cares about the global error log, is left over in the\n> process table. To be more precise: For all loggers new processes get started,\n> and all apart from the described old one terminate. The problem is this\n> unnecessary old process that doesn't die.\n\nSome questions:\n\n1. Does the respective /bin/sh -c die?\n2. Does a new rotatelog process get forked after the restart?\n3. What is the parent process of the hanging logrotate process\n4. What version of Solaris do you use?\n5. Could you please truss /bin/sh -c and logrotate during the restart with\n   options -faedl -vall -rall -wall?\n\n> It would be nice to at least document the behaviour. Really nice would be to\n> make SHELL_PATH changeable via configure and to be able to change it via Apaches\n> configure (and if that would be documented).\n\nSounds reasonable to me.
40651	Rainer Jung	1159711601000	Hi R??diger,\n\nSome questions:\n\n1. Does the respective /bin/sh -c die?\n\nYes. All of them die.\n\n2. Does a new rotatelog process get forked after the restart?\n\nYes. All needed new ones get started.\n\n3. What is the parent process of the hanging logrotate process\n\nPID 1\n\n4. What version of Solaris do you use?\n\nThe behaviour was observed on SunOS 5.9 Generic_118558-05 sun4u sparc. I could\ntry with Solaris 8 and 10 to, but that would have to wait until tuesday.\n\n5. Could you please truss /bin/sh -c and logrotate during the restart with\n   options -faedl -vall -rall -wall?\n\nYes, I'll attach them in a minute. I didn't do the 'rall', because I don't want\nthe whole config to be in the truss. I'm confident, that the reads are not that\nimportant. Otherwise I need to redo the thing with a test configuration.\n\nAlso I'll attach three ps excerpts, one directly after start, the second after\ngraceful and the third after restart. The processes I'm talking about are:\n\nps1.out:    root 11820 11818  0 22:58:45 ?        0:00 /bin/sh -c\n/usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 8\nps1.out:    root 11822 11820  0 22:58:45 ?        0:00\n/usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 86400\n\n!ps2.out:    root 11822     1  0 22:58:45 ?        0:00\n/usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 86400\nps2.out:    root 11926 11818  0 22:59:32 ?        0:00 /bin/sh -c\n/usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 8\nps2.out:    root 11929 11926  0 22:59:32 ?        0:00\n/usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 86400\n\n!ps3.out:    root 11822     1  0 22:58:45 ?        0:00\n/usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 86400\n!ps3.out:    root 11929     1  0 22:59:32 ?        0:00\n/usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 86400\nps3.out:    root 12034 11818  0 23:00:04 ?        0:00 /bin/sh -c\n/usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 8\nps3.out:    root 12037 12034  0 23:00:04 ?        0:00\n/usr/local/apache22/bin/rotatelogs /var/apache/logs/error_log_main 86400\n\n
40651	Rainer Jung	1159711875000	Created an attachment (id=18944)\ngzipped truss\n
40651	Rainer Jung	1159711919000	Created an attachment (id=18945)\nProcess table after start\n
40651	Rainer Jung	1159711948000	Created an attachment (id=18946)\nProcess table after apachectl graceful\n
40651	Rainer Jung	1159711969000	Created an attachment (id=18947)\nProcess table after apachectl restart\n
40651	Ruediger Pluem	1159719587000	Hi Rainer,\n\nmany thanks for the quick feedback. I think I know why this problem only happens\nto the main error logrotater:\n\nhttpd closes the writing side of the pipe to the logrotater. This auses the\nlogrotater to exit and thus /bin/sh -c to exit. There is no need to send a\nSIGTERM to either /bin/sh -c or logrotate in this case. This does not work this\nway with the main error logrotater since the writing side fd has been previously\ncopied (dup2ed) to stderr. After a start of the new main error log logrotater\nits wrting side should be dup2ed again to stderr. This should cause the old\nstderr file descriptor to be closed and thus causing the logrotator to exit as\nthis is the last open writing side of the pipe. This does not seem to work on\nSolaris (libc on Solaris seems to do a fcntl(13, F_DUP2FD, 0x00000002) instead\nof dup2(13,2)). I did not have the time to do further tests on this issue. As\nyou may notice the logrotater dies after the main httpd process has died as the\nOS does now seem to close the file descriptor correctly.\n\nSince I personally do not use logrotation on the main error log file for years\n(and this works perfectly if you do everything else in virtual hosts and nothing\nin the main server) I am not quite sure anymore, but I think I stopped\nlogrotating the main error log file because log messages did not arrive there\nduring restart / graceful restart.\n\nNevertheless it makes still sense to me to stop hardcoding /bin/sh in APR.\nAdditionally to be able to set SHELL_PATH via configure it might be even better\nif you can set the shell path via some APR function and APR only uses SHELL_PATH\nif nothing was set.
40651	Rainer Jung	1159720455000	Hi R??diger,\n\nI'm impressed! I had a look at the truss output to, but got stuck exactly around\nthe dup2 fcntl.\n\nYou comments about main error logger are interesting. In fact it would be better\nnot to pipe that one to be sure, that errors can be written at any time. And\nusually everything else happens in vhosts, so not rotating that one is not a\nhuge problem.\n\nBut nevertheless, freeing up half of the log child processes by using another\nshell to invoke still would be nice. The process table looks a lot cleaner after\ndropping the '/bin/sh -c' processes.\n\nI'm not very experienced with the auto(conf|make|header) stuff, although I did\nsome changes to the configure process in mod_jk. If time permits, I could have a\nlook at it for APR next sunday, but if you or anyone else knows easily how to\ninclude this feature I would be happy.\n
40651	Ruediger Pluem	1159756992000	Created an attachment (id=18949)\nSmall test program for dup2\n\nAttached a small quick and dirty test program. If dup2 really does not work on\nSolaris it should print out: \n\nChild: Hello World!\n\nand NOT return to shell. If it returns to the shell dup2 works as expected. On\nmy Solaris 9 testbox dup2 seems to work as expected. Odd!\n
40651	Ruediger Pluem	1159757232000	If it turns out not to be a Solaris bug with dup2, can you please do the following:\n\n1. Do a truss again as previously (-vall -wall -faedl).\n2. Do a graceful restart.\n3. Issue pfiles <pid of remaining logrotater>\n4. Issue pfiles <pid of httpd main process>\n5. Attach outputs of pfiles and truss and let me know the pids of the httpd main\n   process and the remaining logrotater.\n
40651	Joe Orton	1159765372000	This is reproducible on Linux by using, e.g.:\n\nErrorLog '| true; /path/to/rotatelogs etc'\n\nwhich forces the sh process to hang around.
40651	Joe Orton	1159765984000	This is a fun bug!\n\nAfter the graceful restart, the *new* piped logger for the main error log is\nrunning with its fd 2 pointing to the pipe to the *old* piped logger which it is\nreplacing.  That is the only place that fd is left open, and it's what is\npreventing the old piped logger from exiting.\n\nThe use of the 'sh' process is just what is needed to make this problem\napparent.  Otherwise the rotatelogs will get SIGTERMed by the parent directly on\nrestart.  (courtesy of piped_log_cleanup)\n
40651	Joe Orton	1159767664000	Created an attachment (id=18950)\nproof-of-concept fix\n\nThis should prevent the orphaned piped loggers, not sure if this is the optimal\nsolution though.
40651	Joe Orton	1159767805000	Re-assigning this to httpd.
40651	Ruediger Pluem	1159779333000	(In reply to comment #12)\n> This is a fun bug!\n\nIndeed yes\n\n> \n> After the graceful restart, the *new* piped logger for the main error log is\n> running with its fd 2 pointing to the pipe to the *old* piped logger which it is\n> replacing.  That is the only place that fd is left open, and it's what is\n> preventing the old piped logger from exiting.\n\nExcellent analysis many thanks.
40651	Ruediger Pluem	1159779518000	(In reply to comment #13)\n> Created an attachment (id=18950) [edit]\n> proof-of-concept fix\n> \n> This should prevent the orphaned piped loggers, not sure if this is the optimal\n> solution though.\n\nI am a little worried that nobody reads at the other end of the pipe. What if\nthe logger writes a huge amount of data to its stderr? Wouldn't it get blocked?\nWhat about using the stdout of the main process (should be /dev/null) for the\nlogger? I modified your patch to do this. A quick test shows that it works.\nComments welcome.\n\n\n
40651	Ruediger Pluem	1159779582000	Created an attachment (id=18952)\nAdjust proof-of-concept fix to use stdout of main process\n
40651	Ruediger Pluem	1159779699000	Hi Rainer,\n\nas your specific problem has to be fixed inside of httpd I propose that you open\na new report for the enhancement of APR's configure to make SHELL_PATH configurable.
40651	Will Rowe	1159788304000	This raises a deeper question though.  Should a graceful restart even recycle\nthe logger processes in httpd?  Or should they be persistent and continue to\nrun (short circuit the open logs to keep the existing files *and processes*\naround?)\n\n\n\n
40651	Ruediger Pluem	1159795555000	Created an attachment (id=18954)\nUpdated version of the stdout version of the fix, which fixes a fd leak\n
40651	Joe Orton	1159850491000	Thanks Ruediger, that's definitely a better approach.\n\nI've tweaked that, and also realised that this needs to be done *only* for the\nlogger for the main server.  Piped loggers for vhosts should continue to inherit\nstderr from the main server as before.\n\nCommitted as http://svn.apache.org/viewvc?view=rev&revision=452431
40651	Ruediger Pluem	1159853548000	(In reply to comment #21)\n> Thanks Ruediger, that's definitely a better approach.\n> \n> I've tweaked that, and also realised that this needs to be done *only* for the\n\nThanks for tweaking and committing.\n\n> logger for the main server.  Piped loggers for vhosts should continue to  inherit\n> stderr from the main server as before.\n\nJust for my clarification: This works because the error log of the main server\nis the first logger that gets 'restarted' during a graceful / restart, right?\nSo the other loggers inherit a stderr that is the writing side of the pipe to\nthe *restarted* main server error logger, correct?
40651	Joe Orton	1159854915000	Yes, exactly correct. ap_open_logs handles it: opens the main server log, does\nthe dup2-to-stderr trick, then loops through all the vhosts and opens their logs. 
40651	Ruediger Pluem	1159855238000	(In reply to comment #23)\n> Yes, exactly correct. ap_open_logs handles it: opens the main server log, does\n> the dup2-to-stderr trick, then loops through all the vhosts and opens their logs. \n\nThanks for clarification. Proposed for backport to 2.2.x as r452457\n(http://svn.apache.org/viewvc?view=rev&rev=452457).
40651	toadie	1165405084000	The error log still spawns the process using \n\nrc = apr_procattr_cmdtype_set(procattr,\n                                        APR_SHELLCMD_ENV)) == APR_SUCCESS)\n\ninstead of \n\nrc = apr_procattr_cmdtype_set(procattr,\n                                        APR_PROGRAM_ENV)) == APR_SUCCESS)\n\nas documented http://issues.apache.org/bugzilla/show_bug.cgi?id=16761\n\nTypically this is an issue with Windows env . Any chance if the same patch \nproposal from 16761 can be applied here as well?\n\n\n
40651	Ruediger Pluem	1165583828000	Backported to 2.2.4
40651	Ruediger Pluem	1165584003000	(In reply to comment #25)\n\n> \n> Typically this is an issue with Windows env . Any chance if the same patch \n\nHave you really checked that there is an issue on windows?\nAnyway the original bug described here is now fixed thus I will close the report\nagain. Feel free to open a new one if there is really a problem on windows with\nthis.
40653	Larry Stefani	1159777822000	More information.  PHP developers consider this issue a problem with apxs.\n\nFrom http://bugs.php.net/bug.php?id=38997&edit=2\n\n    [2 Oct 3:19pm UTC] tony2001@php.net \n    If you want apxs utility to be enhanced - please report it as a feature\n    request to Apache developers.\n    There is nothing PHP can do about it.\n
40653	Nick Kew	1160115045000	Feel free to contribute an alternative build tool.  You'll have to deal with \nthe dependencies too, of course.  And bear in mind that apxs is designed to \nwork in packages, where you don't have all the build debris lying around.\n\nAnyway, cross-compiling PHP sounds to me like a *much* bigger job than this.
40653	Larry Stefani	1160115974000	>>Feel free to contribute an alternative build tool.  You'll have to deal with \n>>the dependencies too, of course.  And bear in mind that apxs is designed to \n>>work in packages, where you don't have all the build debris lying around.\n\nThat may explain the need to run httpd from apxs.  It appeared that since apxs \nis created dynamically, it could at least contain all of the CFLAGS, include \npaths, etc. that would be required by a fairly popular external module (PHP), \nwithout reading other files.\n\n>>Anyway, cross-compiling PHP sounds to me like a *much* bigger job than this.\n\nI'm not so sure.  PHP configure supports the same --host= and --target= \noptions as Apache configure.  I was able to configure and cross-compile PHP \nsuccessfully, that is, until I added the --with-apxs2= option.  I didn't \nrealize that without it, the loadable module that Apache needs isn't built.\n\nNow I'm left with a cross-compiled httpd daemon that loads and runs just fine \non my target platform, but with no PHP support.\n\nI appreciate the feedback.  I'll probably need to revert to installing the GCC \ntoolchain and software packages on my target platform and rerun the \nconfigure/make steps in 'native' mode.  I was hoping for any workaround that \nwould allow me to avoid that.\n
40653	Larry Stefani	1160722534000	Just wanted to note a workaround for this problem.  By editing the PHP \nconfigure script to replace appropriate $APXS -q calls with explicit \ndirectories and filenames, I was able to avoid executing apxs during the \nconfigure step.  What was necessary was to perform the apxs -q queries on the \ntarget platform (where the apxs can run httpd properly), then take the result \nand enter it into the PHP configure script, run configure, then cross-compile \nPHP accordingly.\n\nThe alternative would be to edit apxs to *not* invoke httpd on simple -q \nqueries, which can be easily determined when apxs is created.\n
40653	David M. Lee	1168353746000	Created an attachment (id=19384)\nFixes apxs for cross-compilation\n\nThe attached patch removes the need for apxs to invoke httpd.  \n\nWith this patch, the value of enable_so is saved into config_vars.mk.  apxs\nthen looks up this value instead of invoking httpd.
40653	Joe Orton	1168397561000	Great patch David, thanks, that code has annoyed me forever.  I tweaked it\nslightly and committed it to the trunk:\n\nhttp://svn.apache.org/viewvc?view=rev&revision=494781
40656	Ruediger Pluem	1159798582000	Thanks for the report. Fixed in trunk as r452212\n(http://svn.apache.org/viewvc?view=rev&rev=452212).
40656	Ruediger Pluem	1159799049000	Proposed for backport to 2.2.x as r452218\n(http://svn.apache.org/viewvc?view=rev&rev=452218).
40656	Ruediger Pluem	1159855301000	Backport to 2.2.x as r452459 (http://svn.apache.org/viewvc?view=rev&rev=452459).
40658	Ruediger Pluem	1159798584000	Thanks for the report. Fixed in trunk as r452213\n(http://svn.apache.org/viewvc?view=rev&rev=452213).
40658	Ruediger Pluem	1159799048000	Proposed for backport to 2.2.x as r452218\n(http://svn.apache.org/viewvc?view=rev&rev=452218).
40658	Ruediger Pluem	1159855337000	Backported to 2.2.x as r452462 (http://svn.apache.org/viewvc?view=rev&rev=452462).
40756	Trevin Beattie	1160743954000	Created an attachment (id=19005)\nFix to check the result of apr_sockaddr_info_get before passing uri_addr to\nap_proxy_checkproxyblock\n
40756	Kelly	1188298098000	Is this ever going to be addressed.  I guess my users like requesting pages that\naren't in dns because I'm seeing it all over the place.  But I can only\nreproduce it with ProxyRemote as well as ProxyBlock.  If I have ProxyRemote off\nthen it works just fine.
40756	Kelly	1188298166000	As soon as I sent that, I realized that I probably sounded snippity.  Totally\nnot intended.  Thank you for the wonderful web server and for all of your hard\nwork.  Dude I'm a dork some times.
40756	Nick Kew	1188492633000	Reviewing after far too long, it appears your CONNECT patch may still be needed,\nbut the FTP patch appears unnecessary, as the current code makes the check\nbefore using the addr.  Is that a fair summary of 2.2?
40756	Trevin Beattie	1188499512000	After reviewing the code for httpd-2.2.0, it appears your assessment is correct.\n The patch I made applies to version 2.0.x.
40756	Nick Kew	1189258315000	Fixed in 2.2.6
40805	Ruediger Pluem	1161697464000	Can you please try the attached patch?
40805	Ruediger Pluem	1161697525000	Created an attachment (id=19038)\nPatch against trunk\n
40805	Noah Robin	1161767952000	Yep, that works.
40805	Noah Robin	1163075939000	Is this patch going to be applied against the 2.2 branch?
40805	Ruediger Pluem	1163082609000	I need to commit this to trunk first and propose it for backport to 2.2.x.\nPlease bug me here if you see no update on this here within the next week. Thanks.
40805	Ruediger Pluem	1163860762000	Committed to trunk as r476625 (http://svn.apache.org/viewvc?view=rev&rev=476625).
40805	Noah Robin	1166430454000	Any update on getting this backported to 2.2?
40805	Ruediger Pluem	1166446467000	Proposed for backport to 2.2.x as r488411\n(http://svn.apache.org/viewvc?view=rev&rev=488411). Thanks for the reminder.
40805	Noah Robin	1168937569000	What are the chances of this making it into 2.2.5?
40805	Ruediger Pluem	1178526940000	Backported to 2.2.x as r535903 (http://svn.apache.org/viewvc?view=rev&rev=535903).
40805	portalez	1182775807000	Hello,\n\nexcuse my poor english, I'm french.\n\nCan someone explain to me how to apply this patch, please ?\nI have the 2.2.4 version of Apache. I need to apply the patch on a linux and on\na Windows plateform.\n\nThanks.
40805	Basant Kumar Kukreja	1182779937000	Go to the directory from where the patch is being created e.g Apache root\ndirectory in this patch and run the command.\n$ patch -p 0 -u -i <patchfile>
40865	Ruediger Pluem	1162383729000	Thanks for the patch. Committed to trunk as r470076\n(http://svn.apache.org/viewvc?view=rev&rev=470076).
40865	Ruediger Pluem	1188697613000	Backported to 2.2.x as r571929 (http://svn.apache.org/viewvc?view=rev&rev=571929).
40878	Rob Baily	1162458619000	Created an attachment (id=19076)\nProposed patch for the enhancement.\n\nIdeally I think the 10 and 5 in the failures loop would be configrable with\nsome defaults like the numbers that are currently used.  However I wasn't\nreally sure about the best way to put that in so I did not do that.
40878	Rob Baily	1162459582000	Changing severity to enhancement.  Although some people may think it is a bug\nsince it eventually fails the LDAP authentication.
40878	Brad Nicholes	1162990117000	Checked into trunk and proposed for backport to 2.2
40878	John Tracy	1177320947000	In our environment we're running Apache 2.2.3 on a Solaris 10 box authenticating\nagainst a Windows 2003 LDAP server. This issue also appeared when our developers\nstarted porting applications over to Apache from IIS. In our situation, it would\nsometimes appear even upon an initial connection from a user after attempting to\nauthenticate against LDAP. This was after the web server daemon was online for a\nfew hours (four). The end user, if they entered their username/password\ncorrectly (or perhaps incorrectly too) would immediately get a 500 Internal\nServer error message, and an entry like this would be logged:\n\n[Mon Apr 23 12:05:36 2007] [warn] [client 101.10.115.53] [21514] auth_ldap\nauthenticate: user tracy authentication failed; URI /em/gs [LDAP:\nldap_simple_bind_s() failed][Can't contact LDAP server]\n\n
40910	Ruediger Pluem	1162801895000	Could you please give the attached patch a try? It should fix your problem.
40910	Ruediger Pluem	1162801927000	Created an attachment (id=19092)\nPatch against trunk\n
40910	Markus Lind	1162804939000	Thanks, the Patch fixes the problem\n\n
40910	Ruediger Pluem	1165152419000	Committed to trunk as r481901 (http://svn.apache.org/viewvc?view=rev&rev=481901).
40910	Ruediger Pluem	1188702042000	Proposed for backport as r571936 (http://svn.apache.org/viewvc?rev=571936&view=rev).
40910	Ruediger Pluem	1188828079000	Backported to 2.2.x as r572420 (http://svn.apache.org/viewvc?rev=572420&view=rev).
40932	Will Rowe	1199050786000	You are correct.\n\nAlthough we have to close it before the return because we are\nabout to signal it in the shutdown case further down.  So the\nmost sensible patch is to close it immediate before the two\nreturn cases.  Although that's just my minor tweak - fantastic\ncatch and assigning you full credit for the repair, thanks!\n
40950	Thijs Kinkhorst	1163304726000	Created an attachment (id=19115)\nadjust xml text\n
40950	Nick Kew	1166277774000	Fixed in /trunk/ and 2.2.x - thanks\n
41035	Roy T. Fielding	1188471769000	Committed to trunk in rev 571260.\n
41056	Jim Jagielski	1164706505000	Created an attachment (id=19183)\nFrom PR 19954\n
41056	Jim Jagielski	1164707345000	Patch committed to trunk. Not yet in 2.2.x
41056	Ruediger Pluem	1196683705000	Proposed for backport as r600652\n(http://svn.apache.org/viewcvs.cgi?rev=600652&view=rev).
41056	Ruediger Pluem	1197183343000	Backported to 2.2.x as r602679 (http://svn.apache.org/viewvc?rev=602679&view=rev).
41097	Dave Sparks	1166624104000	IME Apache 2.2.0 used as a reverse proxy *does* append to an existing\nX-Forwarded-For header.\n\nWhen I access a private server at work from my home machine, I connect via a\nforward proxy (Squid 2.6) on my home machine, an authenticating reverse proxy\n(Apache 2.2.0) on the remote firewall, and a reverse proxy (Apache 2.2.0) on the\nremote DMZ machine.  The server (running under Tomcat 5.5) has a facility for\nreporting the headers in the request it receives, and the X-Forwarded-For:\nheader contains the private IP address of my home machine (added by Squid), the\npublic IP address of my home machine (added by the firewall Apache), and the DMZ\nIP address of the remote firewall (added by the DMZ Apache).  As I would expect.
41097	Joshua Slive	1185887433000	These headers are now somewhat documented on trunk. Thanks.
41123	Michal Prochazka	1165470538000	Created an attachment (id=19224)\nOCSP Patch\n
41123	Michal Prochazka	1168409841000	Created an attachment (id=19386)\nNew version of OCSP patch containg missing file ssl_ocsp.c\n\nIn previous bug I forgot to add ssl_ocsp.c file.
41123	Marc Stern	1168495817000	Created an attachment (id=19390)\nNew version of OCSP patch generalising validation check, and including\nssl_ocsp.c file in Visual C++ project\n\nThis implements the following validation workflow:\n\n1. if (useOCSP)\n   => check OCSP\n   => if ( OCSP validation possible ) return status\n2. Other online validation checks in the future (LDAP, etc.)\n   => check new protocol\n   => if ( validation possible ) return status\n3. if (crl)\n   => check CRL\n   => If ( CRL validation possible ) return status\n4. If ( forceValidation ) return !ok\n5. return ok
41123	Marc Stern	1168498478000	Created an attachment (id=19391)\nCorrected a #include\n
41123	Marc Stern	1168498643000	Created an attachment (id=19392)\nCorrected a #include\n
41123	Marc Stern	1168565707000	Created an attachment (id=19399)\nPort to 2.2.4\n
41123	Marc Stern	1169607019000	Created an attachment (id=19445)\nDocumentation patch\n
41123	Marc Stern	1169608502000	Created an attachment (id=19446)\nValidation schema\n\nSchema describing the certificates validation mechanism
41123	Joe Orton	1170825349000	From review of attachment in comment 6:\n\nA couple of things which make this code hard to review:\n- many code style issues with this code; tabs, many indenting problems,\nwhitespace around if statements, see: \nhttp://httpd.apache.org/dev/styleguide.html and be familiar with existing httpd\ncode \n- don't use C++-style comments\n- lots of stretches of code have been commented out rather than just deleted. \nIf they aren't needed, delete them.\n\nGeneral review:\n- don't log anything in the ssl_cmd_* functions, this doesn't add much\n- don't invent macros for logging in ssl_ocsp.c, just use ap_log_* directly\n- when and where is NO_OCSP supposed to be defined?  this needs an autoconf\ncheck presumably; call the define MODSSL_something\n- if it's useful for users to be able configure a proxy make it properly\nconfigurable, otherwise remove the debugging code\n- X509_Int2Str() should be static and have a name outside a namespace owned by\nOpenSSL.  Use of the static result buffer inside is not thread-safe.\n- use pools not malloc\n- using pools, and pool cleanups, or just better function structure, should be\nable to eliminate the excessive use of goto in VerifyOCSP\n- GetExtensionValue looks scary.  Why is this not looking up extensions by NID,\ncan X509_get_ext_d2i not be used here?\n- also a bit scared about using the toy HTTP/1.0 client in OpenSSL :(
41123	Marc Stern	1170998538000	I modified and cleaned up the code as requested; I will upload a new patch.\n\nSome questions:\n\n1. I used the connection pool for memory allocation: c->pool from\nssl_callback_SSLVerify_Validity(). Is that correct ? I did not use any pool\ncleanup, as this will be closed at the end of the connection.\n\n2. I originally added the #ifdef NOOCSP in case you want a version that is\ncompiled with this code. Is this really needed ? Can I remove it ?\n\n3. Should I replace the HTTP connection by some calls to some Apache API ? Which\nAPI is available ?\n\n4. Probably dependent to the previous question, is there any global setting\ndefining a proxy to call when opening an outgoing HTTP(S) connection ? I could\ndefine it for the OCSP call only, but some other code (even external modules)\ncould also need it; this would lead to the same info being defined several time.\nShould I implement it only for my code ? Or can I assume that the server will\nalways have a direct access to the OCSP server ?\n
41123	Marc Stern	1171000651000	Is it possible to use mod_proxy connection pools ?\nThis would make sense, although the outgoing connection pool should go out from\nmod_proxy to a separate module in order to be reusable by every module ...\nThis would maybe be the future best track, but it sounds a bit heavy to\nreimplement all mod_proxy connection pool handling just for the OCSP connection.\nCan we leave this as a future improvement and currently use the OpenSSL\nconnection (which works well in practice in several very big eGov sites) ?
41123	Ruediger Pluem	1171070995000	(In reply to comment #10)\n> I modified and cleaned up the code as requested; I will upload a new patch.\n\n\n>\n> 3. Should I replace the HTTP connection by some calls to some Apache API ? Which\n> API is available ?\n> \n> 4. Probably dependent to the previous question, is there any global setting\n> defining a proxy to call when opening an outgoing HTTP(S) connection ? I could\n> define it for the OCSP call only, but some other code (even external modules)\n> could also need it; this would lead to the same info being defined several time.\n> Should I implement it only for my code ? Or can I assume that the server will\n> always have a direct access to the OCSP server ?\n> \n\nProbably not well thought out, but how about a sub request to the proxy_handler\nprovided by mod_proxy?
41123	Marc Stern	1171238059000	> how about a sub request to the proxy_handler provided by mod_proxy?\n\nIs there any documentation on how to do that ?\nWould it be acceptable to oblige loading mod_proxy for OCSP validation ?
41123	Ruediger Pluem	1171283105000	(In reply to comment #13)\n> > how about a sub request to the proxy_handler provided by mod_proxy?\n> \n> Is there any documentation on how to do that ?\n\nNot as far as I know. But having a look into mod_include for subrequest\ninclusion and at mod_rewrite for preparing a request to go to the proxy could be\nhelpful.\n\n> Would it be acceptable to oblige loading mod_proxy for OCSP validation ?\n\nI think this should be discussed on dev@httpd.apache.org and not here.
41123	Marc Stern	1173082746000	Created an attachment (id=19667)\nCode following recommandations\n\nI followed all recommandations, except the connection that is still established\nby OpenSSL calls - using mod_proxy was too complex. Note that the OpenSSL\nconnection works very well in big production environments.
41123	Joe Orton	1178178730000	I've been working on a cleanup of this patch - we need a CLA on file for all the\ncontributors before anything can be committed, since it's a contribution of new\ncode; I'm not sure who out of the following that means:\n\n1) Marc Stern [no CLA]\n2) Matthieu Estrade [CLA on file] has worked on this previously\n3) Michal Prochazka [no CLA] wrote the initial port to 2.2 attached here.\n\nMarc, can you confirm the lineage of the patch most recently attached?\n\nhttp://issues.apache.org/bugzilla/attachment.cgi?id=19667\n
41123	Marc Stern	1180666672000	Joe,\n\nI submitted the CLA some time ago.\nMichal did only port the patch to the new version, no new code was added.\nMatthieu could provide a CLA if needed (don't know if need for apache.org members).\n\nCan you acknowledge that everything is OK.\n\nThanks
41123	Ruediger Pluem	1180668057000	(In reply to comment #17)\n> Joe,\n> \n> I submitted the CLA some time ago.\n\nYour iCLA has been registered a while ago (May 7th, see\nhttp://people.apache.org/~jim/committers.html and search for Marc Stern).\nSo this is fine.\n\n> Michal did only port the patch to the new version, no new code was added.\n\nNot quite sure if an iCLA is needed in this case. Joe?\n\n> Matthieu could provide a CLA if needed (don't know if need for apache.org\nmembers).\n\nHis iCLA is already on file. So this is fine too.
41123	Wolfram Joost	1189669368000	In ssl_ocsp.c, function ap_ocsp_verify_ocsp:\n\n----- start -----\n   if (rc == SSL_OCSP_OK) {\n        /* Get issuer */\n        ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, 'Get Issuer');\n        rc = X509_STORE_CTX_get1_issuer(&issuer, ctx, cert);\n        if (rc != 1) {\n            ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n                         'Cannot get issuer of '%s'. rc=%d',\nX509_SUBJ_NAME(cert), rc);\n            rc = SSL_OCSP_ERROR_INTERNAL;\n        }\n    }\n\n    if (rc == SSL_OCSP_OK) {\n----- end -----\n\nThis can't work. If there's no issuer rc is set to SSL_OCSP_ERROR_INTERNAL. If\nthere is one, rc stays '1'. However, SSL_OCSP_OK is 0, 1 means\nSSL_OCSP_ERROR_PARSE_URL\n\n
41123	Marc Stern	1192074418000	Created an attachment (id=20958)\nSmall corrections in error handling and OCSp response logging\n
41123	Marc Stern	1192170141000	(From update of attachment 20958)\ndiff -uaEbwNp orig/ssl_ocsp.c ./ssl_ocsp.c\n--- orig/ssl_ocsp.c\t1970-01-01 01:00:00.000000000 +0100\n+++ ./ssl_ocsp.c\t2007-10-11 16:37:20.866178500 +0200\n@@ -0,0 +1,441 @@\n+/* Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the 'License'); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *\thttp://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an 'AS IS' BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+    \n+/*\t\t\t _\t       _\n+ *  _ __ ___\t___   __| |    ___ ___| |  mod_ssl\n+ * | '_ " _ / / _ / / _" |   / __/ __| |  Apache Interface to OpenSSL\n+ * | | | | | | (_) | (_| |   /__ /__ / |\n+ * |_| |_| |_|/___/ /__,_|___|___/___/_|\n+ *\t\t\t |_____|\n+ *  ssl_ocsp.c\n+ *  The SSL OCSP checking\n+ *\n+ *  Developed by Marc Stern, for Approach Belgium / CSC / Belgian Government\n+ *\t      based on code developed by Zetes Pass\n+ *\n+ *  This code was added to support the Belgian Electronic Identity Card\n+ *\n+ *  The OCSP responder URL is read from the certificate itself\n+ *\n+ */ \n+    /* ""When the only tool you own is a hammer,\n+\t  every problem begins to resemble a nail.????\n+     */ \n+    \n+#include 'mod_ssl.h'\n+#include 'ssl_private.h'\n+#include 'apr_base64.h'\n+\n+#define X509_NAME2STR(name_)\t     X509_NAME_oneline(name_, NULL, 0)\n+#define X509_SUBJ_NAME(cert_)\t    \nX509_NAME2STR(X509_get_subject_name(cert_))\n+#define X509_ISSUER_NAME(cert_)     X509_NAME2STR(X509_get_issuer_name(cert_))\n+\n+\n+static char *ap_ocsp_ASN1_Int2Str(ASN1_INTEGER *data, apr_pool_t *pool)\n+{\n+    char *result = (char *)apr_palloc(pool, 100); /* 100 should be enough */\n+    char *buf = NULL;\n+    BIGNUM *bn = ASN1_INTEGER_to_BN(data, NULL);\n+\n+    *result = 0;\n+    if (bn && !BN_is_zero(bn)) {\n+\t buf = BN_bn2hex(bn);\n+\t if (buf) {\n+\t     strncpy(result, buf, sizeof(result) - 1);\n+\t     result[sizeof(result) - 1 ] = 0;\n+\t }\n+    }\n+\n+    if (bn) BN_free(bn);\n+    if (buf) OPENSSL_free(buf);\n+    return result;\n+}\n+\n+static char *ap_ocsp_get_ocsp_uri(X509 *cert, apr_pool_t *pool)\n+{\n+    int crit, j;\n+    STACK_OF(ACCESS_DESCRIPTION) *values =\n+\t (STACK_OF(ACCESS_DESCRIPTION) *)\n+\t\tX509_get_ext_d2i(cert, NID_info_access, &crit, NULL);\n+    if (! values) return NULL;\n+\n+    for (j = 0; j < sk_ACCESS_DESCRIPTION_num(values); j++) {\n+\t ACCESS_DESCRIPTION *value = sk_ACCESS_DESCRIPTION_value(values, j);\n+\t if(OBJ_obj2nid(value->method) == NID_ad_OCSP) {\n+\t     /* Name found in extension */\n+\t\t\tchar *result;\n+\t\t\t\n+\t\t\t/* Check that it is a URI */\n+\t\t\tif (value->location->type != GEN_URI)\n+\t\t\t\tcontinue;\n+\n+\t     result = apr_pstrdup(pool,\n+\t\t\t      (char\n*)value->location->d.uniformResourceIdentifier->data);\n+\t\t\t AUTHORITY_INFO_ACCESS_free(values);\n+\t     return result;\n+\t }\n+    }\n+\n+\tsk_ACCESS_DESCRIPTION_free(values);\n+\t//AUTHORITY_INFO_ACCESS_free(values);\n+    return NULL;\n+}\n+\n+\n+static BIO *ap_ocsp_connect(const char *host, int port) \n+{\n+    BIO *connection = BIO_new_connect((char *)host);\n+    if (!connection) return 0;\n+\n+    BIO_set_conn_int_port(connection, &port);\n+    if (BIO_do_connect(connection) <= 0) {\n+\t /* Not needed - default: BIO_set_close(connection, BIO_CLOSE); */\n+\t BIO_free_all(connection);\n+\t return NULL;\n+    }\n+\n+    return connection;\n+\n+}\n+\n+\n+static OCSP_RESPONSE *ap_ocsp_sendreq(const char *ocspHost, const char\n*ocspPort, const char *ocspPath, OCSP_REQUEST *request, server_rec *s) \n+{\n+    BIO *bio = NULL;\n+    OCSP_RESPONSE *response = NULL;\n+\n+    /* establish a connection to the OCSP responder */ \n+    ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t 'Connect to OCSP responder '%s:%s'', ocspHost, ocspPort);\n+    bio = ap_ocsp_connect(ocspHost, atoi(ocspPort));\n+    if (!bio) {\n+\t ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t 'Cannot connect to OCSP responder '%s:%s'', ocspHost,\nocspPort);\n+\t return NULL;\n+    }\n+    \n+    /* send the request and get a response */ \n+    ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s,\n+\t\t 'sending request to OCSP responder');\n+    response = OCSP_sendreq_bio(bio, (char *)ocspPath, request);\n+    if (!response) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t\t 'Cannot send request to OCSP responder '%s'',\nocspHost);\n+\t }\n+\n+    BIO_free_all(bio);\n+\n+    return response;\n+}\n+\n+\n+static int ap_ocsp_verify_ocsp(X509 *cert, X509_STORE_CTX *ctx, server_rec *s,\n+\t\t\t\tint *ocspStatus, apr_pool_t *pool) \n+{\n+    int rc = SSL_OCSP_OK;\n+    X509 *issuer = NULL;\n+    char *ocspUrl = NULL, *ocspHost = NULL, *ocspPort = NULL, *ocspPath =\nNULL;\n+    BIO * bio = NULL;\n+    OCSP_RESPONSE * response = NULL;\n+    OCSP_BASICRESP * basicResponse = NULL;\n+    OCSP_REQUEST * request = NULL;\n+    OCSP_CERTID * certID = NULL;\n+    int ssl = 0;\n+    SSLSrvConfigRec *sc = mySrvConfig(s);\n+\tchar *subj_name = X509_SUBJ_NAME(cert);\n+\tchar *issuer_name = X509_ISSUER_NAME(cert);\n+\n+    *ocspStatus = V_OCSP_CERTSTATUS_UNKNOWN;\n+    X509_STORE_CTX_set_error(ctx, X509_V_ERR_APPLICATION_VERIFICATION);\n+    ap_log_error(APLOG_MARK, APLOG_INFO, 0, s,\n+\t 'OCSP check - cert='%s', issuer='%s'', subj_name, issuer_name);\n+   \n+    \n+    /* First look if we force the responder url*/\n+    if (sc->server->OCSPForceResponderURL) {\n+\t ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s,\n+\t\t 'Force the url of responder to: %s',\nsc->server->OCSPForceResponderURL);\n+\t ocspUrl = sc->server->OCSPForceResponderURL;\n+    }\n+    /* if not, look inside the certificate if we have one */\n+    else {\n+\t  /* Get OCSP Responder URI (only first one) */\n+\t ocspUrl = ap_ocsp_get_ocsp_uri(cert, pool); \n+\t if (ocspUrl)\n+\t     ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s,\n+\t\t 'OCSP responder from certificate: %s', ocspUrl);\n+    }\n+\n+    if (!ocspUrl && sc->server->OCSPDefaultResponderURL) {\n+\t ap_log_error(APLOG_MARK, APLOG_INFO, 0, s,\n+\t     'No Responder URL in certificate - using default: %s',\n+\t     sc->server->OCSPDefaultResponderURL);\n+\t ocspUrl = sc->server->OCSPDefaultResponderURL;\n+    }\n+\n+    if (!ocspUrl) {\n+\t ap_log_error(APLOG_MARK, APLOG_WARNING, 0, s,\n+\t  'Cannot get OCSP responder URL from '%s' and no default URL\nResponder',\n+\t  subj_name);\n+\t rc = SSL_OCSP_ERROR_PARSE_URL;\n+    }\n+    \n+    if (rc == SSL_OCSP_OK) {\n+\t if (!OCSP_parse_url(ocspUrl, &ocspHost, &ocspPort, &ocspPath, &ssl)) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t 'Cannot parse OCSP responder URL from '%s'',\n+\t\t\t\tsubj_name);\n+\t     rc = SSL_OCSP_ERROR_PARSE_URL;\n+\t }\n+    }\n+    \n+\n+    if (rc == SSL_OCSP_OK) {\n+\t ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, 'Create new OCSP\nrequest');\n+\t request = OCSP_REQUEST_new();\n+\t if (!request) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t\t 'Cannot create new OCSP request');\n+\t     rc = SSL_OCSP_ERROR_INTERNAL;\n+\t }\n+    }\n+    \n+    if (rc == SSL_OCSP_OK) {\n+\t /* Get issuer */\n+\t\tint r;\n+\t\t/* Enhancement: ctx->chain is already ordered -> extract 2nd ?\n*/\n+\t ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, 'Get Issuer');\n+\t r = X509_STORE_CTX_get1_issuer(&issuer, ctx, cert);\n+\t if (r != 1) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t\t 'Cannot get issuer of '%s'. rc=%d', subj_name, rc);\n+\t     rc = SSL_OCSP_ERROR_INTERNAL;\n+\t }\n+    }\n+\n+    if (rc == SSL_OCSP_OK) {\n+\t certID = OCSP_cert_to_id(0, cert, issuer);\n+\t if (!certID || !OCSP_request_add0_id(request, certID)) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s\n+\t\t\t, 'Cannot get certificate id from '%s'', subj_name);\n+\t     rc = SSL_OCSP_ERROR_INTERNAL;\n+\t }\n+    }\n+\n+    if (rc == SSL_OCSP_OK) {\n+\t OCSP_request_add1_nonce(request, 0, -1);\n+\n+\t /*  To use a proxy, do the following\n+\t       - ocspHost = proxyHost;\n+\t       - ocspPort = proxyPort;\n+\t       - ocspPath = ocspUrl;\n+\t  */\n+    \n+\t /* establish a connection to the OCSP responder */ \n+\t response = ap_ocsp_sendreq(ocspHost, ocspPort, ocspPath, request, s);\n+\t if (!response) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t     'Cannot send request to OCSP responder '%s'', ocspHost);\n+\t     rc = SSL_OCSP_ERROR_INTERNAL;\n+\t }\n+    }\n+\n+\n+    if ( (rc == SSL_OCSP_OK) && (s->loglevel >= APLOG_DEBUG) ) {\n+\t /* Log OCSP answer (complete OpenSSL buffer) */\n+\t char *buf = apr_palloc(pool,\n+\t\t\napr_base64_encode_len(response->responseBytes->response->length) + 1);\n+\t if (buf) {\n+\t     apr_base64_encode(buf,\n+\t\t\t (const char*)response->responseBytes->response->data,\n+\t\t\t response->responseBytes->response->length);\n+\t     ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s,\n+\t\t\t 'OCSP response (OpenSSL bufer): serial=%s | dn=%s |\n%s',\n+\t\t\t  ap_ocsp_ASN1_Int2Str(X509_get_serialNumber(cert),\npool),\n+\t\t\t   X509_SUBJ_NAME(cert), buf);\n+\t }\n+\t else {\n+\t    ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, 'Cannot allocate\nbuffer');\n+\t }\n+    }\n+\n+    if (rc == SSL_OCSP_OK) {\n+\t\tint r;\n+\t ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s,\n+\t\t 'Analyse OCSP request answer');\n+\t r = OCSP_response_status(response);\n+\t if (r != OCSP_RESPONSE_STATUS_SUCCESSFUL) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t\t 'Bad OCSP responder answer. rc=%d', rc);\n+\t     rc = SSL_OCSP_ERROR_INTERNAL;\n+\t }\n+    }\n+    \n+    if ( (rc == SSL_OCSP_OK) && (s->loglevel >= APLOG_DEBUG) ) {\n+\t /* Log OCSP answer (only the 'bare' response) */\n+\t int len = i2d_OCSP_RESPONSE(response, NULL);\n+\t if (len <= 0)\n+\t    rc = SSL_OCSP_ERROR_INTERNAL;\n+\t else {\n+\t\t\tunsigned char *buf1, *buf2;\n+\t     buf1 = buf2 = (unsigned char *)apr_palloc(pool, len);\n+\t     if (!buf1) {\n+\t\t\t\tap_log_error(APLOG_MARK, APLOG_ERR, 0, s, 'Out\nof memory');\n+\t\t rc = SSL_OCSP_ERROR_INTERNAL;\n+\t     }\n+\t     else {\n+\t\tif (i2d_OCSP_RESPONSE(response, &buf1) != len) \n+\t\t\t       rc = SSL_OCSP_ERROR_INTERNAL;\n+\t\telse {\n+\t\t     /* contents is in buf2, because buf1 is now pointing\n+\t\t\tto the end of the structure */\n+\t\t     char h[] = 'OCSP response : ';\n+\t\t     int len64 = apr_base64_encode_len(len);\n+\t\t     char *msg = (char *)apr_palloc(pool, len64 + strlen(h) +\n1);\n+\t\t     if (msg) {\n+\t\t\t strcpy(msg, h);\n+\t\t\t apr_base64_encode(msg + strlen(h), buf2, len);\n+\t\t\t msg[strlen(h) + len64 + 1] = 0;\n+\t\t\t ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, msg);\n+\t\t     }\n+\t\t}\n+\t    }\n+\t}\n+    }\n+\n+    if (rc == SSL_OCSP_OK) {\n+\t basicResponse = OCSP_response_get1_basic(response);\n+\t if (!basicResponse) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t\t 'Bad OCSP responder answer');\n+\t     rc = SSL_OCSP_ERROR_INTERNAL;\n+\t }\n+    }\n+\n+    if (rc == SSL_OCSP_OK) {\n+\t if (OCSP_check_nonce(request, basicResponse) <= 0) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t\t 'Bad OCSP responder answer (bad nonce)');\n+\t     rc = SSL_OCSP_ERROR_INTERNAL;\n+\t }\n+    }\n+\t \n+    if (rc == SSL_OCSP_OK) {\n+\t if (OCSP_basic_verify(basicResponse, 0, ctx->ctx,\n+\t\t sc->server->OCSPResponderVerifyFlag) <= 0) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t\t 'Error verifying OCSP responder answer');\n+\t     rc = SSL_OCSP_ERROR_INTERNAL;\n+\t }\n+    }\n+    \n+    if (rc == SSL_OCSP_OK) {\n+\t int ocspReason = -1;\n+\t ASN1_GENERALIZEDTIME * ocspProducedAt, *ocspThisUpdate,\n+\t     *ocspNextUpdate;\n+\t rc = OCSP_resp_find_status(basicResponse, certID, ocspStatus,\n+\t\t       &ocspReason, &ocspProducedAt,\n+\t\t       &ocspThisUpdate, &ocspNextUpdate);\n+\t if (rc == 0) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, 'Bad OCSP status');\n+\t     rc = SSL_OCSP_ERROR_INTERNAL;\n+\t }\n+    ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t 'OCSP validation completed: status=%d', *ocspStatus);\n+    rc = SSL_OCSP_OK;\n+    }\n+\n+    ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, 'Cleanup OCSP code');\n+\tif (issuer) X509_free(issuer);\n+\tif (subj_name)\t OPENSSL_free(subj_name);\n+\tif (issuer_name) OPENSSL_free(issuer_name);\n+    if (request)  OCSP_REQUEST_free(request);\n+    if (response) OCSP_RESPONSE_free(response);\n+    if (basicResponse) OCSP_BASICRESP_free(basicResponse);\n+\tif (ocspHost) OPENSSL_free(ocspHost);\n+\tif (ocspPort) OPENSSL_free(ocspPort);\n+\tif (ocspPath) OPENSSL_free(ocspPath);\n+    /* certID is just a pointer, nothing to free */ \n+\n+    ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s, 'Ending cleanup OCSP code');\n+    return rc;\n+}\n+\n+int ssl_cmd_VerifyOCSP(X509_STORE_CTX *ctx, server_rec *s, int *ocspStatus,\n+ apr_pool_t *pool) \n+{\n+    int rc = SSL_OCSP_OK, i;\n+    X509 *cert = X509_STORE_CTX_get_current_cert(ctx);\n+    X509_STORE_CTX *ocspCtx = NULL;\n+    X509_STORE *store = NULL;\n+    SSLSrvConfigRec *sc = mySrvConfig(s);\n+\tchar *subj_name = X509_SUBJ_NAME(cert);\n+\tchar *issuer_name = X509_ISSUER_NAME(cert);\n+\n+    ap_log_error(APLOG_MARK, APLOG_INFO, 0, s,\n+\t 'Validating certificate '%s', issuer: '%s'',\n+\t    subj_name, issuer_name);\n+    \n+    /* Store certif chain in a store */ \n+    if (!ctx->chain) {\n+\t ap_log_error(APLOG_MARK, APLOG_ERR, 0, s, 'No certificate chain');\n+\t return SSL_OCSP_ERROR_INTERNAL;\n+    }\n+\n+    /*\n+    ap_log_error(APLOG_MARK, APLOG_DEBUG, 0, s,\n+\t 'certificates chain length: %d', ctx->chain->num);\n+    */ \n+\n+    store = X509_STORE_new();\n+    if (!store) {\n+\t ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t 'Cannot create a new X509 store');\n+\t return SSL_OCSP_ERROR_INTERNAL;\n+    }\n+    \n+    for (i = 0; i < ctx->chain->num; i++)\n+    if (!X509_STORE_add_cert(store, sk_X509_value(ctx->chain, i))) {\n+\t ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t 'Cannot add certificate to X509 store');\n+\t rc = SSL_OCSP_ERROR_INTERNAL;\n+    }\n+\n+    if (rc == SSL_OCSP_OK) {\n+\t ocspCtx = X509_STORE_CTX_new();\n+\t if (!ocspCtx) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t     'Cannot create a new X509 context');\n+\t     rc = SSL_OCSP_ERROR_INTERNAL;\n+\t }\n+    }\n+    if (rc == SSL_OCSP_OK) {\n+\t if (X509_STORE_CTX_init(ocspCtx, store, cert, 0) != 1) {\n+\t     ap_log_error(APLOG_MARK, APLOG_ERR, 0, s,\n+\t\t\t 'Cannot initialise the new X509 context');\n+\t     rc = SSL_OCSP_ERROR_INTERNAL;\n+\t }\n+    }\n+\n+    if (rc == SSL_OCSP_OK)\n+\t rc = ap_ocsp_verify_ocsp(cert, ocspCtx, s, ocspStatus, pool);\n+\n+\t if (subj_name)   OPENSSL_free(subj_name);\n+\t if (issuer_name) OPENSSL_free(issuer_name);\n+    if (store)   X509_STORE_free(store);\n+    if (ocspCtx) X509_STORE_CTX_free(ocspCtx);\n+    return rc;\n+}\n
41123	Dr Stephen Henson	1192774147000	I've been looking into updating the patch to use mod_proxy and the sub request\nmechanism for OCSP queries. Unfortunately the request_rec structure is not set\nin SSL_get_app_exdata2() at the time it is needed and there doesn't appear to be\nan easy way to obtain it. This may be because the requested page is unknown at\nthis time because the SSL handshake is in progress and no HTTP headers have been\nsent. Does this make sub requests a non starter for OCSP or is it possible to\nuse an alternative technique?
41123	Joe Orton	1194505224000	*** Bug 31383 has been marked as a duplicate of this bug. ***
41123	Joe Orton	1194505611000	Yes it doesn't look like use of mod_proxy subrequests will be possible\nunfortunately, per discussion on dev@.\n\nI've got a heavily cleaned up version of the latest patch which I will attach\nshortly.\n\nI notice the latest patches have a comment 'based on code developed by Zetes\nPass' which scares me again.   It is important to understand that we cannot\ninclude code in the ASF repository unless the copyright status is clear.  So\nagain, Marc; is this an original contribution to which you entirely own the\ncopyright?  If some other party wrote half the code then we need a CLA from them\ntoo since this is a substantial contribution of new code.
41123	Marc Stern	1194507548000	> I notice the latest patches have a comment 'based on code developed by Zetes\n> Pass' which scares me again.\n> is this an original contribution to which you entirely own the\n> copyright?\nYou can remove the copyright, as\n1. the code I mentionned was developped for the same project (Belgian Government)\n2. Nothing exists anymore from the original code, I rewrote everything\nThis was a kind of 'recognition'
41123	Marc Stern	1194509641000	(In reply to comment #24)\n> I've got a heavily cleaned up version of the latest patch which I will attach\n> shortly.\n1. Just to notice that ocsp.c must also be added to config.m4, but I guess you\ndiscovered this.\n2. I also noticed that, in order to compile it with the latest Microsoft SDK\n(from Visual C++ 2008), we need to include 'openssl/ocsp.h' at the very\nbeginning of ssl_ocsp.h & ssl_engine_kernel.c.\n3. I am also planning to move the directives (SSLUseOCSP, etc.) to a location\nlevel, to offer more flexibility. Do you want to tackle this at the same time,\nor do you prefer I do it ?\n4. For which version did you plan to rework the patch ? 2.2.4, 2.2.6, Head ?
41123	Joe Orton	1195107239000	Created an attachment (id=21130)\nattempt 1 of refactored OCSP support\n\nThis is the cleaned up version of Marc's OCSP patch, diff relative to the\ntrunk.\t\n\nRelative changes:\n\n- moves OCSP code to ssl_engine_ocsp.c\n- heavily refactors, cleans up, simplifies code style etc in the above\n- tones down the debugging a lot.  some common helper functions are needed in\nssl_engine_log.c to log cert subject name etc, if desired\n- updates config.m4\n- removed error handling for OpenSSL functions which can only fail on OOM\n- removed poorly-named SSLOCSPResponderVerify (can be added back separately)\n- removed addition of SSLForceValidation, which is orthogonal to basic OCSP\nsupport (likewise add separately later)\n- reworked the config options to be:\n\n    SSLOCSPEnable <bool>\n    SSLOCSPOverrideResponder <bool>\n    SSLOCSPDefaultResponder <URL>\n\n  rather than redundantly having two directives to supply a URL.\n- simplify unnecessarily complex status/error handling for OCSP code \n\nThis is untested since my OCSP test setup is broken currently, so it probably\ndoesn't actually work.
41123	Joe Orton	1195107394000	(In reply to comment #26)\n> 1. Just to notice that ocsp.c must also be added to config.m4, but I guess you\n> discovered this.\n\nYup :)\n\n> 2. I also noticed that, in order to compile it with the latest Microsoft SDK\n> (from Visual C++ 2008), we need to include 'openssl/ocsp.h' at the very\n> beginning of ssl_ocsp.h & ssl_engine_kernel.c.\n\nWhy, what's the failure otherwise?  The #include in ssl_toolkit_compat.h should\nbe sufficient.\n\n> 3. I am also planning to move the directives (SSLUseOCSP, etc.) to a location\n> level, to offer more flexibility. Do you want to tackle this at the same time,\n> or do you prefer I do it ?\n\nSounds useful, let's get the basic functionality committed first then deal with\nstuff like that incrementally.\n\n> 4. For which version did you plan to rework the patch ? 2.2.4, 2.2.6, Head ?\n\ntrunk.\n
41123	Marc Stern	1195110649000	> > In order to compile it with the latest Microsoft SDK\n> > (from Visual C++ 2008), we need to include 'openssl/ocsp.h' at the very\n> > beginning of ssl_ocsp.h & ssl_engine_kernel.c.\n> \n> Why, what's the failure otherwise?  The #include in ssl_toolkit_compat.h\n> should be sufficient.\nSome general Apache include files end up in including standard MS SDK.\nIn latest SDK, MS defines some types if they are not defined yet. These types\nare defined by OpenSSL, so they have to be included before SDK .h, so before\nApache .h.\nThis could also be done in ssl_private.h: either include 'openssl/ocsp.h' before\nApache files, or 'ssl_toolkit_compat.h', or all 'ssl*.h' files.
41123	Marc Stern	1195111183000	(In reply to comment #27)\n> - removed addition of SSLForceValidation, which is orthogonal to basic OCSP\nThis is a very important feature (also for other validation mechanisms, like CRL\nor, maybe in the future LDAP).\nWithout that, the administrator cannot decide what to do when no validation\nmechanism is available (OCSp responder not available, or CRL files not up to\ndate). Depending on the server security level, the implementation will either be\nseen as conatining a security hole (the cert is accepted although it is\ninvalid),  or it will be considered as too strict (blocking valid users because\nof third party infrastsucture problems).\nThis is a feature that we see as crucial for most of the application owners.
41123	Joe Orton	1195111771000	(In reply to comment #30)\n> (In reply to comment #27)\n> > - removed addition of SSLForceValidation, which is orthogonal to basic OCSP\n> This is a very important feature (also for other validation mechanisms, like \n\nYes, that's fine, but it's also orthogonal to getting basic OCSP support\nworking, so it can be added afterwards.  Removing the intrusive changes to the\nverification callback makes the basic code easier to review and test.
41123	Dr Stephen Henson	1195188814000	Some comments on the latest patch.\n\n1. The function extract_responder_uri() has a memory leak. It should call:\n\nAUTHORITY_INFO_ACCESS_free(values);\n\ninstead of:\n\nsk_ACCESS_DESCRIPTION_free(values);\n\n2. After the call to apr_uri_parse() shouldn't we check the scheme is\nreally 'http'? I've heard of some responders which use 'https'. There is also\nthe possibility that the URL will be split up into a path and query string which\nshould be concatenated when passed to OpenSSL.\n\n3. The OCSP query code doesn't include a timeout. This is a problem with the\nOpenSSL's rather simplistic OCSP handler and the fact that there is no\ngeneralized socket timeout code in OpenSSL. There are several ways to work\naround this. The easiest is to use APR sockets with a timeout. See my OCSP query\ncode in Bug 43822\n\n4. The code unconditionally uses an OCSP nonce. Some responders do not sign\nevery request but just server pre-cached responses. As a result the nonce value\ncan't be honoured and an error will occur when attempting to use such\nresponders. The most notable example is VeriSign's OCSP responder but there are\nothers.\n
41123	Joe Orton	1196154135000	Created an attachment (id=21193)\nupdated patch\n
41123	Joe Orton	1196154837000	Changes in second patch:\n\n1) fixed to check URI scheme, and correctly free 'values' stack per Steve's comment\n\n2) drop the duplicate X509_STORE_CTX & X509_STORE creation.  I can't see why\nthis is necessary; Marc, can you explain what that was for?  OCSP_basic_verify()\ncreates its own X509_STORE_CTX anyway in which to do the verify the response\nsignature, so it was never used directly.  Dropping this doesn't seem to make\nany difference to result in testing, either.\n\nWas this just here to allow for future customisation of how the response\nsignature is verified?\n\n3) simplified some more logging/debugging.  Uses the new ssl_log_cxerror()\nfunction added on the trunk to log cert details as context.\n\nSteve, thanks for a lot for the review - agree with your points (3) and (4) but\nwould like to address these later.
41123	Joe Orton	1196155115000	[adding CC]
41123	Dr Stephen Henson	1196182341000	> \n> 2) drop the duplicate X509_STORE_CTX & X509_STORE creation.  I can't see why\n> this is necessary; Marc, can you explain what that was for?  \n\nI haven't tested it explicitly but I think the extra X509_STORE and ctx was\nintended to extract the issuer certificate from the client certificate in a\nreliable way.\n\nNote that X509_STORE_CTX_get1_issuer() will only retrieve the issuer certificate\nif it is trusted, hence the extra store to make all certificates trusted. To see\nwhy suppose you have this situation:\n\nRoot->Intermediate->Cert\n\nWhere Root only is trusted. The client would send Cert and Intermediate. The\nOpenSSL validation logic would then build the whole chain.\n\nA call to X509_STORE_CTX_get1_issuer() would fail because Intermediate is not in\nthe trusted store.\n\nIn actual fact it isn't necessary to create a separate store because the\ncertificate chain has already been built and validated. All you should need to\ndo is to extract the second member of the validated chain like this....\n\nissuer = sk_X509_value(X509_STORE_CTX_get_chain(ctx), 1);\nif (issuer == NULL) /* Error */\n\nSince issuer is an internal pointer it shouldn't be freed as it will be freed up\nwhen the ctx is cleaned up.\n\nOh and btw you do need to free up certID.\n
41123	Joe Orton	1196217281000	OK, but the SSLVerify callback (and hence this OCSP validation code) is invoked\nfor each and (necessarily) every cert from the root CA down to the peer's\ncertificate, to verify the complete chain - so:\n\n1) we must always be able to assume that the issuer of the\nX509_STORE_CTX_get_current_cert() cert is trusted, since otherwise we wouldn't\nget this far?\n\n2) sk_X509_value(X509_STORE_CTX_get_chain(ctx), 1) is not necessarily the issuer\nof the current cert - it might *be* the current cert?\n\n...right?  Or am I missing something fundamental?\n\nOn the CERTID front, if I add \n\n    if (certID) OCSP_CERTID_free(certID);\n\nit crashes on that line:\n\n#0  0x0000003800e75edb in free () from /lib64/libc.so.6\n#1  0x00000038094572fd in CRYPTO_free () from /lib64/libcrypto.so.6\n#2  0x00000038094bcc37 in ASN1_STRING_free () from /lib64/libcrypto.so.6\n...
41123	Joe Orton	1196249839000	Created an attachment (id=21201)\nfinal patch\n\nFinal patch before committing to trunk.  Changes:\n\n1) factors out the HTTP client into ssl_util_ocsp, and re-implements using APR\nfunctions directly; fixing I/O timeout handling, server address handling, and\nadding response memory use constraints rather than streaming into RAM\nindefinitely (!) as the OpenSSL code does.  Also allows this code to be easily\nswitched out for a Real HTTP Client (TM) later.\n\n2) removes the debugging code which dumps base64-encoded which seems overkill;\ntcpdump/wireshark works for such case.\n\n3) use a temporary pool to constrain connection pool memory use\n
41123	Dr Stephen Henson	1196256230000	> \n> 1) we must always be able to assume that the issuer of the\n> X509_STORE_CTX_get_current_cert() cert is trusted, since otherwise we wouldn't\n> get this far?\n> \n\nI'll check the current patch. As things stand I suspect if the server just\ntrusts a root CA and the client sends root->intermediate->EE it will fail to\nfind the intermediate CA because it isn't in the store.\n\n> 2) sk_X509_value(X509_STORE_CTX_get_chain(ctx), 1) is not necessarily the issuer\n> of the current cert - it might *be* the current cert?\n> \n> ...right?  Or am I missing something fundamental?\n> \n\nI was missing something. I was assuming the OCSP calls were being made *after*\nthe chain is validated instead of inside the verification callback.\n\nIf you make OCSP calls inside the verification callback the chain may not be\nfully trusted when you make the OCSP requests. This would allow a carefully\nconstructed certificate chain to persuade a server to make arbitrary OCSP\nrequests to any URL. Some would regard this as undesirable.\n\n> On the CERTID front, if I add \n> \n>     if (certID) OCSP_CERTID_free(certID);\n> \n> it crashes on that line:\n> \n\nYes, I missed that, sorry. It will be freed when the request is freed.\n\n
41123	Joe Orton	1196260108000	(In reply to comment #39)\n> I was missing something. I was assuming the OCSP calls were being made *after*\n> the chain is validated instead of inside the verification callback.\n> \n> If you make OCSP calls inside the verification callback the chain may not be\n> fully trusted when you make the OCSP requests. This would allow a carefully\n> constructed certificate chain to persuade a server to make arbitrary OCSP\n> requests to any URL. Some would regard this as undesirable.\n\nIf the cert being verified is not trusted the SSLVerify callback will get\ninvoked with ok=0 though surely? (the OCSP code won't get invoked in that case,\nonly if the cert *is* trusted) \n\nBut I did find this confusing, anyway.  Is it at all desirable to be doing OCSP\nvalidation of every cert in the chain, including whatever root CA?  Marc, was\nthe code written like this deliberately?\n\nIt would be simple enough to only do the OCSP validation for the actual peer cert.
41123	Dr Stephen Henson	1196266429000	It wasn't quite as bad as I originally though. The final verification step is\nthe signature validation of each cert in the chain. So if that is successful the\ncallback is called ok==1 for each cert in the chain. \n\nI thought that the chain went leaf to root which would have allowed arbitrary\nURIs from a bogus chain.\n\nInstead it goes root to leaf which isn't as bad but would allow a bogus EE cert\nto trigger chain validation because it isn't checked until the end.\n\nAs things stand the current_issuer field of X509_STORE_CTX can be used to obtain\nthe issuer cert. Think that was first added in OpenSSL 0.9.7.\n\nThe only other case is when ok is set to 1 because it tolerates an earlier\nerror. That could end up doing an OCSP (and CRL) check twice AFAICS.\n\n\n
41123	Joe Orton	1196307774000	Committed to trunk:\n\nhttp://svn.apache.org/viewvc?view=rev&revision=599385\n\nthanks to all for the patches, review, and patience to those who have worked on\nthis.\n\nFurther work:\n\n* add config options to configure whether CRL-and/or-OCSP validation is\nmandatory as in the 'ForceValidation' config option, whether a nonce is used,\nwhat verification flags are passed to OCSP_basic_verify()\n\n* move verification to per-location context?\n\npatches welcome for all the above!  Marking this fixed; for issues with the\ncommitted code please file new bugs or mail dev@httpd, likewise for discussion\nof above future work.  (and as always, patches welcome!)
41123	Marc Stern	1196309658000	(In reply to comment #40)\n> Is it at all desirable to be doing OCSP validation of every cert in the chain,\n> including whatever root CA?\n> It would be simple enough to only do the OCSP validation for the actual peer\n> cert.\nIf you compromise the intermediate certificate, you could create a fake OCSP\nserver, with responses that will be accepted by Apache. The only way to ensure\nthe OCSP response is valid is to validate its certificate, and the same up to\nthe root.
41144	Davi Arnaut	1165763718000	Created an attachment (id=19240)\npatch against the 2.2.x branch\n
41144	Davi Arnaut	1165763944000	ap_proxy_date_canon is called for the fowling headers:\n\n'Date', 'Expires', 'Last-Modified'\n\nHeader example:\n\n'Date: Monday, oops'\n\n\n
41144	Nick Kew	1165766234000	A simpler fix would just be to check strlen of the date at the top of the\nfunction, wouldn't it?
41144	Davi Arnaut	1165780831000	(In reply to comment #3)\n> A simpler fix would just be to check strlen of the date at the top of the\n> function, wouldn't it?\n\nNot quite, because the length varies per date format. Well, let's make it less likely to bite us later.\n
41144	Davi Arnaut	1166711049000	Created an attachment (id=19299)\nproxy canon date gmt\n
41144	Davi Arnaut	1166711221000	The first patch version incorrectly converted the time in local timezone instead of GMT.
41144	Nick Kew	1166785218000	Both your patches are identical - but they're more sensible than the original\ncode.  I'm updating it to use gmt as you intended, and made the tiny\noptimisation of avoiding a copy.
41144	Nick Kew	1166785380000	Created an attachment (id=19301)\nupdated patch on 2.2\n
41144	Nick Kew	1166785948000	Should've mentioned: my patch relies on Davi's patch to have got the format right:-)\n\nMore importantly, this needs to be applied to trunk ahead of 2.2.x.
41144	Davi Arnaut	1166791219000	I double checked, the patches are not identical. Anyway, your patch is better. Thanks.
41144	Davi Arnaut	1186552641000	Committed to trunk in revision 561616:\n\nhttp://svn.apache.org/viewvc?view=rev&rev=561616\n\nBackported to 2.2.x in revision 563198:\n\nhttp://svn.apache.org/viewvc?view=rev&rev=563198\n\nBackported to 2.0.x in revision 563329:\n\nhttp://svn.apache.org/viewvc?view=rev&rev=563329
41148	Joe Orton	1165817357000	What is missing that -DNO_DETACH (prevent the parent from forking) and \n-DFOREGROUND (prevent the parent from calling setsid() et al) do not provide?\n\nUse of some hack like -C 'ErrorLog '|cat'' can force error logging to stderr,\npossibly some easier way with -E and /proc/*/fd.
41148	Luke Kenneth Casson Leighton	1165827478000	joe, hi,\n\nthanks for pointing that out!  i'll try it out.\n\nfunny.  been looking for this for nearly 18 months, and richard's been\nlooking for it for probably three years.\n\ni'll boot up my laptop with depinit on it and let you know, straight away,\nif it works.\n
41148	Luke Kenneth Casson Leighton	1165829034000	ok: yes, that works as expected.  so the question becomes, really, how come\ntwo experienced linux developers could not find that option, easily, by\nlooking in every place that they could think of?\n\nman pages, online, documentation - nothing mentions -DFOREGROUND in any\nof the kinds of prominent places in which you'd expect to find advice on\nhow to run the world's most popular web server in a mode which dramatically\nchanges how it operates.\n\nbizarre!\n\n
41148	Joe Orton	1165829765000	Obligatory 'use the source, Luke' jokes aside, no answers... changing to Docs bug.
41148	Joshua Slive	1185888084000	Added to the docs for httpd -D in trunk.
41193	Davi Arnaut	1166354330000	Created an attachment (id=19272)\nRemove useless calls to apr_os_sock_get\n
41193	Jeff Trawick	1166943177000	thanks for the patch\ncommitted to trunk
41231	Michael Stapelberg	1166868167000	Apparantly the APR_BUCKET_IS_EOC is true for some reason, so \nssl_filter_io_shutdown is called and the result is not filtered via SSL \nanymore. Before APR_BUCKET_IS_EOC is true, ssl_filter_write (which is called \nwhen APR_BUCKET_IS_EOC is not true) is called two times with NULL as data-\npointer. \n\nI don't know if this is normal behaviour and i'm not very into debugging \napache, but maybe it gives a hint to the developers.
41231	Joe Orton	1194332608000	Fixed on trunk:  http://svn.apache.org/viewvc?view=rev&revision=592446
41475	Ruediger Pluem	1170334058000	*** Bug 41516 has been marked as a duplicate of this bug. ***
41475	Ruediger Pluem	1170744545000	Could you please give the attached patch a try and report back whether it solves\nyour problem?
41475	Ruediger Pluem	1170744578000	Created an attachment (id=19529)\nPatch against trunk\n
41475	Lars Uffmann	1170746925000	(In reply to comment #2)\n> Could you please give the attached patch a try and report back whether it solves\n> your problem?\n\nI applied your patch against 2.2.4.\n\nThe testcase I used to report the problem (see above) worked for me.
41475	Dean Scothern	1171262931000	(In reply to comment #4)\n> (In reply to comment #2)\n> > Could you please give the attached patch a try and report back whether it solves\n> > your problem?\n> \n> I applied your patch against 2.2.4.\n> \n> The testcase I used to report the problem (see above) worked for me.\n\nConfirming that this solved my problems also (duplicate reported bug 41516),\nwhen applied to 2.2.4.
41475	Ruediger Pluem	1171283412000	Thanks for the feedback. Committed to trunk as r506621\n(http://svn.apache.org/viewvc?view=rev&revision=506621).
41475	Ruediger Pluem	1179411611000	Backported to 2.2.x as r539112 (http://svn.apache.org/viewvc?view=rev&rev=539112).
41484	Fredrik Widlund	1169988882000	Created an attachment (id=19473)\nPatch to add CacheIgnoreQueryString option\n
41484	Ruediger Pluem	1170638359000	The patch looks good in general. Please fix the following things such that it\ncan be appplied:\n\n1. Provide a version of this patch against trunk.\n2. Provide a patch for the documentation (docs/manual/mod/mod_cache.xml) to\n   document the new directive.\n3. Provide the diff files in unix format (only LF at the end) if possible.\n   Otherwise just mention that they are in DOS format (CR-LF).
41484	Ruediger Pluem	1170638815000	Forgot one thing:\n\nPlease put\n\nint ignorequerystring;\nint ignorequerystring_set;\n\nat the end of the cache_server_conf struct to avoid binary incompatibility and\nthus the need for a major bump. A patch that creates binary incompatibility\ncannot be backported to 2.2.x.\nPutting them to the end of the structure only requires a minor bump which can be\nbackported (include/ap_mmn.h).
41484	Fredrik Widlund	1170738041000	Created an attachment (id=19527)\nPatch against trunk adding IgnoreQueryString directive\n
41484	Fredrik Widlund	1170738138000	Created an attachment (id=19528)\nPatch against trunk adding documentation for IgnoreQueryString\n
41484	Fredrik Widlund	1170740839000	1/2/3:\nDone\n\nKind regards,\nFredrik Widlund
41484	Ruediger Pluem	1170748747000	Committed with some minor style fixes as r504183\n(http://svn.apache.org/viewvc?view=rev&revision=504183) to trunk. For future\npatches please ensure that they follow the style guide\n(http://httpd.apache.org/dev/styleguide.html) (especially no tabs). Thanks for\nsubmitting the patch.
41484	Ruediger Pluem	1178527727000	Proposed for backport to 2.2.x as r535911\n(http://svn.apache.org/viewvc?view=rev&rev=535911).
41484	Ruediger Pluem	1179411626000	Backported to 2.2.x as r539111 (http://svn.apache.org/viewvc?view=rev&rev=539111).
41484	Thomas Van de Velde	1186057231000	I am pretty sure this was not committed to the 2.2.4 release. Is this version\nset correctly?
41551	Eric Covener	1176410504000	I am seeing the etag blown away on 2.2.4 and trunk as well, running with a\nsingle child process and no concurrent connections.  This happens _before_\nrevalidation based on Expires or Age (on a particular system/config 4th\nnon-conditional request gets the ETag removed in some way (truncated, random\ngarbage)\n\nI was occasionally seeing the Last-Modified time set to 0 as well, but not able\nto reproduce it as easily.
41551	Eric Covener	1176441766000	Created an attachment (id=19948)\ndon't use apr_table_copy to store/recall headers\n\nnaive patch to deep copy in/out headers before storing/retrieving from cache.\n\nwhen retrieving, we only bother to do the deep copy to appease pool debugging,\nwho would abort even when the cache pool is longer living, but not an ancester\nof, the request pool.\n
41551	Xuekun Hu	1176689932000	(In reply to comment #2)\n> Created an attachment (id=19948) [edit]\n> don't use apr_table_copy to store/recall headers\n> naive patch to deep copy in/out headers before storing/retrieving from cache.\n> when retrieving, we only bother to do the deep copy to appease pool debugging,\n> who would abort even when the cache pool is longer living, but not an ancester\n> of, the request pool.\n\nNo. Your patch didn't resolve this issue. The same error still was blown away. 
41551	Davi Arnaut	1177702663000	Ouch, that's my fault. I naively believed that apr_table_copy copied the table data. We should revert \nrevision 484642 ASAP.
41551	Davi Arnaut	1177703838000	Created an attachment (id=20064)\ntable copy warning\n
41551	Davi Arnaut	1177704864000	Created an attachment (id=20065)\ndeep table copy\n
41551	Davi Arnaut	1177704935000	Could you try the above patch and let me know if you still have these errors? Thanks.
41551	Xuekun Hu	1177876933000	(In reply to comment #7)\n> Could you try the above patch and let me know if you still have these errors? \nThanks.\n\nI tried your patch with several hours run, all seems fine. Thanks \n\n
41551	Davi Arnaut	1178638595000	Created an attachment (id=20150)\ntable copy (clone) function for apr\n
41551	Ruediger Pluem	1188190080000	Backported to 2.2.x as r555626 (http://svn.apache.org/viewvc?\nview=rev&revision=555626).
41796	Michael Krieger	1173378535000	My TEMPORARY solution was to create these virtualhosts (apparently it's an IP6\nrequest in my configuration, so I needed the second).\n\n<Virtualhost 127.0.0.1>\n        ServerName      localhost\n        DocumentRoot    /var/www\n</VirtualHost>\n<Virtualhost [::1]>\n        ServerName      localhost\n        DocumentRoot    /var/www\n</VirtualHost>\n\nAt least these I know will return MY dummy file instead of a huge PHP script\nwhere the database queries and numbers do matter.\n\nHowever, this issue needs to be addressed if this method is used to wake up the\nchildren.  Making requests blindly and without care to a Web server can throw\noff numbers in more than the logs in an era where everything is dynamic.  The\nREQUEST FILE either NEEDS to be configurable, or the HOST NEEDS to be\nconfigurable, or the request TYPE needs to be harmless and dealt with\ninternally, or the request needs to be silently handled internally without doing\nany processing.  Either way really, with the preference being internally\nhandling it, then changing the type.\n
41796	Joe Orton	1173685807000	Agreed, as discussed recently on dev@ - committed in: \n\nhttp://svn.apache.org/viewvc?view=rev&revision=517233
41798	Nick Kew	1189352288000	*** Bug 35100 has been marked as a duplicate of this bug. ***
41798	Nick Kew	1189355102000	*** Bug 42592 has been marked as a duplicate of this bug. ***
41798	Nick Kew	1189393846000	*** Bug 39455 has been marked as a duplicate of this bug. ***
41798	Nick Kew	1193414927000	Fixed in Trunk in r588791.
41798	Nick Kew	1195543791000	Fixed in r596712.
41798	Wil Tan	1206977087000	I have an instance of mod_proxy doing reverse proxying using the 'nocanon' parameter in the ProxyPass directive. The reason I needed this was that I'm dealing with IRIs on the path, and mod_proxy was decoding the characters for me.\n\nIn any case, I find that when 'nocanon' is turned on, mod_proxy appends the query twice and sent it to the target host, e.g.:\n\nOriginal request:\n\nhttp://mod-proxy-host.com/path?query\n\nThe target was sent:\n\nhttp://localhost:8003/target?query?query\n\n\nThis seems to be due to r->unparsed_uri containing the original query, whereas r->uri doesn't (and other parts of the code appends it to the target.)
41798	Wil Tan	1206977183000	Created an attachment (id=21743)\nProof-of-concept that fixes the issue\n\nThis is meant to demonstrate that it fixes the issue. However, I have not checked for security issues or whether it breaks other configurations.
41798	Nick Kew	1206978180000	Comments 6 and 7 appear to be opening a new report.  Please don't hijack an old report for that.  And if we're to take your NEW report seriously, we'll need more information, such as a configuration and request that trigger the problem with 2.2.8.
41798	Wil Tan	1207047814000	Sorry for hijacking this report. I've created bug 44730 to track the issue.
41826	Ruediger Pluem	1173795990000	*** Bug 41833 has been marked as a duplicate of this bug. ***
41826	Joshua Slive	1174983462000	Fixed. Thanks.
41826	Takashi Sato	1181778201000	*** Bug 41767 has been marked as a duplicate of this bug. ***
41826	Takashi Sato	1183449081000	please backport to 2.0\nhttp://httpd.apache.org/docs/2.0/en/mod/mod_access.html
41826	Takashi Sato	1185900379000	backported\nhttp://svn.apache.org/viewvc?view=rev&revision=561438
41829	Torsten F	1173748200000	Created an attachment (id=19700)\nit initializes opts.override_opts properly\n
41829	Torsten F	1174901129000	Fixed as revision 522011, see\n\nhttp://svn.apache.org/viewvc?view=rev&revision=522011
41835	Nick Kew	1185435231000	This is a bug, but it's actually just some of the comparisons being reversed!\nIn a related bug, integer comparisons to 0 will fail.\n\nHacking a patch now.
42005	Christophe JAILLET	1175350344000	Created an attachment (id=19853)\nProposed patch\n
42005	Nick Kew	1184870690000	http://svn.apache.org/viewvc?view=rev&revision=557837\n
42006	Christophe JAILLET	1175351041000	Created an attachment (id=19854)\nProposed patch\n
42006	Christophe JAILLET	1175353032000	Created an attachment (id=19858)\nCorrected patch\n
42006	Nick Kew	1184870706000	http://svn.apache.org/viewvc?view=rev&revision=557837\n
42007	Christophe JAILLET	1175351668000	Created an attachment (id=19855)\nProposed patch\n
42007	Nick Kew	1184870727000	http://svn.apache.org/viewvc?view=rev&revision=557837\n
42008	Christophe JAILLET	1175352435000	Created an attachment (id=19856)\nProposed patch\n
42008	Nick Kew	1184870739000	http://svn.apache.org/viewvc?view=rev&revision=557837\n
42008	Ruediger Pluem	1185195229000	This patch is not contained in r557837.
42009	Christophe JAILLET	1175352804000	Created an attachment (id=19857)\nProposed patch\n
42009	Nick Kew	1184870751000	http://svn.apache.org/viewvc?view=rev&revision=557837\n
42031	Ruediger Pluem	1175606465000	I have not have the time to analyse this in more detail, but from first glance I\ntend to say that the lock aquired in line 1058 of event.c is being held for too\nlong, such that we can run into a deadlock. In the backtrace below thread 2 is\nholding this lock and preventing all the worker threads from doing their jobs\n(they need to get hold of this lock). OTH thread 2 waits for a free worker via a\nconditional wait. BOOOM.
42031	Paul Querna	1187621102000	Created an attachment (id=20684)\n2.2.x deadlock fix\n\nHere is a patch that might fix this issue on 2.2.x.  I haven't been able to\nlocally reproduce it --  can you please try this patch out and let me know if\nit fixes the issue?\n\nThis reorders the locking logic inside the timeout ring iteration, so that we\nonly lock when doing ops on the ring, but once we are ready to push to a child,\nwe are lock free.
42031	Paul Querna	1187622789000	I've committed a potential fix to trunk with r567852:\nhttps://svn.apache.org/viewvc?view=rev&revision=567852\n\nThe approach is different form the patch attached here -- it avoids rewriting\nthe loops.
42031	Takashi Sato	1187684618000	> Here is a patch that might fix this issue on 2.2.x.  I haven't been able to\n> locally reproduce it --  can you please try this patch out and let me know if\n> it fixes the issue?\n\nI wasn't able to reproduce the bug on 2.2.x. I should've mentioned it.
42031	Takashi Sato	1187686864000	Now I can't reproduce the bug on trunk rev 567852 nor rev 525116.\n(4) execute many downloading simultaneously,\nThen child process exit signal Segmentation fault.\nWhy???\n\ngdb output (rev 525116)\n\n(gdb) run -X\nStarting program: /usr/local/apache2/bin/httpd -X\n[Thread debugging using libthread_db enabled]\n[New Thread -1208502592 (LWP 561)]\n[New Thread -1208738928 (LWP 574)]\n[New Thread -1219228784 (LWP 575)]\n[New Thread -1229718640 (LWP 576)]\n[New Thread -1240208496 (LWP 577)]\n[New Thread -1250698352 (LWP 578)]\n[Thread -1208738928 (LWP 574) exited]\n\nProgram received signal SIGPIPE, Broken pipe.\n[Switching to Thread -1240208496 (LWP 577)]\n0x00110402 in __kernel_vsyscall ()\n(gdb) thread apply all bt full\n\nThread 6 (Thread -1250698352 (LWP 578)):\n#0  0x00110402 in __kernel_vsyscall ()\nNo symbol table info available.\n#1  0x003e2b21 in __lll_mutex_unlock_wake () from /lib/libpthread.so.0\nNo symbol table info available.\n#2  0x003df839 in _L_mutex_unlock_99 () from /lib/libpthread.so.0\nNo symbol table info available.\n#3  0x003df4b0 in __pthread_mutex_unlock_usercnt () from /lib/libpthread.so.0\nNo symbol table info available.\n#4  0x003df830 in pthread_mutex_unlock () from /lib/libpthread.so.0\nNo symbol table info available.\n#5  0x0016b37e in apr_thread_mutex_unlock (mutex=0x9a99010)\n    at /home/user1/httpd-trunk/srclib/apr/locks/unix/thread_mutex.c:121\n\tstatus = 0\n#6  0x0809518f in ap_queue_push (queue=0x9a98ff8, sd=0x9b2bec8, cs=0x0, \np=0x9b2be90)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/fdqueue.c:337\n\telem = (fd_queue_elem_t *) 0x9a99094\n\trv = 0\n#7  0x08091cc7 in listener_thread (thd=0x9a991d0, dummy=0x9ac7168)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1027\n\trc = 0\n\tti = (proc_info *) 0x9ac7168\n\tprocess_slot = 0\n\ttpool = (apr_pool_t *) 0x9aa2f80\n\tcsd = (void *) 0x9b2bec8\n\tptrans = (apr_pool_t *) 0x9b2be90\n\tlr = (ap_listen_rec *) 0x9a33520\n\thave_idle_worker = 1\n\tcs = (conn_state_t *) 0x9b0dea0\n\tout_pfd = (const apr_pollfd_t *) 0x9aa3080\n\tnum = 1\n\ttime_now = 1187710557998374\n\ttimeout_interval = 1000000\n\ttimeout_time = 1187710558098374\n\tpt = (listener_poll_type *) 0x9aa30b0\n#8  0x00179754 in dummy_worker (opaque=0x9a991d0)\n    at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142\n\tthread = (apr_thread_t *) 0x9a991d0\n#9  0x003dc44b in start_thread () from /lib/libpthread.so.0\nNo symbol table info available.\n#10 0x002bd80e in clone () from /lib/libc.so.6\nNo symbol table info available.\n\nThread 5 (Thread -1240208496 (LWP 577)):\n#0  0x00110402 in __kernel_vsyscall ()\nNo symbol table info available.\n#1  0x002b41ee in sendfile64 () from /lib/libc.so.6\nNo symbol table info available.\n#2  0x00173b2a in apr_socket_sendfile (sock=0x9b2bec8, file=0x9b2c618, \nhdtr=0x17f9f8, offset=0xb613e0e0, \n    len=0xb613e0dc, flags=0) at /home/user1/httpd-\ntrunk/srclib/apr/network_io/unix/sendrecv.c:329\n\trv = 0\n\tnbytes = 0\n\ttotal_hdrbytes = 0\n\ti = 134909576\n\tarv = 1569892\n\toff = 16384\n#3  0x0807a583 in sendfile_nonblocking (s=0x9b2bec8, bucket=0x9b2e0c8, \ncumulative_bytes_written=0x9b2c5d0, \n    c=0x9b2c0c0) at /home/user1/httpd-trunk/server/core_filters.c:774\n\tn = 190898180\n\tarv = 0\n\told_timeout = 10000000\n\trv = 0\n\tfile_bucket = (apr_bucket_file *) 0x9b2e018\n\tfd = (apr_file_t *) 0x9b2c618\n\tfile_length = 190898180\n\tfile_offset = 16384\n\tbytes_written = 0\n#4  0x08079ea7 in send_brigade_nonblocking (s=0x9b2bec8, bb=0x9b2c5f8, \nbytes_written=0x9b2c5d0, c=0x9b2c0c0)\n    at /home/user1/httpd-trunk/server/core_filters.c:576\n\tfile_bucket = (apr_bucket_file *) 0x9b2e018\n\tfd = (apr_file_t *) 0x9b2c618\n\tdid_sendfile = 1\n\tbucket = (apr_bucket *) 0x9b2e0c8\n\tnext = (apr_bucket *) 0x9b2e070\n\trv = 162731568\n\tvec = {{iov_base = 0x9b31388, iov_len = 0}, {iov_base = 0x9b2c09c, \niov_len = 162717632}, {\n    iov_base = 0x9b31368, iov_len = 162728960}, {iov_base = 0x9b31488, iov_len \n= 0}, {iov_base = 0x0, \n    iov_len = 162727224}, {iov_base = 0x0, iov_len = 162731128}, {iov_base = \n0x9b2dfc0, \n    iov_len = 162717808}, {iov_base = 0x9b31388, iov_len = 3054756344}, \n{iov_base = 0x8074626, \n    iov_len = 162728960}, {iov_base = 0x9b31488, iov_len = 0}, {iov_base = \n0x0, iov_len = 190914564}, {\n    iov_base = 0x0, iov_len = 162717632}, {iov_base = 0x198e18, iov_len = \n162103320}, {iov_base = 0x0, \n    iov_len = 0}, {iov_base = 0x16e525, iov_len = 4129}, {iov_base = \n0xffffffff, iov_len = 162031304}}\n\tnvec = 0\n#5  0x08079c97 in ap_core_output_filter (f=0x9b2c568, new_bb=0x9b2c6a0)\n    at /home/user1/httpd-trunk/server/core_filters.c:488\n\trv = 162709608\n\tc = (conn_rec *) 0x9b2c0c0\n\tnet = (core_net_rec *) 0x9b2c540\n\tctx = (core_output_filter_ctx_t *) 0x9b2c5c8\n\tbb = (apr_bucket_brigade *) 0x9b2c5f8\n\tbucket = (apr_bucket *) 0x9b2c5fc\n\tnext = (apr_bucket *) 0x9b2c5fc\n\tbytes_in_brigade = 190898180\n\tnon_file_bytes_in_brigade = 0\n#6  0x08087609 in ap_pass_brigade (next=0x9b2c568, bb=0x9b2c6a0)\n    at /home/user1/httpd-trunk/server/util_filter.c:526\n\te = (apr_bucket *) 0x9b2dfc0\n#7  0x0808b0e5 in ap_process_async_request (r=0x9b2fed8)\n    at /home/user1/httpd-trunk/modules/http/http_request.c:261\n\taccess_status = 0\n\tbb = (apr_bucket_brigade *) 0x9b2c6a0\n\tb = (apr_bucket *) 0x9b2dfc0\n\tc = (conn_rec *) 0x9b2c0c0\n#8  0x08087b6a in ap_process_http_async_connection (c=0x9b2c0c0)\n    at /home/user1/httpd-trunk/modules/http/http_core.c:140\n\tr = (request_rec *) 0x9b2fed8\n\tcs = (conn_state_t *) 0x9b2c068\n#9  0x0808353f in ap_run_process_connection (c=0x9b2c0c0) at /home/user1/httpd-\ntrunk/server/connection.c:43\n\tpHook = (ap_LINK_process_connection_t *) 0x9ac1970\n\tn = 0\n\trv = -2\n#10 0x080911eb in process_socket (p=0x9b2be90, sock=0x9b2bec8, cs=0x9b2c068, \nmy_child_num=0, \n    my_thread_num=2) at /home/user1/httpd-\ntrunk/server/mpm/experimental/event/event.c:626\n\tc = (conn_rec *) 0x9b2c0c0\n\tpt = (listener_poll_type *) 0x9b2c0a0\n\tconn_id = 2\n\trc = -2\n\tsbh = (ap_sb_handle_t *) 0x9b2c060\n#11 0x080921e8 in worker_thread (thd=0x9a991b0, dummy=0x9ac7158)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1194\n\tti = (proc_info *) 0x9ac7158\n\tprocess_slot = 0\n\tthread_slot = 2\n\tcsd = (apr_socket_t *) 0x9b2bec8\n\tcs = (conn_state_t *) 0x0\n\tptrans = (apr_pool_t *) 0x9b2be90\n\trv = 0\n\tis_idle = 0\n#12 0x00179754 in dummy_worker (opaque=0x9a991b0)\n    at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142\n\tthread = (apr_thread_t *) 0x9a991b0\n#13 0x003dc44b in start_thread () from /lib/libpthread.so.0\nNo symbol table info available.\n#14 0x002bd80e in clone () from /lib/libc.so.6\nNo symbol table info available.\n\nThread 4 (Thread -1229718640 (LWP 576)):\n#0  0x00110402 in __kernel_vsyscall ()\nNo symbol table info available.\n#1  0x003e0206 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/libpthread.so.0\nNo symbol table info available.\n#2  0x0016cf4f in apr_thread_cond_wait (cond=0x9a99040, mutex=0x9a99010)\n    at /home/user1/httpd-trunk/srclib/apr/locks/unix/thread_cond.c:68\n\trv = 0\n#3  0x08095200 in ap_queue_pop (queue=0x9a98ff8, sd=0xb6b3f38c, cs=0xb6b3f388, \np=0xb6b3f384)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/fdqueue.c:363\n\telem = (fd_queue_elem_t *) 0x0\n\trv = 0\n#4  0x08092147 in worker_thread (thd=0x9a99190, dummy=0x9ac7168)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1162\n\tti = (proc_info *) 0x9ac7168\n\tprocess_slot = 0\n\tthread_slot = 1\n\tcsd = (apr_socket_t *) 0x9ad1970\n\tcs = (conn_state_t *) 0x9ad1b10\n\tptrans = (apr_pool_t *) 0x9ad1938\n\trv = 0\n\tis_idle = 1\n#5  0x00179754 in dummy_worker (opaque=0x9a99190)\n    at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142\n\tthread = (apr_thread_t *) 0x9a99190\n#6  0x003dc44b in start_thread () from /lib/libpthread.so.0\nNo symbol table info available.\n#7  0x002bd80e in clone () from /lib/libc.so.6\nNo symbol table info available.\n\nThread 3 (Thread -1219228784 (LWP 575)):\n#0  0x00110402 in __kernel_vsyscall ()\nNo symbol table info available.\n#1  0x002b41ee in sendfile64 () from /lib/libc.so.6\nNo symbol table info available.\n#2  0x00173b2a in apr_socket_sendfile (sock=0x9ac78d8, file=0x9ac8028, \nhdtr=0x17f9f8, offset=0xb7540190, \n    len=0xb754018c, flags=0) at /home/user1/httpd-\ntrunk/srclib/apr/network_io/unix/sendrecv.c:329\n\trv = 0\n\tnbytes = 0\n\ttotal_hdrbytes = 0\n\ti = 0\n\tarv = 162676768\n\toff = 10301440\n#3  0x0807a583 in sendfile_nonblocking (s=0x9ac78d8, bucket=0x9ac9ad8, \ncumulative_bytes_written=0x9ac7fe0, \n    c=0x9ac7ad0) at /home/user1/httpd-trunk/server/core_filters.c:774\n\tn = 183644164\n\tarv = 0\n\told_timeout = 10000000\n\trv = 0\n\tfile_bucket = (apr_bucket_file *) 0x9ac9a28\n\tfd = (apr_file_t *) 0x9ac8028\n\tfile_length = 183644164\n\tfile_offset = 7270400\n\tbytes_written = 0\n#4  0x08079ea7 in send_brigade_nonblocking (s=0x9ac78d8, bb=0x9ac80c0, \nbytes_written=0x9ac7fe0, c=0x9ac7ad0)\n    at /home/user1/httpd-trunk/server/core_filters.c:576\n\tfile_bucket = (apr_bucket_file *) 0x9ac9a28\n\tfd = (apr_file_t *) 0x9ac8028\n\tdid_sendfile = 1\n\tbucket = (apr_bucket *) 0x9ac9ad8\n\tnext = (apr_bucket *) 0x9ac9a80\n\trv = 0\n\tvec = {{iov_base = 0x9afbc70, iov_len = 162511984}, {iov_base = \n0x9afa3d8, iov_len = 162503552}, {\n    iov_base = 0x0, iov_len = 162505488}, {iov_base = 0x1302f4, iov_len = \n3075736136}, {\n    iov_base = 0x8087564, iov_len = 162505304}, {iov_base = 0x9afa3d8, iov_len \n= 2549142}, {\n    iov_base = 0x17bccc, iov_len = 3075736132}, {iov_base = 0x0, iov_len = \n162511752}, {iov_base = 0xb, \n    iov_len = 0}, {iov_base = 0x46cb065c, iov_len = 457949}, {iov_base = \n0x9af9d70, iov_len = 0}, {\n    iov_base = 0x9af9da4, iov_len = 3075736184}, {iov_base = 0x806ae86, \niov_len = 0}, {iov_base = 0x0, \n    iov_len = 3075736184}, {iov_base = 0x806ce1f, iov_len = 162512072}, \n{iov_base = 0x9b23e20, \n    iov_len = 3075736216}}\n\tnvec = 0\n#5  0x08079ad6 in ap_core_output_filter (f=0x9ac7f78, new_bb=0x0)\n    at /home/user1/httpd-trunk/server/core_filters.c:423\n\trv = 304\n\tc = (conn_rec *) 0x9ac7ad0\n\tnet = (core_net_rec *) 0x9ac7f50\n\tctx = (core_output_filter_ctx_t *) 0x9ac7fd8\n\tbb = (apr_bucket_brigade *) 0x9ac80c0\n\tbucket = (apr_bucket *) 0x3e2b21\n\tnext = (apr_bucket *) 0x9ac8330\n\tbytes_in_brigade = 162297992\n\tnon_file_bytes_in_brigade = 4112372\n#6  0x0809123c in process_socket (p=0x9ac78a0, sock=0x9ac78d8, cs=0x9ac7a78, \nmy_child_num=0, \n    my_thread_num=0) at /home/user1/httpd-\ntrunk/server/mpm/experimental/event/event.c:644\n\toutput_filter = (ap_filter_t *) 0x9ac7f78\n\trv = 0\n\tc = (conn_rec *) 0x9ac7ad0\n\tpt = (listener_poll_type *) 0x9ac7ab0\n\tconn_id = 0\n\trc = 2\n\tsbh = (ap_sb_handle_t *) 0x9ac8330\n#7  0x080921e8 in worker_thread (thd=0x9a99170, dummy=0x9ac7158)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1194\n\tti = (proc_info *) 0x9ac7158\n\tprocess_slot = 0\n\tthread_slot = 0\n\tcsd = (apr_socket_t *) 0x9ac78d8\n\tcs = (conn_state_t *) 0x9ac7a78\n\tptrans = (apr_pool_t *) 0x9ac78a0\n\trv = 0\n\tis_idle = 0\n#8  0x00179754 in dummy_worker (opaque=0x9a99170)\n    at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142\n\tthread = (apr_thread_t *) 0x9a99170\n#9  0x003dc44b in start_thread () from /lib/libpthread.so.0\nNo symbol table info available.\n#10 0x002bd80e in clone () from /lib/libc.so.6\nNo symbol table info available.\n\nThread 1 (Thread -1208502592 (LWP 561)):\n#0  0x00110402 in __kernel_vsyscall ()\nNo symbol table info available.\n#1  0x003e3f3e in do_sigwait () from /lib/libpthread.so.0\nNo symbol table info available.\n#2  0x003e3fdf in sigwait () from /lib/libpthread.so.0\nNo symbol table info available.\n#3  0x0017b242 in apr_signal_thread (signal_handler=0x8092279 <check_signal>)\n    at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/signals.c:383\n\tsignal_received = 4095\n\tsig_mask = {__val = {1073340935, 4294967294, 4294967295 <repeats 30 \ntimes>}}\n\tsig_func = (int (*)(int)) 0x8092279 <check_signal>\n#4  0x08092be4 in child_main (child_num_arg=0)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1520\n\tthreads = (apr_thread_t **) 0x9ac7148\n\trv = 0\n\tts = (thread_starter *) 0x9a98f90\n\tthread_attr = (apr_threadattr_t *) 0x9a98fa0\n\tstart_thread_id = (apr_thread_t *) 0x9a98fd8\n#5  0x08092d42 in make_child (s=0x9a36f78, slot=0)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1602\n\tpid = 0\n#6  0x08092e4b in startup_children (number_to_start=1)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1658\n\ti = 0\n#7  0x08093570 in ap_mpm_run (_pconf=0x9a350a8, plog=0x9a65168, s=0x9a36f78)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1978\n\tremaining_children_to_start = 1\n#8  0x08064aeb in main (argc=2, argv=0xbff4d244) at /home/user1/httpd-\ntrunk/server/main.c:750\n\tc = 88 'X'\n\tconfigtestonly = 0\n\tconfname = 0x80a0e3d 'conf/httpd.conf'\n\tdef_server_root = 0x80a0e4d '/usr/local/apache2'\n\ttemp_error_log = 0x0\n\terror = 0x0\n\tprocess = (process_rec *) 0x9a33128\n\tserver_conf = (server_rec *) 0x9a36f78\n\tpglobal = (apr_pool_t *) 0x9a330a0\n\tpconf = (apr_pool_t *) 0x9a350a8\n\tplog = (apr_pool_t *) 0x9a65168\n\tptemp = (apr_pool_t *) 0x9a69178\n\tpcommands = (apr_pool_t *) 0x9a370b0\n\topt = (apr_getopt_t *) 0x9a37148\n\trv = 0\n\tmod = (module **) 0x80ae0b0\n\toptarg = 0x0\n\tsignal_server = (apr_OFN_ap_signal_server_t *) 0\n#0  0x00110402 in __kernel_vsyscall ()\n(gdb) c\nContinuing.\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x00117186 in apr_brigade_cleanup (data=0x0)\n    at /home/user1/httpd-trunk/srclib/apr-util/buckets/apr_brigade.c:42\n42\t    while (!APR_BRIGADE_EMPTY(b)) {\n(gdb) thread apply all bt full\n\nThread 6 (Thread -1250698352 (LWP 578)):\n#0  0x00110402 in __kernel_vsyscall ()\nNo symbol table info available.\n#1  0x003e0206 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/libpthread.so.0\nNo symbol table info available.\n#2  0x0016cf4f in apr_thread_cond_wait (cond=0x9a99108, mutex=0x9a990d8)\n    at /home/user1/httpd-trunk/srclib/apr/locks/unix/thread_cond.c:68\n\trv = 0\n#3  0x08094e70 in ap_queue_info_wait_for_idler (queue_info=0x9a990c0)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/fdqueue.c:158\n\trv = 0\n\tprev_idlers = 0\n#4  0x08091849 in get_worker (have_idle_worker_p=0xb573d364)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:855\n\trc = 4112372\n#5  0x08091f10 in listener_thread (thd=0x9a991d0, dummy=0x9ac7168)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1087\n\trc = 0\n\tti = (proc_info *) 0x9ac7168\n\tprocess_slot = 0\n\ttpool = (apr_pool_t *) 0x9aa2f80\n\tcsd = (void *) 0x9b2bec8\n\tptrans = (apr_pool_t *) 0x9b2be90\n\tlr = (ap_listen_rec *) 0x9a33520\n\thave_idle_worker = 0\n\tcs = (conn_state_t *) 0x9ae5c40\n\tout_pfd = (const apr_pollfd_t *) 0x9aa3094\n\tnum = 0\n\ttime_now = 1187710592861859\n\ttimeout_interval = 1000000\n\ttimeout_time = 1187710592961859\n\tpt = (listener_poll_type *) 0x9aa30b0\n#6  0x00179754 in dummy_worker (opaque=0x9a991d0)\n    at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142\n\tthread = (apr_thread_t *) 0x9a991d0\n#7  0x003dc44b in start_thread () from /lib/libpthread.so.0\nNo symbol table info available.\n#8  0x002bd80e in clone () from /lib/libc.so.6\nNo symbol table info available.\n\nThread 5 (Thread -1240208496 (LWP 577)):\n#0  0x00117186 in apr_brigade_cleanup (data=0x0)\n    at /home/user1/httpd-trunk/srclib/apr-util/buckets/apr_brigade.c:42\n\tb = (apr_bucket_brigade *) 0x0\n\te = (apr_bucket *) 0x0\n#1  0x08079921 in ap_core_output_filter (f=0x9b2c568, new_bb=0x0)\n    at /home/user1/httpd-trunk/server/core_filters.c:357\n\tc = (conn_rec *) 0x9b2c0c0\n\tnet = (core_net_rec *) 0x9b2c540\n\tctx = (core_output_filter_ctx_t *) 0x9b2c5c8\n\tbb = (apr_bucket_brigade *) 0x808366d\n\tbucket = (apr_bucket *) 0x0\n\tnext = (apr_bucket *) 0x9b2c068\n\tbytes_in_brigade = 3054756600\n\tnon_file_bytes_in_brigade = 134755647\n#2  0x0809123c in process_socket (p=0x9b2be90, sock=0x9b2bec8, cs=0x9b2c068, \nmy_child_num=0, \n    my_thread_num=2) at /home/user1/httpd-\ntrunk/server/mpm/experimental/event/event.c:644\n\toutput_filter = (ap_filter_t *) 0x9b2c568\n\trv = 0\n\tc = (conn_rec *) 0x9b2c0c0\n\tpt = (listener_poll_type *) 0x9b2c0a0\n\tconn_id = 2\n\trc = -2\n\tsbh = (ap_sb_handle_t *) 0x9b2c060\n#3  0x080921e8 in worker_thread (thd=0x9a991b0, dummy=0x9ac7158)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1194\n\tti = (proc_info *) 0x9ac7158\n\tprocess_slot = 0\n\tthread_slot = 2\n\tcsd = (apr_socket_t *) 0x9b2bec8\n\tcs = (conn_state_t *) 0x0\n\tptrans = (apr_pool_t *) 0x9b2be90\n\trv = 0\n\tis_idle = 0\n#4  0x00179754 in dummy_worker (opaque=0x9a991b0)\n    at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142\n\tthread = (apr_thread_t *) 0x9a991b0\n#5  0x003dc44b in start_thread () from /lib/libpthread.so.0\nNo symbol table info available.\n#6  0x002bd80e in clone () from /lib/libc.so.6\nNo symbol table info available.\n\nThread 4 (Thread -1229718640 (LWP 576)):\n#0  0x00110402 in __kernel_vsyscall ()\nNo symbol table info available.\n#1  0x003e2a0e in __lll_mutex_lock_wait () from /lib/libpthread.so.0\nNo symbol table info available.\n#2  0x003de883 in _L_mutex_lock_79 () from /lib/libpthread.so.0\nNo symbol table info available.\n#3  0x003de3ad in pthread_mutex_lock () from /lib/libpthread.so.0\nNo symbol table info available.\n#4  0x0016b2fc in apr_thread_mutex_lock (mutex=0x9aa2fb8)\n    at /home/user1/httpd-trunk/srclib/apr/locks/unix/thread_mutex.c:92\n\trv = 0\n#5  0x080912c0 in process_socket (p=0x9b0dcc8, sock=0x9b0dd00, cs=0x9b0dea0, \nmy_child_num=0, \n    my_thread_num=1) at /home/user1/httpd-\ntrunk/server/mpm/experimental/event/event.c:656\n\toutput_filter = (ap_filter_t *) 0x9b0e3a0\n\trv = 0\n\tc = (conn_rec *) 0x9b0def8\n\tpt = (listener_poll_type *) 0x9b0ded8\n\tconn_id = 1\n\trc = 2\n\tsbh = (ap_sb_handle_t *) 0x9b0e568\n#6  0x080921e8 in worker_thread (thd=0x9a99190, dummy=0x9ac7168)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1194\n\tti = (proc_info *) 0x9ac7168\n\tprocess_slot = 0\n\tthread_slot = 1\n\tcsd = (apr_socket_t *) 0x9b0dd00\n\tcs = (conn_state_t *) 0x9b0dea0\n\tptrans = (apr_pool_t *) 0x9b0dcc8\n\trv = 0\n\tis_idle = 0\n#7  0x00179754 in dummy_worker (opaque=0x9a99190)\n    at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142\n\tthread = (apr_thread_t *) 0x9a99190\n#8  0x003dc44b in start_thread () from /lib/libpthread.so.0\nNo symbol table info available.\n#9  0x002bd80e in clone () from /lib/libc.so.6\nNo symbol table info available.\n\nThread 3 (Thread -1219228784 (LWP 575)):\n#0  0x00110402 in __kernel_vsyscall ()\nNo symbol table info available.\n#1  0x003e2a0e in __lll_mutex_lock_wait () from /lib/libpthread.so.0\nNo symbol table info available.\n#2  0x003de883 in _L_mutex_lock_79 () from /lib/libpthread.so.0\nNo symbol table info available.\n#3  0x003de3ad in pthread_mutex_lock () from /lib/libpthread.so.0\nNo symbol table info available.\n#4  0x0016b2fc in apr_thread_mutex_lock (mutex=0x9aa2fb8)\n    at /home/user1/httpd-trunk/srclib/apr/locks/unix/thread_mutex.c:92\n\trv = 0\n#5  0x080912c0 in process_socket (p=0x9ac78a0, sock=0x9ac78d8, cs=0x9ac7a78, \nmy_child_num=0, \n    my_thread_num=0) at /home/user1/httpd-\ntrunk/server/mpm/experimental/event/event.c:656\n\toutput_filter = (ap_filter_t *) 0x9ac7f78\n\trv = 0\n\tc = (conn_rec *) 0x9ac7ad0\n\tpt = (listener_poll_type *) 0x9ac7ab0\n\tconn_id = 0\n\trc = 2\n\tsbh = (ap_sb_handle_t *) 0x9ac8330\n#6  0x080921e8 in worker_thread (thd=0x9a99170, dummy=0x9ac7158)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1194\n\tti = (proc_info *) 0x9ac7158\n\tprocess_slot = 0\n\tthread_slot = 0\n\tcsd = (apr_socket_t *) 0x9ac78d8\n\tcs = (conn_state_t *) 0x9ac7a78\n\tptrans = (apr_pool_t *) 0x9ac78a0\n\trv = 0\n\tis_idle = 0\n#7  0x00179754 in dummy_worker (opaque=0x9a99170)\n    at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/thread.c:142\n\tthread = (apr_thread_t *) 0x9a99170\n#8  0x003dc44b in start_thread () from /lib/libpthread.so.0\nNo symbol table info available.\n#9  0x002bd80e in clone () from /lib/libc.so.6\nNo symbol table info available.\n\nThread 1 (Thread -1208502592 (LWP 561)):\n#0  0x00110402 in __kernel_vsyscall ()\nNo symbol table info available.\n#1  0x003e3f3e in do_sigwait () from /lib/libpthread.so.0\nNo symbol table info available.\n#2  0x003e3fdf in sigwait () from /lib/libpthread.so.0\nNo symbol table info available.\n#3  0x0017b242 in apr_signal_thread (signal_handler=0x8092279 <check_signal>)\n    at /home/user1/httpd-trunk/srclib/apr/threadproc/unix/signals.c:383\n\tsignal_received = 4095\n\tsig_mask = {__val = {1073340935, 4294967294, 4294967295 <repeats 30 \ntimes>}}\n\tsig_func = (int (*)(int)) 0x8092279 <check_signal>\n#4  0x08092be4 in child_main (child_num_arg=0)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1520\n\tthreads = (apr_thread_t **) 0x9ac7148\n\trv = 0\n\tts = (thread_starter *) 0x9a98f90\n\tthread_attr = (apr_threadattr_t *) 0x9a98fa0\n\tstart_thread_id = (apr_thread_t *) 0x9a98fd8\n#5  0x08092d42 in make_child (s=0x9a36f78, slot=0)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1602\n\tpid = 0\n#6  0x08092e4b in startup_children (number_to_start=1)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1658\n\ti = 0\n#7  0x08093570 in ap_mpm_run (_pconf=0x9a350a8, plog=0x9a65168, s=0x9a36f78)\n    at /home/user1/httpd-trunk/server/mpm/experimental/event/event.c:1978\n\tremaining_children_to_start = 1\n#8  0x08064aeb in main (argc=2, argv=0xbff4d244) at /home/user1/httpd-\ntrunk/server/main.c:750\n\tc = 88 'X'\n\tconfigtestonly = 0\n\tconfname = 0x80a0e3d 'conf/httpd.conf'\n\tdef_server_root = 0x80a0e4d '/usr/local/apache2'\n\ttemp_error_log = 0x0\n\terror = 0x0\n\tprocess = (process_rec *) 0x9a33128\n\tserver_conf = (server_rec *) 0x9a36f78\n\tpglobal = (apr_pool_t *) 0x9a330a0\n\tpconf = (apr_pool_t *) 0x9a350a8\n\tplog = (apr_pool_t *) 0x9a65168\n\tptemp = (apr_pool_t *) 0x9a69178\n\tpcommands = (apr_pool_t *) 0x9a370b0\n\topt = (apr_getopt_t *) 0x9a37148\n\trv = 0\n\tmod = (module **) 0x80ae0b0\n\toptarg = 0x0\n\tsignal_server = (apr_OFN_ap_signal_server_t *) 0\n0x00117186\t42\t    while (!APR_BRIGADE_EMPTY(b)) {\n(gdb) c\nContinuing.\n\nProgram terminated with signal SIGSEGV, Segmentation fault.\nThe program no longer exists.\n(gdb) quit\n
42031	Paul Querna	1187691536000	Your latest backtrace appears to be a separate bug. The crashing thread is\ncrashing in sendfile_nonblocking, which is also new code in trunk.
42031	Paul Querna	1187692107000	Please update to trunk again, I believe I have fixed the last crash with r568202:\nhttps://svn.apache.org/viewvc?view=rev&revision=568202
42031	Takashi Sato	1187719688000	I tried two source trees:\n(A)rev 568202\n(B)rev 568202 + revert r567852 ( svn merge -r 567852:567851 ./ )\n\n(A) works fine, there seems to be no issues.\nAnd I can reproduce the dead lock bug on (B).\nRESOLVED FIXED?\n\nthanks\n\n
42031	Takashi Sato	1187723347000	sorry, not resolved\n\nOn (A), repeat \n(4) execute many downloading simultaneously.\n(5) terminate downloading\nthen child freezes.\n\nReproducing the deadlock issue on (A) is harder than on (B),\nso r567852 is effective but not complete, IMHO.
42031	Takashi Sato	1187746876000	I took a bachtrace of a frozen child process.\nThe bt was the same as  bt I have posted in April.\n\n'Reproducing the deadlock issue on (A) is harder than on (B)' was how I felt, \nbut now seems wrong.
42031	Takashi Sato	1187759834000	I tried 2.2 and reproduced the deadlock, so I tried that patch against 2.2.\n\nAother error occurs:\n\n[Wed Aug 22 19:51:22 2007] [error] event_loop: unexpected state 2\n[Wed Aug 22 19:51:22 2007] [crit] [Wed Aug 22 19:51:22 2007] \nfile /home/user1/httpd-2.2.x/server/mpm/experimental/event/event.c, line 925, \nassertion '0' failed\n[Wed Aug 22 19:51:23 2007] [notice] child pid 17224 exit signal Aborted (6)\n\nThis error occurs when I access a HTML page from browser.
42031	Takashi Sato	1188899065000	Created an attachment (id=20769)\nfor trunk\n\nHow about this patch?\n\nnow:\napr_thread_mutex_lock(timeout_mutex)\nget_worker(&have_idle_worker)\nAPR_RING_REMOVE(cs, timeout_list)\napr_thread_mutex_unlock(timeout_mutex)\npush2worker(&cs->pfd, event_pollset)\n\nthis patch:\napr_thread_mutex_lock(timeout_mutex)\nAPR_RING_REMOVE(cs, timeout_list)\napr_thread_mutex_unlock(timeout_mutex)\nget_worker(&have_idle_worker)\npush2worker(&cs->pfd, event_pollset)
42031	Paul Querna	1189463428000	I've committed a slightly modified version of your patch in r574462.
42096	Takashi Sato	1183591938000	I think 'Deny from all' is wasteful.\n\nRequire valid-user\nOrder allow,deny\nAllow from 192.168.1\nSatisfy Any
42096	Alexander Koch	1183640853000	You are right, if the Order statement is 'Order allow,deny'. So the example could be like yours.
42096	Tony Stevenson	1185460188000	Patch applied.  http://svn.apache.org/viewvc?view=rev&rev=559990\nShould be visible within a few hours.\n\nCheers,\nTony\n
42186	Issac Goldstand	1177223065000	Created an attachment (id=20011)\nPatch to fix bug\n
42186	Nick Kew	1185431028000	Patch committed to /trunk/ in http://svn.apache.org/viewvc?view=rev&revision=559804
42186	Nick Kew	1186120073000	http://svn.apache.org/viewvc?view=rev&revision=562441
42286	Davi Arnaut	1177796065000	Which functions ? Meanwhile, this might do the trick:\n\nextern 'C' {\n    #include 'ap_mpm.h' \n}
42286	Takashi Sato	1177814635000	(In reply to comment #1)\n> Which functions ? \nMy module written in C++ needs to call ap_mpm_query.\n\n>Meanwhile, this might do the trick:\nYes, I'm using it.\n\n\nHeaders files which declare functions with extern 'C' :\nap_regex.h\nap_regkey.h\nhttp_config.h\nhttp_connection.h\nhttp_core.h\nhttp_log.h\nhttp_protocol.h\nhttp_request.h\nhttp_vhost.h\nhttpd.h\nmpm_common.h\nscoreboard.h\nutil_ebcdic.h\nutil_filter.h\nutil_md5.h\nutil_mutex.h\nutil_script.h\nutil_time.h\nutil_xml.h\n\nHeaders files which declare functions without extern 'C' :\nap_listen.h\nap_mpm.h\nap_provider.h\nutil_cfgtree.h\nutil_ldap.h
42286	Davi Arnaut	1178100619000	Created an attachment (id=20092)\nAdd a few missing externs to the headers\n
42286	Davi Arnaut	1178258439000	Committed to trunk, revision 535169, by Ruediger Pluem.
42286	Ruediger Pluem	1178714199000	Backported to 2.2.x as r536627 (http://svn.apache.org/viewvc?view=rev&rev=536627)
42549	Eric Covener	1180530101000	Created an attachment (id=20293)\nmimic htcacheclean trunk build for httxt2dbm\n\nnot sure if there's an EOL issue in patch, working outside of comfort zone
42549	Will Rowe	1198272069000	all resolved for 2.2.7
42572	Davi Arnaut	1181023472000	Created an attachment (id=20311)\nFixes NULL pointer deference in the winnt mpm\n\nWhen creating threads, the index (i) might not be sequential if the scoreboard\nentry status is not SERVER_GRACEFUL or SERVER_DEAD.\n\nCould you try the patch and let me know if the error still happens? Thanks.
42572	Nick Kew	1186412781000	(In reply to comment #1)\n> Created an attachment (id=20311) [edit]\n> Fixes NULL pointer deference in the winnt mpm\n\nThe patch looks right, but should probably also log an error (at EMERG or at\nleast CRIT level if the server has just leaked a whole thread?)\n\nIt would be good to know whether Davi's patch at least stops the crashing.
42572	Marcos Boyington	1186427913000	Davi's fix does work, tested on the same server, crashing stopped.
42572	Nick Kew	1191782046000	This got fixed in trunk but missed the changelog.  I guess it wants backporting.
42572	Will Rowe	1192467039000	Fixed in trunk and for the next 2.2.7 release, thanks for the patch!\n
42592	Nick Kew	1189355102000	This appears to be an instance of PR #41798.\n\n*** This bug has been marked as a duplicate of 41798 ***
42592	Nick Kew	1191860411000	This is not in fact a duplicate of PR 41798.  Although the symptoms are the\nsame, the code path and therefore the fix are entirely different.\n\nThis is a good report of the forward proxy bug with a testcase I could easily\nreproduce, so I'm re-opening it with a more generic title, in order to document\nthe bug and its fix.
42592	Nick Kew	1191860612000	*** Bug 35100 has been marked as a duplicate of this bug. ***
42592	Nick Kew	1191860721000	*** Bug 39455 has been marked as a duplicate of this bug. ***
42592	Nick Kew	1191862197000	Fixed in trunk in r583002.
42592	Nick Kew	1195543820000	Fixed in r596712.
42757	Joe Orton	1200660616000	Fixed on trunk, http://svn.apache.org/viewcvs.cgi?rev=613263&view=rev
42993	Nikolas Coukouma	1185707771000	Created an attachment (id=20562)\nPatch against 2.2.4\n\nThis moves the code for getting Content-Encoding in deflate_out_filter into a\nseparate (static) function so that inflate_out_filter can use the exact same\ncode. It also updates the clearing of Content-Encoding so it's done a bit later\n(after triying to initialize zlib, which is when the Content-Length header is\nremoved) and updates both the header table and r->content_encoding.
42993	Nikolas Coukouma	1185707918000	Created an attachment (id=20563)\nPatch against trunk\n\nThis makes the same changes, but against trunk. All that's changed is line\nnumbers, so it applies cleanly.
42993	Nick Kew	1186464084000	http://svn.apache.org/viewvc?view=rev&rev=563464
42993	Nick Kew	1186464473000	Ouch.  I didn't look carefully enough.  This bug is fixed in /trunk/ but still\npending for 2.2.
42993	Jim Jagielski	1186648393000	In 2.2.5-dev...
43183	Brian Rectanus	1187712309000	Created an attachment (id=20686)\npatch typo\n
43183	Vincent Bray	1187741664000	The attached patch changes the code rather than the docs. Could dev@ confirm that the code rather than \nthe docs are wrong?\n\nIf not I'll fix up the docs.
43183	Ruediger Pluem	1187784904000	Please fix the docs. Thus we avoid regressions with configurations in the wild\nthat found out this situation and adjusted their config to the code.
43183	Brian Rectanus	1187789284000	What about all those that have read the docs, have their configs set as such? \nThose people continue to have broken setups if you fix the docs.  Changing the\ncode will at least allow people using the proxy-sendchunked env var to start\nworking in the next release.  I think the chances of someone noticing this in\nthe code and adjusting their configs is much less than someone following the\ndocs and never verifying that it was working.  Look how long this bug has been\nthere as proof of this.
43183	Brian Rectanus	1187789338000	If you do decide to fix the docs, please fix the code comments as well.
43183	Vincent Bray	1187789956000	Grepping the (trunk) sources gives:\n\n./docs/manual/env.html.en:329:   <h3><a name='proxy' id='proxy'>force-proxy-request-1.0, proxy-nokeepalive, proxy-\nsendchunked, proxy-sendcl</a></h3>\n./docs/manual/env.html.ja.euc-jp:321:   <h3><a name='proxy' id='proxy'>force-proxy-request-1.0, proxy-nokeepalive, \nproxy-sendchunked, proxy-sendcl</a></h3>\n./docs/manual/env.xml:369:   <section id='proxy'><title>force-proxy-request-1.0, proxy-nokeepalive, proxy-sendchunked, \nproxy-sendcl</title>\n./docs/manual/env.xml.ja:356:   <section id='proxy'><title>force-proxy-request-1.0, proxy-nokeepalive, proxy-\nsendchunked, proxy-sendcl</title>\n./docs/manual/mod/mod_proxy.html.en:289:    <code>proxy-sendchunked</code> minimizes resource usage by using\n./docs/manual/mod/mod_proxy.xml:260:    <code>proxy-sendchunked</code> minimizes resource usage by using\n./modules/proxy/mod_proxy_http.c:910:     *   not setenv proxy-sendchunked or has set setenv proxy-sendcl\n./modules/proxy/mod_proxy_http.c:913:     *   setenv proxy-sendcl, and not setenv proxy-sendchunked\n./modules/proxy/mod_proxy_http.c:915:     * If both proxy-sendcl and proxy-sendchunked are set, the\n./modules/proxy/mod_proxy_http.c:921:     * To reduce server resource use,   setenv proxy-sendchunked\n\nSo it's clear that there's some confusion over the variable name. In fact, there's more references to 'proxy-sendchunked' in the \ncode comments than there are in the docs.\n\nI was about to commit a sed-style fix to the trunk docs, but I'm holding off in case send-chunked (which seems to me a better \nphrase) wins out over send-chunks (which at least has comical value to the English :)
43183	Jeff Trawick	1187885921000	My suggestion:\nDouble-check that all docs say 'chunked' instead of 'chunks'.\nFor code in 2.0.x and 2.2.x 'stable' branches, check for 'chunked' like the docs\nsay now, as well as 'chunks' which somebody who read the code might use.\nFor code in trunk, check only 'chunked'.\n
43183	Vincent Bray	1187934647000	Created an attachment (id=20699)\nCheck for both -s and -ed variants in 2.2\n\nCheck for both sendchunks and sendchunked in 2.2 following from Jeff Trawick's\nsuggestion. Brian's original patch for trunk is also valid. No changes required\nfor the 2.2 docs, or any comments in the C code.
43183	Vincent Bray	1187934779000	Created an attachment (id=20700)\nCheck for -s and -ed variants in 2.0\n\nAgain following from Jeff Trawick's suggestion, this time for 2.0. The 2.0 docs\ndon't mention either variant in env.xml, so I guess there's no changes to make\nthere.\n\nPlease review the logic of both patches carefully, as I'm not a C coder and not\nparticularly confident that it's right.
43183	Brian Rectanus	1188417630000	Sorry, been busy ;)\n\nThe patches in comments #8 and #9 look fine.  I have not tested, though (no\ntime) as I applied my patch to our 2.2.x tree.\n\nThanks Vincent!\n\n-B
43183	Ruediger Pluem	1188828466000	Backported to 2.2.x as r572421 (http://svn.apache.org/viewvc?rev=572421&view=rev).
43210	Phil Endecott	1187967590000	Created an attachment (id=20703)\nPatch as described\n
43210	Chris Darroch	1206016250000	Patch committed to trunk with changes and additional reformatting in r639079.
43213	Julien Perez	1187985776000	Created an attachment (id=20708)\nAdds an error message when ExpiresByType is supplied with an invalid mimetype,\navoids a segfault\n
43213	Nick Kew	1187996204000	Thanks for the report.  Fixed in /trunk/ - r569622.
43213	Nick Kew	1188194114000	Fixed in r570093.
43233	Roy T. Fielding	1188473978000	Thank you for reporting this problem  I have fixed it for the next release.\n
43310	SunHo Kim	1188967930000	Created an attachment (id=20774)\nPatch against httpd-2.2.4\n\nnull terminator is not used
43310	Basant Kumar Kukreja	1189107901000	I reviewed the patch. Patch looks ok to me. Here is the description of the bug\n:\n\nIn ap_vrprintf, vrprintf_buf is a array allocated on stack of 8192 bytes.\nap_vrprintf invokes ap_vformatter to format the string.  ap_vformatter prints\nthe data character by character, if buffer is overflowed, then it flushes the\ndata and reset the vdbuf.curpos to beginning of buffer.\n\nIf  the size of the output is a multiplication of 8192 then after\nap_vformatter returns, vbuff.curpos just passes one byte after the allocated\nvalue. (ap_vformatter himself doesn't write beyond the allocated buffer). We\ncan't write NULL to this value as it overflow the buffer.\n\nFor a request with /test/?8192, here is the debugger session :\n\nBreakpoint 1, ap_vrprintf (r=0x91f6028, fmt=0xd137af '%s', va=0xb731d218\n'(??M/t/005')\n    at protocol.c:1530\n1530        vd.vbuff.curpos = vrprintf_buf;\n(gdb) n\n1531        vd.vbuff.endpos = vrprintf_buf + AP_IOBUFSIZE;\n(gdb) n\n1532        vd.r = r;\n(gdb) n\n1533        vd.buff = vrprintf_buf;\n(gdb) n\n1535        if (r->connection->aborted)\n(gdb) n\n1538        written = apr_vformatter(r_flush, &vd.vbuff, fmt, va);\n(gdb) n\n1541        *(vd.vbuff.curpos) = '/0';\n(gdb) p vd.vbuff.curpos - vrprintf_buf\n$1 = 8192\n(gdb) p sizeof(vrprintf_buf)\n$2 = 8192\n(gdb)\n\nThis patch deletes the statement which sets the null value. This null value is\nnot used later in the function. buffer_output function flushes rest of the\ndata and it doesn't see the data beyond vdbuff.curpos. Also buffer_output\ndoesn't make any call which assumes NULL character at the end.\n
43310	Basant Kumar Kukreja	1189197114000	Created an attachment (id=20781)\nSame patch against trunk.\n\nSame patch as submitted by Sunho kim but patch is against trunk.\n
43310	Davi Arnaut	1194894251000	A patch for this issue was committed in revision 589461:\n\nhttp://svn.apache.org/viewvc?rev=589461&view=rev
43310	Takashi Sato	1195942308000	a backport proposal (2.2.x)\nhttp://svn.apache.org/viewvc?view=rev&revision=589638
43310	Jim Jagielski	1197113650000	In 2.2.7
43358	Takashi Sato	1189539528000	Created an attachment (id=20793)\n
43358	Vincent Bray	1189568114000	Patch applied.\n\nhttp://svn.apache.org/viewvc?rev=574882&view=rev\n\nThanks again.
43472	Ruediger Pluem	1190719391000	Created an attachment (id=20877)\nPatch proposal against trunk\n\nCan you please check if the attached patch fixes your problem after you set\nUSE_ALTERNATE_IS_CONNECTED back to 1? Thanks.
43472	Christian BOITEL	1190764202000	(In reply to comment #1)\n\nApplied patch and perform testes: it fixes problem.\n\nI believe patch should also be backported to 2.2.x branch.
43472	Nick Kew	1190982666000	Fixed in trunk - r580466
43472	Ruediger Pluem	1191067475000	Proposed for backport to  2.2.x as r580625\n(http://svn.apache.org/viewcvs.cgi?rev=580466&view=rev).
43472	Nick Kew	1191735409000	Fix backported in r582620
43509	Nick Kew	1190980684000	Fixed in trunk: r580457
43509	Nick Kew	1191918528000	Fixed in r583194.
43512	Ruediger Pluem	1191033494000	Can you please provide the changes that made it work for you as a patch. Even if\nthis is not the solution is would be helpful for analysis of the problem.
43512	Nick Kew	1191035260000	I just tested both www.cnn.com and www.ebay.com (using my apache as forward\nproxy and commandline telnet to request uncompressed output), and got the\ncorrectly-uncompressed output.\n\nYou've been confusing yourself and scaring the rest of us on IRC for rather a\nlong time.  Perhaps it would be a good idea to revert to a clean 2.2.6 install,\nand work from there.
43512	Peter Belau	1191035728000	Nick,\n\nIn order to duplicate this bug, you need to be using Apache with mod_proxy\nenabled and mod_deflate in the filter chain set to INFLATE gzip-ed content.\nI'll be attached an httpd.conf for Apache 2.2.6 that  provokes the buggy behavior.
43512	Peter Belau	1191035800000	Created an attachment (id=20897)\nhttpd config for  provoking mod_deflate bug\n
43512	Peter Belau	1191035910000	Also, forgot to mention two things:\n\n1. Setting VALIDATON_SIZE to 0 fixes the problem when it pops up\n2. Both cnn.com and ebay.com do occasionally send all 8 validation bytes. Please\ntry making the request a few times before you conclude that there's nothing broken  
43512	Nick Kew	1191037113000	Please set up a testcase for the alleged bug, so I can reproduce it.\nYou can use mod_asis to set exact headers, as well as the gzipped data.
43512	Peter Belau	1191040262000	I'm working on a test case for you, but the bug is really not at all hard to\nreproduce. It shows up both with 2.2.6 and TRUNK. Both cnn.com and ebay.com\nroutinely fail more than 50% of the time with both Firefox 1.5 and 2.0.
43512	Peter Belau	1191042706000	I have been so far unable to reproduce this bug by copying the responses\ngeneated by  by perl IO::Socket to .asis files. In such cases, the files are\nrendered perfectly through INFLATE. I will continue my attempts at creating a\nbetter test case but I'm quite exhausted at this point.\n\nPlease note that this really is a bug and not a configuration issue. I would be\nglad to give someone access to my server if it allows him/her to more\nexpediently identify that this is indeed a bug and not a figment of my imagination.\n\nHopefully someone can take a look at this thing in earnest; I have not been\nhaving a pleasant time trying to fix it myself.
43512	Peter Belau	1191043231000	Another bit of information:\n\nThe log output in error_log is Zlib: Validation bytes not present
43512	Eric Covener	1191050606000	I was able to reproduce this intermittently (2 requests fail w/ 0 length body,\nthen a success) with:\n\nLoadModule proxy_module modules/mod_proxy.so\nLoadModule proxy_http_module modules/mod_proxy_http.so\nLoadModule deflate_module modules/mod_deflate.so\n\nProxyPass /proxy/  http://www.cnn.com/\nLoadModule ext_filter_module modules/mod_ext_filter.so\nExtFilterDefine foo mode=output cmd='/usr/bin/perl -p -e 's/^/|/g'' ftype=21\n<location /proxy/>\nExtFilterOptions debuglevel=999\nSetoutputfilter INFLATE;foo;DEFLATE\n</location>\n\nI sent a request with wget and --header='Accept-Encoding: gzip'
43512	Nick Kew	1191055626000	Fixed in trunk - r580598.  I expect you'll report back whether this fixes it for\nyou.\n\nComments:\n(1) Easy once I could reproduce the problem.\n(2) This is a problem that has affected many filters that worked fine in 2.0\nwhen moving to 2.2.\n(3) Sorry about my initial scepticism!
43512	Peter Belau	1191064896000	Looking good ! I'll do some more testing and try to wrap my head around what you\ndid later (seems like a two line fix, but I didn't immediately understand why it\nworks...)\n\nGood night for now; hope to close out the ticket later. Thanks again.\n
43512	Takashi Sato	1200734627000	2.2 r580916\nhttp://svn.apache.org/viewvc?view=rev&revision=580916
43519	Nick Kew	1191176128000	Not relevant to proxying after all:\nhttp://marc.info/?l=apache-httpd-dev&m=119119652229134&w=2\n\nRemoving block on PR 43454
43519	Nick Kew	1191225386000	OK, I shouldn't be doing this at 2 a.m.  Bah.\n\nOPTIONS * gets the permissions of DocumentRoot, and the test machine I\nencountered this on had no Allow in its documentroot.\n\nThis is IMO still a bug: OPTIONS * shouldn't be mapped to the filesystem, and if\nany permissions apply it should be <Location /> (which was set to ALLOW in my\nconfig).
43519	Will Rowe	1191228405000	I would propose that only one walk, an explicit <Location '*'> should ever\nbe applied to OPTIONS *.  However, the test must ensure the directive is\nOPTIONS and deny all other requests for '*' (unless there is some other\nedge case hiding in RFC2616 or later std/rfc docs).\n\n
43519	Nick Kew	1191235058000	Created an attachment (id=20902)\nSimple patch to allow OPTIONS *\n\nOK, the simple fix to this is to patch mod_authz_host.\tI'll do it here,\nbecause such a simple fix is n/a in /trunk/.
43519	Jim Jagielski	1191821001000	http://svn.apache.org/viewvc/httpd/httpd/trunk/modules/http/http_core.c?r1=581358&r2=581389
43534	Tom Donovan	1191298225000	Created an attachment (id=20905)\nmod_perl and FastCGI patch\n\nAllows mod_perl and FastCGI programs to run with Apache 2.2.6 on Windows
43534	Tom Donovan	1191304333000	Typo in 2. above - I meant:\n\n'(i.e. to set stdin to 'NUL' except in single-process\nmode)'\n\nAlso observed that this patch does not interfere with the new APR behavior re:\nnot leaking unwanted handles.  rotatelogs.exe works as expected with APR 1.2.10+.\n
43534	Tom Donovan	1197457075000	Created an attachment (id=21264)\nnew patch for 2.2.x branch 12/12/2007\n\nUpdated patch for 2.2.x trunk (revision 603073 - Dec 12, 2007).  \n\nPer Bug 43329 - reverting the apr_proc_create behavior fixes the problem for\nnew processes created by mod_fastcgi or mod_fcgid.  STD_OUTPUT_HANDLE and\nSTD_ERROR_HANDLE are now INVALID_HANDLE_VALUE as required.\n\nThe Apache child process itself must be created with valid stdout and stdin\nfile descriptors (vs. HANDLEs) for modules which use fd's. It is OK for these\nto be file descriptors to 'NUL'.\n\nThis patch always creates the Apache child with 'NUL' as stdout, which the\nchild later _dup2's to stdin after all the info has been collected from the\nparent via the stdin pipe.  This leaves the Apache child with acceptable fd's\nfor stdin and stdout to satisfy modules which use fd's instead of HANDLEs (like\nmod_perl).\n
43534	Will Rowe	1198846826000	I'm reviewing the patch I had already authored (see URL above) which applied\nto both 2.2.x and 2.0.x branches.\n\nI'll then examine that it meets the requirements of the patch Tom has attached\nto this incident, because I think it covers all the bases but need to confirm.\n\nIf anyone else active in resolving this bug is interested, the current httpd\n2.2.x branch from svn, and the 1.2.12 apr[-util] release (or 1.2.x svn branch)\ncan be used to verify the current behavior before release.
43534	Tom Donovan	1198993407000	(In reply to comment #4)\n> I'm reviewing the patch I had already authored (see URL above) which applied\n> to both 2.2.x and 2.0.x branches.\n\nNot sure which 'URL above' is meant here.\n\nThe current revision of the 2.2.x branch (rev 607543 30-Dec-2007), which\nincludes change 607311 to mpm_winnt.c, will run mod_perl only when Apache is\nstarted as a Windows service.  If Apache is started from the command line, the\nerror when mod_perl is invoked is:\n\n Failed to dup STDOUT: Bad file descriptor.\n [Sun Dec 30 08:18:22 2007] [notice] Parent: child process exited with status 9\n-- Restarting.\n\nIt is a welcome improvement that mod_perl errors (like 'Failed to dup') now\nappear in the error log.
43534	Tom Donovan	1199601626000	Created an attachment (id=21351)\nUpdated patch for 2.2.7\n\nUpdated patch to work with Apache 2.2.7 RC.  Only the command-line case needed\nto be fixed.  \n\nmpm_winnt already creates a stdout handle to 'NUL', but only when started as a\nWindows Service.  This 'NUL' handle is acceptable to mod_perl as both stdin and\nstdout.  Since console handles don't inherit - when Apache is started from the\ncommand-line mod_perl gets an invalid stdout. This patch changes mpm_winnt to\n*always* create a 'NUL' stdout handle when creating a child process, for both\nWindows service and command-line startup.\n\nSingle-process mode (-X) has always worked with mod_perl.  There is no process\ncreation, therefore no handle inheritance is involved.\tBecause the original\n(real) console handles are valid, mod_perl runs correctly.
43534	Will Rowe	1199610586000	Troubles with this patch; it doesn't mirror unix behavior (which is actually\nright in this case) and it introduces a service regression just as the earlier\npatch I committed introduced a console regression.\n\nThe unix behavior is that the stdout channel should be fixed at the moment that \nconfigure is finished.  This ensures any normal emits from perl, etc are seen\nin the parent by the user.  I'm working to track down where that happens, it\nmay be at daemonize() and actually embedded in apr, and I'm looking at a best\nsolution to mirror unix.\n\nThe regression is that stdio (and stderr and stdin) are third rails in a service\nthat we can't touch before they have been repaired.  The existing location of\nthe stdout substitution can't and won't be changed.\n\nThanks for the patch and the thorough explanation on dev@httpd, I'm proceeding\nwith the patch that will resolve this without modifying unix nor services.\n\n
43534	Will Rowe	1199612324000	Here we go;\n\non Unix, apr_proc_detach(1) causes all of the descriptors to be replaced with\nthe /dev/null handle, and this is precisely the behavior we want.\n\nToday on unix this occurs in pre_config (c.f. worker.c and prefork.c).  However\nthis behavior is a bit borked in the minds of some developers, who are frustrated\nwith the fact that perl emits that showed up in 1.3 no longer show up in 2.0.\nBut I can agree for now that we have to mirror unix, at least our register_hooks\nand earlier pre_config hooks will mirror unix.\n\nSee the revised patch which only modifies normal console-mode operation at;\n\n  http://svn.apache.org/viewvc?view=rev&revision=609354\n\nreview and let me know if this satisfies your test cases, and I'll backport\nASAP.\n\n
43534	Will Rowe	1199615834000	Corrected patch cited (now that I can take it to win32).  Sorry the initial\nbackport was actually from unix.\n\nhttp://svn.apache.org/viewvc/httpd/httpd/trunk/server/mpm/winnt/mpm_winnt.c?r1=607677&r2=609366\n 
43534	Tom Donovan	1199686443000	(In reply to comment #9)\nr609366 applied to Apache 2.2.7 works as expected.\n\nWindows-service, command-line, and single-process (-X) all run mod_perl OK with\nthis change.\n\nCommand-line startup with no console also works OK - e.g. 'START /B httpd.exe'\nor Apache started via CreateProcess(...DETACHED_PROCESS...).\n
43534	Will Rowe	1199698743000	Backported to both 2.0 and 2.2, I think we can at last tag this FIXED for the\nforthcoming 2.2.8 and 2.0.63 releases.  Thanks for all of your help Tom!
43534	Tom Donovan	1199706346000	(In reply to comment #11)\n> Backported to both 2.0 and 2.2, I think we can at last tag this FIXED for the\n> forthcoming 2.2.8 and 2.0.63 releases.  Thanks for all of your help Tom!\n\nThanks for the kind words - but you may not want to thank me just yet.\n\nI failed to notice that with the current fix, closing the Apache window does not\nshut down Apache (presuming a window is displayed) .  Ditto for right-click\n[Close] on the task-bar icon.  This was not a problem with the previous patch,\nso somehow the windows console (vs. the child window itself) is not associated\nwith the parent process with this fix.\n\nI see this on Win2k and Steffen reports the same on XP. I regret we didn't catch\nthis quicker.
43534	Ruediger Pluem	1200743397000	Fixed in 2.2.8.
43562	Jose Kahan	1191574888000	Created an attachment (id=20923)\nremoves PR 21059 from mod_speling. Patch against 2.2.6\n
43562	Jose Kahan	1191574914000	Created an attachment (id=20924)\nremoves PR 21059 from mod_speling. Patch against trunk\n
43562	Ted Guild	1191577737000	One thing to add to this report is a rather serious side effect this\nmod_speling/pathinfo bug inadvertently introduces, infinitely recursive uris. \nClueless crawlers, which are many, do not notice from the ETAG that they are\ngetting is identical to a resource they already indexed.  When parsing a\nresource for links they accessed with a trailing / and coming across a relative\nuri they naturally append the relative path to the uri they already have as a\nresource to crawl.\n\nFor example:\n\nhttp://www.w3.org/INSTALL.html/Library/src/Library/src/ --> 200 OK\n\nhttp://www.w3.org/INSTALL.html/Library/src/Library/src/Library/src/ --> 200 OK\n\nad nauseam\n\nExcept as perhaps a teergrube exercise to trap and hold hostage unsuspecting\ncrawlers indefinitely this is generally undesirable.\n\nRegards,
43562	Jim Jagielski	1205221107000	fixed in trunk r635953. Will propose for 2.2 backport
43562	Takashi Sato	1208419092000	backported to 2.2 as r649120\nhttp://svn.apache.org/viewvc?view=rev&revision=649120
43649	Jose Kahan	1192695152000	Created an attachment (id=21003)\nmod_autoindex was not adding the xhtml namespace\n\nPatch against 2.2.6
43649	Jose Kahan	1192695176000	Created an attachment (id=21004)\nmod_autoindex was not adding the xhtml namespace\n\nPatch against trunk
43649	Ruediger Pluem	1194704212000	Committed to trunk as r59381 (http://svn.apache.org/viewvc?rev=593778&view=rev).\nThanks for the patch.
43649	Ruediger Pluem	1194704569000	Proposed for backport as r593818 (http://svn.apache.org/viewvc?rev=593818&view=rev).
43649	Ted Guild	1194968636000	Here's an idea:\n\nThese autoindexes should not only be valid markup but promote open standards\n(valid markup) by linking back to W3C's Validator.  If you are open to the idea\nit would be ideal if Apache were to include W3C valid markup logos in the /icons\ndirectory so as to distribute load of serving those icons on all the new valid\nautoindex URIs.\n\nIn turn we can promote adoption of Apache 2.2, as apparently many are still 1.3,\non the Validator's results page eg  \n\nhttp://validator.w3.org/check?uri=http%3A//www.w3.org/&doctype=Inline&%20outline=\n\nWe could give an alternate markup for Apache instances >2.2.N to all users or\nperhaps just for sites we detect the Server: header as still Apache 1.3 or 2.0\n\n  <p>\n    <a href='http://validator.w3.org/check?uri=referer'><img\n        src='/icons/valid-xhtml10'\n        alt='Valid XHTML 1.0 Strict' height='31' width='88' /></a>\n  </p>
43649	Andr?? Malo	1195047384000	I don't like it.
43649	Takashi Sato	1195572496000	to 2.2 as r596675\n<http://svn.apache.org/viewvc?view=rev&revision=596675>
43711	Nick Kew	1193415543000	Thanks for entering this as a bug.\n\nThe basic problem is that the HTTP protocol input filter (ap_http_filter)\nactually sends the 100-continue.  That's way too early.\n\nI think the fix should be to remove that code from the protocol filter, and send\nthe 100 response from a fixups hook.  Bug me if I don't get around to doing\nanything about it.
43711	Ruediger Pluem	1193472091000	Created an attachment (id=21053)\nPatch against trunk\n
43711	Ruediger Pluem	1193472130000	Can you please check if the attached patch solves your problem?
43711	Ragini Bisarya	1193657629000	Thanks for the patch. \n\nI patched in the change to the Apache 2.2.6 source code version. And it did not\nwork as I expected it to. The server sent both a 401 AND a 100 response for the\nPUT request!\n\nNext I will pull the trunk version of the source code to test this patch and let\nyou know the results.\n\n
43711	Ruediger Pluem	1193665051000	For 2.2.6 you also need to apply the patch for PR38014\n(http://svn.apache.org/viewvc?view=rev&revision=574950) which has been already\nbackported to 2.2.x. Thus it worked for me.
43711	Ragini Bisarya	1193680161000	Results of testing this using the trunk version of the source code + the patch.\n\nA 401 was returned instead of the 100 continue, so that is good. But when the\nPUT request with the auth header was sent by the client on that connection, the\nserver's state seemed to be all wrong.\n\nLooking at the hex dump of the 401 response returned by the server, it looks\nlike the last chunk of the response (the 401 response has Transfer-encoding =\nchunked) with 0 length and the CRLF was not sent by the server so the 401\nresponse sent by the server is actually incomplete.\n\nTest 1 - PUT request for resource that requires authentication - Result is NOT OK\n\n===> sending the request with out the Auth header\nPUT /secret/test.html HTTP/1.1\nHost: 10.10.10.1:8080\nExpect: 100-continue\nDate: Mon, 15 Oct 2007 20:05:24 GMT\nConnection: Keep-Alive\nContent-Length: 49\nContent-Type: application/octet-stream \n\nHTTP/1.1 401 Authorization Required\nDate: Tue, 30 Oct 2007 00:04:18 GMT\nServer: Apache/2.3.0-dev (Unix)\nWWW-Authenticate: Basic realm='secret_access'\nKeep-Alive: timeout=5, max=100\nConnection: Keep-Alive\nTransfer-Encoding: chunked\nContent-Type: text/html; charset=iso-8859-1\n\n192\n<!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'>\n<html><head>\n<title>401 Authorization Required</title>\n</head><body>\n<h1>Authorization Required</h1>\n<p>This server could not verify that you\nare authorized to access the document\nrequested.  Either you supplied the wrong\ncredentials (e.g., bad password), or your\nbrowser doesn't understand how to supply\nthe credentials required.</p>\n</body></html>\n\n===> NOTE - the 0 length chunk was not sent.\n===> sending the request WITH the auth header\nPUT /secret/test.html HTTP/1.1\nHost: 10.10.10.1:8080\nAuthorization: Basic dGVzdDp0ZXN0\nDate: Mon, 15 Oct 2007 22:22:24 GMT\nConnection: Keep-Alive\nContent-Length: 49\nContent-Type: application/octet-stream0\n\n<!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'>\n<html><head>\n<title>501 Method Not Implemented</title>\n</head><body>\n<h1>Method Not Implemented</h1>\n<p>8080 to /index.html not supported.<br />      ===> the server thinks the new\nrequest method is 8080 - the characters halfway through the Host header in the\nrequest.\n</p>\n</body></html>\n\nConnection closed by foreign host.\n\nLooks like even though a 401 was sent out, the server is in some weird state. If\nthe client sends two CRs at this point this results in the server sending back a\n0 length chunk.\n\nTrying a GET request on this server confirmed that this server does send a\ncorrect and complete 401 in the case of GET as shown below.\n\nGET /secret/test.html HTTP/1.1\nHost: 1.1.1.1\n\nHTTP/1.1 401 Authorization Required\nDate: Tue, 30 Oct 2007 00:44:15 GMT\nServer: Apache/2.3.0-dev (Unix)\nWWW-Authenticate: Basic realm='secret_access'\nTransfer-Encoding: chunked\nContent-Type: text/html; charset=iso-8859-1\n\n192\n<!DOCTYPE HTML PUBLIC '-//IETF//DTD HTML 2.0//EN'>\n<html><head>\n<title>401 Authorization Required</title>\n</head><body>\n<h1>Authorization Required</h1>\n<p>This server could not verify that you\nare authorized to access the document\nrequested.  Either you supplied the wrong\ncredentials (e.g., bad password), or your\nbrowser doesn't understand how to supply\nthe credentials required.</p>\n</body></html>\n\n\n0\n\nConnection closed by foreign host.\n\n\n\nTest 2 - PUT request for resource that does not required authentication - OK.\nSame as before patch.\n\n\nPUT /test.html HTTP/1.1\nHost: 10.10.10.1:8888\nExpect: 100-continue\nDate: Mon, 15 Oct 2007 22:22:24 GMT\nConnection: Keep-Alive\nContent-Length: 49\nContent-Type: application/octet-stream\n\nHTTP/1.1 100 Continue\n\n<html><body><h1>Secret works!</h1></body></html>\n\nHTTP/1.1 204 No Content\nDate: Mon, 29 Oct 2007 21:31:13 GMT\nServer: Apache/2.3.0-dev (Unix)\nContent-Length: 0\nKeep-Alive: timeout=5, max=100\nConnection: Keep-Alive\nContent-Type: text/html\n
43711	Ragini Bisarya	1193682897000	Test results for Apache 2.2.6 + PR38014 patch + patch for this bug are the same\nas those reported in Comment #6.\n\nThe hexdump for the 401 response is as follows - \n\n 0     :  48 54 54 50 2F 31 2E 31  20 34 30 31 20 41 75 74   *HTTP/1.1 401 Aut*\n 16    :  68 6F 72 69 7A 61 74 69  6F 6E 20 52 65 71 75 69   *horization Requi*\n 32    :  72 65 64 0D 0A 44 61 74  65 3A 20 54 75 65 2C 20   *red..Date: Tue, *\n 48    :  33 30 20 4F 63 74 20 32  30 30 37 20 30 31 3A 32   *30 Oct 2007 01:2*\n 64    :  37 3A 35 39 20 47 4D 54  0D 0A 53 65 72 76 65 72   *7:59 GMT..Server*\n 80    :  3A 20 41 70 61 63 68 65  2F 32 2E 32 2E 36 20 28   *: Apache/2.2.6 (*\n 96    :  55 6E 69 78 29 0D 0A 57  57 57 2D 41 75 74 68 65   *Unix)..WWW-Authe*\n 112   :  6E 74 69 63 61 74 65 3A  20 42 61 73 69 63 20 72   *nticate: Basic r*\n 128   :  65 61 6C 6D 3D 22 6C 65  76 65 6C 5F 31 35 5F 61   *ealm='level_15_a*\n 144   :  63 63 65 73 73 22 0D 0A  4B 65 65 70 2D 41 6C 69   *ccess'..Keep-Ali*\n 160   :  76 65 3A 20 74 69 6D 65  6F 75 74 3D 35 2C 20 6D   *ve: timeout=5, m*\n 176   :  61 78 3D 31 30 30 0D 0A  43 6F 6E 6E 65 63 74 69   *ax=100..Connecti*\n 192   :  6F 6E 3A 20 4B 65 65 70  2D 41 6C 69 76 65 0D 0A   *on: Keep-Alive..*\n 208   :  54 72 61 6E 73 66 65 72  2D 45 6E 63 6F 64 69 6E   *Transfer-Encodin*\n 224   :  67 3A 20 63 68 75 6E 6B  65 64 0D 0A 43 6F 6E 74   *g: chunked..Cont*\n 240   :  65 6E 74 2D 54 79 70 65  3A 20 74 65 78 74 2F 68   *ent-Type: text/h*\n 256   :  74 6D 6C 3B 20 63 68 61  72 73 65 74 3D 69 73 6F   *tml; charset=iso*\n 272   :  2D 38 38 35 39 2D 31 0D  0A 0D 0A 31 39 31 0D 0A   *-8859-1....191..*\n 288   :  3C 21 44 4F 43 54 59 50  45 20 48 54 4D 4C 20 50   *<!DOCTYPE HTML P*\n 304   :  55 42 4C 49 43 20 22 2D  2F 2F 49 45 54 46 2F 2F   *UBLIC '-//IETF//*\n 320   :  44 54 44 20 48 54 4D 4C  20 32 2E 30 2F 2F 45 4E   *DTD HTML 2.0//EN*\n 336   :  22 3E 0A 3C 68 74 6D 6C  3E 3C 68 65 61 64 3E 0A   *'>.<html><head>.*\n 352   :  3C 74 69 74 6C 65 3E 34  30 31 20 41 75 74 68 6F   *<title>401 Autho*\n 368   :  72 69 7A 61 74 69 6F 6E  20 52 65 71 75 69 72 65   *rization Require*\n 384   :  64 3C 2F 74 69 74 6C 65  3E 0A 3C 2F 68 65 61 64   *d</title>.</head*\n 400   :  3E 3C 62 6F 64 79 3E 0A  3C 68 31 3E 41 75 74 68   *><body>.<h1>Auth*\n 416   :  6F 72 69 7A 61 74 69 6F  6E 20 52 65 71 75 69 72   *orization Requir*\n 432   :  65 64 3C 2F 68 31 3E 0A  3C 70 3E 54 68 69 73 20   *ed</h1>.<p>This *\n 448   :  73 65 72 76 65 72 20 63  6F 75 6C 64 20 6E 6F 74   *server could not*\n 464   :  20 76 65 72 69 66 79 20  74 68 61 74 20 79 6F 75   * verify that you*\n 480   :  0A 61 72 65 20 61 75 74  68 6F 72 69 7A 65 64 20   *.are authorized *\n 496   :  74 6F 20 61 63 63 65 73  73 20 74 68 65 20 64 6F   *to access the do*\n 512   :  63 75 6D 65 6E 74 0A 72  65 71 75 65 73 74 65 64   *cument.requested*\n 528   :  2E 20 20 45 69 74 68 65  72 20 79 6F 75 20 73 75   *.  Either you su*\n 544   :  70 70 6C 69 65 64 20 74  68 65 20 77 72 6F 6E 67   *pplied the wrong*\n 560   :  0A 63 72 65 64 65 6E 74  69 61 6C 73 20 28 65 2E   *.credentials (e.*\n 576   :  67 2E 2C 20 62 61 64 20  70 61 73 73 77 6F 72 64   *g., bad password*\n 592   :  29 2C 20 6F 72 20 79 6F  75 72 0A 62 72 6F 77 73   *), or your.brows*\n 608   :  65 72 20 64 6F 65 73 6E  27 74 20 75 6E 64 65 72   *er doesn't under*\n 624   :  73 74 61 6E 64 20 68 6F  77 20 74 6F 20 73 75 70   *stand how to sup*\n 640   :  70 6C 79 0A 74 68 65 20  63 72 65 64 65 6E 74 69   *ply.the credenti*\n 656   :  61 6C 73 20 72 65 71 75  69 72 65 64 2E 3C 2F 70   *als required.</p*\n 672   :  3E 0A 3C 2F 62 6F 64 79  3E 3C 2F 68 74 6D 6C 3E   *>.</body></html>*\n 688   :  0A 0D 0A -- -- -- -- --  -- -- -- -- -- -- -- --   *...-------------*\n
43711	Ragini Bisarya	1195037586000	Changing the state of the bug since the required information has been provided.
43711	Chetan Reddy	1200762375000	Created an attachment (id=21407)\ndon't send 100 continue if a client error (4xx) occurred\n\nCould you please try this patch (made against apache 2.2.6) and let me know if\nit fixes your issue.\n\nThanks
43711	Chetan Reddy	1200766529000	Created an attachment (id=21408)\ndon't send 100 continue if a client error (4xx) occurred\n\nTry this instead of the previous patch (again made against 2.2.6)
43711	Chetan Reddy	1201016868000	Created an attachment (id=21414)\ndon't send 100 continue if a client error (4xx) occurred - patch against 2.2.8\n\nPatch to fix the issue made against httpd 2.2.8
43711	Ragini Bisarya	1201279584000	(In reply to comment #11)\n> Created an attachment (id=21414) [edit]\n> don't send 100 continue if a client error (4xx) occurred - patch against 2.2.8\n> \n> Patch to fix the issue made against httpd 2.2.8\n\nThis patch worked perfectly. Thanks for fixing this.\n\nFYI - \nTest result for resource that requires authentication -\n\nPUT /secret/test.html HTTP/1.1\nHost: 10.10.10.1:8080\nExpect: 100-continue\nDate: Mon, 15 Oct 2007 20:05:24 GMT\nConnection: Keep-Alive\nContent-Length: 49\nContent-Type: application/octet-stream \n\nHTTP/1.1 401 Authorization Required\nDate: Fri, 25 Jan 2008 22:52:05 GMT\nServer: Apache/2.2.8 (Unix)\nWWW-Authenticate: Basic realm='test'\nContent-Length: 401\nKeep-Alive: timeout=5, max=100\nConnection: Keep-Alive\nContent-Type: text/html; charset=iso-8859-1\netc...\n\nPUT /secret/test.html HTTP/1.1\nHost: 10.10.10.1:8080\nAuthorization: Basic dGVzdDp0ZXN0DQo=\nDate: Mon, 15 Oct 2007 22:22:24 GMT\nConnection: Keep-Alive\nContent-Length: 49\nContent-Type: application/octet-stream\n\n<html><body><h1>Secret works!</h1></body></html>\n\nHTTP/1.1 204 No Content\nDate: Fri, 25 Jan 2008 22:52:10 GMT\nServer: Apache/2.2.8 (Unix)\nContent-Length: 0\nKeep-Alive: timeout=5, max=99\nConnection: Keep-Alive\nContent-Type: text/html\n\n
43711	Nick Kew	1203295101000	Fixed in trunk - r628644
43711	Nick Kew	1203698253000	Fix backported to 2.2.x in r630366 - will be in 2.2.9.
43711	Ruediger Pluem	1204026204000	*** Bug 44492 has been marked as a duplicate of this bug. ***
43738	Joe Orton	1193824934000	Curious.  Can you get a dump of the r->input_filters in gdb at the point where\nap_get_client_block() is called in mod_fastcgi?\n\nsource /path/to/httpd-source/.gdbinit\ndump_filters r->input_filters\n
43738	Garrett Wollman	1193841646000	Here's what GDB thinks\n(gdb) b ap_get_client_block\nBreakpoint 1 at 0x441f60\n(gdb) cont\nContinuing.\n\nBreakpoint 1, 0x0000000000441f60 in ap_get_client_block ()\n(gdb) up\n#1  0x00002b952d63a703 in do_work (r=0x819238, fr=0x84d0c0)\n    at mod_fastcgi.c:868\n868             if ((countRead = ap_get_client_block(fr->r, end, count)) < 0)\n(gdb) source /afs/csail.mit.edu/u/w/wollman/public/apache2/apache2-2.2.3/.gdbinit \n(gdb) dump_filters fr->r->input_filters\nhttp_in(0x826c98): ctx=0x83e990, r=0x819238, c=0x810248\nssl/tls filter(0x81e098): ctx=0x81c048, r=0x0, c=0x810248\nlog_input_output(0x8109f0): ctx=0x0, r=0x0, c=0x810248\ncore_in(0x81e140): ctx=0x81e120, r=0x0, c=0x810248\n(gdb) p *r\n$1 = {pool = 0x825088, connection = 0x810248, server = 0x6d0478, next = 0x0, \n  prev = 0x8250f8, main = 0x0, \n  the_request = 0x8266b0 'POST /16.410/wiki/index.php?title=Special:Preferences\nHTTP/1.1', assbackwards = 0, proxyreq = 0, header_only = 0, \n  protocol = 0x8267b0 'HTTP/1.1', proto_num = 1001, \n  hostname = 0x826c78 'more-courses.csail.mit.edu', \n  request_time = 1193866479991696, status_line = 0x0, status = 200, \n  method = 0x826700 'POST', method_number = 2, allowed = 0, \n  allowed_xmethods = 0x0, allowed_methods = 0x84b828, sent_bodyct = 0, \n  bytes_sent = 0, mtime = 0, chunked = 0, range = 0x0, clength = 0, \n  remaining = 525, read_length = 0, read_body = 1, read_chunked = 0, \n  expecting_100 = 0, headers_in = 0x8253d8, headers_out = 0x819af0, \n  err_headers_out = 0x825d20, subprocess_env = 0x819d38, notes = 0x84b688, \n  content_type = 0x84a308 'application/x-httpd-fastphp5', \n  handler = 0x2b952d6428c8 'fastcgi-script', content_encoding = 0x0, \n  content_languages = 0x0, vlist_validator = 0x0, \n  user = 0x84d028 'wollman@MIT.EDU', ap_auth_type = 0x0, no_cache = 0, \n  no_local_copy = 0, \n  unparsed_uri = 0x819518\n'/.php5-cgi/16.410/wiki/index.php?title=Special:Preferences', uri = 0x819558\n'/.php5-cgi/16.410/wiki/index.php', \n  filename = 0x84c418 '/usr/bin/php5-cgi', \n  canonical_filename = 0x84c418 '/usr/bin/php5-cgi', \n  path_info = 0x84c2f9 '/16.410/wiki/index.php', \n---Type <return> to continue, or q <return> to quit--- \n  args = 0x819580 'title=Special:Preferences', finfo = {pool = 0x825088, \n    valid = 7598448, protection = 1877, filetype = APR_REG, user = 0, \n    group = 0, inode = 283762, device = 2049, nlink = 1, size = 5483216, \n    csize = 8540296, atime = 1193866145000000, mtime = 1183409032000000, \n    ctime = 1193860247000000, fname = 0x84c418 '/usr/bin/php5-cgi', \n    name = 0x6bb731 '/.php5-cgi', filehand = 0x7fff808d1370}, parsed_uri = {\n    scheme = 0x0, hostinfo = 0x0, user = 0x0, password = 0x0, hostname = 0x0, \n    port_str = 0x0, path = 0x819558 '/.php5-cgi/16.410/wiki/index.php', \n    query = 0x819580 'title=Special:Preferences', fragment = 0x0, \n    hostent = 0x0, port = 0, is_initialized = 1, dns_looked_up = 0, \n    dns_resolved = 0}, used_path_info = 0, per_dir_config = 0x819e60, \n  request_config = 0x8195a0, htaccess = 0x83cdb0, output_filters = 0x8265d0, \n  input_filters = 0x826c98, proto_output_filters = 0x8265d0, \n  proto_input_filters = 0x826c98, eos_sent = 0}\n
43738	Joe Orton	1193881430000	That all looks correct.  The filter chain is correct; r->remaining is 525 which\nmatches the number of bytes the SSL buffer captured.\n\nI can't see why this would fail, and I can't think what else to suggest here\nother than stepping through the code to see what is happening, or adding a lot\nof ap_log_rerror() debugging calls in ap_get_client_block()/ap_http_filter().  \n\n- is this ap_get_client_block() call happening *before* the timeout?\n- does ap_get_client_block() fail?\n- the topmost filter is ap_http_filter - breakpoint on that; does it get\ninvoked?  step through; what does it do?\n\n
43738	Garrett Wollman	1193905835000	What makes you say that the filter chain is correct?  I would expect the\n'ssl/tls buffer' filter to be at the head to the chain, since that's where all\nthe data is being buffered.  There's no chance that reading from 'ssl/tls\nfilter' will give me any data since its data has already been read and stored in\nthe buffer.\n\nTo answer your questions:\n>- is this ap_get_client_block() call happening *before* the timeout?\n\nYes, I thought I made that clear in my analysis.\n\n>- does ap_get_client_block() fail?\n\nNo, as I said before, it returns end-of-stream (0).\n\nI haven't traced through ap_http_filter; however, in the course of instrumenting\nap_get_client_block() before I filed this bug, I made it skip over 'http_in' and\nread directly from 'ssl/tls filter'.  Same result: end of stream.\n
43738	Ruediger Pluem	1193908572000	(In reply to comment #4)\n> What makes you say that the filter chain is correct?  I would expect the\n> 'ssl/tls buffer' filter to be at the head to the chain, since that's where all\n> the data is being buffered.  There's no chance that reading from 'ssl/tls\n> filter' will give me any data since its data has already been read and stored in\n> the buffer.\n\nIt is correct. You have to read the whole thing as a stack:\n\n\nhttp_in(0x826c98):          HTTP filter: Does dechunking if transfer-encoding of \n                            the body is chunked or reads up to Content-length\n                            bytes from the body.\nssl/tls filter(0x81e098):   Does decryption of the input stream and deals with\n                            client certificates. Sometimes this filter buffers\n                            data.\nlog_input_output(0x8109f0): Counts bytes that came in.\ncore_in(0x81e140):          Core network connection to the raw socket.\n
43738	Garrett Wollman	1193909661000	>ssl/tls filter(0x81e098):   Does decryption of the input stream and deals with\n>                            client certificates. Sometimes this filter buffers\n>                            data.\n\nThat's not what the code claims.  See the end of ssl_io_buffer_fill() in\nssl_engine_io.c:\n\n    /* Insert the filter which will supply the buffered data. */\n    ap_add_input_filter(ssl_io_buffer, ctx, r, c);\n\n    return 0;\n\nThe buffered data can only come from the 'ssl/tls buffer' filter, not the\n'ssl/tls filter' filter.  As I noted in my original report, we know from the\ndebug logs that the 'ssl/tls buffer' filter's read routine\n(ssl_io_filter_buffer) is in fact being called, but not until after the\n30-second timeout.
43738	Joe Orton	1193909896000	Created an attachment (id=21077)\ntest fix\n\nSorry, I read the filter stack wrong; I was only looking to check that http_in\nwas at the top; the second filter down should be the buffering filter not the\nnormal SSL filter (they are separate filters).\n\nI note that r->prev is set here so an internal redirect will have happened. \nAnd that will filters < AP_FTYPE_PROTOCOL, which includes this one... oops. \nCan you try this fix?
43738	Joe Orton	1193910027000	should read: ^And that will kill filters < AP_FTYPE_PROTOCOL
43738	Joe Orton	1193910717000	Ah, no, that won't work at all.  The buffering filter is AP_FTYPE_PROTOCOL - 1\nexactly because it the fill_buffer reads from r->proto_input_filters.  Ick.  I\ncan't see any obvious fix here.\n\nTo confirm the diagnosis can you reproduce without whatever triggered the\ninternal redirect?
43738	Garrett Wollman	1193913686000	> To confirm the diagnosis can you reproduce without whatever triggered the\n> internal redirect?\n\nCan you suggest how I might figure out what that was?\n\nFor what it's worth, ssl_io_filter_buffer() is eventually called from\nap_discard_request_body() after mod_fastcgi gives up.\n
43738	Garrett Wollman	1193914132000	> To confirm the diagnosis can you reproduce without whatever triggered the\n> internal redirect?\n\nI think I figured it out.  This problem is not seen by mod_php4 applications,\nnor by regular CGI applications.  The internal redirect is caused by mod_action,\nwhich is used to implement PHP5 under FastCGI.  The configuration looks like this:\n\nFastCgiServer /usr/bin/php5-cgi -processes 5\nScriptAlias /.php5-cgi /usr/bin/php5-cgi\n<Directory /usr/bin>\n  Order deny,allow\n  Deny from all\n  <Files php5-cgi>\n    Options ExecCGI\n    SetHandler fastcgi-script\n    Order allow,deny\n    Allow from all\n  </Files>\n</Directory>\nAction php5-script /.php5-cgi\nAction application/x-httpd-fastphp5 /.php5-cgi\n\nThen in .htaccess, users who want php5 instead of php4 specify:\n\nAddHandler php5-script .php\n
43738	Will Rowe	1193919815000	I don't see how your conf is triggering an internal redirect?\n\nCan you differentiate if this is a fast-internal redirect or a straight\nredirect?  Is this because the client requests /app/Login instead of\nrequesting /app/Login.php ?\n
43738	Garrett Wollman	1193921647000	> Can you differentiate if this is a fast-internal redirect or a straight\n> redirect?\n\nNot sure I know what that means.  Here is what the two request_rec structures\nlook like.  Note that the first one is generated in mod_actions by calling\nap_internal_redirect_handler() and the second one is the original request:\n\n(gdb) p *r\n$2 = {pool = 0x839398, connection = 0x80ba98, server = 0x6ce468, next = 0x0, \n  prev = 0x839408, main = 0x0, \n  the_request = 0x83a9c0 'GET /16.410/wiki/index.php?title=Special:Preferences\nHTTP/1.1', assbackwards = 0, proxyreq = 0, header_only = 0, \n  protocol = 0x83aac0 'HTTP/1.1', proto_num = 1001, \n  hostname = 0x83aeb8 'more-courses.csail.mit.edu', \n  request_time = 1193938941817986, status_line = 0x44efd3 '200 OK', \n  status = 200, method = 0x83aa10 'GET', method_number = 0, allowed = 0, \n  allowed_xmethods = 0x0, allowed_methods = 0x81d928, sent_bodyct = 1, \n  bytes_sent = 8192, mtime = 0, chunked = 1, range = 0x0, clength = 0, \n  remaining = 0, read_length = 0, read_body = 1, read_chunked = 0, \n  expecting_100 = 0, headers_in = 0x8396e8, headers_out = 0x861668, \n  err_headers_out = 0x83a030, subprocess_env = 0x85af28, notes = 0x81d788, \n  content_type = 0x861450 'text/html; charset=utf-8', \n  handler = 0x2b7546f648c8 'fastcgi-script', content_encoding = 0x0, \n  content_languages = 0x0, vlist_validator = 0x0, \n  user = 0x840608 'wollman@MIT.EDU', ap_auth_type = 0x0, no_cache = 0, \n  no_local_copy = 0, \n  unparsed_uri = 0x85a708\n'/.php5-cgi/16.410/wiki/index.php?title=Special:Preferences', uri = 0x85a748\n'/.php5-cgi/16.410/wiki/index.php', \n  filename = 0x81e518 '/usr/bin/php5-cgi', \n  canonical_filename = 0x81e518 '/usr/bin/php5-cgi', \n  path_info = 0x81e3f9 '/16.410/wiki/index.php', \n---Type <return> to continue, or q <return> to quit--- \n  args = 0x85a770 'title=Special:Preferences', finfo = {pool = 0x839398, \n    valid = 7598448, protection = 1877, filetype = APR_REG, user = 0, \n    group = 0, inode = 283762, device = 2049, nlink = 1, size = 5483216, \n    csize = 8623000, atime = 1193936766000000, mtime = 1183409032000000, \n    ctime = 1193860247000000, fname = 0x81e518 '/usr/bin/php5-cgi', \n    name = 0x6b9721 '/.php5-cgi', filehand = 0x7fff66fafa30}, parsed_uri = {\n    scheme = 0x0, hostinfo = 0x0, user = 0x0, password = 0x0, hostname = 0x0, \n    port_str = 0x0, path = 0x85a748 '/.php5-cgi/16.410/wiki/index.php', \n    query = 0x85a770 'title=Special:Preferences', fragment = 0x0, \n    hostent = 0x0, port = 0, is_initialized = 1, dns_looked_up = 0, \n    dns_resolved = 0}, used_path_info = 0, per_dir_config = 0x85b050, \n  request_config = 0x85a790, htaccess = 0x817f00, output_filters = 0x83a908, \n  input_filters = 0x83aed8, proto_output_filters = 0x83a908, \n  proto_input_filters = 0x83aed8, eos_sent = 0}\n(gdb) p r->prev\n$3 = (request_rec *) 0x839408\n(gdb) p *r->prev\n$4 = {pool = 0x839398, connection = 0x80ba98, server = 0x6ce468, \n  next = 0x85a428, prev = 0x0, main = 0x0, \n  the_request = 0x83a9c0 'GET /16.410/wiki/index.php?title=Special:Preferences\nHTTP/1.1', assbackwards = 0, proxyreq = 0, header_only = 0, \n  protocol = 0x83aac0 'HTTP/1.1', proto_num = 1001, \n  hostname = 0x83aeb8 'more-courses.csail.mit.edu', \n  request_time = 1193938941817986, status_line = 0x0, status = 200, \n  method = 0x83aa10 'GET', method_number = 0, allowed = 0, \n  allowed_xmethods = 0x0, allowed_methods = 0x8396a8, sent_bodyct = 0, \n  bytes_sent = 0, mtime = 0, chunked = 0, range = 0x0, clength = 0, \n  remaining = 0, read_length = 0, read_body = 0, read_chunked = 0, \n  expecting_100 = 0, headers_in = 0x8396e8, headers_out = 0x839de8, \n  err_headers_out = 0x83a030, subprocess_env = 0x839a68, notes = 0x83a1d0, \n  content_type = 0x83daf8 'application/x-httpd-fastphp5', \n  handler = 0x83d980 'php5-script', content_encoding = 0x0, \n  content_languages = 0x0, vlist_validator = 0x0, \n  user = 0x819ac0 'wollman@MIT.EDU', ap_auth_type = 0x0, no_cache = 0, \n  no_local_copy = 0, \n  unparsed_uri = 0x83aa50 '/16.410/wiki/index.php?title=Special:Preferences', \n  uri = 0x83aa88 '/16.410/wiki/index.php', \n  filename = 0x83b108 '/afs/csail.mit.edu/proj/courses/data/16.410/wiki/index.php', \n  canonical_filename = 0x83b108\n'/afs/csail.mit.edu/proj/courses/data/16.410/wik---Type <return> to continue, or\nq <return> to quit---\ni/index.php', path_info = 0x83b03a '', \n  args = 0x83aaa0 'title=Special:Preferences', finfo = {pool = 0x839398, \n    valid = 7598448, protection = 1604, filetype = APR_REG, user = 12369, \n    group = 12369, inode = 831797006, device = 18, nlink = 1, size = 3218, \n    csize = 0, atime = 1183079954000000, mtime = 1183079954000000, \n    ctime = 1183079954000000, \n    fname = 0x83b000\n'/afs/csail.mit.edu/proj/courses/data/16.410/wiki/index.php', name = 0x0,\nfilehand = 0x0}, parsed_uri = {scheme = 0x0, hostinfo = 0x0, \n    user = 0x0, password = 0x0, hostname = 0x0, port_str = 0x0, \n    path = 0x83aa88 '/16.410/wiki/index.php', \n    query = 0x83aaa0 'title=Special:Preferences', fragment = 0x0, \n    hostent = 0x0, port = 0, is_initialized = 1, dns_looked_up = 0, \n    dns_resolved = 0}, used_path_info = 2, per_dir_config = 0x817f58, \n  request_config = 0x83a370, htaccess = 0x817f00, output_filters = 0x83a8e0, \n  input_filters = 0x83aed8, proto_output_filters = 0x83a8e0, \n  proto_input_filters = 0x83aed8, eos_sent = 0}\n
43738	Garrett Wollman	1193921796000	Oops, I should have noticed that that was a GET request that I tripped over\nwhile debugging, rather than the POST requests that are the problem.  I'll try\nto grab another dump from the right request.
43738	Garrett Wollman	1193922422000	Here's a better example:\n\n(gdb) p *r\n$3 = {pool = 0x817ca8, connection = 0x80ba98, server = 0x6ce468, next = 0x0, \n  prev = 0x817d18, main = 0x0, \n  the_request = 0x8192d0 'POST /16.410/wiki/index.php?title=Special:Preferences\nHTTP/1.1', assbackwards = 0, proxyreq = 0, header_only = 0, \n  protocol = 0x8193d0 'HTTP/1.1', proto_num = 1001, \n  hostname = 0x819898 'more-courses.csail.mit.edu', \n  request_time = 1193947551567157, status_line = 0x0, status = 200, \n  method = 0x819320 'POST', method_number = 2, allowed = 0, \n  allowed_xmethods = 0x0, allowed_methods = 0x84a5b8, sent_bodyct = 0, \n  bytes_sent = 0, mtime = 0, chunked = 0, range = 0x0, clength = 0, \n  remaining = 528, read_length = 0, read_body = 1, read_chunked = 0, \n  expecting_100 = 0, headers_in = 0x817ff8, headers_out = 0x843ea0, \n  err_headers_out = 0x818940, subprocess_env = 0x8440e8, notes = 0x84a418, \n  content_type = 0x83daf8 'application/x-httpd-fastphp5', \n  handler = 0x2b7546f648c8 'fastcgi-script', content_encoding = 0x0, \n  content_languages = 0x0, vlist_validator = 0x0, \n  user = 0x840608 'wollman@MIT.EDU', ap_auth_type = 0x0, no_cache = 0, \n  no_local_copy = 0, \n  unparsed_uri = 0x8438c8\n'/.php5-cgi/16.410/wiki/index.php?title=Special:Preferences', uri = 0x843908\n'/.php5-cgi/16.410/wiki/index.php', \n  filename = 0x84b1a8 '/usr/bin/php5-cgi', \n  canonical_filename = 0x84b1a8 '/usr/bin/php5-cgi', \n  path_info = 0x84b089 '/16.410/wiki/index.php', \n---Type <return> to continue, or q <return> to quit--- \n  args = 0x843930 'title=Special:Preferences', finfo = {pool = 0x817ca8, \n    valid = 7598448, protection = 1877, filetype = APR_REG, user = 0, \n    group = 0, inode = 283762, device = 2049, nlink = 1, size = 5483216, \n    csize = 8486056, atime = 1193936766000000, mtime = 1183409032000000, \n    ctime = 1193860247000000, fname = 0x84b1a8 '/usr/bin/php5-cgi', \n    name = 0x6b9721 '/.php5-cgi', filehand = 0x7fff66fafa30}, parsed_uri = {\n    scheme = 0x0, hostinfo = 0x0, user = 0x0, password = 0x0, hostname = 0x0, \n    port_str = 0x0, path = 0x843908 '/.php5-cgi/16.410/wiki/index.php', \n    query = 0x843930 'title=Special:Preferences', fragment = 0x0, \n    hostent = 0x0, port = 0, is_initialized = 1, dns_looked_up = 0, \n    dns_resolved = 0}, used_path_info = 0, per_dir_config = 0x844210, \n  request_config = 0x843950, htaccess = 0x82c5a0, output_filters = 0x8191f0, \n  input_filters = 0x8198b8, proto_output_filters = 0x8191f0, \n  proto_input_filters = 0x8198b8, eos_sent = 0}\n(gdb) p *r->prev\n$4 = {pool = 0x817ca8, connection = 0x80ba98, server = 0x6ce468, \n  next = 0x8435e8, prev = 0x0, main = 0x0, \n  the_request = 0x8192d0 'POST /16.410/wiki/index.php?title=Special:Preferences\nHTTP/1.1', assbackwards = 0, proxyreq = 0, header_only = 0, \n  protocol = 0x8193d0 'HTTP/1.1', proto_num = 1001, \n  hostname = 0x819898 'more-courses.csail.mit.edu', \n  request_time = 1193947551567157, status_line = 0x0, status = 200, \n  method = 0x819320 'POST', method_number = 2, allowed = 0, \n  allowed_xmethods = 0x0, allowed_methods = 0x817fb8, sent_bodyct = 0, \n  bytes_sent = 0, mtime = 0, chunked = 0, range = 0x0, clength = 0, \n  remaining = 0, read_length = 0, read_body = 0, read_chunked = 0, \n  expecting_100 = 0, headers_in = 0x817ff8, headers_out = 0x8186f8, \n  err_headers_out = 0x818940, subprocess_env = 0x818378, notes = 0x818ae0, \n  content_type = 0x83daf8 'application/x-httpd-fastphp5', \n  handler = 0x83d980 'php5-script', content_encoding = 0x0, \n  content_languages = 0x0, vlist_validator = 0x0, \n  user = 0x82e1d8 'wollman@MIT.EDU', ap_auth_type = 0x0, no_cache = 0, \n  no_local_copy = 0, \n  unparsed_uri = 0x819360 '/16.410/wiki/index.php?title=Special:Preferences', \n  uri = 0x819398 '/16.410/wiki/index.php', \n  filename = 0x819ae8 '/afs/csail.mit.edu/proj/courses/data/16.410/wiki/index.php', \n  canonical_filename = 0x819ae8\n'/afs/csail.mit.edu/proj/courses/data/16.410/wik---Type <return> to continue, or\nq <return> to quit--- \ni/index.php', path_info = 0x819a1a '', \n  args = 0x8193b0 'title=Special:Preferences', finfo = {pool = 0x817ca8, \n    valid = 7598448, protection = 1604, filetype = APR_REG, user = 12369, \n    group = 12369, inode = 831797006, device = 18, nlink = 1, size = 3218, \n    csize = 0, atime = 1183079954000000, mtime = 1183079954000000, \n    ctime = 1183079954000000, \n    fname = 0x8199e0\n'/afs/csail.mit.edu/proj/courses/data/16.410/wiki/index.php', name = 0x0,\nfilehand = 0x0}, parsed_uri = {scheme = 0x0, hostinfo = 0x0, \n    user = 0x0, password = 0x0, hostname = 0x0, port_str = 0x0, \n    path = 0x819398 '/16.410/wiki/index.php', \n    query = 0x8193b0 'title=Special:Preferences', fragment = 0x0, \n    hostent = 0x0, port = 0, is_initialized = 1, dns_looked_up = 0, \n    dns_resolved = 0}, used_path_info = 2, per_dir_config = 0x82c5f8, \n  request_config = 0x818c80, htaccess = 0x82c5a0, output_filters = 0x8191f0, \n  input_filters = 0x82e1a0, proto_output_filters = 0x8191f0, \n  proto_input_filters = 0x8198b8, eos_sent = 0}\n
43738	Garrett Wollman	1193923000000	And I can now confirm that the head of the input filter chain for the original\nrequest is 'ssl/tls buffer':\n\n(gdb) p *r->prev->input_filters\n$7 = {frec = 0x6333b8, ctx = 0x84b760, next = 0x858e18, r = 0x857278, \n  c = 0x80ba98}\n(gdb) p *r->prev->input_filters->frec\n$8 = {name = 0x628a18 'ssl/tls buffer', filter_func = {\n    out_func = 0x2b7547f58370 <ssl_io_filter_buffer>, \n    in_func = 0x2b7547f58370 <ssl_io_filter_buffer>}, filter_init_func = 0, \n  ftype = 29, next = 0x0, providers = 0x0, debug = 0, proto_flags = 0}\n
43738	Garrett Wollman	1193923122000	Here's the full filter chain for both requests:\n\n(gdb) dump_filters r->input_filters\nhttp_in(0x81e8d8): ctx=0x85b050, r=0x818eb8, c=0x80ba98\nssl/tls filter(0x816ce8): ctx=0x814c98, r=0x0, c=0x80ba98\nlog_input_output(0x80c240): ctx=0x0, r=0x0, c=0x80ba98\ncore_in(0x816d90): ctx=0x816d70, r=0x0, c=0x80ba98\n(gdb) dump_filters r->prev->input_filters\nssl/tls buffer(0x85b070): ctx=0x85b020, r=0x81cd38, c=0x80ba98\nhttp_in(0x81e8d8): ctx=0x85b050, r=0x818eb8, c=0x80ba98\nssl/tls filter(0x816ce8): ctx=0x814c98, r=0x0, c=0x80ba98\nlog_input_output(0x80c240): ctx=0x0, r=0x0, c=0x80ba98\ncore_in(0x816d90): ctx=0x816d70, r=0x0, c=0x80ba98\n
43738	Joe Orton	1193985234000	Created an attachment (id=21080)\nworking fix\n\nHere's a tested fix.  Moving the filter to AP_FTYPE_PROTOCOL is the right thing\nto do; there were a few tricks needed to getting this working though.\n\nFurther testing welcome!
43738	Joe Orton	1193997075000	Fixed on trunk as per attached patch with only comment tweaks:\n\nhttp://svn.apache.org/viewvc?rev=591393&view=rev\n\nResults from testing still desirable!\n\n
43738	Garrett Wollman	1194008520000	It appears to work on my test server.\n
43738	Joe Orton	1194232817000	Great, thanks a lot for the testing and debugging work.
43738	Ruediger Pluem	1199242815000	Proposed for backport in r608076.
43738	Joe Orton	1199412285000	Merged for 2.2.x: http://svn.apache.org/viewvc?view=rev&revision=608787
43789	Tom Donovan	1194072938000	Created an attachment (id=21082)\nscoreboard.c declaration for ap_time_process_request\n
43789	Ruediger Pluem	1194146472000	Committed to trunk as r591760\n(http://svn.apache.org/viewvc?rev=591760&view=rev). Thanks for the fix.
43856	Frantisek Sokolovsky	1195019392000	also server http://www.perldoc.com/ doesn't working. Only today (14th november \n2007)?\n
43856	Andr?? Malo	1195022223000	Changed the references to perldoc.perl.org. Thanks for your care.
43882	Nick Kew	1195194075000	Fixed in trunk in r595672.
43882	Bj	1195246701000	From the latest version:\n\n            /* RFC2616 allows qualifiers, so use strncasecmp */\n            if (!strncasecmp(tenc, 'chunked', 7) && !ap_strchr_c(tenc, ',')) {\n                ctx->state = BODY_CHUNK;\n            }\n            else {\n                /* Something that isn't in HTTP, unless some future\n                 * edition defines new transfer ecodings, is unsupported.\n                 */\n\nI am a bit worried, I am unsure what 'qualifiers' refers to and the code below \nseems to match on 'Transfer-Encoding: chunkedfoo' which it should not. And the \noriginal example 'Transfer-Encoding: gzip,chunked' is 'in HTTP', Apache just \ndoes not support it. So shouldn't this be something like\n\n            if (!strcasecmp(tenc, 'chunked')) {\n                ctx->state = BODY_CHUNK;\n            }\n            else {\n                /* Other Transfer-Encodings are not implemented */\n
43882	Nick Kew	1195259392000	Bj??rn, this is turning into discussion, and as such should be on dev@httpd, not\nbugzilla.  Do you follow that?\n\n1.  Qualifiers come from the BNF-style representation of the header, which means\nsomething like\nTransfer-Encoding: chunked;foo=bar\nis syntactically valid.  But in practice, no qualifiers are defined.\n\n2.  gzip is a content-encoding, not a transfer-encoding.  The passage in RFC2616\nthat suggests otherwise is clearly a drafter who'd been staring at it too long,\nand had a brainfart.\n\n3.  You're right about 'chunkedfoo' - I'll fix it.  If noone shouts, I'll just\nset it back to strcasecmp, so we don't support any qualifiers.  As it happens,\nI'd already realised it wasn't right, but just wasn't rushing the job again:-)\n\nThank you for your attention to detail.
43882	Bj	1195262682000	Ah you meant parameters, they are indeed allowed, but not knowing what to do \nwith them they didn't seem to affect the issue. I don't follow the development \nlist, but I also have nothing to add if you do 3., except to point out that you \nare wrong about gzip not being a Transfer-Encoding...
43882	Nick Kew	1197095725000	Fixed in r602470.
43889	Dr Stephen Henson	1195279248000	Created an attachment (id=21141)\nLog associated error string\n
43889	Joe Orton	1195437579000	The man page for ERR_get_error_line_data() implies that you have to check for\nflags&ERR_TXT_MALLOCED and free the 'data' string if true - but the fact that\ndata is passed as const char * somewhat contradicts that - what's correct here?
43889	Dr Stephen Henson	1195450498000	The manual page is a bit confusing in that respect. Almost all applications just\ncall ERR_print_errors() and forget about it, that isn't of course possible here.\n\nThe data will be freed internally when the circular buffer is reused (e.g. by\nmore errors or explicitly cleared).\n\nIf you free up the data explicitly it wont reset the internal flags and data so\nyou'd end up with the data being freed twice.\n\nNow I've checked the sources in more detail there is a simpler way to achieve\nthe same thing and free up the data properly: peek the error first and call\nERR_get_error() afterwards. New patch included.
43889	Dr Stephen Henson	1195450716000	Created an attachment (id=21151)\nUpdated associated error print patch.\n
43889	Joe Orton	1195623459000	Great, thanks.  I also took the opportunity to tweak the log message to\ndelineate the error/data/annotation better; committed to trunk:\n\nhttp://svn.apache.org/viewvc?view=rev&revision=597077
43890	Tony Stevenson	1198512350000	Bill,\n\nThanks for the heads up here.  I have corrected this is in the trunk branch of \nthe documentation, and committed it.  These changes should be visible within a \nfew hours.  \n\nFor some reason my build tool will not build 2.2, or 2.0 docs at the moment, so \nI cannot commit these changes to the older branches.  \n\nSee here for the SVN commit log:  http://svn.apache.org/\nviewvc?view=rev&revision=606748\n\n
43890	Tony Stevenson	1198514014000	Bill,\n\nAs promised here are the commits for 2.2, and 2.0\n\n2.2 Updated:  http://svn.apache.org/viewvc?rev=606749&view=rev\n2.0 Updated:  http://svn.apache.org/viewvc?rev=606750&view=rev\n\n\nRegards,\nTony
43922	Basant Kumar Kukreja	1195599875000	Created an attachment (id=21170)\nPatch for the bug\n\nCorrected the CustomLog directive entry in httpd-vhosts.in file.\n
43922	Jeff Trawick	1195616867000	Fixed in 2.2.x branch; not a problem in trunk; thanks!
44001	Vincent Bray	1196545522000	http://svn.apache.org/viewvc?view=rev&revision=600245\n\nDocs updated, thanks. The update doesn't include instructions for browser version detection as the hack is \nused as a fallback and doesn't get invoked by msie7's correct digest hashing.
44014	Victor Stinner	1196664659000	Created an attachment (id=21220)\nFix the XSS\n
44014	Will Rowe	1196683007000	For a host of reasons, this is generally not exploitable in any usual case,\nand would represent a very unusual client.  Quoting the 'vulnerability' report;\n\n'This type of attack can result in non-persistent defacement of the target site, \nor the redirection of confidential information (i.e. session IDs) to unauthorised \nthird parties provided that a web browser is tricked to submit a malformed HTTP \nmethod.'\n\nGiven that this is nonsense in the context of a web browser, no CVE will be\nassigned, but thank you for the report, it is a bug worth fixing.  Proposed\nfor backport to 2.2 and 2.0.\n
44073	yl	1197530017000	Sorry, httpd-2.2.6 is concerned by this bug, not the version 2.0.61 which\ndoesn't implement the certificate OIDs requirements.\n\nI want to submit a patch on httpd-2.0.61 for this to be handled, hence my confusion.
44073	Ruediger Pluem	1197547714000	Proposed patch for inclusion to 2.2.x in r604012\n(http://svn.apache.org/viewvc/httpd/httpd/branches/2.2.x/STATUS?r1=604012&r2=604011&pathrev=604012)
44073	yl	1197606347000	Ok for the patch in 2.2.x, but the problem is there in trunk too :\n           *ptr = apr_pstrmemdup(p, buf->data, buf->length);\nThis will not create a nul-terminated string either, while it is supposed to, I\nsuggest to use apr_strndup here too.\n\nShould I open a new ticket for trunk ?
44073	yl	1197606840000	Trunk changes in http://svn.apache.org/viewvc?view=rev&revision=289444 has moved\nthe problem described above in httpd-trunk/modules/ssl/ssl_engine_vars.c,\nfunction ssl_ext_list()
44073	Joe Orton	1197635907000	pstrmemdup does NUL-terminate the returned string.
44073	Ruediger Pluem	1197679476000	Included in 2.2.x per r604403 (http://svn.apache.org/viewvc?rev=604403&view=rev).
44073	yl	1197855933000	Sorry, I didn't notice that, the name drove me wrong.\nThanks for the patch.
44152	Michael Clark	1198904903000	Here is the relevant part of the litmus debug log.\n\n2.2.6\n\nSending request headers:\nHEAD /uploads/litmus/lockme HTTP/1.1\nHost: localhost\nUser-Agent: litmus/0.11 neon/0.26.3\nConnection: TE\nTE: trailers\nAuthorization: Basic bWNsYXJrOnNhZ2kxNzcx\nX-Litmus: locks: 16 (fail_cond_put)\n\nSending request-line and headers:\nRequest sent; retry is 1.\n[status-line] < HTTP/1.1 200 OK\n[hdr] Date: Sat, 29 Dec 2007 10:09:11 GMT\nHeader Name: [date], Value: [Sat, 29 Dec 2007 10:09:11 GMT]\n[hdr] Server: Apache/2.2.7-dev (Unix) DAV/2\nHeader Name: [server], Value: [Apache/2.2.7-dev (Unix) DAV/2]\n[hdr] Last-Modified: Sat, 29 Dec 2007 10:09:10 GMT\nHeader Name: [last-modified], Value: [Sat, 29 Dec 2007 10:09:10 GMT]\n[hdr] ETag: 'ec400e-20-4426a008c3d80'\nHeader Name: [etag], Value: ['ec400e-20-4426a008c3d80']\n\n\n2.2.7-dev\n\nSending request headers:\nHEAD /uploads/litmus/lockme HTTP/1.1\nHost: localhost\nUser-Agent: litmus/0.11 neon/0.26.3\nConnection: TE\nTE: trailers\nAuthorization: Basic bWNsYXJrOnNhZ2kxNzcx\nX-Litmus: locks: 15 (cond_put)\n\nSending request-line and headers:\nRequest sent; retry is 1.\n[status-line] < HTTP/1.1 200 OK\n[hdr] Date: Sat, 29 Dec 2007 12:53:31 GMT\nHeader Name: [date], Value: [Sat, 29 Dec 2007 12:53:31 GMT]\n[hdr] Server: Apache/2.2.7-dev (Unix) DAV/2\nHeader Name: [server], Value: [Apache/2.2.7-dev (Unix) DAV/2]\n[hdr] Last-Modified: Sat, 29 Dec 2007 12:53:31 GMT\nHeader Name: [last-modified], Value: [Sat, 29 Dec 2007 12:53:31 GMT]\n[hdr] ETag: W/'ec400e-20-4426c4c4f28c0'\nHeader Name: [etag], Value: [W/'ec400e-20-4426c4c4f28c0']\n
44152	Michael Clark	1198905084000	Reversing the changes to http_etag.c fixes the problem.\n\nWhich I guess is this CHANGES entry:\n\n *) core: Change etag generation to produce identical results on\n     32-bit and 64-bit platforms.  PR 40064.  [Joe Orton]\n\n
44152	Michael Clark	1198905725000	Created an attachment (id=21331)\nhttp_etags change when reversed solves regression\n
44152	Michael Clark	1198906167000	Just another quick note. From looking at the debug.log with 2.2.6, the\nlast-modified date is 1 second behind the Date header.\n\nWith 2.2.7-dev, the dates are equal.\n\nI'm am unsure how the patch effects the dates to cause the Weak ETag in\n2.2.7-dev as it does not apparently change any date fields only reads them.\n\nI have run the tests many times to ensure it is not a timing issue.\n
44152	Michael Clark	1198907505000	The date issue and Etag I mentioned is a red herring.\n\nHere the test is succedding on 2.2.7-dev with the 64bit etag patches reversed\n(Dates are equal and ETag is weak - so not related).\n\nMust be one of the 64 bits casts is putting garbage in the Etag making the\ncondition fail.\n\nThis is a successful run on 32bit Linux with the patch reversed.\n\n\n******* Running test 15: cond_put ********\nah_create, for WWW-Authenticate\nRunning pre_send hooks\nauth: Sending 'Basic' response.\nSending request headers:\nHEAD /uploads/litmus/lockme HTTP/1.1\nHost: localhost\nUser-Agent: litmus/0.11 neon/0.26.3\nConnection: TE\nTE: trailers\nAuthorization: Basic bWNsYXJrOnNhZ2kxNzcx\nX-Litmus: locks: 15 (cond_put)\n\nSending request-line and headers:\nRequest sent; retry is 1.\n[status-line] < HTTP/1.1 200 OK\n[hdr] Date: Sat, 29 Dec 2007 13:46:43 GMT\nHeader Name: [date], Value: [Sat, 29 Dec 2007 13:46:43 GMT]\n[hdr] Server: Apache/2.2.7-dev (Unix) DAV/2\nHeader Name: [server], Value: [Apache/2.2.7-dev (Unix) DAV/2]\n[hdr] Last-Modified: Sat, 29 Dec 2007 13:46:43 GMT\nHeader Name: [last-modified], Value: [Sat, 29 Dec 2007 13:46:43 GMT]\n[hdr] ETag: W/'ec400e-20-a9136c0'\nHeader Name: [etag], Value: [W/'ec400e-20-a9136c0']\n[hdr] Accept-Ranges: bytes\nHeader Name: [accept-ranges], Value: [bytes]\n[hdr] Content-Length: 32\nHeader Name: [content-length], Value: [32]\n[hdr] Content-Type: text/plain\nHeader Name: [content-type], Value: [text/plain]\n[hdr] \nEnd of headers.\nRunning post_send hooks\nah_post_send (#0), code is 200 (want 401), WWW-Authenticate is (none)\nRequest ends, status 200 class 2xx, error line:\n200 OK\nRunning destroy hooks.\nRequest ends.\nah_create, for WWW-Authenticate\nRunning pre_send hooks\nauth: Sending 'Basic' response.\nSending request headers:\nPUT /uploads/litmus/lockme HTTP/1.1\nHost: localhost\nUser-Agent: litmus/0.11 neon/0.26.3\nConnection: TE\nTE: trailers\nContent-Length: 32\nIf: (<opaquelocktoken:7da06b5a-b614-11dc-89f6-f543e31a2f21> [W/'ec400e-20-a9136c0'])\nAuthorization: Basic bWNsYXJrOnNhZ2kxNzcx\nX-Litmus: locks: 15 (cond_put)\n\nSending request-line and headers:\nSending request body:\nBody block (32 bytes):\n[This\nis\na\ntest\nfile\ncalled\nfoo\n\n]\nRequest sent; retry is 1.\n[status-line] < HTTP/1.1 204 No Content\n[hdr] Date: Sat, 29 Dec 2007 13:46:43 GMT\nHeader Name: [date], Value: [Sat, 29 Dec 2007 13:46:43 GMT]\n[hdr] Server: Apache/2.2.7-dev (Unix) DAV/2\nHeader Name: [server], Value: [Apache/2.2.7-dev (Unix) DAV/2]\n[hdr] Content-Length: 0\nHeader Name: [content-length], Value: [0]\n[hdr] Content-Type: text/plain\nHeader Name: [content-type], Value: [text/plain]\n[hdr] \nEnd of headers.\nRunning post_send hooks\nah_post_send (#0), code is 204 (want 401), WWW-Authenticate is (none)\nRequest ends, status 204 class 2xx, error line:\n204 No Content\nRunning destroy hooks.\nRequest ends.\n
44152	Michael Clark	1198910201000	It appears the problem is mod_dav:dav_fs_getetag routine not being updating to\ncreate 64bit time in the etags.\n\nPlease apply this patch so we can avoid this regression in 2.2.7\n\nI will verify if the same issue is present in trunk (I think it is)
44152	Michael Clark	1198910255000	Created an attachment (id=21332)\nupdate to print 64 bit time in the etag\n
44152	Michael Clark	1198910430000	Created an attachment (id=21333)\nAll fields should be 64bit for parity with http_etag implementation\n
44152	Michael Clark	1198911593000	Just verified that the same issue is present in trunk 2.3.0-dev.\n\nPatch applies there with 4 lines offset.\n\nI get no litmus failures with this patch applied on both 2.2.7-dev and 2.3.0-dev\n
44152	Michael Clark	1198912170000	Created an attachment (id=21334)\nmissed mtime only case\n
44152	Ruediger Pluem	1198915716000	Thanks for the patch. Committed a slightly modified version of the patch\n(r607437, http://svn.apache.org/viewvc?rev=607437&view=rev) plus a warning to\nthe FileETAG documentation that changing the default could cause breakage with\nconditional WebDAV requests against mod_dav_fs provided backends.
44152	Ruediger Pluem	1198916526000	Proposed for backport as r607441 (http://svn.apache.org/viewvc?rev=607441&view=rev).
44152	Ruediger Pluem	1200743448000	Fixed in 2.2.8.
44311	Ruediger Pluem	1201505394000	1. There was no 2.2.7 release. Do you talk about the candidate that was\npublished on the dev list for review?\n2. How does it break www.hotels.com?
44311	Peter Belau	1201505520000	(In reply to comment #1)\n> 1. There was no 2.2.7 release. Do you talk about the candidate that was\n> published on the dev list for review?\n> 2. How does it break www.hotels.com?\n\nSorry, I meant 2.2.6. In Firefox and Opera there is no visible page data. In the\nlogs with debug turned on I'm seeing:\n\n[Mon Jan 28 07:27:21 2008] [debug] mod_proxy_http.c(1822): proxy: HTTP: serving\nURL http://www.hotels.com/\n[Mon Jan 28 07:27:21 2008] [debug] proxy_util.c(1855): proxy: HTTP: has acquired\nconnection for (*)\n[Mon Jan 28 07:27:21 2008] [debug] proxy_util.c(1916): proxy: connecting\nhttp://www.hotels.com/ to www.hotels.com:80\n[Mon Jan 28 07:27:21 2008] [debug] proxy_util.c(2015): proxy: connected / to\nwww.hotels.com:80\n[Mon Jan 28 07:27:21 2008] [debug] proxy_util.c(2172): proxy: HTTP: fam 2 socket\ncreated to connect to *\n[Mon Jan 28 07:27:21 2008] [debug] proxy_util.c(2269): proxy: HTTP: connection\ncomplete to 72.246.51.115:80 (www.hotels.com)\n[Mon Jan 28 07:27:21 2008] [debug] mod_proxy_http.c(1607): proxy: start body send\n[Mon Jan 28 07:27:21 2008] [debug] mod_headers.c(665): headers:\nap_headers_output_filter()\n[Mon Jan 28 07:27:21 2008] [info] [client 127.0.0.1] (104)Connection reset by\npeer: core_output_filter: writing data to the network\n[Mon Jan 28 07:27:21 2008] [debug] mod_proxy_http.c(1696): proxy: end body send\n[Mon Jan 28 07:27:21 2008] [debug] proxy_util.c(1873): proxy: HTTP: has released\nconnection for (*)\n[Mon Jan 28 07:27:21 2008] [info] [client 127.0.0.1] (32)Broken pipe:\ncore_output_filter: writing data to the network\n\n\n\n
44311	Peter Belau	1201506157000	Also, I should not that hotels.com seems to send a redirect depending upon what\ncountry you are from. You can perhaps try this link from  Germany:\n\nhttp://www.hotels.com/?isRedirect=true&js=1&zz=1201533352859\n\n(In reply to comment #1)\n> 1. There was no 2.2.7 release. Do you talk about the candidate that was\n> published on the dev list for review?\n> 2. How does it break www.hotels.com?\n\n
44311	Ruediger Pluem	1201506592000	Please post your configuration. I tried to use 2.2.8 as forward proxy and I had\nno hassle reaching www.hotels.com. The messages from the error log indicate that\nyou have a client problem.
44311	Peter Belau	1201506875000	(In reply to comment #4)\n> Please post your configuration. I tried to use 2.2.8 as forward proxy and I had\n> no hassle reaching www.hotels.com. The messages from the error log indicate that\n> you have a client problem.\n\nMy configuration is posted in the body of the original message. I have been able\nto reproduce this error on 3 different Apache builds running on 3 different\nnetworks. The errors occurs both with Firefox and Opera.\n\n
44311	Takashi Sato	1201508715000	I've succeeded to reproduce this IE 7.0 WinXP SP3RC1
44311	Takashi Sato	1201510921000	If IE setting 'Use HTTP/1.1 for proxy' is turned off, work correct.\nI guess something happens in chunked encoding.
44311	Ruediger Pluem	1201511227000	(In reply to comment #3)\n> Also, I should not that hotels.com seems to send a redirect depending upon what\n> country you are from. You can perhaps try this link from  Germany:\n> \n> http://www.hotels.com/?isRedirect=true&js=1&zz=1201533352859\n\nThanks for the link. With the help of the link I was able to reproduce your issue.\nIt is caused by www.hotels.com sending a Connection: Transfer-Encoding header in\nits response. This is IMHO unusual (Transfer-Encoding is a hop-by-hop header\nanyway), but allowed. This causes httpd to remove Transfer-Encoding too early\nduring its internal processing and thus disables it from processing the chunked\nresponse. Please let me know if the patch I will attach in a second fixes your\nproblem. \n\n
44311	Ruediger Pluem	1201511260000	Created an attachment (id=21438)\nPatch against Trunk\n
44311	Peter Belau	1201513403000	Thanks a lot for tackling this issue, but must this patch be strictly applied to\ntrunk ? I tried it against 2.2.8 with no success ...\n\n(In reply to comment #9)\n> Created an attachment (id=21438) [edit]\n> Patch against Trunk\n> \n\n
44311	Ruediger Pluem	1201519591000	(In reply to comment #10)\n> Thanks a lot for tackling this issue, but must this patch be strictly applied to\n> trunk ? I tried it against 2.2.8 with no success ...\n\nNo, it should work with 2.2.8. I tested it with the link you provided against\n2.2.x (which is currently identical to 2.2.8 with respect to mod_proxy) and\nafterwards everything was fine.\n\n
44311	Peter Belau	1201541231000	You are right. In my sleepy state, I incorrectly manually applied the patch. It\ndoes indeed fix this issue. Thanks again !\n\n(In reply to comment #11)\n> (In reply to comment #10)\n> > Thanks a lot for tackling this issue, but must this patch be strictly applied to\n> > trunk ? I tried it against 2.2.8 with no success ...\n> \n> No, it should work with 2.2.8. I tested it with the link you provided against\n> 2.2.x (which is currently identical to 2.2.8 with respect to mod_proxy) and\n> afterwards everything was fine.\n> \n> \n\n
44311	Takashi Sato	1201595286000	Reopen because no fixes haven't been committed yet
44311	Ruediger Pluem	1201611409000	Committed a slightly optimized version to trunk as r616517\n(http://svn.apache.org/viewvc?rev=616517&view=rev).
44311	Takashi Sato	1201879549000	backported to 2.2\nhttp://svn.apache.org/viewvc?view=rev&revision=617686
44346	Ruediger Pluem	1201953528000	I agree with this. Does the following patch solve the problem for you?
44346	Ruediger Pluem	1201953566000	Created an attachment (id=21462)\nPatch against trunk\n
44346	Toralf F	1201954493000	(In reply to comment #2)\n> Created an attachment (id=21462) [edit]\n> Patch against trunk\n> \nyes, works fine :-)
44346	Ruediger Pluem	1201955878000	Committed to trunk as r617890 (http://svn.apache.org/viewvc?rev=617890&view=rev).
44346	Ruediger Pluem	1202010116000	*** Bug 40734 has been marked as a duplicate of this bug. ***
44346	Toralf F	1202012240000	I'm wondering why this bug was open such a long time w/o a solution (bug #40734\nwas opened at 2006-10-11 14:50)\n
44346	Ruediger Pluem	1202092917000	Proposed for backport to 2.2.x as r618229\n(http://svn.apache.org/viewvc?rev=618229&view=rev).
44346	Takashi Sato	1208418907000	backported to 2.2\n<http://svn.apache.org/viewvc?view=rev&revision=618229>
44346	Takashi Sato	1208547365000	sorry, wrong revision\n\nbackported to 2.2 as r649114\nhttp://svn.apache.org/viewvc?view=rev&revision=649114
44360	Rainer Jung	1202229852000	Created an attachment (id=21474)\nTypo correction patch (timout)\n
44360	Ruediger Pluem	1202298757000	Thanks for the patch. Committed to trunk in r619125.
44402	Basant Kumar Kukreja	1202836443000	I tried to debug the crash \n=>[1] allocator_free(allocator = 0x101f870, node = (nil)), line 331 in 'apr_pools.c'\n  [2] apr_pool_clear(pool = 0x102fb88), line 710 in 'apr_pools.c'\n  [3] ap_core_output_filter(f = 0x1020550, b = 0x101f9e8), line 899 in\n'core_filters.c'\n\nIn ap_core_output_filter, crash is happening when apr_pool_clear is called for\ndeferred_write_pool.\n            apr_pool_clear(ctx->deferred_write_pool);\nOn further investigation, I found that for ctx->deferred_write_pool, pool->ref\npoints to pool->next i.e\npool->ref == &pool->next\n\nThus in apr_pool_clear :\n    if (active->next == active)\n        return;\n\n    *active->ref = NULL; // ---> this cause active->next to set to NULL because\n                         // active->ref points to active->next\n    allocator_free(pool->allocator, active->next);\n\nThe situation doesn't arrive on normal single connection situation. This\nhappens only under stress. Under normal connection active->next == active and\nfunction returns from apr_pool_clear (when called for ctx->deferred_write_pool)\n
44402	Basant Kumar Kukreja	1202843742000	Crashes are happening on 32 bit apache too therefore changing the summary.
44402	Basant Kumar Kukreja	1202843878000	Here is the crash from 32 bit apache :\n=>[1] allocator_free(allocator = 0x8aae018, node = (nil)), line 331 in 'apr_pools.c'\n  [2] apr_pool_clear(pool = 0x8b629b8), line 710 in 'apr_pools.c'\n  [3] ap_core_output_filter(f = 0x8aae870, b = 0x8aae0e0), line 899 in\n'core_filters.c'\n  [4] ap_pass_brigade(next = 0x8aae870, bb = 0x8aae0e0), line 526 in 'util_filter.c'\n  [5] logio_out_filter(f = 0x8aae830, bb = 0x8aae0e0), line 135 in 'mod_logio.c'\n  [6] ap_pass_brigade(next = 0x8aae830, bb = 0x8aae0e0), line 526 in 'util_filter.c'\n  [7] ap_flush_conn(c = 0x8aae390), line 84 in 'connection.c'\n  [8] ap_lingering_close(c = 0x8aae390), line 123 in 'connection.c'\n  [9] process_socket(p = 0x8aae0a0, sock = 0x8aae0e0, my_child_num = 1,\nmy_thread_num = 249, bucket_alloc = 0x8b5c9a0), line 545 in 'worker.c'\n  [10] worker_thread(thd = 0x81a6788, dummy = 0x831f5a0), line 894 in 'worker.c'\n  [11] dummy_worker(opaque = 0x81a6788), line 142 in 'thread.c'\n  [12] _thr_setup(0xf004d200), at 0xfec6f282\n  [13] _lwp_start(0xfee7ddb9, 0xfee7f55e, 0xfffffff6, 0x0, 0x1, 0xfeea1984), at\n0xfec6f4e0\n
44402	Basant Kumar Kukreja	1202845431000	Here is the debug information from a crash of 32 bit apache :\n\nt@414 (l@414) terminated by signal SEGV (Segmentation Fault)\nCurrent function is apr_sockaddr_ip_get\n  104       *addr = apr_palloc(sockaddr->pool, sockaddr->addr_str_len);\n(dbx) where\ncurrent thread: t@414\n=>[1] apr_sockaddr_ip_get(addr = 0x974a3d0, sockaddr = (nil)), line 104 in\n'sockaddr.c'\n  [2] core_create_conn(ptrans = 0x974a348, server = 0x80d9020, csd = 0x974a388,\nid = 411, sbh = 0x974a398, alloc = 0x9788670), line 3895 in 'core.c'\n  [3] ap_run_create_connection(0x974a348, 0x80d9020, 0x974a388, 0x19b,\n0x974a398, 0x9788670), at 0x8090ae8\n  [4] process_socket(p = 0x974a348, sock = 0x974a388, my_child_num = 0,\nmy_thread_num = 411, bucket_alloc = 0x9788670), line 542 in 'worker.c'\n  [5] worker_thread(thd = 0x83a6ff8, dummy = 0x8125e80), line 894 in 'worker.c'\n  [6] dummy_worker(opaque = 0x83a6ff8), line 142 in 'thread.c'\n  [7] _thr_setup(0xf008e200), at 0xfec6f282\n  [8] _lwp_start(0x0, 0xfee8410c, 0xe451bef8, 0xe451bef8, 0x8081a83, 0x974a3d0),\nat 0xfec6f4e0\n(dbx) p sockaddr\nsockaddr = (nil)\n(dbx) where\ncurrent thread: t@414\n=>[1] apr_sockaddr_ip_get(addr = 0x974a3d0, sockaddr = (nil)), line 104 in\n'sockaddr.c'\n  [2] core_create_conn(ptrans = 0x974a348, server = 0x80d9020, csd = 0x974a388,\nid = 411, sbh = 0x974a398, alloc = 0x9788670), line 3895 in 'core.c'\n  [3] ap_run_create_connection(0x974a348, 0x80d9020, 0x974a388, 0x19b,\n0x974a398, 0x9788670), at 0x8090ae8\n  [4] process_socket(p = 0x974a348, sock = 0x974a388, my_child_num = 0,\nmy_thread_num = 411, bucket_alloc = 0x9788670), line 542 in 'worker.c'\n  [5] worker_thread(thd = 0x83a6ff8, dummy = 0x8125e80), line 894 in 'worker.c'\n  [6] dummy_worker(opaque = 0x83a6ff8), line 142 in 'thread.c'\n  [7] _thr_setup(0xf008e200), at 0xfec6f282\n  [8] _lwp_start(0x0, 0xfee8410c, 0xe451bef8, 0xe451bef8, 0x8081a83, 0x974a3d0),\nat 0xfec6f4e0\n(dbx) up\nCurrent function is core_create_conn\n 3895       apr_sockaddr_ip_get(&c->local_ip, c->local_addr);\n(dbx) p *c\n*c = {\n    pool                  = 0x974a348\n    base_server           = (nil)\n    vhost_lookup_data     = (nil)\n    local_addr            = (nil)\n    remote_addr           = (nil)\n    remote_ip             = (nil)\n    remote_host           = (nil)\n    remote_logname        = (nil)\n    aborted               = 0\n    keepalive             = AP_CONN_UNKNOWN\n    double_reverse        = 0\n    keepalives            = 0\n    local_ip              = (nil)\n    local_host            = (nil)\n    id                    = 0\n    conn_config           = 0x974a400\n    notes                 = 0x974a6a0\n    input_filters         = (nil)\n    output_filters        = (nil)\n    sbh                   = 0x974a398\n    bucket_alloc          = (nil)\n    cs                    = (nil)\n    data_in_input_filters = 0\n}\n(dbx) dump\nalloc = 0x9788670\nrv = 0\nptrans = 0x974a348\nserver = 0x80d9020\nsbh = 0x974a398\nc = 0x974a3a0\nid = 411\ncsd = 0x974a388\n(dbx) _arch_networkio.h"struct apr_socket_t*)csd                              <\n*((struct apr_socket_t *) csd) = {\n    pool                    = (nil)\n    socketdes               = 158893680\n    type                    = -17726080\n    protocol                = 134660748\n    local_addr              = (nil)\n    remote_addr             = 0x19b\n    timeout                 = 158638920LL\n    local_port_unknown      = 0\n    local_interface_unknown = 0\n    remote_addr_unknown     = 0\n    options                 = 0\n    inherit                 = 0\n    userdata                = (nil)\n}\n\nPlease let me know if any other information is need.\n
44402	Ruediger Pluem	1202907786000	First guess for your last crash in comment #4 (all line numbers 2.2.8):\n\nlr->accept_func(&csd, lr, ptrans); (line 742 in worker.c) fails with\nrv != APR_SUCCESS, but with a non NULL value for csd.\nIn contrast to the code in prefork we don't check this situation:\n\nLines 621 - 631 of prefork.c:\n\n        status = lr->accept_func(&csd, lr, ptrans);\n\n        SAFE_ACCEPT(accept_mutex_off());      /* unlock after 'accept' */\n\n        if (status == APR_EGENERAL) {\n            /* resource shortage or should-not-occur occured */\n            clean_child_exit(1);\n        }\n        else if (status != APR_SUCCESS) {\n            continue;\n        }\n\nMaybe we need to do a continue in the worker case as well or we need to do\nsomething like the following:\n\nIndex: server/mpm/worker/worker.c\n===================================================================\n--- server/mpm/worker/worker.c  (Revision 627576)\n+++ server/mpm/worker/worker.c  (Arbeitskopie)\n@@ -743,6 +743,9 @@\n             /* later we trash rv and rely on csd to indicate success/failure */\n             AP_DEBUG_ASSERT(rv == APR_SUCCESS || !csd);\n\n+            if (rv != APR_SUCCESS) {\n+                csd = NULL;\n+            }\n             if (rv == APR_EGENERAL) {\n                 /* E[NM]FILE, ENOMEM, etc */\n                 resource_shortage = 1;\n\n\n\n
44402	Basant Kumar Kukreja	1202943362000	I did the stress test with the patch you suggested. After your patch, I\nstill got the 1st crash. If it crashed in second stack trace then I will update\nthe bug.\n\nHere are some more information about 1st crash.\n* I am able to reproduce the crash on Solaris 10 update 1 (on a different\n  machine) too. It took around 4 hours of stress before I got the crash on\n  Solaris 10 while it takes around < 30 minutes to reproduce on Solaris nevada.\n  It was crash 1 (allocator_free with node = null) (without your patch).\n\nHere is more information of the crash 1 :\n(dbx) where\ncurrent thread: t@21\n=>[1] allocator_free(allocator = 0x8afe2e0, node = (nil)), line 331 in 'apr_pools.c'\n  [2] apr_pool_clear(pool = 0xa0d01c0), line 710 in 'apr_pools.c'\n  [3] ap_core_output_filter(f = 0xa0b28c8, b = 0xa0b2a08), line 899 in\n'core_filters.c'\n  [4] ap_pass_brigade(next = 0xa0b28c8, bb = 0xa0b2a08), line 526 in 'util_filter.c'\n  [5] logio_out_filter(f = 0xa0b2888, bb = 0xa0b2a08), line 135 in 'mod_logio.c'\n  [6] ap_pass_brigade(next = 0xa0b2888, bb = 0xa0b2a08), line 526 in 'util_filter.c'\n  [7] ap_flush_conn(c = 0xa0b23e8), line 84 in 'connection.c'\n  [8] ap_lingering_close(c = 0xa0b23e8), line 123 in 'connection.c'\n  [9] process_socket(p = 0x8afe368, sock = 0x8aff660, my_child_num = 1,\nmy_thread_num = 18, bucket_alloc = 0xa0be178), line 545 in 'worker.c'\n  [10] worker_thread(thd = 0x81487d8, dummy = 0x8117b30), line 894 in 'worker.c'\n  [11] dummy_worker(opaque = 0x81487d8), line 142 in 'thread.c'\n  [12] _thr_setup(0xfe244800), at 0xfeccf92e\n  [13] _lwp_start(), at 0xfeccfc10\n(dbx) up\nCurrent function is apr_pool_clear\n  710       allocator_free(pool->allocator, active->next);\n(dbx) p *active\n*active = {\n    next        = (nil)\n    ref         = 0xa0d01a8\n    index       = 1U\n    free_index  = 0\n    first_avail = 0xa0d01f8 '/xc0^A^M/n/xfc^A^M/n/xfc^A^M/nx/xe1^K/n'\n    endp        = 0xa0d21a8 '^A '\n}\n(dbx) up\nCurrent function is ap_core_output_filter\n  899               apr_pool_clear(ctx->deferred_write_pool);\n(dbx) p *ctx\n*ctx = {\n    b                   = (nil)\n    deferred_write_pool = 0xa0d01c0\n}\n(dbx) p *ctx->deferred_write_pool\n*ctx->deferred_write_pool = {\n    parent           = 0x8afe368\n    child            = (nil)\n    sibling          = 0xa0c6198\n    ref              = 0x8afe36c\n    cleanups         = (nil)\n    free_cleanups    = (nil)\n    allocator        = 0x8afe2e0\n    subprocesses     = (nil)\n    abort_fn         = (nil)\n    user_data        = (nil)\n    tag              = 0x80bfd1c 'deferred_write'\n    active           = 0xa0d01a8\n    self             = 0xa0d01a8\n    self_first_avail = 0xa0d01f8 '/xc0^A^M/n/xfc^A^M/n/xfc^A^M/nx/xe1^K/n'\n}\n(dbx) p *c\n*c = {\n    pool                  = 0x8afe368\n    base_server           = 0x80e6bf8\n    vhost_lookup_data     = (nil)\n    local_addr            = 0x8aff698\n    remote_addr           = 0x8aff7c0\n    remote_ip             = 0xa0b2850 '192.168.11.1'\n    remote_host           = (nil)\n    remote_logname        = (nil)\n    aborted               = 0\n    keepalive             = AP_CONN_KEEPALIVE\n    double_reverse        = 0\n    keepalives            = 1\n    local_ip              = 0xa0b2840 '192.168.11.2'\n    local_host            = (nil)\n    id                    = 518\n    conn_config           = 0xa0b2448\n    notes                 = 0xa0b26e8\n    input_filters         = 0xa0b2870\n    output_filters        = 0xa0b2888\n    sbh                   = 0xa0b23e0\n    bucket_alloc          = 0xa0be178\n    cs                    = (nil)\n    data_in_input_filters = 0\n}\n\nOne putting some printfs I figured out the following :\n\nIn apr_pool_clear (when invoked for deferred_write_pool)\n    ...\n    active = pool->active = pool->self;\n    active->first_avail = pool->self_first_avail;\n\n    if (active->next == active)\n        return;\n\nactive->next should typically be s circular link list. What is happenning some\ncases is that active->next points to some thing else and active->ref still\npoints to active->next.  I put a printf of active->next before it is set to\nNULL. For a particular crash, here is my debugging session. I found that\nactive->next\nwas set to 0x20e8810 before it was set to NULL.\n\n(dbx) up\nCurrent function is apr_pool_clear\n  774       allocator_free(pool->allocator, active->next);\n(dbx) up\nCurrent function is ap_core_output_filter\n  923               apr_pool_clear(ctx->deferred_write_pool);\n(dbx) p (struct apr_memnode_t*)0x20e8810 -----> This was active->next before set\nto NULL.\n(struct apr_memnode_t *) 0x20e8810 = 0x20e8810\n(dbx) p *(struct apr_memnode_t*)0x20e8810\n*((struct apr_memnode_t *) 0x20e8810) = {\n    next        = 0x288c5b0\n    ref         = 0x20e8810\n    index       = 1U\n    free_index  = 0\n    first_avail = 0x20e9eb0 'GET /file_set/dir00104/class1_3 HTTP/1.0'\n    endp        = 0x20ea810 '^A '\n}\n(dbx) down\nCurrent function is apr_pool_clear\n  774       allocator_free(pool->allocator, active->next);\n(dbx) p active\nactive = 0x20e27e0\n(dbx) p *((struct apr_memnode_t*)0x20e8810)->next\n*((struct apr_memnode_t *) 0x20e8810)->next = {\n    next        = 0x20e07d0\n    ref         = 0x20e07d0\n    index       = 1U\n    free_index  = 0\n    first_avail = 0x288d008 ''\n    endp        = 0x288e5b0 '^A '\n}\n(dbx) p active\nactive = 0x20e27e0\n(dbx) p *(((struct apr_memnode_t*)0x20e8810)->next)->next\n*((struct apr_memnode_t *) 0x20e8810)->next->next = {\n    next        = 0x28905d0\n    ref         = 0x288c5b0\n    index       = 1U\n    free_index  = 0\n    first_avail = 0x20e2738 ''\n    endp        = 0x20e27d0 '^A '\n}\n(dbx) p *((((struct apr_memnode_t*)0x20e8810)->next)->next)->next\n*((struct apr_memnode_t *) 0x20e8810)->next->next->next = {\n    next        = 0x288e5c0\n    ref         = 0x28905d0\n    index       = 1U\n    free_index  = 0\n    first_avail = 0x2890668 '/xf8^E/x89^B'\n    endp        = 0x28925d0 '^Q^P'\n}\n(dbx) p *(((((struct apr_memnode_t*)0x20e8810)->next)->next)->next)->next\n*((struct apr_memnode_t *) 0x20e8810)->next->next->next->next = {\n    next        = (nil)\n    ref         = (nil)\n    index       = 1U\n    free_index  = 0\n    first_avail = 0x288e5e8 '"^_'\n    endp        = 0x28905c0 '^A '\n}\n\nOn further debugging, I figured out that typically ap_core_output_filter is\ncalled 4 times for a request. The crash always happen in 4th invocation. It\nseems to me that it gets corrupted somewhere after the 3rd invocation (after it\nreturns from ap_core_output_filter) and before it enters into\nap_core_output_filter 4th time (when ap_lingering_close is in call stack). Also\nconn->keepalives was always set to 1.\n
44402	Basant Kumar Kukreja	1202947430000	With Ruediger patch, I still got the crash (#2). Here is the debug information :\n\nt@314 (l@314) terminated by signal SEGV (Segmentation Fault)\nCurrent function is apr_sockaddr_ip_get\n  104       *addr = apr_palloc(sockaddr->pool, sockaddr->addr_str_len);\n(dbx) where\ncurrent thread: t@314\n=>[1] apr_sockaddr_ip_get(addr = 0x1ebb4b0, sockaddr = (nil)), line 104 in\n'sockaddr.c'\n  [2] core_create_conn(ptrans = 0x1ebb3b8, server = 0x4c0200, csd = 0x1ebb728,\nid = 311, sbh = 0x1ebb458, alloc = 0x2128b58), line 3895 in 'core.c'\n  [3] ap_run_create_connection(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0x4602c3\n  [4] process_socket(p = 0x1ebb3b8, sock = 0x1ebb728, my_child_num = 0,\nmy_thread_num = 311, bucket_alloc = 0x2128b58), line 566 in 'worker.c'\n  [5] worker_thread(thd = 0x7195c8, dummy = 0x6e2310), line 923 in 'worker.c'\n  [6] dummy_worker(opaque = 0x7195c8), line 142 in 'thread.c'\n  [7] _thr_setup(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5d8f7\n  [8] _lwp_start(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5dba0\n(dbx) p *addr\n*addr = (nil)\n(dbx) up\nCurrent function is core_create_conn\n 3895       apr_sockaddr_ip_get(&c->local_ip, c->local_addr);\n(dbx) p *c\n*c = {\n    pool                  = 0x1ebb3b8\n    base_server           = (nil)\n    vhost_lookup_data     = (nil)\n    local_addr            = (nil)\n    remote_addr           = (nil)\n    remote_ip             = (nil)\n    remote_host           = (nil)\n    remote_logname        = (nil)\n    aborted               = 0\n    keepalive             = AP_CONN_UNKNOWN\n    double_reverse        = 0\n    keepalives            = 0\n    local_ip              = (nil)\n    local_host            = (nil)\n    id                    = 0\n    conn_config           = 0x1ebb508\n    notes                 = 0x1ebba48\n    input_filters         = (nil)\n    output_filters        = (nil)\n    sbh                   = 0x1ebb458\n    bucket_alloc          = (nil)\n    cs                    = (nil)\n    data_in_input_filters = 0\n}\n(dbx) dump\nalloc = 0x2128b58\nrv = 0\nptrans = 0x1ebb3b8\nserver = 0x4c0200\nsbh = 0x1ebb458\nc = 0x1ebb460\nid = 311\ncsd = 0x1ebb728\n(dbx) p csd\ncsd = 0x1ebb728\n(dbx) p *(struct apr_socket_t*) csd\n*((struct apr_socket_t *) csd) = {\n    pool                    = (nil)\n    socketdes               = 0\n    type                    = 0\n    protocol                = 0\n    local_addr              = (nil)\n    remote_addr             = (nil)\n    timeout                 = 0\n    local_port_unknown      = 0\n    local_interface_unknown = 0\n    remote_addr_unknown     = 0\n    options                 = 0\n    inherit                 = 0\n    userdata                = (nil)\n}\n \n
44402	Ruediger Pluem	1202991952000	I assume that the ptrans pool somehow gets corrupted. I guess it is used by two\nthreads in parallel which could lead to a corruption since pools as such are not\nthread safe. So I think a good starting point for further investigations would be \n\nap_queue_info_wait_for_idler in mpm/worker/fdqueue.c\n\nor the lines 731 - 740 in worker.c:\n\n            if (ptrans == NULL) {\n                /* we can't use a recycled transaction pool this time.\n                 * create a new transaction pool */\n                apr_allocator_t *allocator;\n\n                apr_allocator_create(&allocator);\n                apr_allocator_max_free_set(allocator, ap_max_mem_free);\n                apr_pool_create_ex(&ptrans, pconf, NULL, allocator);\n                apr_allocator_owner_set(allocator, ptrans);\n            }\n\n
44402	Basant Kumar Kukreja	1202998527000	Thanks Ruediger for your suggestion. I will try to explore based on your\nsuggestion.\n\nMeanwhile here is the 3rd type of crash (with your patch).\n\nt@13 (l@13) terminated by signal SEGV (Segmentation Fault)\nCurrent function is apr_pool_cleanup_kill\n 2045       c = p->cleanups;\n(dbx) where\ncurrent thread: t@13\n=>[1] apr_pool_cleanup_kill(p = 0xa0, data = 0x195b888, cleanup_fn =\n0xfffffd7fff223540 = &"libapr-1.so.0.2.11"sockets.c"socket_cleanup(void *sock)),\nline 2045 in 'apr_pools.c'\n  [2] apr_pool_cleanup_run(p = 0xa0, data = 0x195b888, cleanup_fn =\n0xfffffd7fff223540 = &"libapr-1.so.0.2.11"sockets.c"socket_cleanup(void *sock)),\nline 2088 in 'apr_pools.c'\n  [3] apr_socket_close(thesocket = 0x195b888), line 149 in 'sockets.c'\n  [4] ap_lingering_close(c = 0x17407f0), line 135 in 'connection.c'\n  [5] process_socket(p = 0x1740748, sock = 0x195b888, my_child_num = 1,\nmy_thread_num = 10, bucket_alloc = 0x195b728), line 569 in 'worker.c'\n  [6] worker_thread(thd = 0x52bb48, dummy = 0x4f3480), line 951 in 'worker.c'\n  [7] dummy_worker(opaque = 0x52bb48), line 142 in 'thread.c'\n  [8] _thr_setup(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5d8f7\n  [9] _lwp_start(0x0, 0x0, 0x0, 0x0, 0x0, 0x0), at 0xfffffd7ffef5dba0\n(dbx) up\nCurrent function is apr_pool_cleanup_run\n 2088       apr_pool_cleanup_kill(p, data, cleanup_fn);\n(dbx) up\nCurrent function is apr_socket_close\n  149       return apr_pool_cleanup_run(thesocket->pool, thesocket, socket_cleanup);\n(dbx) p *thesocket\n*thesocket = {\n    pool                    = 0xa0\n    socketdes               = 26588968\n    type                    = 0\n    protocol                = 26588928\n    local_addr              = 0x195b7e8\n    remote_addr             = 0x1741158\n    timeout                 = 24383832\n    local_port_unknown      = 4895848\n    local_interface_unknown = 0\n    remote_addr_unknown     = 0\n    options                 = 0\n    inherit                 = 0\n    userdata                = (nil)\n}\n(dbx) dump\nthesocket = 0x195b888\n(dbx) up\nCurrent function is ap_lingering_close\n  135           apr_socket_close(csd);\n(dbx) dump\ntimeup = 0\ndummybuf = ''\nc = 0x17407f0\nnbytes = 4294967296U\ncsd = 0x195b888\n(dbx) p *c\n*c = {\n    pool                  = 0x1740748\n    base_server           = 0x4c0300\n    vhost_lookup_data     = (nil)\n    local_addr            = 0x195b8d8\n    remote_addr           = 0x195ba18\n    remote_ip             = 0x1740f88 '192.168.22.2'\n    remote_host           = (nil)\n    remote_logname        = (nil)\n    aborted               = 0\n    keepalive             = AP_CONN_UNKNOWN\n    double_reverse        = 0\n    keepalives            = 0\n    local_ip              = 0x1740f78 '192.168.22.1'\n    local_host            = (nil)\n    id                    = 510\n    conn_config           = 0x1740898\n    notes                 = 0x1740dd8\n    input_filters         = 0x1740fa8\n    output_filters        = 0x1740fd0\n    sbh                   = 0x17407e8\n    bucket_alloc          = 0x195b728\n    cs                    = (nil)\n    data_in_input_filters = 0\n}\n(dbx) _arch_networkio.h"struct apr_socket_t*)csd                              <\n*((struct apr_socket_t *) csd) = {\n    pool                    = 0xa0\n    socketdes               = 26588968\n    type                    = 0\n    protocol                = 26588928\n    local_addr              = 0x195b7e8\n    remote_addr             = 0x1741158\n    timeout                 = 24383832\n    local_port_unknown      = 4895848\n    local_interface_unknown = 0\n    remote_addr_unknown     = 0\n    options                 = 0\n    inherit                 = 0\n    userdata                = (nil)\n}\n(dbx) etworkio.h"struct apr_socket_t*)csd->local_addr                         <\ndbx: can't find field 'local_addr' in '*(csd)'\n(dbx) p (("srclib/apr/include/arch/unix/apr_arch_networkio.h"struct apr_socke >\n((struct apr_socket_t *) csd)->local_addr = 0x195b7e8\n(dbx) p *(("srclib/apr/include/arch/unix/apr_arch_networkio.h"struct apr_sock >\n*((struct apr_socket_t *) csd)->local_addr = {\n    pool         = 0xa0\n    hostname     = 0x195b728 'H^Gt^A'\n    servname     = 0x195b700 ''\n    port         = 0\n    family       = 0\n    salen        = 24383744U\n    ipaddr_len   = 0\n    addr_str_len = 24383744\n    ipaddr_ptr   = 0xfffffd7fff2e8010\n    next         = (nil)\n    sa           = {\n        sin  = {\n            sin_family = 0\n            sin_port   = 0\n            sin_addr   = {\n                S_un = {\n                    S_un_b = {\n                        s_b1 = '/0'\n                        s_b2 = '/0'\n                        s_b3 = '/0'\n                        s_b4 = '/0'\n                    }\n                    S_un_w = {\n                        s_w1 = 0\n                        s_w2 = 0\n                    }\n                    S_addr = 0\n                }\n            }\n            sin_zero   = ''\n        }\n        sin6 = {\n            sin6_family   = 0\n            sin6_port     = 0\n            sin6_flowinfo = 0\n            sin6_addr     = {\n                _S6_un = {\n                    _S6_u8     = ''\n                    _S6_u32    = (0, 0, 4373928U, 0)\n                    __S6_align = 0\n                }\n            }\n            sin6_scope_id = 26588968U\n            __sin6_src_id = 0\n        }\n        sas  = {\n            ss_family = 0\n            _ss_pad1  = ''\n            _ss_align = 0.0\n            _ss_pad2  = 'xxB'\n        }\n    }\n}\n
44402	Ruediger Pluem	1203000260000	As you wrote Solaris on Sun I suppose you mean on SPARC. Have you checked if the\ncrashes happen with the same Solaris version on x86? Background of the question:\nap_queue_info_wait_for_idler uses atomics whose implementation depends on the\nhardware architecture. Non functional atomics could be a source for concurrency\nproblems under load.
44402	Ruediger Pluem	1203000943000	(In reply to comment #10)\n> As you wrote Solaris on Sun I suppose you mean on SPARC. Have you checked if the\n> crashes happen with the same Solaris version on x86? Background of the question:\n\nOops my fault: You already said that you are using x86. Nevertheless does the\nsame happen on SPARC with the same Solaris version or if you compile with \n--enable-nonportable-atomics=no ?\n
44402	Basant Kumar Kukreja	1203076132000	Thanks Ruediger for your pointer. It was really useful.\n\nRegarding the function : ap_queue_info_wait_for_idler (lines 188-196)\n188:        struct recycled_pool *first_pool = queue_info->recycled_pools;\n189:        if (first_pool == NULL) {\n190:            break;\n191:        }\n192:        if (apr_atomic_casptr((volatile\nvoid**)&(queue_info->recycled_pools), first_pool->next,\n193:                              first_pool) == first_pool) {\n194:            *recycled_pool = first_pool->pool;\n195:            break;\n196:        }\n\nI will represent queue_info->receycled_pools as qu->rp to make it make it\nshort.  Inside apr_atomic_casptr we acquire a mutex. So I will write 3 steps :\n1. Calcualte first_pool.\n2. Calculate first_pool->next and invoke apr_atomic_caspptr\n3. Acquire lock on qi->rp (inside apr_atomic_casptr)\n\nThere is a very clear race condition between the two statement (line 188 and\nline 193) and between step 2 & 3. Though I agree that\n&queue_info->recycled_pool is protected and it is atomically correct but the\nnext pointer (first_pool and first_pool->next) are not protected correctly.\nThere is a very clear race condition between the two. To prove my point, here\nis an example :\n\nSuppose at a particular moment recycled_pool pool list is \n1 --> 2 ---> 3 . Where 1,2,3 are the pool nodes. qi->rp = 1. Now consider the\nfollowing situation :\nThread 1 :\n    first_pool = 1;\n    first_pool->next = 2.\n    \nNow before step 3 is executed that is before we acquire a lock on qi->rp,\ncontext switch happens.\n\nThread 2 :\n    Thread 2 pops a node (1) from the list and hence list becomes 2->3.\n\nThread 3 :\n    Thread 3 pops another node (2) from the list and hence list becomes 3.\n\nThread 2 :\n    push the node back and now list becomes 1->3.\n\nThread 1:\n    first->pool->next = 2.  qi->rp is still 1.  Thread acquires a lock &1 and\natomically compare and swap with 2. It succeeded because qi->rp was 1 but\nqi->rp->next was not 3, it becomes 2 and hence queue becomes 2 (or 2-->3).\n        \nI believe, I can prove my point with a sample standalone application. So far I\nused a separate mutex and protected both qi->rp and qi->rp->next both.  I tried\nwith the attached patch. With this patch, I am able to run the stress for more\nthan 10 hour without any crash. Without this patch, crash used to happen in\nless than 30 minutes. Here is the patch which I tried :\n---------------------------------------------------------------------------\n\n--- orghttpd-2.2.6/server/mpm/worker/fdqueue.c\tWed Jul 25 06:13:49 2007\n+++ httpd-2.2.6/server/mpm/worker/fdqueue.c\tFri Feb 15 10:57:42 2008\n@@ -25,6 +25,7 @@\n struct fd_queue_info_t {\n     apr_uint32_t idlers;\n     apr_thread_mutex_t *idlers_mutex;\n+    apr_thread_mutex_t *queue_mutex;\n     apr_thread_cond_t *wait_for_idler;\n     int terminated;\n     int max_idlers;\n@@ -36,6 +37,7 @@\n     fd_queue_info_t *qi = data_;\n     apr_thread_cond_destroy(qi->wait_for_idler);\n     apr_thread_mutex_destroy(qi->idlers_mutex);\n+    apr_thread_mutex_destroy(qi->queue_mutex);\n \n     /* Clean up any pools in the recycled list */\n     for (;;) {\n@@ -65,6 +67,11 @@\n     if (rv != APR_SUCCESS) {\n         return rv;\n     }\n+    rv = apr_thread_mutex_create(&qi->queue_mutex, APR_THREAD_MUTEX_DEFAULT,\n+                                 pool);\n+    if (rv != APR_SUCCESS) {\n+        return rv;\n+    }\n     rv = apr_thread_cond_create(&qi->wait_for_idler, pool);\n     if (rv != APR_SUCCESS) {\n         return rv;\n@@ -93,14 +100,14 @@\n         new_recycle = (struct recycled_pool *)apr_palloc(pool_to_recycle,\n                                                          sizeof(*new_recycle));\n         new_recycle->pool = pool_to_recycle;\n-        for (;;) {\n-            new_recycle->next = queue_info->recycled_pools;\n-            if (apr_atomic_casptr((volatile void**)&(queue_info->recycled_pools),\n-                                  new_recycle, new_recycle->next) ==\n-                new_recycle->next) {\n-                break;\n-            }\n-        }\n+        rv = apr_thread_mutex_lock(queue_info->queue_mutex);\n+        if (rv != APR_SUCCESS)\n+            return rv;\n+        new_recycle->next = queue_info->recycled_pools;\n+        queue_info->recycled_pools = new_recycle;\n+        rv = apr_thread_mutex_unlock(queue_info->queue_mutex);\n+        if (rv != APR_SUCCESS)\n+            return rv;\n     }\n \n     /* Atomically increment the count of idle workers */\n@@ -182,19 +189,18 @@\n \n     /* Atomically decrement the idle worker count */\n     apr_atomic_dec32(&(queue_info->idlers));\n-\n-    /* Atomically pop a pool from the recycled list */\n-    for (;;) {\n+    rv = apr_thread_mutex_lock(queue_info->queue_mutex);\n+    if (rv != APR_SUCCESS)\n+        return rv;\n+    if (queue_info->recycled_pools) {\n         struct recycled_pool *first_pool = queue_info->recycled_pools;\n-        if (first_pool == NULL) {\n-            break;\n-        }\n-        if (apr_atomic_casptr((volatile void**)&(queue_info->recycled_pools),\nfirst_pool->next,\n-                              first_pool) == first_pool) {\n-            *recycled_pool = first_pool->pool;\n-            break;\n-        }\n+        queue_info->recycled_pools = first_pool->next;\n+        *recycled_pool = first_pool->pool;\n+        first_pool->next = NULL;\n     }\n+    rv = apr_thread_mutex_unlock(queue_info->queue_mutex);\n+    if (rv != APR_SUCCESS)\n+        return rv;\n \n     if (queue_info->terminated) {\n         return APR_EOF;\n---------------------------------------------------------------------------\n\nIf you agree that there is a clear race condition then to correct this, I have\nfollowing suggestion :\n(a) Use a dedicated pool for each worker thread, this will avoid any locking.\nIt will perform better but may require little more memory in those situations\nwhen worker threads are not fully used.\n(b) Use some other technique other than a recycled pool list which avoids race\nconditions.\n\nI am in favour of option (a) until some good idea for (b) comes to my mind.\nIf you agree with (a) then I can work and generate a patch.\n\nNote : Also I believe that the crash will happen in linux too. I never ran more\nthan 1 hour in linux. I will try that tonight.\n
44402	Ruediger Pluem	1203121503000	(In reply to comment #12)\n\n> If you agree that there is a clear race condition then to correct this, I have\n> following suggestion :\n> (a) Use a dedicated pool for each worker thread, this will avoid any locking.\n> It will perform better but may require little more memory in those situations\n> when worker threads are not fully used.\n> (b) Use some other technique other than a recycled pool list which avoids race\n> conditions.\n> \n> I am in favour of option (a) until some good idea for (b) comes to my mind.\n> If you agree with (a) then I can work and generate a patch.\n> \n> Note : Also I believe that the crash will happen in linux too. I never ran more\n> than 1 hour in linux. I will try that tonight.\n> \n\nThank you for your thorough investigation. I agree with you that we have the\ndescribed race conditions here. We have a similar race in the event MPM.\nNext steps:\n\n1. Bring your patch above into trunk. Currently I see no significant performance \n   loss over the current code as we are using a mutex there as well. We only\n   increase the time during which we lock the resource. I don't know right\n   now when I find the cycles to apply the patch to trunk, but if you could\n   attach a trunk version of your patch to this report it would be a big help.\n\n2. Move the further discussion regarding options a) or b) to \n   dev@httpd.apache.org and lets wait for its results to decide how to move \n   along and improve the situation here in the long run.\n \n
44402	Ruediger Pluem	1203171819000	I think I have to correct myself in two points.\n\n1. On APR trunk there are better implementations for apr_atomic_casptr which no \n   longer use a mutex, but native platform processor / OS features. So in \n   contrast to my first assumption there could be a performance degradation by\n   your patch on trunk, which would be bad.\n\n2. The race scenario you described cannot happen in this way, because it assumes\n   that multiple threads pop pools from the list in parallel. This is not the \n   case as only the listener thread does this. What happens in parallel are:\n\n   - Multiple pushes to the list\n   - (Multiple) pushes to the list and a pop\n\nOTOH I still believe that there is some kind of race scenario as your patch\nshowed that the error goes away if the locking / syncing is changed here.\nSo maybe its only a different scenario (that I haven't figured out so far) or\nthere is a bug in apr_atomic_casptr.\nDo the same crashes happen with trunk?\n   
44402	Basant Kumar Kukreja	1203334435000	Regarding the example given in comments # 12, I need to correct myself. I\nagree with you that the example is not valid for worker implementation because\nthere is single thread which pop the nodes and multiple threads which pushes\nthe node.  ( ap_queue_info_wait_for_idler is not thread safe but it is not\ncalled by multiple threads. It is only invoked by single listener_thread. )\n\nI could not yet think of any race condition in which single popping thread\nand several pushing thread cause recycle_pool list corruption.\n\nI am still working on it to find the real cause of the crashes.\n\n\n
44402	Basant Kumar Kukreja	1203618293000	Few more updates : \n* Probably these crashes also exist on Linux (64 bit). But I can't say for\nsure. I saw 3 crashes so far. Out of 3, I get core dump only once and stack\ntrace from that core dump didn't seem much sense to me so I can't say for sure\nthat the bug reproduces on Linux or not. (Linux is 64 bit Fedora 8 with 64 bit\napache). \n\nOn Solaris, I tried the following things :\n* Replaced apr_atomic_casptr with solaris's atomic_casptr. But the result\nremained the same. I still saw the crashes. This means that this may not\nbe the apr bug.\n* If I replace apr_atomic_casptr code but keep the for loop then  the crashes\ndisappear.\n---------------------------------- ap_queue_info_set_idle-------------\n            if (apr_atomic_casptr((volatile void**)&(queue_info->recycled_pools),\n                                  new_recycle, new_recycle->next) ==\n                new_recycle->next) {\n                break;\n            }\n---------------------------------- replace with -----------------------\n            rv = apr_thread_mutex_lock(queue_info->queue_mutex);\n            if (queue_info->recycled_pools == new_recycle->next) {\n                queue_info->recycled_pools = new_recycle;\n                success = 1;\n            }\n            rv = apr_thread_mutex_unlock(queue_info->queue_mutex);\n\n\n---------------------------------- ap_queue_info_wait_for_idler --------------\n        if (apr_atomic_casptr((volatile void**)&(queue_info->recycled_pools),\nfirst_pool->next,\n                              first_pool) == first_pool) {\n            *recycled_pool = first_pool->pool;\n            break;\n        }\n---------------------------------- replace with ---------------------------\n        rv = apr_thread_mutex_lock(queue_info->queue_mutex);\n        if (queue_info->recycled_pools == first_pool) {\n            queue_info->recycled_pools = next;\n            success = 1;\n        }\n        rv = apr_thread_mutex_unlock(queue_info->queue_mutex);\n----------------------------------\n
44402	Basant Kumar Kukreja	1203683297000	Created an attachment (id=21581)\nPatch for httpd-2.2.8\n\nEventually I figured out where is the real race condition.\n\nLines fdqueue.c:96-102 (in httpd-2.2.8)\n\tfor (;;) {\n\t    new_recycle->next = queue_info->recycled_pools;\n\t    if (apr_atomic_casptr((volatile\nvoid**)&(queue_info->recycled_pools),\n\t\t\t\t  new_recycle, new_recycle->next) ==\n\t\tnew_recycle->next) {\n\t\tbreak;\n\t    }\n\t}\n\nThe race condition is between return of apr_atomic_casptr and calculating\nnew_recycle->next.\n\nLet us write the look into three steps (qi->rp is queue_info->recycled_pools):\n1. Set new_recycle->next to qi->rp\n2. atomically compare and swap qi->rp with new_recycle if matches with\n    new_recycle->next.\n3. Calculate new_recycle->next again.\n4. Determine the call apr_atomic_casptr is successful based on the return value\nand\n   result of step 3.\n\nThe race condition is in between step2 and step3. If apr_atomic_casptr was\nsuccessful (it means it successfully swapped the value) and If there is a\ncontext switch between 2 and 3 then new_recycle->next can point to something\nelse and can also be corrupted. The result of which is that if condition will\nfail.\n\nI saved the new_recycle->next in a local variable and then used the local\nvariable as shown in the patch and the issue got resolved.\n\nHere is the example how new_recycle->next can be changed by a race condition :\nSuppose our list is 1-->2-->3, where 1,2,3 are list nodes. Now suppose worker\nthread 1 wants to add a node 4 to it's head. Here is how it goes :\n\n-----------------------------------------------------------\nWorker thread 1 :\n   new_recycle = 4;\n   qi->rp = 1;\n   new_recycle->next = 1;\n   apr_atomic_casptr successfully compare and swap it with qi->rp that means\n   qi->rp = 4; \n   (list now becomes 4-->1-->2-->3)\n\n   Now context switch happens :\n\nListener_thread : \n   qi->rp is 4 and hence it pops the node 4 and gives it to worker thread 2.\n   The list becomes 1-->2-->3.\n\n   Listener thread pops another node and give it worker thread 3 and now list\n   becomes 2-->3.\n\nWorker thread 2 :\n   Returns the node 4 into the list and list becomes 4-->2-->3.\n\nWorker thread 1 :\n   new_recycle->next now becomes 2 and it compares with 1 and hence\ncomparision fails.\n-----------------------------------------------------------\n\n   Real situations can be little different than what I described because before\n\nworker thread returns node 4 to the list, pool is cleared (line 897 of\nworker.c,\nin worker_thread function )\n\tapr_pool_clear(ptrans);\n\tlast_ptrans = ptrans;\n\nwhich means new_recycle->next will be corrupted and point to a deleted value.\n\nHow I figured out this is that if you put a assert statement like :\n\t    struct recycled_pool *next = queue_info->recycled_pools;\n\t    new_recycle->next = next;\n\t    if (apr_atomic_casptr((volatile\nvoid**)&(queue_info->recycled_pools),\n\t\t\t\t  new_recycle, new_recycle->next) == next) {\n\t\tap_assert(next == new_recycle->next);\n\t\tbreak;\n\t    }\nthen assertion fails under stress situations.\n\nThe bug also exist in event mpm too (server/mpm/experimental/event/fdqueue.c).\n\nRuediger, can you review the patch? The patch is against 2.2.8. Should I submit\n\npatch against trunk?\n
44402	Basant Kumar Kukreja	1203683669000	Since the crash happens on linux too so I am changing the summary.
44402	Basant Kumar Kukreja	1203684071000	Created an attachment (id=21582)\nRevised patch\n\nMade small correction in comments of patch.
44402	Nick Kew	1203689879000	Fixed in trunk in r630335.
44402	Ruediger Pluem	1203692431000	Great work Basant. Nick beat me to committing your patch, but in the meantime I\napplied your patch to the event MPM on trunk as well (r630348).
44402	Nick Kew	1203701712000	*** Bug 44474 has been marked as a duplicate of this bug. ***
44402	Ruediger Pluem	1204029474000	Backported to 2.2.x as r631362 (http://svn.apache.org/viewvc?rev=631362&view=rev).
44402	Nick Kew	1204126069000	*** Bug 42086 has been marked as a duplicate of this bug. ***
44511	Ruediger Pluem	1204268758000	Can you check if the following patch fixes your problem:\n\nIndex: modules/cache/cache_util.c\n===================================================================\n--- modules/cache/cache_util.c  (revision 632318)\n+++ modules/cache/cache_util.c  (working copy)\n@@ -235,6 +235,14 @@\n     cc_cresp = apr_table_get(h->resp_hdrs, 'Cache-Control');\n     expstr = apr_table_get(h->resp_hdrs, 'Expires');\n\n+    if (ap_cache_liststr(NULL, cc_cresp, 'no-cache', NULL)) {\n+        /*\n+         * The cached entity contained Cache-Control: no-cache, so treat as\n+         * stale causing revalidation\n+         */\n+        return 0;\n+    }\n+\n     if ((agestr = apr_table_get(h->resp_hdrs, 'Age'))) {\n         age_c = apr_atoi64(agestr);\n     }\n
44511	Ruediger Pluem	1204268893000	Created an attachment (id=21604)\nPatch against trunk\n\n
44511	Eric Suran	1204424001000	Hello Ruediger,\n\nYour patch works fine. Thank you.\nRegards,\n\nEric
44511	Ruediger Pluem	1204432534000	Committed to trunk as r632749 (http://svn.apache.org/viewvc?rev=632749&view=rev).
44699	Takashi Sato	1206658017000	>Each style/lang/(lang).xml defines nativename with their own charset.\n\nThis is not true. For example, style/lang/es.xml defines nativename as Espa&#241;ol.\n
44699	Andr?? Malo	1206710877000	The input charset is not relevant anyway.\n\nThis looks like a bug in IE 7 for me. It doesn't seem to translate the characters correctly to unicode (or fails to select the correct font). For example, the title looks fine in firefox 2 /linux (German locale).
44699	Takashi Sato	1206723936000	(In reply to comment #2)\n> This looks like a bug in IE 7 for me. It doesn't seem to translate the\n> characters correctly to unicode (or fails to select the correct font). For\n> example, the title looks fine in firefox 2 /linux (German locale).\n\nNo, this is not an IE bug. Charset of Japanese HTMLs is EUC-JP, but Japanese HTMLs contain ISO-8859-1. I opens them with many text editor, and they are garbled.\nFirefox actually shows it correctly. I think Firefox has special handler for EUC-JP-ISO-8859-1-mixed text.\n\nI checked Korean file, and found that it contains numeric character references.\n\n<a href='./es/install.html' hreflang='es' rel='alternate' title='Espa&#241;ol'>&nbsp;es&nbsp;</a> |\n<a href='./fr/install.html' hreflang='fr' rel='alternate' title='Fran&#231;ais'>&nbsp;fr&nbsp;</a> |\n\nWhy do XSLT processors convert numeric character references to raw data for Japanese HTML files?\nI don't have deep knowledge about XML and XSLT...
44699	Takashi Sato	1207119540000	Created an attachment (id=21768)\nmake Japanese HTML UTF-8 against trunk\n\nJapanese character and alphabets with diacritic cannot live together in EUC-JP.\n
44699	Andr?? Malo	1207123375000	You're right. I'm sure, I saw HTML character references somewhere in ja files. So it seems to be actually java problem then.\n\nI'm gonna take the ja.xml part of your patch, run "build.sh bootstrap" and move the files around.\n\nThanks for your care.
44699	Andr?? Malo	1207132038000	trunk is already synced to the live server, the other branches are coming soon.
